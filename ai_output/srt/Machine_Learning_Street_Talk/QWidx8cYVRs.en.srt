1
00:00:00,160 --> 00:00:03,679
In the past 10 years, I think the

2
00:00:02,159 --> 00:00:06,000
question about the intelligence or

3
00:00:03,679 --> 00:00:08,480
artificial intelligence has uh captured

4
00:00:06,000 --> 00:00:10,400
people's imagination. Uh I'm one of

5
00:00:08,480 --> 00:00:13,440
them, but it took me about 10 years try

6
00:00:10,400 --> 00:00:16,080
to really understand uh can we actually

7
00:00:13,440 --> 00:00:18,800
make understanding intelligence a truly

8
00:00:16,080 --> 00:00:21,279
scientific or mathematical problem to

9
00:00:18,800 --> 00:00:24,720
formalize it. You probably will get some

10
00:00:21,279 --> 00:00:27,039
of my opinion and also the the facts

11
00:00:24,720 --> 00:00:29,279
about it and probably will change your

12
00:00:27,039 --> 00:00:31,760
view what is intelligence is which is

13
00:00:29,279 --> 00:00:34,719
also a very so certain process for me.

14
00:00:31,760 --> 00:00:36,640
How do we clarify uh some

15
00:00:34,719 --> 00:00:38,000
misunderstandings the common

16
00:00:36,640 --> 00:00:40,800
misunderstandings about the

17
00:00:38,000 --> 00:00:43,040
intelligence? Through this journey uh

18
00:00:40,800 --> 00:00:45,520
maybe we'll gain a entirely new view

19
00:00:43,040 --> 00:00:47,280
about what we really have done right in

20
00:00:45,520 --> 00:00:49,840
the past 10 years. The practice of

21
00:00:47,280 --> 00:00:52,559
artificial intelligence the mechanism we

22
00:00:49,840 --> 00:00:54,719
have implemented the all the mechanism

23
00:00:52,559 --> 00:00:57,440
behind all the large models deep

24
00:00:54,719 --> 00:01:01,120
networks and the large models are truly

25
00:00:57,440 --> 00:01:04,479
are and uh the true natures and uh hence

26
00:01:01,120 --> 00:01:07,439
understand their limitations and also

27
00:01:04,479 --> 00:01:10,799
what it takes to truly build a system

28
00:01:07,439 --> 00:01:12,799
that has intelligent behaviors or

29
00:01:10,799 --> 00:01:15,040
capabilities. I think we have reached

30
00:01:12,799 --> 00:01:17,840
the point right we'll be able to address

31
00:01:15,040 --> 00:01:20,080
what's the next for understanding even

32
00:01:17,840 --> 00:01:21,280
more advanced form of intelligence

33
00:01:20,080 --> 00:01:23,759
what's the difference between

34
00:01:21,280 --> 00:01:27,360
compression and abstraction difference

35
00:01:23,759 --> 00:01:29,520
between memorization and understanding I

36
00:01:27,360 --> 00:01:34,320
think of future those are the big open

37
00:01:29,520 --> 00:01:37,600
problems for all of us to study

38
00:01:34,320 --> 00:01:39,759
MLST is supported by cyber fund link in

39
00:01:37,600 --> 00:01:42,240
the description

40
00:01:39,759 --> 00:01:44,320
>> the idea of having to traffic and

41
00:01:42,240 --> 00:01:47,439
squishy people in order to make our

42
00:01:44,320 --> 00:01:48,479
systems go is not immediately appealing.

43
00:01:47,439 --> 00:01:51,200
Let's put it that way.

44
00:01:48,479 --> 00:01:53,840
>> This episode is sponsored by Prolific.

45
00:01:51,200 --> 00:01:56,720
>> Let's get few quality examples in. Let's

46
00:01:53,840 --> 00:01:59,040
get the right humans in to get the right

47
00:01:56,720 --> 00:02:01,040
quality of human feedback in. So, so

48
00:01:59,040 --> 00:02:02,240
we're trying to make human data or human

49
00:02:01,040 --> 00:02:03,920
feedback. We treat it as an

50
00:02:02,240 --> 00:02:06,159
infrastructure problem. We try to make

51
00:02:03,920 --> 00:02:07,920
it accessible. We make it cheaper. We

52
00:02:06,159 --> 00:02:10,160
effectively democratize access to this

53
00:02:07,920 --> 00:02:12,720
data. Professor Ma, it's amazing to have

54
00:02:10,160 --> 00:02:14,720
you on MLST. Welcome.

55
00:02:12,720 --> 00:02:16,720
>> Thank you for having me.

56
00:02:14,720 --> 00:02:18,720
>> So, normally I ask guests to introduce

57
00:02:16,720 --> 00:02:20,160
themselves, but given your your stature

58
00:02:18,720 --> 00:02:21,760
in the field, I think it's best that

59
00:02:20,160 --> 00:02:24,959
that that I give you an introduction.

60
00:02:21,760 --> 00:02:26,879
So, um, Yimar is a worldleading expert

61
00:02:24,959 --> 00:02:29,120
in deep learning and artificial

62
00:02:26,879 --> 00:02:31,200
intelligence. He's the inaugural

63
00:02:29,120 --> 00:02:34,000
director of the school of computing and

64
00:02:31,200 --> 00:02:36,000
data science at Hong Kong University and

65
00:02:34,000 --> 00:02:38,879
director of the Institute of Data

66
00:02:36,000 --> 00:02:41,120
Science at the University of Hong Kong.

67
00:02:38,879 --> 00:02:43,280
He's also a visiting professor at UC

68
00:02:41,120 --> 00:02:45,519
Berkeley where he previously served as a

69
00:02:43,280 --> 00:02:48,160
full professor in electrical engineering

70
00:02:45,519 --> 00:02:51,840
and computer science. He's an ITE E

71
00:02:48,160 --> 00:02:54,239
fellow, ACM fellow and CM fellow whose

72
00:02:51,840 --> 00:02:56,000
pioneering work on sparse representation

73
00:02:54,239 --> 00:02:57,920
and low rank structures has

74
00:02:56,000 --> 00:03:00,400
fundamentally shaped modern computer

75
00:02:57,920 --> 00:03:02,560
vision and machine learning. His

76
00:03:00,400 --> 00:03:05,120
recently published book learning deep

77
00:03:02,560 --> 00:03:07,360
representations of data distributions

78
00:03:05,120 --> 00:03:10,080
proposes a mathematical theory of

79
00:03:07,360 --> 00:03:12,959
intelligence built on two principles

80
00:03:10,080 --> 00:03:15,040
pasimony and self-consistency.

81
00:03:12,959 --> 00:03:17,040
This framework has led to whitebox

82
00:03:15,040 --> 00:03:19,120
transformers known as crate

83
00:03:17,040 --> 00:03:21,760
architectures where every component can

84
00:03:19,120 --> 00:03:24,800
be derived from first principles rather

85
00:03:21,760 --> 00:03:26,959
than empirical guesswork. So um

86
00:03:24,800 --> 00:03:29,760
professor mah tell me about your book.

87
00:03:26,959 --> 00:03:31,440
>> You know about you know uh eight or

88
00:03:29,760 --> 00:03:33,840
seven years ago you know you know deep

89
00:03:31,440 --> 00:03:37,200
networks uh deep learning has been

90
00:03:33,840 --> 00:03:39,040
pretty you know changed the practice of

91
00:03:37,200 --> 00:03:42,799
machine learning or artificial

92
00:03:39,040 --> 00:03:45,519
intelligence uh in the past decade. Um

93
00:03:42,799 --> 00:03:48,480
about uh eight years ago I had a chance

94
00:03:45,519 --> 00:03:51,680
to get back to Berkeley and um gave me a

95
00:03:48,480 --> 00:03:53,840
chance to look into this uh topics more

96
00:03:51,680 --> 00:03:57,200
deeply try to understand it from more

97
00:03:53,840 --> 00:03:59,840
principled approach and hence uh the

98
00:03:57,200 --> 00:04:02,159
book is kind of a summarizing the kind

99
00:03:59,840 --> 00:04:05,040
of progress we made in the past uh you

100
00:04:02,159 --> 00:04:07,360
know eight or beyond years myself my

101
00:04:05,040 --> 00:04:09,840
group as well as many colleagues uh

102
00:04:07,360 --> 00:04:14,319
trying to understand uh the principles

103
00:04:09,840 --> 00:04:17,280
behind Um the deep networks explained it

104
00:04:14,319 --> 00:04:21,120
uh from our first principle and uh in

105
00:04:17,280 --> 00:04:24,320
that journey we also seems to embark on

106
00:04:21,120 --> 00:04:26,479
um a little bit beyond that uh find uh

107
00:04:24,320 --> 00:04:29,040
something probably more general behind

108
00:04:26,479 --> 00:04:32,560
that is the uh the intelligence at a

109
00:04:29,040 --> 00:04:35,360
certain level of intelligence and hence

110
00:04:32,560 --> 00:04:38,560
um when I get back to joined Hong Kong U

111
00:04:35,360 --> 00:04:41,680
about two years ago had a chance to

112
00:04:38,560 --> 00:04:44,320
design or redesign some of uh curriculum

113
00:04:41,680 --> 00:04:46,880
to reflect those uh some of the progress

114
00:04:44,320 --> 00:04:49,759
updates in our field, the rapid progress

115
00:04:46,880 --> 00:04:51,440
in our field. Um so my students and

116
00:04:49,759 --> 00:04:55,120
colleagues decided that maybe it's time

117
00:04:51,440 --> 00:04:56,880
to uh systematic organize uh this body

118
00:04:55,120 --> 00:04:59,919
of knowledge

119
00:04:56,880 --> 00:05:02,160
and uh reflect as a as a textbook as

120
00:04:59,919 --> 00:05:05,520
well as a new course uh which I'm

121
00:05:02,160 --> 00:05:07,280
teaching this semester and uh likely

122
00:05:05,520 --> 00:05:10,240
will be offered as well at Berkeley next

123
00:05:07,280 --> 00:05:13,199
semester. So this is actually a first

124
00:05:10,240 --> 00:05:16,400
time probably we try to uh provide a

125
00:05:13,199 --> 00:05:20,000
more principle approach to explain the

126
00:05:16,400 --> 00:05:21,919
the deep networks um as well as some

127
00:05:20,000 --> 00:05:24,160
principle of uh intelligence

128
00:05:21,919 --> 00:05:25,919
>> and these principles are panimony and

129
00:05:24,160 --> 00:05:27,759
self-consistency.

130
00:05:25,919 --> 00:05:30,160
So it's it's an ambitious idea that

131
00:05:27,759 --> 00:05:32,960
these principles could explain natural

132
00:05:30,160 --> 00:05:33,759
and artificial intelligence. What do you

133
00:05:32,960 --> 00:05:37,360
mean by that?

134
00:05:33,759 --> 00:05:40,080
>> Intelligence artificial or natural uh or

135
00:05:37,360 --> 00:05:42,000
whatever uh adjectives you add to

136
00:05:40,080 --> 00:05:44,479
intelligence uh we have to be very

137
00:05:42,000 --> 00:05:46,240
specific. It's a very loaded world,

138
00:05:44,479 --> 00:05:49,919
right? I mean, even intelligence

139
00:05:46,240 --> 00:05:53,600
itselfves may have different levels um

140
00:05:49,919 --> 00:05:57,919
different um stages, right? So, it's

141
00:05:53,600 --> 00:06:00,479
high time we clarify that concept

142
00:05:57,919 --> 00:06:02,880
scientifically or mathematically, right?

143
00:06:00,479 --> 00:06:06,240
Um then so that we'll be able to talk

144
00:06:02,880 --> 00:06:09,759
about uh study intelligence the

145
00:06:06,240 --> 00:06:11,520
mechanism behind it at each level. uh

146
00:06:09,759 --> 00:06:13,440
there are some more unified principle

147
00:06:11,520 --> 00:06:15,039
behind even different stages of

148
00:06:13,440 --> 00:06:18,000
intelligence there's there's something

149
00:06:15,039 --> 00:06:21,120
in common there also s are different so

150
00:06:18,000 --> 00:06:22,880
it's high time we we we do that one of

151
00:06:21,120 --> 00:06:26,400
the intelligence at the level is that

152
00:06:22,880 --> 00:06:29,199
common to animals are human right human

153
00:06:26,400 --> 00:06:31,520
we are animals that int level of

154
00:06:29,199 --> 00:06:35,840
intelligence is what we think are very

155
00:06:31,520 --> 00:06:38,080
common to all life which is how memory

156
00:06:35,840 --> 00:06:41,759
how we learn knowledges about the

157
00:06:38,080 --> 00:06:44,960
external world and then memorize as part

158
00:06:41,759 --> 00:06:46,800
of our memory and use that to predict to

159
00:06:44,960 --> 00:06:48,400
react to the world help us make

160
00:06:46,800 --> 00:06:50,160
decisions predict and make better

161
00:06:48,400 --> 00:06:52,560
decisions with for survival and so on so

162
00:06:50,160 --> 00:06:54,560
forth that's very very common and this

163
00:06:52,560 --> 00:06:56,880
is the level of intelligence we're

164
00:06:54,560 --> 00:07:00,479
talking about very much for the book as

165
00:06:56,880 --> 00:07:03,919
well right and um hence for this level

166
00:07:00,479 --> 00:07:05,759
of intelligence uh how our memory works

167
00:07:03,919 --> 00:07:09,360
uh today we also have a fancy word for

168
00:07:05,759 --> 00:07:11,280
memory we call it a world model Okay. Um

169
00:07:09,360 --> 00:07:13,599
and it's how this how we develop such a

170
00:07:11,280 --> 00:07:16,479
memory such a world model and how the

171
00:07:13,599 --> 00:07:18,240
model gets evolved and uh how we use it

172
00:07:16,479 --> 00:07:21,360
that's actually this is the level of we

173
00:07:18,240 --> 00:07:23,599
talk. So we actually believe that uh for

174
00:07:21,360 --> 00:07:26,560
this level of intelligence for how our

175
00:07:23,599 --> 00:07:28,240
memory formed and how they work is

176
00:07:26,560 --> 00:07:31,520
precisely the two principles are

177
00:07:28,240 --> 00:07:34,960
incredibly important. um and we believe

178
00:07:31,520 --> 00:07:37,680
they're necessary uh is that

179
00:07:34,960 --> 00:07:39,599
me memory or knowledge is precisely try

180
00:07:37,680 --> 00:07:43,120
to discover what's predictable about the

181
00:07:39,599 --> 00:07:46,960
world. Hence um for all understand all

182
00:07:43,120 --> 00:07:48,880
such information are have intrinsically

183
00:07:46,960 --> 00:07:53,039
very low degree of freedom. we call the

184
00:07:48,880 --> 00:07:55,360
lowdimensional structures and uh hence

185
00:07:53,039 --> 00:07:57,919
the way to pursue such knowledge is

186
00:07:55,360 --> 00:08:00,400
precisely through uh trying to find the

187
00:07:57,919 --> 00:08:03,199
most simple representation of the data

188
00:08:00,400 --> 00:08:05,199
and uh hence compression denoising

189
00:08:03,199 --> 00:08:07,599
dimension reduction is actually all just

190
00:08:05,199 --> 00:08:10,240
different words to pursue such knowledge

191
00:08:07,599 --> 00:08:13,280
such structure and hence that's the word

192
00:08:10,240 --> 00:08:16,080
captured by the word parimony

193
00:08:13,280 --> 00:08:18,319
finding you know explain making things

194
00:08:16,080 --> 00:08:21,520
as simple as possible but not any

195
00:08:18,319 --> 00:08:23,520
simpler right um so this is Einstein

196
00:08:21,520 --> 00:08:25,120
says this word uh this the sentence

197
00:08:23,520 --> 00:08:26,319
Einstein used to describe science

198
00:08:25,120 --> 00:08:28,000
actually this is also what the

199
00:08:26,319 --> 00:08:30,720
intelligence at least at this level is

200
00:08:28,000 --> 00:08:33,839
precisely doing the same thing um the

201
00:08:30,720 --> 00:08:37,760
second part of the sentence not any

202
00:08:33,839 --> 00:08:40,159
simpler precisely says consistent

203
00:08:37,760 --> 00:08:43,760
consistency make sure your memory is

204
00:08:40,159 --> 00:08:47,360
actually consistent with be able to um

205
00:08:43,760 --> 00:08:49,360
recreate simulate the world just right

206
00:08:47,360 --> 00:08:53,600
um not any similar. If you're simpler,

207
00:08:49,360 --> 00:08:56,959
you may lose part of the um the uh

208
00:08:53,600 --> 00:08:58,959
predictivity uh predictivity uh and also

209
00:08:56,959 --> 00:09:00,720
ability to predict it well. And so

210
00:08:58,959 --> 00:09:03,040
that's actually the those two actually

211
00:09:00,720 --> 00:09:04,880
uh coexist we believe and those are two

212
00:09:03,040 --> 00:09:07,200
principles parsimmony and the

213
00:09:04,880 --> 00:09:10,080
consistency or subconsistency are

214
00:09:07,200 --> 00:09:14,080
actually the two characteristic about

215
00:09:10,080 --> 00:09:16,160
how our memory works. So we want to have

216
00:09:14,080 --> 00:09:19,279
understanding which carves the world up

217
00:09:16,160 --> 00:09:21,839
by the joints which represents the

218
00:09:19,279 --> 00:09:25,120
important invariances in the world and

219
00:09:21,839 --> 00:09:28,640
the thesis is I think that compression

220
00:09:25,120 --> 00:09:31,680
might be necessary for understanding. My

221
00:09:28,640 --> 00:09:34,320
possible concern with that is that what

222
00:09:31,680 --> 00:09:37,600
we are doing with machine learning is

223
00:09:34,320 --> 00:09:39,120
representing extent examples of a long

224
00:09:37,600 --> 00:09:40,720
phoggenetic

225
00:09:39,120 --> 00:09:43,680
tree of evolution. Mhm.

226
00:09:40,720 --> 00:09:46,800
>> So to what extent does knowing their

227
00:09:43,680 --> 00:09:49,200
representation now help us? Do we also

228
00:09:46,800 --> 00:09:51,040
need to know how they evolved and where

229
00:09:49,200 --> 00:09:55,839
they might go in the future?

230
00:09:51,040 --> 00:09:59,440
>> The the process to acquire knowledge

231
00:09:55,839 --> 00:10:01,839
to gain information about our side world

232
00:09:59,440 --> 00:10:04,160
that's a

233
00:10:01,839 --> 00:10:05,839
compression. Uh find what is

234
00:10:04,160 --> 00:10:08,160
compressible,

235
00:10:05,839 --> 00:10:10,800
what has orders, what phenomena has

236
00:10:08,160 --> 00:10:14,560
orders. uh has low dimension structures

237
00:10:10,800 --> 00:10:17,760
that allow us to predict to rule out uh

238
00:10:14,560 --> 00:10:20,399
variabilities to predict world uh

239
00:10:17,760 --> 00:10:23,279
tomorrows or predict world better in

240
00:10:20,399 --> 00:10:26,560
that sense. Um so in a sense that uh

241
00:10:23,279 --> 00:10:29,120
that is ability we uh believe is really

242
00:10:26,560 --> 00:10:31,600
what intelligence is all about uh at

243
00:10:29,120 --> 00:10:33,360
least the the common intelligence we're

244
00:10:31,600 --> 00:10:35,519
talking about right we can talk about

245
00:10:33,360 --> 00:10:38,640
the more higher level intelligence later

246
00:10:35,519 --> 00:10:43,839
uh um and if you look at the the history

247
00:10:38,640 --> 00:10:47,680
of life how life was developed um um so

248
00:10:43,839 --> 00:10:49,120
we actually come up to believe right uh

249
00:10:47,680 --> 00:10:51,279
uh you know you know the the the

250
00:10:49,120 --> 00:10:53,519
mechanism that we laws that governs the

251
00:10:51,279 --> 00:10:55,519
physical law world we call the physics

252
00:10:53,519 --> 00:10:57,200
right but what is the mechanism governs

253
00:10:55,519 --> 00:11:00,399
the evolution of life I think it's

254
00:10:57,200 --> 00:11:03,839
intelligence right even the process you

255
00:11:00,399 --> 00:11:07,920
mentioned that uh through evolution and

256
00:11:03,839 --> 00:11:09,360
um life evolves um precisely they they

257
00:11:07,920 --> 00:11:12,000
learn more and more knowledge about the

258
00:11:09,360 --> 00:11:15,279
world and they encode them through DNA

259
00:11:12,000 --> 00:11:18,720
to pass it on to next generation and

260
00:11:15,279 --> 00:11:21,120
that is a compressing that's a that's a

261
00:11:18,720 --> 00:11:23,120
process to compress logic

262
00:11:21,120 --> 00:11:26,240
that learned about the world through our

263
00:11:23,120 --> 00:11:29,440
DNAs. But the the the the mechanism to

264
00:11:26,240 --> 00:11:32,640
update it is actually very brutal, very

265
00:11:29,440 --> 00:11:35,279
brutal force and um through you know

266
00:11:32,640 --> 00:11:39,519
random mutation and the natural

267
00:11:35,279 --> 00:11:44,160
selection. Yes, it does evolve. It does

268
00:11:39,519 --> 00:11:47,600
advance but at a huge cost of resource

269
00:11:44,160 --> 00:11:50,880
time and also very unpredictable

270
00:11:47,600 --> 00:11:52,800
which if you if you're acute you

271
00:11:50,880 --> 00:11:56,560
probably observe there's some similarity

272
00:11:52,800 --> 00:11:59,920
with how current big model evolves right

273
00:11:56,560 --> 00:12:04,160
um many many groups try uh without

274
00:11:59,920 --> 00:12:07,279
principle try and error empirical and um

275
00:12:04,160 --> 00:12:09,760
the lucky one survive and gets advocated

276
00:12:07,279 --> 00:12:12,959
uh you everywhere and become very very

277
00:12:09,760 --> 00:12:14,800
popular right dominate the practice so

278
00:12:12,959 --> 00:12:16,720
so in a sense that you can make the

279
00:12:14,800 --> 00:12:18,959
allergy right I think to the people you

280
00:12:16,720 --> 00:12:22,480
know students ask me at which stage our

281
00:12:18,959 --> 00:12:26,000
artificial intelligence uh is at today

282
00:12:22,480 --> 00:12:28,320
um then there's already a allergy in in

283
00:12:26,000 --> 00:12:32,560
nature right we are very much at the

284
00:12:28,320 --> 00:12:34,480
early stage of the life form right and

285
00:12:32,560 --> 00:12:36,000
so hence that is a compression process

286
00:12:34,480 --> 00:12:37,839
that's a process that also gain

287
00:12:36,000 --> 00:12:40,160
knowledge about the world But of course

288
00:12:37,839 --> 00:12:42,639
later on we develop uh individual

289
00:12:40,160 --> 00:12:46,000
animals to develop the brain develop you

290
00:12:42,639 --> 00:12:48,480
know neural systems develop uh senses

291
00:12:46,000 --> 00:12:50,800
including visual and touch and so on. So

292
00:12:48,480 --> 00:12:54,399
we actually you start to use a very very

293
00:12:50,800 --> 00:12:57,600
different mechanism to learn to compress

294
00:12:54,399 --> 00:13:01,519
our observations to learn knowledge and

295
00:12:57,600 --> 00:13:03,440
to build memories of world and even

296
00:13:01,519 --> 00:13:05,440
individuals start to have that ability

297
00:13:03,440 --> 00:13:08,560
rather than just inherit knowledge from

298
00:13:05,440 --> 00:13:11,440
their DNAs. So that's a different stages

299
00:13:08,560 --> 00:13:13,200
uh about uh and then that part of the

300
00:13:11,440 --> 00:13:15,760
knowledge is not no longer encoded in

301
00:13:13,200 --> 00:13:17,519
our genetics in our genes but also in

302
00:13:15,760 --> 00:13:20,399
our brains.

303
00:13:17,519 --> 00:13:22,240
Um and that's actually that's actually a

304
00:13:20,399 --> 00:13:24,000
level of intelligence we talk about most

305
00:13:22,240 --> 00:13:26,880
of the time these days you know which is

306
00:13:24,000 --> 00:13:29,920
common to animals which is common to to

307
00:13:26,880 --> 00:13:31,519
humans and the le the knowledge the or

308
00:13:29,920 --> 00:13:34,000
the intelligence we talk about what

309
00:13:31,519 --> 00:13:35,839
brain functions. Yeah, I mean I I think

310
00:13:34,000 --> 00:13:39,200
we would definitely agree with the

311
00:13:35,839 --> 00:13:42,000
statement that intelligence as a system

312
00:13:39,200 --> 00:13:44,639
produces artifacts. So Shallay's example

313
00:13:42,000 --> 00:13:46,880
is a road building network. It produces

314
00:13:44,639 --> 00:13:48,320
roads and the system has adaptivity

315
00:13:46,880 --> 00:13:49,839
because it can create new roots where

316
00:13:48,320 --> 00:13:52,240
they weren't there before.

317
00:13:49,839 --> 00:13:54,480
>> And then there's the question of well

318
00:13:52,240 --> 00:13:56,959
there are many ways to compress a thing.

319
00:13:54,480 --> 00:13:58,639
>> So some ways of compression represent

320
00:13:56,959 --> 00:14:01,120
the world at a deep abstract level and

321
00:13:58,639 --> 00:14:03,279
some don't. So we might argue that LLMs

322
00:14:01,120 --> 00:14:05,120
today even though they do compress the

323
00:14:03,279 --> 00:14:07,120
data they only compress it in a

324
00:14:05,120 --> 00:14:09,120
superficially semantic way.

325
00:14:07,120 --> 00:14:10,959
>> And then there's this notion of well

326
00:14:09,120 --> 00:14:13,199
maybe we agree that intelligence is

327
00:14:10,959 --> 00:14:15,040
about the synthesis of new knowledge. So

328
00:14:13,199 --> 00:14:16,959
it's the acquisition of new knowledge

329
00:14:15,040 --> 00:14:19,760
but we can only do that if the knowledge

330
00:14:16,959 --> 00:14:22,000
we already have represents the world at

331
00:14:19,760 --> 00:14:24,320
a deep abstract level. So rather than it

332
00:14:22,000 --> 00:14:26,560
being random mutations in evolution,

333
00:14:24,320 --> 00:14:29,440
it's very very structured because the

334
00:14:26,560 --> 00:14:31,519
processes are physically instantiated

335
00:14:29,440 --> 00:14:33,839
which means rather than just doing

336
00:14:31,519 --> 00:14:35,839
something completely random, it's guided

337
00:14:33,839 --> 00:14:37,760
by the process which created the

338
00:14:35,839 --> 00:14:41,040
manifold hypothesis comes to mind which

339
00:14:37,760 --> 00:14:43,440
is this idea that all natural data falls

340
00:14:41,040 --> 00:14:45,199
on some lowdimensional you know

341
00:14:43,440 --> 00:14:47,120
structure you know with a low intrinsic

342
00:14:45,199 --> 00:14:49,120
dimension. And the other thing that

343
00:14:47,120 --> 00:14:51,199
springs to mind is I mean I'm a fan of

344
00:14:49,120 --> 00:14:54,399
geometric deep learning which is this

345
00:14:51,199 --> 00:14:57,040
idea of you know we should imbue

346
00:14:54,399 --> 00:14:59,839
inductive prior in the system which

347
00:14:57,040 --> 00:15:02,000
represent symmetries and and geometric

348
00:14:59,839 --> 00:15:03,839
structures in in the world and and I

349
00:15:02,000 --> 00:15:06,000
think as a principle that's deeply

350
00:15:03,839 --> 00:15:10,079
embedded in in this idea.

351
00:15:06,000 --> 00:15:12,240
>> Exactly. Um if if you look at my my

352
00:15:10,079 --> 00:15:14,720
whole life I have written four books

353
00:15:12,240 --> 00:15:17,440
right. uh my early interest is studying

354
00:15:14,720 --> 00:15:21,519
is computer vision um and the first book

355
00:15:17,440 --> 00:15:24,240
is vision and from that work I study

356
00:15:21,519 --> 00:15:25,760
multiview geometry from that work I in

357
00:15:24,240 --> 00:15:27,440
my whole book the the all the four book

358
00:15:25,760 --> 00:15:30,320
is actually about the one theme I

359
00:15:27,440 --> 00:15:33,199
realized that it's about structure in

360
00:15:30,320 --> 00:15:35,760
the data especially all reflected know

361
00:15:33,199 --> 00:15:38,720
them the first book of sweet division um

362
00:15:35,760 --> 00:15:42,959
the last chapter I realized precisely

363
00:15:38,720 --> 00:15:46,240
about what importance the symmetry plays

364
00:15:42,959 --> 00:15:50,399
in our perception right and we perceive

365
00:15:46,240 --> 00:15:53,600
object we naturally has a so human being

366
00:15:50,399 --> 00:15:55,680
we remember our vision

367
00:15:53,600 --> 00:15:57,279
we only recognize a long time ago right

368
00:15:55,680 --> 00:16:01,040
these days people oh it's about the

369
00:15:57,279 --> 00:16:02,880
vision is about recre 3D absolutely not

370
00:16:01,040 --> 00:16:05,120
right all the people says we just

371
00:16:02,880 --> 00:16:09,759
multiple images we create a whole point

372
00:16:05,120 --> 00:16:12,000
clouds mesh sign distance function lurf

373
00:16:09,759 --> 00:16:13,759
gion splatter right we We create a

374
00:16:12,000 --> 00:16:15,440
scene. See, I can see from multiple

375
00:16:13,759 --> 00:16:18,959
angles.

376
00:16:15,440 --> 00:16:21,920
Is this 3D understanding or you create

377
00:16:18,959 --> 00:16:26,800
some videos like Sora look at it looks

378
00:16:21,920 --> 00:16:29,680
good for you know absolutely not. Right?

379
00:16:26,800 --> 00:16:32,399
This is not the representation

380
00:16:29,680 --> 00:16:35,040
or understanding of a world model.

381
00:16:32,399 --> 00:16:38,000
Right? Our understanding is far beyond

382
00:16:35,040 --> 00:16:40,000
getting a whole bunch of you know point

383
00:16:38,000 --> 00:16:41,680
clouds or goshes better we can view from

384
00:16:40,000 --> 00:16:43,759
different angles.

385
00:16:41,680 --> 00:16:46,000
Right? Have you noticed that when we see

386
00:16:43,759 --> 00:16:48,639
something, we get excited because we

387
00:16:46,000 --> 00:16:51,040
understand the 3D, we understand the

388
00:16:48,639 --> 00:16:54,000
content, we parse it already in our

389
00:16:51,040 --> 00:16:56,000
brain, but the machine has no idea what

390
00:16:54,000 --> 00:16:58,720
the heck is in there. Okay, it's just a

391
00:16:56,000 --> 00:17:01,279
bunch of point clouds. It's a depth map.

392
00:16:58,720 --> 00:17:03,199
Okay, we when we see this change angle,

393
00:17:01,279 --> 00:17:04,480
we saw 3D. We already automatically

394
00:17:03,199 --> 00:17:07,439
recognize this is a hand, this is a

395
00:17:04,480 --> 00:17:09,919
body, this is a cup, this is a this is

396
00:17:07,439 --> 00:17:12,240
apple, right? We do that. We fill in

397
00:17:09,919 --> 00:17:14,079
that information with our brain. We

398
00:17:12,240 --> 00:17:16,640
think machine once they can recruit the

399
00:17:14,079 --> 00:17:18,959
3D they all understand that this is

400
00:17:16,640 --> 00:17:21,280
completely wrong. Okay. Many many work

401
00:17:18,959 --> 00:17:22,799
they say we're building 3D model by

402
00:17:21,280 --> 00:17:25,199
creating something for people to look

403
00:17:22,799 --> 00:17:27,600
at. That's complete out of purpose. So

404
00:17:25,199 --> 00:17:30,000
look at our vision. Our vision model

405
00:17:27,600 --> 00:17:32,400
right we have hypoc campus we have our

406
00:17:30,000 --> 00:17:35,280
ID code is highly structured. We

407
00:17:32,400 --> 00:17:38,400
understand the relationships

408
00:17:35,280 --> 00:17:42,000
between our view ccentric, object

409
00:17:38,400 --> 00:17:43,840
ccentric and aloscentric reputation.

410
00:17:42,000 --> 00:17:45,919
Right? Neuroscientists understand this

411
00:17:43,840 --> 00:17:47,679
very very well. Right? Scientists

412
00:17:45,919 --> 00:17:49,600
understand this very well but not

413
00:17:47,679 --> 00:17:52,559
computer scientists. Right? Not computer

414
00:17:49,600 --> 00:17:54,160
vision scientist. Um some do. See for

415
00:17:52,559 --> 00:17:55,919
example I give you example right in

416
00:17:54,160 --> 00:17:57,440
order to do spatial now we actually did

417
00:17:55,919 --> 00:18:00,240
a test with you on the corner about a

418
00:17:57,440 --> 00:18:03,360
year ago. Test all the you know top

419
00:18:00,240 --> 00:18:07,280
multi-model models you know huge models

420
00:18:03,360 --> 00:18:09,679
GPT you know that uh GMI right to do

421
00:18:07,280 --> 00:18:13,760
very simple test the the title of the

422
00:18:09,679 --> 00:18:15,760
work called a eyes wide shot right

423
00:18:13,760 --> 00:18:17,679
and it's a very simple test just test

424
00:18:15,760 --> 00:18:20,080
the given images for the those language

425
00:18:17,679 --> 00:18:22,400
model or a big model multimodel highly

426
00:18:20,080 --> 00:18:24,160
trained highly commercialized models

427
00:18:22,400 --> 00:18:26,240
that do they understand the reasoning

428
00:18:24,160 --> 00:18:28,160
spatial reasoning what is on the left of

429
00:18:26,240 --> 00:18:30,640
something

430
00:18:28,160 --> 00:18:32,400
how many objects there is in space right

431
00:18:30,640 --> 00:18:34,799
what is beh behind something, what's on

432
00:18:32,400 --> 00:18:37,200
top of something very simple spatial.

433
00:18:34,799 --> 00:18:40,000
The question requires a little bit, not

434
00:18:37,200 --> 00:18:43,360
even very deep spatial understanding.

435
00:18:40,000 --> 00:18:45,919
But all the models fails miserably and

436
00:18:43,360 --> 00:18:48,400
the majority of them actually even worse

437
00:18:45,919 --> 00:18:51,760
than random guess right only I think

438
00:18:48,400 --> 00:18:54,160
only Gemini and uh GPD uh is a little

439
00:18:51,760 --> 00:18:56,400
bit above human a little bit about the

440
00:18:54,160 --> 00:18:58,080
random guess far below human

441
00:18:56,400 --> 00:19:00,640
understanding. Right? So that's that's

442
00:18:58,080 --> 00:19:02,640
the status right if you do those meaning

443
00:19:00,640 --> 00:19:05,280
that you know those act 3D understanding

444
00:19:02,640 --> 00:19:08,480
is very very difficult but human we do

445
00:19:05,280 --> 00:19:10,640
this effortlessly right so I can easily

446
00:19:08,480 --> 00:19:13,600
point to you right please hand me the

447
00:19:10,640 --> 00:19:16,160
the the bottle to your left if you want

448
00:19:13,600 --> 00:19:19,280
to find let's say a shopping center

449
00:19:16,160 --> 00:19:21,600
right say go through the door turn right

450
00:19:19,280 --> 00:19:25,600
go to the once you get outside of the

451
00:19:21,600 --> 00:19:28,000
building um head south right so through

452
00:19:25,600 --> 00:19:30,320
this this Remember just through this

453
00:19:28,000 --> 00:19:34,960
simple sentence

454
00:19:30,320 --> 00:19:38,400
already we switch from viewcentric to

455
00:19:34,960 --> 00:19:41,039
object centric to alocentric right so

456
00:19:38,400 --> 00:19:43,440
our bra if we don't have this kind of

457
00:19:41,039 --> 00:19:47,120
model this kind of highly structured 3D

458
00:19:43,440 --> 00:19:49,679
models forget about you know people talk

459
00:19:47,120 --> 00:19:51,520
about embodied AI or world model right

460
00:19:49,679 --> 00:19:53,679
we cannot conduct this very simple

461
00:19:51,520 --> 00:19:56,400
spatial references

462
00:19:53,679 --> 00:19:58,480
interacting we have this world model is

463
00:19:56,400 --> 00:20:02,160
not to visualize.

464
00:19:58,480 --> 00:20:05,039
We build a 3D model to interact, to

465
00:20:02,160 --> 00:20:06,960
manipulate, to influence,

466
00:20:05,039 --> 00:20:08,720
right? We're not building a 3D model

467
00:20:06,960 --> 00:20:10,160
just to, oh, this looks like I can

468
00:20:08,720 --> 00:20:11,600
change my view, look at it from this

469
00:20:10,160 --> 00:20:13,840
view or that view, right? Just

470
00:20:11,600 --> 00:20:15,440
visualize. No, turn 360 degree to

471
00:20:13,840 --> 00:20:18,160
visualize. No, we don't do that. That's

472
00:20:15,440 --> 00:20:20,000
not our purpose. Okay. Unfortunately,

473
00:20:18,160 --> 00:20:21,919
but there, you know, it gets distracted

474
00:20:20,000 --> 00:20:25,280
for that kind of uh visualization. It

475
00:20:21,919 --> 00:20:28,320
looks cool but uh almost to to to us if

476
00:20:25,280 --> 00:20:30,960
you really work on robotics uh for all

477
00:20:28,320 --> 00:20:33,600
kind you know navigation local motion

478
00:20:30,960 --> 00:20:35,679
manipulation they're actually pretty uh

479
00:20:33,600 --> 00:20:37,440
the usage is pretty limited. I won't

480
00:20:35,679 --> 00:20:39,679
necessarily say they're useless but they

481
00:20:37,440 --> 00:20:41,200
are actually pretty limited.

482
00:20:39,679 --> 00:20:42,400
We should introduce the coding rate

483
00:20:41,200 --> 00:20:44,720
formula. I did have a question about

484
00:20:42,400 --> 00:20:46,320
that which is there is a there's an

485
00:20:44,720 --> 00:20:48,400
epsilon on there. So there there's a bit

486
00:20:46,320 --> 00:20:50,240
of a question of how how do we tune that

487
00:20:48,400 --> 00:20:51,360
and and what does that mean? We should

488
00:20:50,240 --> 00:20:53,039
also bring we've been talking about this

489
00:20:51,360 --> 00:20:55,200
a little bit this um this concept of an

490
00:20:53,039 --> 00:20:58,400
LDR so a linear um discriminative

491
00:20:55,200 --> 00:21:00,400
representation and just more broadly

492
00:20:58,400 --> 00:21:02,400
with these inductive prior there's

493
00:21:00,400 --> 00:21:05,919
always the question of when we do

494
00:21:02,400 --> 00:21:07,760
abstraction to model regularities in the

495
00:21:05,919 --> 00:21:09,600
universe there's always a little bit

496
00:21:07,760 --> 00:21:11,520
left over isn't there so to to what

497
00:21:09,600 --> 00:21:12,320
extent can we think of these things as

498
00:21:11,520 --> 00:21:13,840
natural

499
00:21:12,320 --> 00:21:15,440
>> actually you touch upon about the deep

500
00:21:13,840 --> 00:21:18,720
stone you touch upon a very very deep

501
00:21:15,440 --> 00:21:21,280
question uh we actually uh it actually

502
00:21:18,720 --> 00:21:23,440
took me almost 30 years to understand it

503
00:21:21,280 --> 00:21:25,760
to be honest right we did mention that

504
00:21:23,440 --> 00:21:27,840
early on when we do try to differentiate

505
00:21:25,760 --> 00:21:30,799
different measure different volumes it

506
00:21:27,840 --> 00:21:33,760
turns out lossy coding is necessary it's

507
00:21:30,799 --> 00:21:35,120
not just something that uh is something

508
00:21:33,760 --> 00:21:39,679
hacky it's actually turns out to be

509
00:21:35,120 --> 00:21:41,440
necessary and to do lossy coding in fact

510
00:21:39,679 --> 00:21:43,440
we recently we start to realize that

511
00:21:41,440 --> 00:21:46,559
noise actually be you know plays very

512
00:21:43,440 --> 00:21:48,799
different roles and uh yet it's very

513
00:21:46,559 --> 00:21:50,720
confounded very confusing to many people

514
00:21:48,799 --> 00:21:52,320
Even um this is something actually my

515
00:21:50,720 --> 00:21:54,480
students will see to realize we actually

516
00:21:52,320 --> 00:21:56,400
probably will have some papers about it.

517
00:21:54,480 --> 00:21:58,000
I can elucidate this a little bit. If

518
00:21:56,400 --> 00:21:59,440
you think about the whole diffusion den

519
00:21:58,000 --> 00:22:02,159
noiseis and model right people very

520
00:21:59,440 --> 00:22:05,120
popular right now to do um why do we add

521
00:22:02,159 --> 00:22:06,640
noise to data right and to the whole

522
00:22:05,120 --> 00:22:09,520
world because we don't know where the

523
00:22:06,640 --> 00:22:13,520
distribution is right so there is a

524
00:22:09,520 --> 00:22:16,880
phrase everybody knows all roads to Rome

525
00:22:13,520 --> 00:22:19,760
right so why is that has anyone give a

526
00:22:16,880 --> 00:22:22,320
thought to why all roads to Rome

527
00:22:19,760 --> 00:22:24,640
because very simple at some point in

528
00:22:22,320 --> 00:22:27,760
history Rome builds the road to reach

529
00:22:24,640 --> 00:22:29,919
the whole Oh, right. That's a diffusion

530
00:22:27,760 --> 00:22:31,919
process.

531
00:22:29,919 --> 00:22:33,440
Then if you want to know Rome, then you

532
00:22:31,919 --> 00:22:36,080
do the den noise. You follow the same

533
00:22:33,440 --> 00:22:37,919
way back you get to where the no room

534
00:22:36,080 --> 00:22:39,280
is. So that's the no dimensional

535
00:22:37,919 --> 00:22:43,280
structure. That's where the knowledge

536
00:22:39,280 --> 00:22:45,280
is, right? That's the osis is right. So

537
00:22:43,280 --> 00:22:48,320
hence it's a very natural process that

538
00:22:45,280 --> 00:22:51,200
we add noise is adding noise to the is

539
00:22:48,320 --> 00:22:53,760
precisely we building roads and the

540
00:22:51,200 --> 00:22:57,760
noising brings us back remember where we

541
00:22:53,760 --> 00:23:00,880
come from and so on and that's a big

542
00:22:57,760 --> 00:23:03,520
slope we have to add noise to reach the

543
00:23:00,880 --> 00:23:05,679
whole earth there's another actually

544
00:23:03,520 --> 00:23:09,039
there's another noise

545
00:23:05,679 --> 00:23:12,720
right remember we only have isolated

546
00:23:09,039 --> 00:23:15,200
sample even we talk about manifolds

547
00:23:12,720 --> 00:23:16,480
Right? But how many points you have on

548
00:23:15,200 --> 00:23:19,760
the manifes? How many points you

549
00:23:16,480 --> 00:23:24,120
observe? They're always finite. Right?

550
00:23:19,760 --> 00:23:24,120
But why do you call it a continum?

551
00:23:24,640 --> 00:23:31,280
Why do you collect dots as lines,

552
00:23:27,120 --> 00:23:34,000
planes, surfaces? When do you do that?

553
00:23:31,280 --> 00:23:35,919
Hence, noise plays another role within

554
00:23:34,000 --> 00:23:37,440
the manifold. Even you have finite

555
00:23:35,919 --> 00:23:40,159
samples,

556
00:23:37,440 --> 00:23:42,720
if you allow lossy coding, if you allow

557
00:23:40,159 --> 00:23:44,559
packing spheres in that things start to

558
00:23:42,720 --> 00:23:46,159
connect. You start to connect. Noise is

559
00:23:44,559 --> 00:23:48,640
very important to help to connect the

560
00:23:46,159 --> 00:23:52,559
dots, right? We all know the phenomena

561
00:23:48,640 --> 00:23:55,280
of percolation, right? We see raindrops

562
00:23:52,559 --> 00:23:57,120
on the floor. You only see two phases,

563
00:23:55,280 --> 00:23:59,919
right? One phase is all the dots are

564
00:23:57,120 --> 00:24:02,559
isolated. Another phase is all things

565
00:23:59,919 --> 00:24:04,720
gets wet. You never see anything into in

566
00:24:02,559 --> 00:24:07,360
the middle because there's a sharp face

567
00:24:04,720 --> 00:24:10,080
transition. Once the the the sphere once

568
00:24:07,360 --> 00:24:12,559
the dots the density gets high enough

569
00:24:10,080 --> 00:24:16,080
they collects everything. Right? Maybe

570
00:24:12,559 --> 00:24:19,440
that's a phase transition we reach we

571
00:24:16,080 --> 00:24:22,080
realizing a connected plane is a better

572
00:24:19,440 --> 00:24:25,360
solution to explain all the data more

573
00:24:22,080 --> 00:24:28,240
parsimmonious more economic.

574
00:24:25,360 --> 00:24:31,440
The cost to memorize all the dots versus

575
00:24:28,240 --> 00:24:33,760
memorize other plane start to switch.

576
00:24:31,440 --> 00:24:36,159
Maybe abstraction has something to do

577
00:24:33,760 --> 00:24:37,919
with that. I don't know. But from a

578
00:24:36,159 --> 00:24:40,640
compression point of view, this can

579
00:24:37,919 --> 00:24:44,880
already allow us to explain when do we

580
00:24:40,640 --> 00:24:47,440
go from zero dimension samples to prefer

581
00:24:44,880 --> 00:24:49,520
a low dimensional manifolds

582
00:24:47,440 --> 00:24:51,120
and also how go from that low

583
00:24:49,520 --> 00:24:53,360
dimensional manifold to reach the rest

584
00:24:51,120 --> 00:24:56,080
of the world. Right? So you can see even

585
00:24:53,360 --> 00:24:58,799
in this process noise is already playing

586
00:24:56,080 --> 00:25:00,960
this epsilon plays different roles and

587
00:24:58,799 --> 00:25:03,360
as at some point they gets collected

588
00:25:00,960 --> 00:25:05,520
right around the surface and that's we

589
00:25:03,360 --> 00:25:07,840
still try to figure out what happens but

590
00:25:05,520 --> 00:25:09,919
at this big two phases uh we already

591
00:25:07,840 --> 00:25:13,760
know right the role of epsilon actually

592
00:25:09,919 --> 00:25:16,080
plays different roles right um and I

593
00:25:13,760 --> 00:25:18,480
think the the definitely in the past

594
00:25:16,080 --> 00:25:21,760
many years uh our understanding about

595
00:25:18,480 --> 00:25:24,240
the subject how do we compress how do we

596
00:25:21,760 --> 00:25:27,600
uh pursue the lowdimensional structure

597
00:25:24,240 --> 00:25:29,440
from finite samples. It's a quite our

598
00:25:27,600 --> 00:25:32,240
understanding about this problem has

599
00:25:29,440 --> 00:25:33,679
truly advanced dramatically. I'm very

600
00:25:32,240 --> 00:25:35,120
happy honestly this is a question

601
00:25:33,679 --> 00:25:37,360
baffles me when I was a graduate

602
00:25:35,120 --> 00:25:38,960
students. uh you can see even my early

603
00:25:37,360 --> 00:25:41,279
work about the lossy coding lossy

604
00:25:38,960 --> 00:25:44,640
compression reflected my bafffulness

605
00:25:41,279 --> 00:25:46,320
about it and I'm really feel very uh

606
00:25:44,640 --> 00:25:48,400
thrilled that I recently start to

607
00:25:46,320 --> 00:25:51,360
understand those things in a more

608
00:25:48,400 --> 00:25:53,120
unified more not only theoretical way

609
00:25:51,360 --> 00:25:54,720
but also even algorithmic way

610
00:25:53,120 --> 00:25:56,159
>> yeah it's so fascinating that we can

611
00:25:54,720 --> 00:25:58,880
look out the window

612
00:25:56,159 --> 00:26:00,880
>> and we we ignore so much detail we don't

613
00:25:58,880 --> 00:26:02,559
look at the leaves on the roads we we

614
00:26:00,880 --> 00:26:04,080
just find that structure and that's why

615
00:26:02,559 --> 00:26:05,679
when I watched your presentation I was

616
00:26:04,080 --> 00:26:08,159
very intrigued when you said that

617
00:26:05,679 --> 00:26:10,640
denoising iterative denoising is is a

618
00:26:08,159 --> 00:26:14,159
form of of compression. I wanted to

619
00:26:10,640 --> 00:26:16,880
mention your ICML 2024 so last year it

620
00:26:14,159 --> 00:26:20,080
was in Vienna right with with Wang and

621
00:26:16,880 --> 00:26:22,799
you found that when you have loss

622
00:26:20,080 --> 00:26:24,320
surfaces using using this technique they

623
00:26:22,799 --> 00:26:25,919
are dramatically different they're very

624
00:26:24,320 --> 00:26:27,840
smooth there's no kind of harsh local

625
00:26:25,919 --> 00:26:28,720
minima and so on what's the intuition

626
00:26:27,840 --> 00:26:30,640
for that

627
00:26:28,720 --> 00:26:32,799
>> in fact the phenomena our understanding

628
00:26:30,640 --> 00:26:34,559
about those phenomena is actually going

629
00:26:32,799 --> 00:26:36,240
back when we early days we study

630
00:26:34,559 --> 00:26:38,159
sparsity

631
00:26:36,240 --> 00:26:41,039
um you know when your data lies on very

632
00:26:38,159 --> 00:26:43,120
low dimensional uh sparse surfaces uh

633
00:26:41,039 --> 00:26:46,080
planes right low dimensional planes also

634
00:26:43,120 --> 00:26:48,240
of the planes or low rank matrix right

635
00:26:46,080 --> 00:26:51,919
and in there we learned a very big

636
00:26:48,240 --> 00:26:54,640
lesson the object function to evaluate

637
00:26:51,919 --> 00:26:56,240
those sparity or low dimensionality uh

638
00:26:54,640 --> 00:26:58,320
those function are highly nonlinear

639
00:26:56,240 --> 00:27:01,039
nonconvex

640
00:26:58,320 --> 00:27:02,720
um but yet you know traditionally in our

641
00:27:01,039 --> 00:27:04,320
orthodox understanding about the l

642
00:27:02,720 --> 00:27:07,279
convex optimization is they're always

643
00:27:04,320 --> 00:27:10,559
hard right and the general class is n

644
00:27:07,279 --> 00:27:13,360
hard and there's a lot local spirus uh

645
00:27:10,559 --> 00:27:15,679
local minima you get stuck with local

646
00:27:13,360 --> 00:27:18,320
minima you there's some stagnant

647
00:27:15,679 --> 00:27:19,760
critical points flat surface so

648
00:27:18,320 --> 00:27:22,400
basically the worst picture is very

649
00:27:19,760 --> 00:27:24,559
worse right it's a nightmare

650
00:27:22,400 --> 00:27:26,159
uh but through the study of those low

651
00:27:24,559 --> 00:27:27,760
dimensional structure uh sparse

652
00:27:26,159 --> 00:27:29,520
structure and that's was actually

653
00:27:27,760 --> 00:27:30,880
featured in our my previous book right

654
00:27:29,520 --> 00:27:32,000
high dimensional a low dimensional

655
00:27:30,880 --> 00:27:35,919
structure of high dimensional data

656
00:27:32,000 --> 00:27:38,320
analysis we actually realized that if a

657
00:27:35,919 --> 00:27:40,080
lot of long convex problem even the

658
00:27:38,320 --> 00:27:42,720
optimization problem had long convex

659
00:27:40,080 --> 00:27:46,000
landscape. If those problem or if those

660
00:27:42,720 --> 00:27:49,840
measure arises from nature very natural

661
00:27:46,000 --> 00:27:56,000
resource those structure actually are

662
00:27:49,840 --> 00:27:59,120
very highly regular highly has symmetry

663
00:27:56,000 --> 00:28:00,720
the landscape actually are extremely

664
00:27:59,120 --> 00:28:03,520
benile

665
00:28:00,720 --> 00:28:06,000
right quite contrary to our common

666
00:28:03,520 --> 00:28:09,520
understanding about linear optimization

667
00:28:06,000 --> 00:28:12,080
at all right this is complete 180Â°ree uh

668
00:28:09,520 --> 00:28:13,840
flip of views In fact, even the higher

669
00:28:12,080 --> 00:28:15,279
dimension helps. The higher the

670
00:28:13,840 --> 00:28:17,600
dimension, the better. We call it the

671
00:28:15,279 --> 00:28:20,080
blessing of dimensionality. So those

672
00:28:17,600 --> 00:28:21,919
regularity, those symmetry will tell us

673
00:28:20,080 --> 00:28:25,760
the landscape of this object function

674
00:28:21,919 --> 00:28:27,600
are actually beautiful, right? And uh

675
00:28:25,760 --> 00:28:29,200
first of all, they're highly regular.

676
00:28:27,600 --> 00:28:33,120
There's no staging. There's no flat

677
00:28:29,200 --> 00:28:35,520
surface. There's no too many spirits

678
00:28:33,120 --> 00:28:37,520
local minima. And even the local minima,

679
00:28:35,520 --> 00:28:40,240
they already have very clear geometric

680
00:28:37,520 --> 00:28:44,000
or statistical meaning. And hence those

681
00:28:40,240 --> 00:28:46,480
landscape are very aminable for very

682
00:28:44,000 --> 00:28:49,279
simple algorithm to find the optimal

683
00:28:46,480 --> 00:28:52,559
solution such as graded descent which in

684
00:28:49,279 --> 00:28:55,120
almost indirectly explain why even we're

685
00:28:52,559 --> 00:28:57,760
doing even more than training neuronet

686
00:28:55,120 --> 00:28:59,840
networks and many more we're searching

687
00:28:57,760 --> 00:29:03,120
uh low dimensional distribution in very

688
00:28:59,840 --> 00:29:06,159
high dimension spaces but somehow greed

689
00:29:03,120 --> 00:29:08,080
always end up with somewhere nice. Okay.

690
00:29:06,159 --> 00:29:09,840
Yeah, fine. You can run a long time but

691
00:29:08,080 --> 00:29:13,039
somehow you always end up those land

692
00:29:09,840 --> 00:29:15,840
landscapes are not that hard to traverse

693
00:29:13,039 --> 00:29:18,480
traverse right. So it actually be

694
00:29:15,840 --> 00:29:21,919
precisely because those object function

695
00:29:18,480 --> 00:29:23,840
are highly regular. Hence now get back

696
00:29:21,919 --> 00:29:25,919
to the rate reduction object function

697
00:29:23,840 --> 00:29:28,880
right if you look at the object function

698
00:29:25,919 --> 00:29:32,080
it's not something arbitrary right it's

699
00:29:28,880 --> 00:29:34,960
counting the volume of the whole minus

700
00:29:32,080 --> 00:29:37,120
the parts right it's something extremely

701
00:29:34,960 --> 00:29:39,120
objective right it's not like a loss

702
00:29:37,120 --> 00:29:41,279
function people come up with randomly oh

703
00:29:39,120 --> 00:29:43,520
add this term weighted sum add different

704
00:29:41,279 --> 00:29:46,240
weights you know if you use this you

705
00:29:43,520 --> 00:29:49,679
know sort of a empirical penalty or

706
00:29:46,240 --> 00:29:52,559
empirical even some kind of ad hoc So

707
00:29:49,679 --> 00:29:55,360
all the terms are describing physical

708
00:29:52,559 --> 00:29:57,360
volumes of the data right. Hence you

709
00:29:55,360 --> 00:30:00,240
should expect those are the quantity

710
00:29:57,360 --> 00:30:02,159
arise in nature. Then from our lesson we

711
00:30:00,240 --> 00:30:04,320
realize indeed actually that actually

712
00:30:02,159 --> 00:30:07,440
those object function has very benile

713
00:30:04,320 --> 00:30:09,520
landscapes uh even the local minima not

714
00:30:07,440 --> 00:30:11,520
only the global minima corresponding

715
00:30:09,520 --> 00:30:14,720
solutions that are give you authoral

716
00:30:11,520 --> 00:30:16,799
subspaces even the local ones right

717
00:30:14,720 --> 00:30:19,279
there not the global optimal ones they

718
00:30:16,799 --> 00:30:22,799
have similar geometric structures right

719
00:30:19,279 --> 00:30:25,600
and there's no other weird

720
00:30:22,799 --> 00:30:27,760
critical points that will slow down the

721
00:30:25,600 --> 00:30:29,120
search for those minimas so that's

722
00:30:27,760 --> 00:30:31,760
actually quite interesting So you can

723
00:30:29,120 --> 00:30:34,880
see this this revelation allow us to

724
00:30:31,760 --> 00:30:38,640
understand right where maybe

725
00:30:34,880 --> 00:30:41,279
intelligence is precisely exploit and

726
00:30:38,640 --> 00:30:43,200
harnessing those things. So there is

727
00:30:41,279 --> 00:30:45,440
actually a misunderstanding about you

728
00:30:43,200 --> 00:30:47,840
know last 10 years when we understand

729
00:30:45,440 --> 00:30:49,840
intelligence more and more

730
00:30:47,840 --> 00:30:52,799
there is a very big misunderstanding

731
00:30:49,840 --> 00:30:55,039
about intelligence right in machine you

732
00:30:52,799 --> 00:30:57,760
you you you study you know maybe machine

733
00:30:55,039 --> 00:31:00,559
learning theory right we have a tendency

734
00:30:57,760 --> 00:31:03,200
to believe intelligence especially

735
00:31:00,559 --> 00:31:06,480
intelligence and nature is designed to

736
00:31:03,200 --> 00:31:10,080
solve the hardest problem the worst case

737
00:31:06,480 --> 00:31:12,880
I actually beg to differ intelligence is

738
00:31:10,080 --> 00:31:16,240
precise the ability to identify what is

739
00:31:12,880 --> 00:31:19,679
easy to address first, what is easy to

740
00:31:16,240 --> 00:31:23,039
learn, what is natural to learn first.

741
00:31:19,679 --> 00:31:25,679
Then only when that has been done and

742
00:31:23,039 --> 00:31:29,760
the resource permit, they start to get

743
00:31:25,679 --> 00:31:31,440
into more and more advanced tasks.

744
00:31:29,760 --> 00:31:34,960
Not everybody needs to learn advanced

745
00:31:31,440 --> 00:31:39,200
mathematics to supply animals don't.

746
00:31:34,960 --> 00:31:41,760
Right? Nature find what is the easiest

747
00:31:39,200 --> 00:31:45,200
things with minimal energy, minimal

748
00:31:41,760 --> 00:31:48,240
effort to learn the most logic so they

749
00:31:45,200 --> 00:31:51,200
survive the best. Right? Again this is

750
00:31:48,240 --> 00:31:53,039
the principle of parimony at play.

751
00:31:51,200 --> 00:31:56,640
There's another level of resource

752
00:31:53,039 --> 00:31:58,720
parimony at play here. Right? Hence once

753
00:31:56,640 --> 00:32:00,240
you realize this you realizing

754
00:31:58,720 --> 00:32:02,320
understanding intelligence should be

755
00:32:00,240 --> 00:32:04,480
really understand what's really most

756
00:32:02,320 --> 00:32:06,240
common.

757
00:32:04,480 --> 00:32:09,360
Right? the low dimensional structure

758
00:32:06,240 --> 00:32:11,600
most easy ones smooth ones benile

759
00:32:09,360 --> 00:32:15,039
distribution easy to get get away with a

760
00:32:11,600 --> 00:32:16,799
few samples fewer samples right uh and

761
00:32:15,039 --> 00:32:18,799
very easy to formulate in fact that's

762
00:32:16,799 --> 00:32:20,320
what how science progress you know a lot

763
00:32:18,799 --> 00:32:21,840
of the physical models you know Newton's

764
00:32:20,320 --> 00:32:23,760
law they're very simple they discover

765
00:32:21,840 --> 00:32:25,840
the simple ones then we reach gradually

766
00:32:23,760 --> 00:32:28,000
reach to general relativity and then to

767
00:32:25,840 --> 00:32:30,640
quantum mechanics those equation gets f

768
00:32:28,000 --> 00:32:33,039
more complicated later right so this is

769
00:32:30,640 --> 00:32:35,519
h the same process we identify what is

770
00:32:33,039 --> 00:32:38,480
the most common first right what is the

771
00:32:35,519 --> 00:32:40,399
most easiest task first hence we don't

772
00:32:38,480 --> 00:32:43,200
want to many of the machine learning

773
00:32:40,399 --> 00:32:46,480
theory try to tend to so derive a bonds

774
00:32:43,200 --> 00:32:48,720
for the worst cases I think that's we

775
00:32:46,480 --> 00:32:50,720
probably should think twice right

776
00:32:48,720 --> 00:32:52,880
>> I love that character characterization

777
00:32:50,720 --> 00:32:54,159
it's um similar to the least action

778
00:32:52,880 --> 00:32:56,559
principle in in physics

779
00:32:54,159 --> 00:32:58,880
>> exactly in in a sense we solve problems

780
00:32:56,559 --> 00:33:00,320
by taking many many steps in different

781
00:32:58,880 --> 00:33:01,760
directions I think we still leave a

782
00:33:00,320 --> 00:33:03,440
little bit of entropy open we don't do

783
00:33:01,760 --> 00:33:05,679
pure hill climbing but collect

784
00:33:03,440 --> 00:33:08,399
Collectively we acquire these stepping

785
00:33:05,679 --> 00:33:11,120
stones and the totality of that process

786
00:33:08,399 --> 00:33:13,120
as we solve very complex problems. But I

787
00:33:11,120 --> 00:33:16,080
wanted to touch on you raised a very

788
00:33:13,120 --> 00:33:18,080
interesting point which is um we notice

789
00:33:16,080 --> 00:33:21,120
that when we have very large deep

790
00:33:18,080 --> 00:33:24,480
learning models they tend to almost

791
00:33:21,120 --> 00:33:26,960
self-regularize and they they learn

792
00:33:24,480 --> 00:33:29,360
better and there's this phenomenon of

793
00:33:26,960 --> 00:33:31,039
double descent and and all of this. Tell

794
00:33:29,360 --> 00:33:33,039
me about that. Fascinating question

795
00:33:31,039 --> 00:33:36,640
actually you uh this question actually

796
00:33:33,039 --> 00:33:38,640
needs to um really u bring me back to

797
00:33:36,640 --> 00:33:41,120
early days when I try to understand deep

798
00:33:38,640 --> 00:33:43,039
learning um when deep aris there's a lot

799
00:33:41,120 --> 00:33:45,039
of phenomena we try to understand I'm

800
00:33:43,039 --> 00:33:47,360
I'm one of those right try to understand

801
00:33:45,039 --> 00:33:48,720
those phenomenas u you know some

802
00:33:47,360 --> 00:33:51,360
something there's some good about

803
00:33:48,720 --> 00:33:53,039
dropout something about the you know

804
00:33:51,360 --> 00:33:56,080
thresholding different thresholding

805
00:33:53,039 --> 00:33:58,720
there's something about uh normalization

806
00:33:56,080 --> 00:34:03,279
then also come to somehow the model are

807
00:33:58,720 --> 00:34:05,679
very big um and parameters a lot somehow

808
00:34:03,279 --> 00:34:08,079
the deep network course has uh do not

809
00:34:05,679 --> 00:34:10,560
have a tendency to overfit somehow they

810
00:34:08,079 --> 00:34:12,079
still generalize okay right and then of

811
00:34:10,560 --> 00:34:15,040
course people realize and there's a sort

812
00:34:12,079 --> 00:34:19,359
of a uh rather unlike the re you know

813
00:34:15,040 --> 00:34:21,440
the traditional classical bias um virus

814
00:34:19,359 --> 00:34:23,359
trade-off but there's tier double

815
00:34:21,440 --> 00:34:24,960
descent

816
00:34:23,359 --> 00:34:28,720
I actually wrote a couple papers about

817
00:34:24,960 --> 00:34:35,760
it and um about the normalization about

818
00:34:28,720 --> 00:34:37,679
around 2000 um or late uh uh 2019

819
00:34:35,760 --> 00:34:39,679
I I really told my student we should

820
00:34:37,679 --> 00:34:42,000
stop not to explain those isolated

821
00:34:39,679 --> 00:34:44,240
phenomena we only see we're like the

822
00:34:42,000 --> 00:34:46,000
blind mental elephants each one say a

823
00:34:44,240 --> 00:34:47,839
little piece each theory try to explain

824
00:34:46,000 --> 00:34:50,399
a little bit I think there should be a

825
00:34:47,839 --> 00:34:52,320
total total explanation to this if we

826
00:34:50,399 --> 00:34:55,839
get the big picture all those are just

827
00:34:52,320 --> 00:34:58,079
the consequences or implications of that

828
00:34:55,839 --> 00:35:01,359
suddenly you know at that time We start

829
00:34:58,079 --> 00:35:05,359
to touch upon the the the concept of

830
00:35:01,359 --> 00:35:08,079
maybe that the the proc of deep network

831
00:35:05,359 --> 00:35:10,320
are optimizing something

832
00:35:08,079 --> 00:35:12,720
the layer wise is realizing optim

833
00:35:10,320 --> 00:35:15,280
they're optimizing objective that

834
00:35:12,720 --> 00:35:17,920
promoting parimony promoting no

835
00:35:15,280 --> 00:35:20,640
dimensionality once we realize actually

836
00:35:17,920 --> 00:35:22,640
I was quite thrilled so then I told my

837
00:35:20,640 --> 00:35:25,520
student from now on we will no longer

838
00:35:22,640 --> 00:35:27,040
write any papers or about overfitting

839
00:35:25,520 --> 00:35:31,520
why

840
00:35:27,040 --> 00:35:35,839
Because if the neuronet networks is try

841
00:35:31,520 --> 00:35:38,480
to the operators try to compress try to

842
00:35:35,839 --> 00:35:40,800
realize certain contracting map

843
00:35:38,480 --> 00:35:43,920
compressed volume then you will never

844
00:35:40,800 --> 00:35:46,880
overfit right even I over parameterize

845
00:35:43,920 --> 00:35:49,280
it will never overfit simple example if

846
00:35:46,880 --> 00:35:51,359
I have data lies on a straight line a

847
00:35:49,280 --> 00:35:53,359
one-dimensional curve whatever I can

848
00:35:51,359 --> 00:35:55,440
embed this one dimensional line in a two

849
00:35:53,359 --> 00:35:59,200
dimension three dimension or a million

850
00:35:55,440 --> 00:36:01,599
dimension But if my operator is always

851
00:35:59,200 --> 00:36:04,400
layer-wise at each iteration, my

852
00:36:01,599 --> 00:36:07,119
operator is always just shrinking

853
00:36:04,400 --> 00:36:08,960
my solution towards the line in all

854
00:36:07,119 --> 00:36:10,960
directions.

855
00:36:08,960 --> 00:36:13,280
I would never lower it. Even I

856
00:36:10,960 --> 00:36:15,200
overparameterize embedded the line into

857
00:36:13,280 --> 00:36:17,520
a billions of dimension. I have a

858
00:36:15,200 --> 00:36:20,160
billions of parameter. But collectively

859
00:36:17,520 --> 00:36:22,480
all those billions of parameter are all

860
00:36:20,160 --> 00:36:24,640
shrinking my solution, pushing the

861
00:36:22,480 --> 00:36:26,320
solution, denoise it, compress it

862
00:36:24,640 --> 00:36:28,720
towards the line, right? like a power

863
00:36:26,320 --> 00:36:31,440
iteration just like a PCA right power

864
00:36:28,720 --> 00:36:33,760
iteration is in regardless of what the

865
00:36:31,440 --> 00:36:35,839
dimension embedded computing the first

866
00:36:33,760 --> 00:36:38,320
singular values right it's always

867
00:36:35,839 --> 00:36:41,520
powerful converge with the same speed

868
00:36:38,320 --> 00:36:43,440
you never over so compression by nature

869
00:36:41,520 --> 00:36:45,760
if the operator are performing

870
00:36:43,440 --> 00:36:48,480
compression or denoising which means

871
00:36:45,760 --> 00:36:51,200
this process will no longer overfit

872
00:36:48,480 --> 00:36:54,160
anything right if you conduct it right

873
00:36:51,200 --> 00:36:56,400
if you converge the solution will

874
00:36:54,160 --> 00:36:57,040
converge on the is the structure you

875
00:36:56,400 --> 00:36:58,800
desire for.

876
00:36:57,040 --> 00:37:01,119
>> That raises a natural question. We were

877
00:36:58,800 --> 00:37:03,200
interviewing Andrew Wilson from NYU and

878
00:37:01,119 --> 00:37:06,400
he's got this, you know, several papers

879
00:37:03,200 --> 00:37:08,800
about implicit biases where you kind of

880
00:37:06,400 --> 00:37:10,640
have a combination of, you know, hard

881
00:37:08,800 --> 00:37:12,800
biases of symmetries and and everything

882
00:37:10,640 --> 00:37:15,359
in in between. And if what you're saying

883
00:37:12,800 --> 00:37:17,280
is true, then why do we need inductive

884
00:37:15,359 --> 00:37:18,800
biases at all? Could we not pair back a

885
00:37:17,280 --> 00:37:19,599
little bit and just have really big

886
00:37:18,800 --> 00:37:21,040
models?

887
00:37:19,599 --> 00:37:23,280
>> No, I think see this is the thing,

888
00:37:21,040 --> 00:37:26,480
right? Exactly. So, this is the thing.

889
00:37:23,280 --> 00:37:28,079
Um um I was uh you know early on people

890
00:37:26,480 --> 00:37:30,800
don't understand deep networks and

891
00:37:28,079 --> 00:37:33,040
there's a lot of empirical uh trial and

892
00:37:30,800 --> 00:37:36,640
error people try to tends to use this

893
00:37:33,040 --> 00:37:39,200
the phrase inductive bias to either as

894
00:37:36,640 --> 00:37:41,839
some kind of magical sauce that either

895
00:37:39,200 --> 00:37:44,320
explain the failures or success of you

896
00:37:41,839 --> 00:37:46,400
do certain way to the neuronet networks

897
00:37:44,320 --> 00:37:48,160
design or how do you train the neuronet

898
00:37:46,400 --> 00:37:49,200
networks to be honest for for a long

899
00:37:48,160 --> 00:37:52,160
time I never understood what the

900
00:37:49,200 --> 00:37:53,760
inductive bias is um and maybe some

901
00:37:52,160 --> 00:37:56,320
regularization Some people is learning

902
00:37:53,760 --> 00:38:00,240
some structures about network about the

903
00:37:56,320 --> 00:38:02,079
data. Um but nowadays in my recent work

904
00:38:00,240 --> 00:38:05,200
I said that probably from at least from

905
00:38:02,079 --> 00:38:07,520
what I understand um all the inductive

906
00:38:05,200 --> 00:38:10,079
bias should be uh formulated as first

907
00:38:07,520 --> 00:38:12,720
principle right at least from we were

908
00:38:10,079 --> 00:38:14,079
able to for example deduce uh all the

909
00:38:12,720 --> 00:38:16,400
different network architectures

910
00:38:14,079 --> 00:38:20,160
including the recent white box crate or

911
00:38:16,400 --> 00:38:22,640
transformer-l like or redunet like uh

912
00:38:20,160 --> 00:38:24,960
reset like architecture or mixture of

913
00:38:22,640 --> 00:38:26,800
expert like architecture all from the

914
00:38:24,960 --> 00:38:29,280
only inductive bias

915
00:38:26,800 --> 00:38:32,400
is assuming your data distribution you

916
00:38:29,280 --> 00:38:35,280
are pursuing are low dimensional. Okay,

917
00:38:32,400 --> 00:38:38,560
you can already get the form the the

918
00:38:35,280 --> 00:38:41,520
main architecture or form of operator of

919
00:38:38,560 --> 00:38:43,440
for each layer as a red structure

920
00:38:41,520 --> 00:38:45,599
mixture of expert structure and and

921
00:38:43,440 --> 00:38:47,920
those operator per layer are precisely

922
00:38:45,599 --> 00:38:50,560
conducting denoising compression or

923
00:38:47,920 --> 00:38:53,200
contrasting. Are there additional

924
00:38:50,560 --> 00:38:55,680
assumption you can make? Yes, you can.

925
00:38:53,200 --> 00:38:58,640
For example, if I my job is not just to

926
00:38:55,680 --> 00:39:01,839
compress the data as it is. I also

927
00:38:58,640 --> 00:39:03,440
wanted to induce I wanted to for example

928
00:39:01,839 --> 00:39:06,640
in object recognition I also want to

929
00:39:03,440 --> 00:39:08,079
enforce make all data I want my

930
00:39:06,640 --> 00:39:10,560
classification to be translational

931
00:39:08,079 --> 00:39:14,800
environment which is symmetry right if

932
00:39:10,560 --> 00:39:17,520
you allow my task will be environ action

933
00:39:14,800 --> 00:39:19,839
I want to compress them together voila

934
00:39:17,520 --> 00:39:21,040
what do you get you can then you still

935
00:39:19,839 --> 00:39:24,000
through compression then you get a

936
00:39:21,040 --> 00:39:26,960
convolution naturally as the structure

937
00:39:24,000 --> 00:39:29,680
for the compression operator so

938
00:39:26,960 --> 00:39:33,119
convolution is not what we impose upon.

939
00:39:29,680 --> 00:39:35,440
is actually results from the first

940
00:39:33,119 --> 00:39:38,160
principle the the quote unquote

941
00:39:35,440 --> 00:39:40,320
inductive bias assume you want to

942
00:39:38,160 --> 00:39:42,400
compress your data also you want your

943
00:39:40,320 --> 00:39:44,800
compression to respect translation

944
00:39:42,400 --> 00:39:47,280
environment or rotation environments

945
00:39:44,800 --> 00:39:49,040
that's the result that is the

946
00:39:47,280 --> 00:39:52,640
characteristic of the compression

947
00:39:49,040 --> 00:39:56,240
operator for you to achieve that task

948
00:39:52,640 --> 00:39:58,640
right so there's a lot of um so we don't

949
00:39:56,240 --> 00:40:00,480
want to build in the the the inductive

950
00:39:58,640 --> 00:40:02,720
bus While we are searching for the

951
00:40:00,480 --> 00:40:05,760
solution, the inductive bias in my

952
00:40:02,720 --> 00:40:07,520
understanding is should be the very

953
00:40:05,760 --> 00:40:10,800
assumption we make in the very

954
00:40:07,520 --> 00:40:12,560
beginning. The rest should be deduction.

955
00:40:10,800 --> 00:40:15,599
The rest should have no induction

956
00:40:12,560 --> 00:40:19,119
anymore. Otherwise, we're doing trial

957
00:40:15,599 --> 00:40:21,440
and error, right? The inductive we so

958
00:40:19,119 --> 00:40:24,400
basically when we build the theory, we

959
00:40:21,440 --> 00:40:27,280
should have done all the inductive

960
00:40:24,400 --> 00:40:30,000
observations, experiment and assumptions

961
00:40:27,280 --> 00:40:34,000
already. The good theory should start

962
00:40:30,000 --> 00:40:37,119
with the very few inductive bias or

963
00:40:34,000 --> 00:40:39,520
assumptions or axioms then the rest

964
00:40:37,119 --> 00:40:41,200
should be deductive. I call that first

965
00:40:39,520 --> 00:40:44,000
principle. We've been speaking about

966
00:40:41,200 --> 00:40:47,040
pasimony which is what to learn and

967
00:40:44,000 --> 00:40:49,119
self-consistency is about how to learn

968
00:40:47,040 --> 00:40:52,320
and we can sketch out a journey I

969
00:40:49,119 --> 00:40:54,480
suppose from control theory to learning

970
00:40:52,320 --> 00:40:57,359
and and also this this methodology has

971
00:40:54,480 --> 00:40:59,200
some interesting um results I think

972
00:40:57,359 --> 00:41:00,960
around um you know the continual

973
00:40:59,200 --> 00:41:01,280
learning problem so let's sketch that

974
00:41:00,960 --> 00:41:04,000
out

975
00:41:01,280 --> 00:41:06,880
>> you can see right so the the compression

976
00:41:04,000 --> 00:41:09,200
um um or the the even the rate reduction

977
00:41:06,880 --> 00:41:11,599
to try to pursue the data distribution

978
00:41:09,200 --> 00:41:15,520
and also So transform it and that's the

979
00:41:11,599 --> 00:41:17,440
one way direction. there's almost

980
00:41:15,520 --> 00:41:20,480
there's no

981
00:41:17,440 --> 00:41:23,760
theoretical guarantee either your data

982
00:41:20,480 --> 00:41:25,200
is sufficient to identify that you know

983
00:41:23,760 --> 00:41:26,720
you may started with very very few

984
00:41:25,200 --> 00:41:28,880
samples there's no way the data is

985
00:41:26,720 --> 00:41:30,720
sufficient I mean may the apple there

986
00:41:28,880 --> 00:41:33,760
are five types maybe I only say four

987
00:41:30,720 --> 00:41:36,480
types right so and then but that process

988
00:41:33,760 --> 00:41:39,440
goes on you do compress what you have

989
00:41:36,480 --> 00:41:41,599
and the reach a memory right and there's

990
00:41:39,440 --> 00:41:44,240
no guarantee the even during that

991
00:41:41,599 --> 00:41:46,560
process you may not get stuck Maybe

992
00:41:44,240 --> 00:41:49,200
there's not enough iterations you may so

993
00:41:46,560 --> 00:41:52,640
memory you get may not be accurate may

994
00:41:49,200 --> 00:41:55,280
not be correct hence how do we check how

995
00:41:52,640 --> 00:41:57,440
do I further develop evolve improve my

996
00:41:55,280 --> 00:42:01,040
memory or make sure my memory actually

997
00:41:57,440 --> 00:42:04,400
be able to authentically predict this is

998
00:42:01,040 --> 00:42:06,640
a work model the model is accurate right

999
00:42:04,400 --> 00:42:08,160
so you actually have to decode it you

1000
00:42:06,640 --> 00:42:10,480
can think about the memory formation is

1001
00:42:08,160 --> 00:42:13,040
a encoding process then from my memory I

1002
00:42:10,480 --> 00:42:15,280
want to decode I want to predict what's

1003
00:42:13,040 --> 00:42:18,480
going to happen next second from what I

1004
00:42:15,280 --> 00:42:20,720
observe right now or at night I may want

1005
00:42:18,480 --> 00:42:22,319
to dream what happen right so that's

1006
00:42:20,720 --> 00:42:24,560
actually the decoding is actually allows

1007
00:42:22,319 --> 00:42:27,040
us to check if my memory serves to be

1008
00:42:24,560 --> 00:42:29,520
right right how accurate I can predict

1009
00:42:27,040 --> 00:42:33,280
next step so hence this actually already

1010
00:42:29,520 --> 00:42:36,160
form a sort of autoenccoding framework

1011
00:42:33,280 --> 00:42:38,720
now of course autoenccoding if I have

1012
00:42:36,160 --> 00:42:41,280
access to both the observation and my

1013
00:42:38,720 --> 00:42:44,400
memory just like our training our big

1014
00:42:41,280 --> 00:42:46,480
data models I have control on both ends.

1015
00:42:44,400 --> 00:42:48,160
I can just force auto encoding back end

1016
00:42:46,480 --> 00:42:52,800
to end, right? The people like to talk

1017
00:42:48,160 --> 00:42:55,119
about it. But in our natural um in a

1018
00:42:52,800 --> 00:42:57,119
natural setting, in animal human

1019
00:42:55,119 --> 00:42:59,920
setting, we don't have control on both

1020
00:42:57,119 --> 00:43:02,000
ends, right? We only have control

1021
00:42:59,920 --> 00:43:04,400
probably control of our own brain,

1022
00:43:02,000 --> 00:43:07,200
what's inside our brain, right? We never

1023
00:43:04,400 --> 00:43:09,520
really quite have access to measure if

1024
00:43:07,200 --> 00:43:11,839
my prediction of the 3D world for

1025
00:43:09,520 --> 00:43:14,720
example, right? the the the frame of the

1026
00:43:11,839 --> 00:43:16,800
picture is rectangular. Do I ever

1027
00:43:14,720 --> 00:43:18,079
measure it?

1028
00:43:16,800 --> 00:43:19,359
Right? You don't have to measure it, but

1029
00:43:18,079 --> 00:43:22,160
somehow everybody believes, you know,

1030
00:43:19,359 --> 00:43:24,160
the model is correct. How do we do that?

1031
00:43:22,160 --> 00:43:26,160
Right? Hence, there's actually a

1032
00:43:24,160 --> 00:43:27,440
self-correcting process. In fact, you

1033
00:43:26,160 --> 00:43:29,119
know, this is actually probably the idea

1034
00:43:27,440 --> 00:43:31,920
goes the idea actually goes back to

1035
00:43:29,119 --> 00:43:34,160
Noble Veer, right? And how animal be

1036
00:43:31,920 --> 00:43:35,760
able to correct its error without see

1037
00:43:34,160 --> 00:43:37,760
cats can capture something very

1038
00:43:35,760 --> 00:43:39,440
accurately. or even make one single

1039
00:43:37,760 --> 00:43:41,599
mistakes, they can correct that very

1040
00:43:39,440 --> 00:43:43,440
clearly. Right? So somehow they're

1041
00:43:41,599 --> 00:43:45,440
they're be able to build a world model

1042
00:43:43,440 --> 00:43:47,520
very consistent, self-consistent with

1043
00:43:45,440 --> 00:43:50,079
the world without actually physically

1044
00:43:47,520 --> 00:43:52,000
measure their errors, right? So hence

1045
00:43:50,079 --> 00:43:54,319
this is the idea about you actually loop

1046
00:43:52,000 --> 00:43:57,359
it back to your brain and close the

1047
00:43:54,319 --> 00:44:00,720
loop, right? and allows you to constant

1048
00:43:57,359 --> 00:44:02,800
predict and based on your prediction and

1049
00:44:00,720 --> 00:44:04,560
your observations check if there's a

1050
00:44:02,800 --> 00:44:06,800
difference still difference between your

1051
00:44:04,560 --> 00:44:10,079
predictive prediction and your

1052
00:44:06,800 --> 00:44:12,480
observation within your brain

1053
00:44:10,079 --> 00:44:15,680
very if there's error and using that

1054
00:44:12,480 --> 00:44:17,760
error to correct turns out um this is a

1055
00:44:15,680 --> 00:44:20,560
work with my student turns out you

1056
00:44:17,760 --> 00:44:22,800
cannot do this of course the our

1057
00:44:20,560 --> 00:44:25,680
observation will lose information right

1058
00:44:22,800 --> 00:44:27,680
why uh we introduce noise or lose loose

1059
00:44:25,680 --> 00:44:29,920
dimension, loose information. But turns

1060
00:44:27,680 --> 00:44:31,760
out as long as the distribution of the

1061
00:44:29,920 --> 00:44:33,839
world, the data, the distribution of the

1062
00:44:31,760 --> 00:44:35,839
world is low dimensional enough. Even

1063
00:44:33,839 --> 00:44:39,200
your encoding process, your observation

1064
00:44:35,839 --> 00:44:41,680
pro perception process is no you this is

1065
00:44:39,200 --> 00:44:43,839
still doable if the precisely when the

1066
00:44:41,680 --> 00:44:46,240
distribution of the data outside world

1067
00:44:43,839 --> 00:44:48,720
has enough structure is highly low

1068
00:44:46,240 --> 00:44:51,280
dimension and hence your brain has

1069
00:44:48,720 --> 00:44:53,200
enough degree of freedom to discern any

1070
00:44:51,280 --> 00:44:55,200
differences. So this is actually quite

1071
00:44:53,200 --> 00:44:57,280
interesting revelation to for us to

1072
00:44:55,200 --> 00:44:59,599
realize that the low dimensionality is

1073
00:44:57,280 --> 00:45:02,400
not just some or technical assumption.

1074
00:44:59,599 --> 00:45:05,920
It's actually necessary for this kind of

1075
00:45:02,400 --> 00:45:08,000
closed loop learning to be possible and

1076
00:45:05,920 --> 00:45:09,760
once you be able to close loop then you

1077
00:45:08,000 --> 00:45:12,400
actually constantly observe constantly

1078
00:45:09,760 --> 00:45:16,800
predict hence you can constantly use

1079
00:45:12,400 --> 00:45:19,280
your memory to predict and correct it.

1080
00:45:16,800 --> 00:45:21,839
Hence support continuous learning even

1081
00:45:19,280 --> 00:45:23,839
lifelong learning right our memory Rome

1082
00:45:21,839 --> 00:45:26,000
is not built in one day our memory is

1083
00:45:23,839 --> 00:45:29,920
never built in one day we constantly

1084
00:45:26,000 --> 00:45:33,359
improve it constantly revise it and this

1085
00:45:29,920 --> 00:45:35,599
is the mechanism of intelligence

1086
00:45:33,359 --> 00:45:38,079
hence this mechanism is itself is

1087
00:45:35,599 --> 00:45:41,040
already generalizable hence you don't

1088
00:45:38,079 --> 00:45:43,520
need to add the adjective general

1089
00:45:41,040 --> 00:45:45,920
general in front of intelligence there's

1090
00:45:43,520 --> 00:45:47,680
no point of calling general intelligence

1091
00:45:45,920 --> 00:45:49,520
if If you implement the intelligence

1092
00:45:47,680 --> 00:45:52,240
mechanism correctly, it's already

1093
00:45:49,520 --> 00:45:56,240
generalizable. The knowledge learned by

1094
00:45:52,240 --> 00:45:59,040
this mechanism at any point of time may

1095
00:45:56,240 --> 00:46:01,440
not be generalizable. The mechanism

1096
00:45:59,040 --> 00:46:03,520
does. Right? This is a very big

1097
00:46:01,440 --> 00:46:06,480
confusion. We think if I accumulate

1098
00:46:03,520 --> 00:46:09,520
enough knowledge, it's generalizable.

1099
00:46:06,480 --> 00:46:12,079
No, it's not. Will never be. Any

1100
00:46:09,520 --> 00:46:14,319
scientific theory by definition being

1101
00:46:12,079 --> 00:46:16,560
scientific is falsifiable, which means

1102
00:46:14,319 --> 00:46:18,720
it's limited, right? can only explain

1103
00:46:16,560 --> 00:46:21,200
the world up to certain point or certain

1104
00:46:18,720 --> 00:46:24,880
accuracy. There's always room for

1105
00:46:21,200 --> 00:46:27,839
improvement. The scientific activity,

1106
00:46:24,880 --> 00:46:30,079
our ability to revise our memory to

1107
00:46:27,839 --> 00:46:33,520
acquire new memory,

1108
00:46:30,079 --> 00:46:36,480
that is a generalizable ability. That is

1109
00:46:33,520 --> 00:46:38,960
intelligence, right? Through natural

1110
00:46:36,480 --> 00:46:41,680
selection early days, through our

1111
00:46:38,960 --> 00:46:44,640
feedback control, feedback correction,

1112
00:46:41,680 --> 00:46:46,400
through the human history of trial and

1113
00:46:44,640 --> 00:46:48,480
error, imp accumulating empirical

1114
00:46:46,400 --> 00:46:52,079
knowledge, through scientific discovery

1115
00:46:48,480 --> 00:46:54,880
is all doing this, right? That is common

1116
00:46:52,079 --> 00:46:56,720
behind intelligence, right? Not the

1117
00:46:54,880 --> 00:46:59,280
memory accumulated up to a certain

1118
00:46:56,720 --> 00:47:00,960
point. So even we manage to memorize the

1119
00:46:59,280 --> 00:47:03,040
whole world the knowledge we have in the

1120
00:47:00,960 --> 00:47:05,440
whole world we will no longer be able to

1121
00:47:03,040 --> 00:47:07,599
apply when we find oursel in a new

1122
00:47:05,440 --> 00:47:09,760
environment in a new situation observe

1123
00:47:07,599 --> 00:47:12,000
some phenomena we have never seen before

1124
00:47:09,760 --> 00:47:14,960
right hence that's the limitation of you

1125
00:47:12,000 --> 00:47:16,640
know you try to gain general general

1126
00:47:14,960 --> 00:47:17,839
intelligence through just accumulate

1127
00:47:16,640 --> 00:47:20,160
enough knowledge right

1128
00:47:17,839 --> 00:47:22,160
>> we should talk about your crate series

1129
00:47:20,160 --> 00:47:25,359
of architecture so crate stands for

1130
00:47:22,160 --> 00:47:26,640
coding rate reduction transformer and

1131
00:47:25,359 --> 00:47:28,480
you made some very interesting

1132
00:47:26,640 --> 00:47:30,640
discoveries So for example multi head

1133
00:47:28,480 --> 00:47:33,359
self attention can be derived as a

1134
00:47:30,640 --> 00:47:36,000
gradient step on rate coding and also

1135
00:47:33,359 --> 00:47:38,800
MLPS as spifying um spification

1136
00:47:36,000 --> 00:47:40,720
operators and and also you were talking

1137
00:47:38,800 --> 00:47:43,040
about how something like a transformer

1138
00:47:40,720 --> 00:47:45,200
could be described in a principled way.

1139
00:47:43,040 --> 00:47:48,400
There there's this interesting thing,

1140
00:47:45,200 --> 00:47:50,000
isn't there, that we we we designed the

1141
00:47:48,400 --> 00:47:51,599
well, we didn't even design them. We we

1142
00:47:50,000 --> 00:47:52,880
kind of empirically tried with lots of

1143
00:47:51,599 --> 00:47:55,040
different things and we happened upon

1144
00:47:52,880 --> 00:47:57,280
the transformer. But something like that

1145
00:47:55,040 --> 00:47:59,200
can actually come about from a first

1146
00:47:57,280 --> 00:48:03,680
principles approach. If you look at the

1147
00:47:59,200 --> 00:48:05,760
past decade also evolution of also it's

1148
00:48:03,680 --> 00:48:08,319
kind of natural selection process for

1149
00:48:05,760 --> 00:48:12,800
the big models right from early days

1150
00:48:08,319 --> 00:48:16,800
Alex let l Alex letter VGG or um then

1151
00:48:12,800 --> 00:48:19,359
reset or uh transformers by the way this

1152
00:48:16,800 --> 00:48:21,839
is just one of those for survivors right

1153
00:48:19,359 --> 00:48:23,359
as I said just like le selections right

1154
00:48:21,839 --> 00:48:25,760
remember don't people don't forgot

1155
00:48:23,359 --> 00:48:29,520
there's a there's a time there's a very

1156
00:48:25,760 --> 00:48:32,240
popular areas called AutoAs, AutoML,

1157
00:48:29,520 --> 00:48:35,920
right? People tends to do random search

1158
00:48:32,240 --> 00:48:38,800
for better architectures, right? Somehow

1159
00:48:35,920 --> 00:48:41,200
why only a few survive? There must be a

1160
00:48:38,800 --> 00:48:42,960
reason, right? They must capture certain

1161
00:48:41,200 --> 00:48:45,359
structures. They must did something

1162
00:48:42,960 --> 00:48:47,680
right. Now from our understanding so

1163
00:48:45,359 --> 00:48:50,000
far, the resonate actually capturing the

1164
00:48:47,680 --> 00:48:52,480
the fact that each layer should be doing

1165
00:48:50,000 --> 00:48:54,720
compar doing optimization.

1166
00:48:52,480 --> 00:48:57,599
The resonance precisely reflect the

1167
00:48:54,720 --> 00:49:00,000
iterative optimization architecture.

1168
00:48:57,599 --> 00:49:02,400
Right. And

1169
00:49:00,000 --> 00:49:05,200
precisely capture fact. We're trying to

1170
00:49:02,400 --> 00:49:08,559
cluster compress what's similar and

1171
00:49:05,200 --> 00:49:12,160
discern or classify what's different or

1172
00:49:08,559 --> 00:49:14,400
contrast what's dissimilar. Right? And

1173
00:49:12,160 --> 00:49:15,760
you want to develop different experts,

1174
00:49:14,400 --> 00:49:17,599
right? We call them experts, we call

1175
00:49:15,760 --> 00:49:21,040
them as cluster, we call them group. So

1176
00:49:17,599 --> 00:49:23,040
be it, right? And the transformer again,

1177
00:49:21,040 --> 00:49:25,599
right? Let's capture what is the

1178
00:49:23,040 --> 00:49:28,240
correlation self attention. is precisely

1179
00:49:25,599 --> 00:49:30,559
compute what's what is the correlation

1180
00:49:28,240 --> 00:49:33,200
in the data coariance in the data what's

1181
00:49:30,559 --> 00:49:36,079
correlated and using that to further

1182
00:49:33,200 --> 00:49:38,880
spify further classify things to

1183
00:49:36,079 --> 00:49:41,119
organize the the the distributions they

1184
00:49:38,880 --> 00:49:44,160
must do something there some somehow

1185
00:49:41,119 --> 00:49:46,000
close to something right right so also

1186
00:49:44,160 --> 00:49:47,680
it's almost like a belief for us right

1187
00:49:46,000 --> 00:49:49,440
if we believe there's something right

1188
00:49:47,680 --> 00:49:51,440
then we should be able to derive create

1189
00:49:49,440 --> 00:49:54,400
from first principle have a very clear

1190
00:49:51,440 --> 00:49:57,599
unified understanding I think we're sort

1191
00:49:54,400 --> 00:50:00,000
managed to do that at least. So for the

1192
00:49:57,599 --> 00:50:02,800
law structure we discovered so far

1193
00:50:00,000 --> 00:50:04,800
provide rather unified explanation to

1194
00:50:02,800 --> 00:50:07,680
what they have done to be honest the

1195
00:50:04,800 --> 00:50:09,440
early even maybe our early earliest mo

1196
00:50:07,680 --> 00:50:11,599
motives try to explain to understand

1197
00:50:09,440 --> 00:50:13,839
what we have done but once we understood

1198
00:50:11,599 --> 00:50:16,640
it we realize that we can go much

1199
00:50:13,839 --> 00:50:18,559
further right and realize even the

1200
00:50:16,640 --> 00:50:20,720
current architectures there's a lot of

1201
00:50:18,559 --> 00:50:22,800
room for improvement not only we can

1202
00:50:20,720 --> 00:50:25,839
dramatically simplify them you can see

1203
00:50:22,800 --> 00:50:27,680
in the past after the create um in the

1204
00:50:25,839 --> 00:50:29,680
last yes last year and this year there's

1205
00:50:27,680 --> 00:50:32,880
a series of work from my group right

1206
00:50:29,680 --> 00:50:34,079
really just showcase people right uh you

1207
00:50:32,880 --> 00:50:36,240
can actually you once you understand

1208
00:50:34,079 --> 00:50:38,559
what is done with the principle you can

1209
00:50:36,240 --> 00:50:42,000
dramatically simplify you you can even

1210
00:50:38,559 --> 00:50:44,800
throw with the MLP layer if you only

1211
00:50:42,000 --> 00:50:47,280
care about the compression um you don't

1212
00:50:44,800 --> 00:50:50,480
care about the final representation and

1213
00:50:47,280 --> 00:50:52,480
or you can make the attention head

1214
00:50:50,480 --> 00:50:54,400
since we know what is optimizing it's

1215
00:50:52,480 --> 00:50:55,599
optim optimizing the rate reduction

1216
00:50:54,400 --> 00:50:59,359
object function

1217
00:50:55,599 --> 00:51:02,079
Then we can find what is the equivalent

1218
00:50:59,359 --> 00:51:04,319
variation form of that object function

1219
00:51:02,079 --> 00:51:06,800
which is much easier to optimize. We end

1220
00:51:04,319 --> 00:51:09,440
up with a we call the toss right the the

1221
00:51:06,800 --> 00:51:11,520
computing the coariance the the self

1222
00:51:09,440 --> 00:51:15,040
tension step is only linear in the

1223
00:51:11,520 --> 00:51:17,280
dimension no longer quadratic like the

1224
00:51:15,040 --> 00:51:18,880
current tension is doing. Of course if

1225
00:51:17,280 --> 00:51:21,839
you look at the literature there are

1226
00:51:18,880 --> 00:51:24,880
other people have found tried to

1227
00:51:21,839 --> 00:51:28,480
identify linear complexity such as uh

1228
00:51:24,880 --> 00:51:32,240
you know manga or uh I think there's the

1229
00:51:28,480 --> 00:51:34,640
rk or something so empirically but again

1230
00:51:32,240 --> 00:51:36,960
it's through trial and error but this is

1231
00:51:34,640 --> 00:51:39,599
so now we derive this in the ma purely

1232
00:51:36,960 --> 00:51:42,079
mathematical way because we just find an

1233
00:51:39,599 --> 00:51:43,680
equivalent varial form of the same

1234
00:51:42,079 --> 00:51:45,839
object function they have the same

1235
00:51:43,680 --> 00:51:47,920
global optimal but it's that's much

1236
00:51:45,839 --> 00:51:50,319
easier to optimize. This is a trick we

1237
00:51:47,920 --> 00:51:54,160
do all the time, right? All the tricks

1238
00:51:50,319 --> 00:51:55,520
see in the 200 years plus years of

1239
00:51:54,160 --> 00:51:58,000
developing better optimization

1240
00:51:55,520 --> 00:52:01,839
algorithm. All those ideas can help us

1241
00:51:58,000 --> 00:52:05,520
now to design better operator descent

1242
00:52:01,839 --> 00:52:07,040
operators or optimization architectures

1243
00:52:05,520 --> 00:52:08,800
to

1244
00:52:07,040 --> 00:52:11,359
improve the design of current

1245
00:52:08,800 --> 00:52:14,000
architectures. Pro honestly we have not

1246
00:52:11,359 --> 00:52:16,000
really started that far. Right? There's

1247
00:52:14,000 --> 00:52:19,040
many acceleration techniques,

1248
00:52:16,000 --> 00:52:20,800
preconditioning, conjugate gradient

1249
00:52:19,040 --> 00:52:23,200
which explore different landscape. Once

1250
00:52:20,800 --> 00:52:25,680
we understand the landscape, the type

1251
00:52:23,200 --> 00:52:28,160
the cost of object function better

1252
00:52:25,680 --> 00:52:29,920
there's gazillions of ideas, we can

1253
00:52:28,160 --> 00:52:31,440
further improve the efficiency.

1254
00:52:29,920 --> 00:52:34,319
Honestly,

1255
00:52:31,440 --> 00:52:36,079
we haven't started that far, right? Um I

1256
00:52:34,319 --> 00:52:40,079
mean that's actually what got some of my

1257
00:52:36,079 --> 00:52:42,160
student uh excited uh to to pursue this

1258
00:52:40,079 --> 00:52:44,880
realizing how much how little we have

1259
00:52:42,160 --> 00:52:46,720
done. um uh from optimization

1260
00:52:44,880 --> 00:52:49,520
perspective how much room there might

1261
00:52:46,720 --> 00:52:51,200
still be for improvement uh some of my

1262
00:52:49,520 --> 00:52:52,960
students are quite excited. So you can

1263
00:52:51,200 --> 00:52:55,200
see you know Neman within last couple

1264
00:52:52,960 --> 00:52:59,839
years we already have two two or three

1265
00:52:55,200 --> 00:53:02,960
different uh uh uh uh generation of

1266
00:52:59,839 --> 00:53:04,800
architectures that um in the past it's

1267
00:53:02,960 --> 00:53:06,160
almost unthinkable because new

1268
00:53:04,800 --> 00:53:08,240
generation always come from different

1269
00:53:06,160 --> 00:53:10,079
group right it's like a random process

1270
00:53:08,240 --> 00:53:12,079
whoever gets lucky maybe discover

1271
00:53:10,079 --> 00:53:13,119
something works try hard enough get

1272
00:53:12,079 --> 00:53:15,040
something to work

1273
00:53:13,119 --> 00:53:16,800
>> it's a tantalizing idea though that

1274
00:53:15,040 --> 00:53:18,960
through this principled optimization

1275
00:53:16,800 --> 00:53:21,280
there could be you know a convergent

1276
00:53:18,960 --> 00:53:22,000
evolution towards the optimum

1277
00:53:21,280 --> 00:53:23,920
architecture

1278
00:53:22,000 --> 00:53:26,079
>> then the search will no longer be random

1279
00:53:23,920 --> 00:53:27,760
will be actually guided right there's

1280
00:53:26,079 --> 00:53:29,359
still just like back to your earlier

1281
00:53:27,760 --> 00:53:31,280
suggestion right this is become

1282
00:53:29,359 --> 00:53:33,440
intelligent search is you know guided

1283
00:53:31,280 --> 00:53:36,640
search we understand the the structure

1284
00:53:33,440 --> 00:53:38,559
of the problems now and hence we can do

1285
00:53:36,640 --> 00:53:41,760
science now we are no longer just to do

1286
00:53:38,559 --> 00:53:45,040
empirical inductive search process

1287
00:53:41,760 --> 00:53:47,040
>> why do open AI they're still using the

1288
00:53:45,040 --> 00:53:49,520
transformer even though there are now

1289
00:53:47,040 --> 00:53:51,520
superior architectures out there and we

1290
00:53:49,520 --> 00:53:53,359
should talk about this token statistics

1291
00:53:51,520 --> 00:53:55,599
um transformer. So as you just said it's

1292
00:53:53,359 --> 00:53:58,480
a linear time complexity which means in

1293
00:53:55,599 --> 00:54:00,240
principle this is something which is

1294
00:53:58,480 --> 00:54:01,599
going to scale dramatically better than

1295
00:54:00,240 --> 00:54:03,280
the kind of transformers we're using

1296
00:54:01,599 --> 00:54:05,440
now. So why aren't we using it?

1297
00:54:03,280 --> 00:54:08,000
>> Well there are tempted to try to scale

1298
00:54:05,440 --> 00:54:10,960
this up. In fact, even you can think

1299
00:54:08,000 --> 00:54:13,119
about uh uh many of of course when you

1300
00:54:10,960 --> 00:54:14,880
try to scale the other factor comes in

1301
00:54:13,119 --> 00:54:17,920
right in terms of whether or not the the

1302
00:54:14,880 --> 00:54:22,000
the the the scalability and so on is all

1303
00:54:17,920 --> 00:54:24,079
related to to to all the design. Um and

1304
00:54:22,000 --> 00:54:26,559
um indeed we actually tried something

1305
00:54:24,079 --> 00:54:28,400
else. uh you know uh for example things

1306
00:54:26,559 --> 00:54:30,480
are much more scalable also I also tried

1307
00:54:28,400 --> 00:54:32,800
to we also scaled up with all the

1308
00:54:30,480 --> 00:54:34,720
resource we have sometimes I don't know

1309
00:54:32,800 --> 00:54:37,119
about company right we we are very

1310
00:54:34,720 --> 00:54:39,200
limited in resource to verify even our

1311
00:54:37,119 --> 00:54:41,359
those architecture scales we can only do

1312
00:54:39,200 --> 00:54:43,119
up to probably a you know few you know

1313
00:54:41,359 --> 00:54:45,839
couple hundred cars and so on that's

1314
00:54:43,119 --> 00:54:48,079
about it uh with our academic resources

1315
00:54:45,839 --> 00:54:50,800
and hopefully that will convince but one

1316
00:54:48,079 --> 00:54:53,760
thing I think recently we did um to

1317
00:54:50,800 --> 00:54:55,680
simplify the current practice in dino

1318
00:54:53,760 --> 00:54:57,760
Right? You know the meta has to which is

1319
00:54:55,680 --> 00:55:00,160
the pre-trained the state-of-the-art uh

1320
00:54:57,760 --> 00:55:02,559
people everybody talk about world model

1321
00:55:00,160 --> 00:55:05,359
visual world model and uh that's sort of

1322
00:55:02,559 --> 00:55:07,119
the best model and the the meta put a

1323
00:55:05,359 --> 00:55:08,720
lot of effort engineer effort to

1324
00:55:07,119 --> 00:55:11,359
pre-train the visual representation

1325
00:55:08,720 --> 00:55:14,000
model uh which is still the best and

1326
00:55:11,359 --> 00:55:15,920
they train on gazillions of images and

1327
00:55:14,000 --> 00:55:17,920
they were using contrastive learning but

1328
00:55:15,920 --> 00:55:21,200
it's a it's a very uh remarkable

1329
00:55:17,920 --> 00:55:24,000
engineering uh feed and now people using

1330
00:55:21,200 --> 00:55:25,680
it right um turns thought actually we

1331
00:55:24,000 --> 00:55:27,839
found that uh the system can be

1332
00:55:25,680 --> 00:55:29,359
dramatically simplified once we realize

1333
00:55:27,839 --> 00:55:31,440
what the purpose what they're really

1334
00:55:29,359 --> 00:55:34,240
trying to do right we have a work called

1335
00:55:31,440 --> 00:55:36,400
a syn deno simplified the deno version

1336
00:55:34,240 --> 00:55:38,079
one version two we simplify both version

1337
00:55:36,400 --> 00:55:41,200
there the architecture is dramatically

1338
00:55:38,079 --> 00:55:43,119
so we get rid of you know dozens of

1339
00:55:41,200 --> 00:55:45,599
hyperparameters I have to do and

1340
00:55:43,119 --> 00:55:48,079
architecture become you know extremely

1341
00:55:45,599 --> 00:55:49,920
extremely 10 times simpler and the

1342
00:55:48,079 --> 00:55:52,160
performance is better we managed to

1343
00:55:49,920 --> 00:55:55,119
scale up to uh probably few few hundred

1344
00:55:52,160 --> 00:55:57,119
millions of scales the appletoapple

1345
00:55:55,119 --> 00:55:59,520
comparison were dramatically much easier

1346
00:55:57,119 --> 00:56:01,920
to train much efficient everything is

1347
00:55:59,520 --> 00:56:04,640
explainable I think that has seriously

1348
00:56:01,920 --> 00:56:06,640
draw attention uh from the meta team and

1349
00:56:04,640 --> 00:56:08,960
also from the Google team and it's

1350
00:56:06,640 --> 00:56:11,119
currently they are there I I know there

1351
00:56:08,960 --> 00:56:13,599
are serious effort that they're trying

1352
00:56:11,119 --> 00:56:15,920
to scale this the new architectures up

1353
00:56:13,599 --> 00:56:17,200
>> yes um we interviewed the dino folks at

1354
00:56:15,920 --> 00:56:19,119
the time and we've spoken to people like

1355
00:56:17,200 --> 00:56:20,799
Ishan Misra there's there I mean there's

1356
00:56:19,119 --> 00:56:24,400
a potential tangent there about they're

1357
00:56:20,799 --> 00:56:26,319
using this kind of um uh non-contrastive

1358
00:56:24,400 --> 00:56:28,240
um self-supervised learning and also

1359
00:56:26,319 --> 00:56:30,079
there's the whole unsupervised thing and

1360
00:56:28,240 --> 00:56:31,599
and how useful those representations are

1361
00:56:30,079 --> 00:56:33,440
for downstream task. May maybe we could

1362
00:56:31,599 --> 00:56:35,839
go there but I should say that Kevin

1363
00:56:33,440 --> 00:56:38,400
Murphy I'm I'm interviewing interviewing

1364
00:56:35,839 --> 00:56:40,319
him soon and um I know that he reviewed

1365
00:56:38,400 --> 00:56:41,920
your your book very very carefully and

1366
00:56:40,319 --> 00:56:45,040
he asked me to give you this question.

1367
00:56:41,920 --> 00:56:46,720
He said code reduction is great but must

1368
00:56:45,040 --> 00:56:49,760
be subject to prediction or

1369
00:56:46,720 --> 00:56:51,920
reconstruction loss in data space. How

1370
00:56:49,760 --> 00:56:54,160
would you go beyond token prediction

1371
00:56:51,920 --> 00:56:55,760
which seems especially weird for images?

1372
00:56:54,160 --> 00:56:56,400
So that that's what Kevin asked me to

1373
00:56:55,760 --> 00:56:57,920
ask you.

1374
00:56:56,400 --> 00:57:01,760
>> So this is actually a great question,

1375
00:56:57,920 --> 00:57:04,640
right? Um so in a in a rate reduction

1376
00:57:01,760 --> 00:57:07,599
remember the the lossiness is actually

1377
00:57:04,640 --> 00:57:12,160
coded through the the EPS ball where

1378
00:57:07,599 --> 00:57:14,240
actually uh uh try to capture the uh the

1379
00:57:12,160 --> 00:57:17,440
the samples how they connect with one

1380
00:57:14,240 --> 00:57:19,280
another. Um right now we actually if we

1381
00:57:17,440 --> 00:57:22,400
just minimizing the coding

1382
00:57:19,280 --> 00:57:25,280
representation uh through this uh lossy

1383
00:57:22,400 --> 00:57:27,200
coding and the error is kind of

1384
00:57:25,280 --> 00:57:30,880
controlled by the IPS law but not

1385
00:57:27,200 --> 00:57:34,480
enforced right so we respect the IPS law

1386
00:57:30,880 --> 00:57:37,280
um through this loss coding process now

1387
00:57:34,480 --> 00:57:39,520
to truly ensure remember everything

1388
00:57:37,280 --> 00:57:40,720
could go wrong and also depends on the

1389
00:57:39,520 --> 00:57:42,400
number of samples you have maybe the

1390
00:57:40,720 --> 00:57:44,640
image you choose is wrong because the

1391
00:57:42,400 --> 00:57:46,640
data does not have that density so you

1392
00:57:44,640 --> 00:57:49,359
may not be able to percolate. Hence the

1393
00:57:46,640 --> 00:57:51,839
repetition learn can be very very funky.

1394
00:57:49,359 --> 00:57:55,839
So now in order to to to ensure that

1395
00:57:51,839 --> 00:57:59,040
your your your your learn the reputation

1396
00:57:55,839 --> 00:58:01,200
distribution learn internally actually

1397
00:57:59,040 --> 00:58:03,200
authentically reflect the original

1398
00:58:01,200 --> 00:58:06,000
distribution up to certain precision you

1399
00:58:03,200 --> 00:58:07,680
have to decode right there is a constant

1400
00:58:06,000 --> 00:58:09,599
encoding decoding actually our brain do

1401
00:58:07,680 --> 00:58:11,920
that all the time predictive coding and

1402
00:58:09,599 --> 00:58:14,720
so on so forth

1403
00:58:11,920 --> 00:58:17,520
and hence that encoding decoding and to

1404
00:58:14,720 --> 00:58:19,440
verify if there's error remain in your

1405
00:58:17,520 --> 00:58:22,559
prediction in your recon construction

1406
00:58:19,440 --> 00:58:26,160
matters a lot only in that now the

1407
00:58:22,559 --> 00:58:28,079
question is if we don't have the oh do I

1408
00:58:26,160 --> 00:58:30,640
do we necessary back to our earlier

1409
00:58:28,079 --> 00:58:33,520
discussion right do we really need to

1410
00:58:30,640 --> 00:58:36,480
measure that error in the data space in

1411
00:58:33,520 --> 00:58:39,599
the original token space uh if we have

1412
00:58:36,480 --> 00:58:42,400
that option so be it do that right make

1413
00:58:39,599 --> 00:58:43,599
the engineering simpler make the but if

1414
00:58:42,400 --> 00:58:46,880
we really want to have a system just

1415
00:58:43,599 --> 00:58:50,160
like a human to selfarn just go out to

1416
00:58:46,880 --> 00:58:52,240
observe right at with two eyes or with

1417
00:58:50,160 --> 00:58:55,040
some sensors. Then we have to come up

1418
00:58:52,240 --> 00:58:58,400
with a way to make sure that our sensing

1419
00:58:55,040 --> 00:59:00,240
process is accurate enough so that we

1420
00:58:58,400 --> 00:59:04,799
can do everything internally. We can

1421
00:59:00,240 --> 00:59:07,839
predict go back rapid back and observe

1422
00:59:04,799 --> 00:59:11,359
compare what we predicted and what we

1423
00:59:07,839 --> 00:59:13,280
observed through same

1424
00:59:11,359 --> 00:59:15,920
sensing

1425
00:59:13,280 --> 00:59:18,079
channel. We compare that locally. In

1426
00:59:15,920 --> 00:59:21,760
theory actually prove at least under

1427
00:59:18,079 --> 00:59:23,440
ideistic cases this is possible. We can

1428
00:59:21,760 --> 00:59:25,839
minimize the error once we correct the

1429
00:59:23,440 --> 00:59:30,160
error. Hence the internal representation

1430
00:59:25,839 --> 00:59:33,119
will the error in a token original data

1431
00:59:30,160 --> 00:59:34,720
space will diminish but under tech

1432
00:59:33,119 --> 00:59:36,079
condition under general condition we

1433
00:59:34,720 --> 00:59:38,240
still don't know. So we actually have a

1434
00:59:36,079 --> 00:59:40,319
paper prove that for the when your data

1435
00:59:38,240 --> 00:59:42,079
distribution is a mixture of subspaces

1436
00:59:40,319 --> 00:59:43,839
you can rigorously prove that's possible

1437
00:59:42,079 --> 00:59:47,200
and if the dimension of the subspace is

1438
00:59:43,839 --> 00:59:50,559
low enough compared to the capacity of

1439
00:59:47,200 --> 00:59:52,480
the perception process.

1440
00:59:50,559 --> 00:59:54,640
Now for general distribution we believe

1441
00:59:52,480 --> 00:59:57,200
this is true. This is actually how we'll

1442
00:59:54,640 --> 01:00:00,319
be able to learn all the low dimensional

1443
00:59:57,200 --> 01:00:03,839
dynamics structure in the natural data

1444
01:00:00,319 --> 01:00:06,640
in the motion in the in the predicted um

1445
01:00:03,839 --> 01:00:09,200
world. So I think this is something in

1446
01:00:06,640 --> 01:00:12,799
the future we can deduct but end to end

1447
01:00:09,200 --> 01:00:14,799
works if you have the option to do so or

1448
01:00:12,799 --> 01:00:16,240
if you have you don't have that option

1449
01:00:14,799 --> 01:00:18,480
you have to figure out how to do this

1450
01:00:16,240 --> 01:00:20,960
autonomous under what condition you can

1451
01:00:18,480 --> 01:00:24,640
do this autonomously and allows you to

1452
01:00:20,960 --> 01:00:26,559
do autonomously to reduce the error to

1453
01:00:24,640 --> 01:00:29,119
almost zero. We spoke about Dino, but

1454
01:00:26,559 --> 01:00:31,520
another example would be VIT. Um, we

1455
01:00:29,119 --> 01:00:33,520
interviewed Lucas Bayer in Switzerland

1456
01:00:31,520 --> 01:00:35,680
earlier this year. So, he invented VIT.

1457
01:00:33,520 --> 01:00:37,839
And if I understand correctly, crate is

1458
01:00:35,680 --> 01:00:39,599
now very very close to VIT, but it it's

1459
01:00:37,839 --> 01:00:41,920
so much more principled. It's

1460
01:00:39,599 --> 01:00:44,880
explainable and so on. How close are we

1461
01:00:41,920 --> 01:00:46,720
to knocking VIT off the off the

1462
01:00:44,880 --> 01:00:49,040
leaderboard if you like?

1463
01:00:46,720 --> 01:00:51,520
>> In fact, u I think in many of the

1464
01:00:49,040 --> 01:00:53,280
comparison, we're already very close. If

1465
01:00:51,520 --> 01:00:55,520
you compare, it's hard to compare apple

1466
01:00:53,280 --> 01:00:58,079
to apple, but in terms of if you similar

1467
01:00:55,520 --> 01:00:59,599
the parameters, we're very much on par.

1468
01:00:58,079 --> 01:01:01,680
And also, by the way, we never really

1469
01:00:59,599 --> 01:01:04,400
quite put much engineer effort into it.

1470
01:01:01,680 --> 01:01:07,200
We just want to verify the concept. Um

1471
01:01:04,400 --> 01:01:10,400
indeed there one thing come out of the

1472
01:01:07,200 --> 01:01:12,000
vi the crit is that uh what we find is

1473
01:01:10,400 --> 01:01:14,400
not only the architecture designs

1474
01:01:12,000 --> 01:01:17,119
principled but then once we did the

1475
01:01:14,400 --> 01:01:18,720
training right the internal structure

1476
01:01:17,119 --> 01:01:21,680
learned

1477
01:01:18,720 --> 01:01:23,599
are both semantically statistically and

1478
01:01:21,680 --> 01:01:26,799
geometrically very meaningful indeed

1479
01:01:23,599 --> 01:01:28,960
each head actually does learns uh you

1480
01:01:26,799 --> 01:01:31,200
know similar structures all gets

1481
01:01:28,960 --> 01:01:33,680
basically each channel each head be

1482
01:01:31,200 --> 01:01:36,319
truly become expert of certain certain

1483
01:01:33,680 --> 01:01:39,599
type of visual patterns for example legs

1484
01:01:36,319 --> 01:01:42,079
of animals ears of animals faces of

1485
01:01:39,599 --> 01:01:44,720
animals so we see that very clearly with

1486
01:01:42,079 --> 01:01:47,760
crates but we don't observe that in the

1487
01:01:44,720 --> 01:01:49,680
vit of course you can see vit may learn

1488
01:01:47,760 --> 01:01:52,720
this is actually the the the interesting

1489
01:01:49,680 --> 01:01:55,040
thing right early days people I'm sure

1490
01:01:52,720 --> 01:01:56,799
large models if they have redundancy

1491
01:01:55,040 --> 01:01:58,640
they definitely learn things internally

1492
01:01:56,799 --> 01:02:01,440
but it's very hard to say which part of

1493
01:01:58,640 --> 01:02:03,680
that network learn the correct channels

1494
01:02:01,440 --> 01:02:06,079
learn the correct operators because it

1495
01:02:03,680 --> 01:02:08,160
is embedded in a more some redundant

1496
01:02:06,079 --> 01:02:12,000
structure, right? So early days people

1497
01:02:08,160 --> 01:02:14,640
call this lottery uh you know lucky

1498
01:02:12,000 --> 01:02:16,720
lottery or lock lottery ticket right

1499
01:02:14,640 --> 01:02:19,920
it's somewhere in there right then then

1500
01:02:16,720 --> 01:02:21,839
people try to distill that that justify

1501
01:02:19,920 --> 01:02:24,559
you should distill you should actually

1502
01:02:21,839 --> 01:02:26,160
be able to compress even people do this

1503
01:02:24,559 --> 01:02:28,160
Laura thing you know all the

1504
01:02:26,160 --> 01:02:30,319
post-processing right justify that is

1505
01:02:28,160 --> 01:02:32,559
necessary and some people you find after

1506
01:02:30,319 --> 01:02:34,240
the post processing not only the network

1507
01:02:32,559 --> 01:02:37,119
become smaller the performance gets

1508
01:02:34,240 --> 01:02:39,520
better right but and so on so forth Now

1509
01:02:37,119 --> 01:02:41,839
probably we don't have to do that. At

1510
01:02:39,520 --> 01:02:43,680
least you know the the architecture does

1511
01:02:41,839 --> 01:02:46,160
what it's supposed what it's designed to

1512
01:02:43,680 --> 01:02:49,200
do right and we can actually at least

1513
01:02:46,160 --> 01:02:51,280
explain what each component is doing

1514
01:02:49,200 --> 01:02:53,440
something statistically geometrically

1515
01:02:51,280 --> 01:02:54,799
very meaningful and there also results

1516
01:02:53,440 --> 01:02:56,640
if there's enough data if your

1517
01:02:54,799 --> 01:03:00,079
optimization

1518
01:02:56,640 --> 01:03:03,599
uh is done training is successful that's

1519
01:03:00,079 --> 01:03:05,599
those structure pops up naturally the

1520
01:03:03,599 --> 01:03:08,400
the structure will do what they're

1521
01:03:05,599 --> 01:03:10,640
designed to do. And and final question,

1522
01:03:08,400 --> 01:03:12,799
many um ML engineers and researchers

1523
01:03:10,640 --> 01:03:14,640
watch the show. Given everything we've

1524
01:03:12,799 --> 01:03:16,880
spoken about, how can they find out more

1525
01:03:14,640 --> 01:03:18,720
about your work and how can they get

1526
01:03:16,880 --> 01:03:22,000
started building these kind of

1527
01:03:18,720 --> 01:03:25,280
architectures? Um I think most of our

1528
01:03:22,000 --> 01:03:28,640
actor are open sourced on GitHub um

1529
01:03:25,280 --> 01:03:30,960
including create uh uh early reduet uh

1530
01:03:28,640 --> 01:03:33,359
there may not be is conceptual but not

1531
01:03:30,960 --> 01:03:35,920
very practical uh create and also even

1532
01:03:33,359 --> 01:03:38,160
toss all the all the codes are available

1533
01:03:35,920 --> 01:03:40,240
but by the way they're sort of kind of

1534
01:03:38,160 --> 01:03:41,680
academic implement we don't we never be

1535
01:03:40,240 --> 01:03:45,440
able to have the resource to scale them

1536
01:03:41,680 --> 01:03:49,359
up most are scale up to GPT2 or image at

1537
01:03:45,440 --> 01:03:51,839
21 that that's we can afford deno Simply

1538
01:03:49,359 --> 01:03:54,400
den is the one we scale the most. We we

1539
01:03:51,839 --> 01:03:56,480
res exhaust a lot of resource and a

1540
01:03:54,400 --> 01:03:58,799
little bit higher than that but still no

1541
01:03:56,480 --> 01:04:01,119
comparison to all this industrial scale

1542
01:03:58,799 --> 01:04:02,640
at all but I do believe that the meta

1543
01:04:01,119 --> 01:04:05,520
and Google are doing something about

1544
01:04:02,640 --> 01:04:08,720
dino simplified dino and the codes are

1545
01:04:05,520 --> 01:04:11,599
there um and also of course if for the

1546
01:04:08,720 --> 01:04:14,640
methodology of course um this is one way

1547
01:04:11,599 --> 01:04:16,640
why we bite the bullet uh uh to uh wrote

1548
01:04:14,640 --> 01:04:18,160
the book in the past two years we

1549
01:04:16,640 --> 01:04:20,640
believe that although there's a series

1550
01:04:18,160 --> 01:04:22,400
of papers uh but we believe that for

1551
01:04:20,640 --> 01:04:24,400
people to get a big picture, the more

1552
01:04:22,400 --> 01:04:27,839
systematic introduction. We put together

1553
01:04:24,400 --> 01:04:30,559
the the books also we open sourced it um

1554
01:04:27,839 --> 01:04:32,400
and we we will post link all the data

1555
01:04:30,559 --> 01:04:34,720
all the code as well. We are also

1556
01:04:32,400 --> 01:04:37,200
teaching the course. So all the we

1557
01:04:34,720 --> 01:04:40,319
actually will have students uh practice

1558
01:04:37,200 --> 01:04:42,400
most of the new architectures method. So

1559
01:04:40,319 --> 01:04:45,280
all those codes will be made public

1560
01:04:42,400 --> 01:04:47,039
available and so I think that might be a

1561
01:04:45,280 --> 01:04:49,440
good entrance if you want people want to

1562
01:04:47,039 --> 01:04:51,920
learn the methodology understand the

1563
01:04:49,440 --> 01:04:54,480
theoretical chain of evidence and also

1564
01:04:51,920 --> 01:04:57,119
even the empirical chain of evidence and

1565
01:04:54,480 --> 01:05:00,000
I think the book is has attempt to do

1566
01:04:57,119 --> 01:05:01,920
that we are already start to organizing

1567
01:05:00,000 --> 01:05:04,319
we're not done yet but we are start

1568
01:05:01,920 --> 01:05:06,160
already organizing if you find of

1569
01:05:04,319 --> 01:05:08,000
chapter seven we're already doing that

1570
01:05:06,160 --> 01:05:11,760
uh in chapter seven to collect the

1571
01:05:08,000 --> 01:05:14,559
theory seriously to to all the real

1572
01:05:11,760 --> 01:05:17,119
world data and the task such as image

1573
01:05:14,559 --> 01:05:19,520
classification, image segmentation and

1574
01:05:17,119 --> 01:05:22,240
the pre-training and even language uh

1575
01:05:19,520 --> 01:05:23,200
GPT2 type scale language models and so

1576
01:05:22,240 --> 01:05:24,559
on. Yeah,

1577
01:05:23,200 --> 01:05:25,920
>> professor Mo, it's been an absolute

1578
01:05:24,559 --> 01:05:26,400
honor. Thank you so much for joining us

1579
01:05:25,920 --> 01:05:29,520
today.

1580
01:05:26,400 --> 01:05:29,520
>> Yeah, thank you very much.

