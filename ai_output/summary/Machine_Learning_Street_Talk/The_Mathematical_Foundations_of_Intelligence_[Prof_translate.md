# The Mathematical Foundations of Intelligence [Professor Yi Ma]

本文内容整理自 **Machine Learning Street Talk** 频道的视频。

原始链接：https://www.youtube.com/watch?v=QWidx8cYVRs

## 📝 视频简介

如果我们对人工智能理解的一切认知都是错误的？压缩是智能的关键吗？还是存在更深层的东西——从记忆到真正的抽象的飞跃？

在这次引人入胜的对话中，我们与马毅教授——深度学习世界知名专家、IEEE/ACM院士、《学习数据分布的深度表征》一书的作者进行了交流。马教授质疑我们对大语言模型实际功能的假设，揭示了为什么3D重建不等同于理解，并提出了一个基于两个原则——简约性和自洽性的统一数学智能理论。

关键洞察：

*大语言模型不是理解——它们是记忆*
语言模型处理文本（已经是压缩的人类知识），使用与我们从原始数据学习相同的机制。

*3D视觉的幻象*
Sora和NeRFs等可以重建3D场景的模型，在基本空间推理上仍然表现糟糕。

*"条条大路通罗马"*
为什么添加噪声对发现结构是必要的。

*为什么梯度下降实际上有效*
自然优化景观出奇地平滑——这是"维度的祝福"。

*从第一原理理解Transformer*
Transformer架构可以从压缩原理数学推导而来。

关于马毅教授：
马毅是香港大学计算与数据科学学院的首任院长，同时也是加州大学伯克利分校的访问教授。

---

> 本文内容整理自香港大学计算与数据科学学院院长马毅（Yi Ma）教授在 Machine Learning Street Talk 频道的学术访谈。

## TL;DR

马毅教授提出智能的数学理论：基于简约性（parsimony）和自洽性（self-consistency）两大原则，智能本质是压缩过程——发现世界中可预测的低维结构。LLM只是记忆压缩后的人类知识，缺乏真正的空间理解，而真正的智能需要闭环学习机制。

## 📑 章节导航表

| 时间戳 | 章节标题 | 一句话概括 |
|--------|----------|-----------|
| 00:00-02:08 | 引言 | 智能研究的科学化挑战与马毅教授的理论愿景 |
| 02:08-05:21 | 第一性原理书籍与研究愿景 | 八年深度学习研究成果总结，构建智能的数学框架 |
| 05:21-09:50 | 简约性与一致性双支柱 | 智能的两大核心原则：寻找最简表示和保持自洽性 |
| 09:50-14:37 | 进化vs学习：压缩机制 | DNA进化与大脑学习都是压缩过程，但机制截然不同 |
| 14:37-20:41 | 3D理解的错觉：Sora与NeRF | 机器重建3D场景≠真正理解，缺乏空间推理能力 |
| 20:41-26:29 | 条条大路通罗马：噪声的作用 | 噪声在连接数据点、发现流形结构中的必要性 |
| 26:29-32:50 | 良性非凸性：优化为何有效 | 自然数据的低维结构导致平滑优化景观，高维反而有利 |
| 32:50-40:41 | 双重下降与过拟合神话 | 压缩算子天然防止过拟合，参数过量也无害 |
| 40:41-47:18 | 自洽性：闭环学习 | 通过预测-观察-纠错的闭环机制实现持续学习 |
| 47:18-56:26 | 从第一性原理推导Transformer | 白盒CRATE架构：每个组件都有明确数学意义 |
| 56:26-01:00:26 | 验证与Kevin Murphy问题 | 如何确保内部表征与真实分布一致的理论保证 |
| 01:00:26-01:05:17 | CRATE vs ViT：白盒AI与结论 | 可解释架构的优势和未来发展方向 |

## 📊 核心论点

#### 智能的双支柱理论：简约性与自洽性

- **核心内容**：马毅提出智能的数学定义基于两个原则：（1）简约性（parsimony）——寻找数据最简单的表示，如爱因斯坦所言"万事万物应该尽可能简单，但不能更简单"；（2）自洽性（self-consistency）——确保内部模型能够准确重构和预测外部世界。这种智能定义适用于从动物到人类的共同认知层面，即如何形成世界模型并用于预测和决策。
- **关键概念**：世界模型、低维结构、压缩、去噪、降维、预测性编码
- **实际意义**：为人工智能提供了统一的数学框架，指导从理论研究到架构设计的全过程，避免纯粹的经验试错。

#### 压缩即智能：发现可预测的低维结构

- **核心内容**：智能本质是一个压缩过程，目标是发现外部世界中具有秩序、可预测的低维结构。从DNA进化（通过遗传编码压缩环境知识）到大脑学习（通过神经网络压缩感官体验），都遵循同样的压缩机制。当前AI处于类似生命早期阶段——通过残酷的试错和自然选择（哪个模型成功就被广泛采用）来获取知识。
- **关键概念**：数据压缩、秩序发现、自然选择、知识编码、残酷优化
- **实际意义**：解释了为什么深度学习有效，同时指出当前AI发展阶段的局限性，为下一阶段演进提供方向。

#### LLM的根本局限：记忆≠理解

- **核心内容**：大语言模型处理的是已经被人类压缩过的文本知识，它们使用与人类处理原始数据相同的机制来处理二手信息。马毅团队的"Eyes Wide Shut"测试显示，所有顶级多模态模型在简单的空间推理任务上都表现糟糕，大多数甚至不如随机猜测。真正的理解需要view-centric（视角中心）、object-centric（物体中心）和allocentric（绝对坐标）表征的结构化转换能力。
- **关键概念**：空间推理、多层表征结构、3D理解、结构化世界模型
- **实际意义**：当前多模态AI在具身智能、机器人导航等需要真实空间理解的应用中存在根本性障碍。

#### 3D重建的错觉：可视化≠理解

- **核心内容**：Sora、NeRF等能生成逼真3D场景的AI系统本质上只是创造了用于人类观看的可视化效果，而非真正的3D理解。当人类看到3D重建时会感到兴奋，因为我们的大脑自动进行了语义解析（识别出手、杯子、苹果等），但机器只看到点云数据。真正的3D世界模型应该支持交互、操控和影响，而非仅仅提供360度观看视角。
- **关键概念**：语义解析、交互式3D模型、点云数据、视觉错觉
- **实际意义**：指出当前计算机视觉研究的方向性问题，强调需要构建可交互的世界模型而非可视化工具。

#### 噪声的双重作用：连接与泛化

- **核心内容**：噪声在智能系统中发挥两个关键作用：（1）"条条大路通罗马"效应——通过在数据周围添加噪声（建路），使扩散去噪过程能找回原始结构（回到罗马）；（2）渗流现象——有限样本点通过噪声连接形成连续流形，当密度超过临界值时发生相变，从记忆离散点转向识别连续平面。这种相变可能是从零维样本到低维流形，再到整个空间泛化的抽象机制。
- **关键概念**：扩散去噪、渗流相变、流形假设、抽象机制、相变临界点
- **实际意义**：为扩散模型的成功提供理论解释，指导噪声参数的选择和优化策略的设计。

#### 良性非凸优化：高维的祝福

- **核心内容**：自然数据的低维结构和对称性导致非凸优化问题具有出人意料的平滑景观。与传统认知相反，高维空间中的自然优化问题更容易解决，存在"高维祝福"现象。这些问题没有平坦表面、停滞点或过多局部极小值，即使局部极小值也具有明确的几何统计意义。智能的核心能力是识别最容易解决的问题并优先处理，而非解决最困难的问题。
- **关键概念**：良性非凸性、高维祝福、对称性、平滑优化景观、资源节约原则
- **实际意义**：解释了为什么梯度下降在深度学习中如此有效，为优化算法设计提供理论指导。

#### 压缩防止过拟合：天然正则化

- **核心内容**：如果神经网络的每一层都在执行压缩操作（收缩映射），那么无论参数多么过量，都不会发生过拟合。例如，一维直线可以嵌入百万维空间，但如果所有操作都向直线方向收缩，系统永远不会偏离目标结构。这解释了深度学习中的双重下降现象和大模型的自我正则化行为，颠覆了传统的偏差-方差权衡理论。
- **关键概念**：收缩映射、双重下降、自我正则化、过参数化、PCA幂迭代
- **实际意义**：为深度学习的泛化能力提供理论保证，支持构建更大规模的模型而无需担心过拟合。

#### 闭环学习：自主智能的关键

- **核心内容**：真正的智能需要预测-观察-纠错的闭环机制，类似控制论中的反馈控制。动物能够在不直接测量误差的情况下自我纠正，通过大脑内部的预测与观察比较来更新世界模型。理论证明，当外部世界具有足够的低维结构且大脑有足够自由度时，这种闭环学习是可行的。这种机制天然支持持续学习和终身学习。
- **关键概念**：预测编码、反馈控制、自主纠错、持续学习、控制论
- **实际意义**：指向真正自主AI的实现路径，摆脱对大规模标注数据的依赖，实现自我演进的智能系统。

#### 白盒Transformer：从原理推导架构

- **核心内容**：CRATE（编码速率缩减Transformer）证明了Transformer架构可以从压缩第一原理推导而出：多头自注意力是速率编码目标函数的梯度步骤，MLP是稀疏化算子。每个组件都有明确的数学意义，而非经验猜测。CRATE不仅性能匹配传统Transformer，还具有线性时间复杂度和完全可解释性，每个注意力头都学习到语义上有意义的视觉模式。
- **关键概念**：白盒AI、可解释性、编码速率缩减、梯度优化、专家分工
- **实际意义**：开启从经验试错转向科学设计的AI架构新时代，为构建更高效、可控的AI系统奠定基础。

#### 智能的可泛化性：机制vs知识

- **核心内容**：真正可泛化的不是积累的知识，而是获取和修正知识的机制。任何科学理论都是可证伪的（有限的），只能在特定精度下解释世界。但科学活动本身——修正记忆、获取新记忆的能力——是可泛化的。从自然选择、反馈控制到科学发现，都体现了这种共同的智能机制。因此无需在智能前加"通用"二字，正确实现的智能机制本身就是可泛化的。
- **关键概念**：机制泛化、知识有限性、科学方法、可证伪性、智能本质
- **实际意义**：重新定义了通用人工智能的目标，从积累知识转向构建自我演进的学习机制，为AGI研究指明方向。

## 🏢 提及的公司/产品

| 公司名 | 讨论语境 | 重要性 |
|--------|----------|--------|
| Meta | DINOv2视觉预训练模型、工程投入、简化版本研究 | ⭐⭐⭐ |
| Google | DINOv2竞争、简化版本实现努力 | ⭐⭐ |
| OpenAI | GPT模型、多模态能力测试、架构选择 | ⭐⭐⭐ |
| Berkeley | 马毅教授学术机构、研究平台 | ⭐⭐ |
| 香港大学 | 计算与数据科学学院、课程设计 | ⭐⭐ |
| NVIDIA | GPU训练资源、工业级算力 | ⭐ |

## 💬 经典金句

> "智能，无论是人工的还是自然的，都必须在科学上或数学上明确定义。"
> — 马毅

> "智能是识别什么最容易首先解决的能力，而不是解决最困难的问题。"
> — 马毅

> "当我们看到某样东西时，我们会兴奋，因为我们理解了3D，理解了内容，我们的大脑已经自动解析了它，但机器不知道里面到底是什么。"
> — 马毅

> "可泛化的不是积累的知识，而是获取和修正知识的机制。"
> — 马毅

> "如果神经网络正在执行压缩，那么即使过参数化也永远不会过拟合。"
> — 马毅

## 👤 主要人物

#### 马毅（Yi Ma）

**身份**：香港大学计算与数据科学学院院长、UC Berkeley访问教授、IEEE/ACM Fellow、图灵奖级别研究者
**背景**：世界领先的深度学习和人工智能专家，在稀疏表示和低秩结构方面做出开创性贡献。著有四本专著，从计算机视觉到智能理论的系统性研究者。过去八年专注于深度网络的第一性原理理解。
**核心观点**：智能可以用简约性和自洽性两个数学原则完全刻画。当前AI处于类似生命早期的发展阶段，通过残酷试错获取知识。真正的智能需要闭环学习机制，能够自主纠错和持续演进。压缩是智能的本质，LLM只是在处理已压缩的人类知识。

#### Kevin Murphy

**身份**：机器学习领域知名学者、《机器学习：概率视角》作者
**背景**：在概率机器学习领域有深厚造诣，对理论基础要求严格
**核心观点**：质疑编码速率缩减理论，认为必须结合数据空间的预测或重构损失，特别是对图像等非文本数据的token预测方法提出挑战。

## 📺 视频类型判断

**访谈对话**：深度学术访谈，主持人与马毅教授就智能理论进行系统性讨论，包含理论阐释、实例分析和问答互动。

---

## 📝 完整翻译

### 📑 章节导航表（翻译参考）

（摘要中未提供章节导航表）

### (0:00 - 2:08) 引言

I apologize for the confusion. I'll translate the transcript directly:

过去10年，关于智能或人工智能的问题深深地占据了人们的想象力。我也是其中之一，但我花了大约10年的时间，真正地思考能否将智能理解为一个真正的科学或数学问题来形式化。你可能会听到我的一些观点和看法，这很可能会改变你对智能的理解，这对我来说也是一个非常有趣的过程。

我们如何澄清关于智能的常见误解？通过这段旅程，我们或许能获得一个全新的视角，了解我们在过去10年中到底做对了什么。探索人工智能的实践，我们已实施的机制，所有大型模型和深度网络背后的本质，理解它们的局限性，以及构建具有智能行为或能力的系统究竟需要什么。

我认为我们已经达到了一个关键点，能够探讨下一步如何理解更高级的智能形式。压缩与抽象之间的区别，记忆与理解之间的区别，这些都是我们未来需要研究的重大开放性问题。

MLST 由 cyber fund 赞助 >> 必须依赖人工处理来推进系统的想法并不那么诱人。>> 本期节目由 Prolific 赞助 >> 让我们获取一些优质的样本。让我们引入合适的人来获取高质量的人工反馈。我们正试图将人工数据或人工反馈视为基础设施问题，努力使其更易访问，降低成本，从而有效地民主化这些数据的获取。

主持人：Ma教授，很高兴请您做客MLST。欢迎。

教授：感谢邀请。

主持人：通常我会请嘉宾自我介绍，但考虑到您在该领域的地位，我认为最好由我来介绍。Yi Ma是深度学习和人工智能领域的世界顶级专家，是香港大学计算和数据科学学院的首任院长，香港大学数据科学研究所主任。他还是加州大学伯克利分校的客座教授，此前曾在电气工程与计算机科学系担任正教授。作为IEEE、ACM和CM的会士，他在稀疏表示和低秩结构方面的开创性工作，从根本上塑造了现代计算机视觉和机器学习。他最近出版的《学习数据分布的深度表示》一书，提出了一个基于节俭和自洽两个原则的智能数学理论。这一框架导致了被称为CRATE架构的白盒Transformer，其中每个组件都可以从第一性原理推导，而非经验猜测。

教授：大约七八年前，深度网络和深度学习已经彻底改变了机器学习或人工智能的实践。大约八年前，我有机会回到伯克利，这给了我更深入地研究这些主题的机会，试图从更有原则的方法来理解它。这本书总结了我们过去八年及以后的进展，包括我的团队以及许多同事，试图从第一性原理解释深度网络。在这个过程中，我们似乎还发现了更广泛的东西，那就是某个层次的智能。

两年前加入香港大学时，我有机会重新设计一些课程，反映我们领域的快速进展。我的学生和同事认为，现在是系统性地整理这些知识体系的时候了，并将其体现为教科书和新课程。我目前正在教授这门课程，下学期可能也会在伯克利开设。这可能是我们首次尝试从更有原则的方法来解释深度网络，以及智能的一些原则。

### (5:21 - 9:50) 简约性与一致性双支柱

I apologize for the confusion. Here's the translation following the specified guidelines:

教授：我们大概是在尝试用更有原则的方法来解释深度网络，以及智能的一些原则。这些原则是简约性和自洽性。这是一个雄心勃勃的想法，这两个原则能够解释自然和人工智能。

主持人：你说的是什么意思？

教授：无论是人工智能还是自然智能，我们必须非常明确地定义"智能"。这是一个非常复杂的词。智能本身可能有不同的层次和阶段。现在是时候用科学或数学的方式来澄清这个概念了。这样我们才能研究每个层次背后的机制。我们相信，即使在不同阶段的智能中，也存在一些更统一的原则。

最基本的智能层次是动物和人类都共有的：关于如何记忆、如何学习外部世界的知识，并将其作为记忆的一部分，然后用它来预测、反应、帮助我们做出生存所需的决策。这正是我们在书中讨论的智能层次。

对于这个层次的智能，我们如今有一个时髦的词：世界模型。重点在于我们如何发展这样的记忆或世界模型，它如何演化，我们如何使用它。我们相信，在这个智能层次上，记忆形成和运作的方式，正是由两个原则决定的。

第一个原则是：记忆或知识本质上是为了发现世界的可预测性。所有这样的信息本质上都有很低的自由度，我们称之为低维结构。追求这种知识的方法，正是通过寻找数据最简单的表示。压缩、去噪、降维，实际上都是追求这种结构的不同说法。这就是"简约性"一词所捕捉到的——正如爱因斯坦描述科学的那句话：尽可能简单，但不能过于简单。

第二个原则是一致性。确保你的记忆能够准确地重建、模拟世界。如果过于简单，你可能会丧失预测能力。这两个原则——简约性和一致性——共同构成了我们记忆运作的特征。

我们的目标是理解世界的关键特征，表达出世界中重要的不变性。我的论点是：压缩可能是理解的必要条件。获取关于外部世界的知识，本质上是一个压缩的过程——找出什么是可压缩的，什么现象具有秩序，什么具有低维结构，使我们能够预测、排除变数，更好地理解世界。

这种能力，我们认为，就是智能的本质——至少是我们讨论的这个普遍智能层次。如果我们回顾生命的历史，支配物理世界的是物理定律，而支配生命进化的，我认为正是智能。

生命通过进化学习越来越多关于世界的知识，并通过DNA将其编码并传递给下一代。这是一个压缩的过程，通过随机突变和自然选择来更新。这个过程很残酷，需要大量资源和时间，进展也极其不可预测。这与当前大模型的进化方式颇为相似：许多团队没有原则地尝试，只有幸运的那些存活并被推广，最终主导实践。

在生命的早期阶段，知识通过DNA压缩并传递。随后，个体动物发展出大脑、神经系统和感官，开始用完全不同的机制来学习、压缩观察结果，并建立关于世界的记忆。个体开始获得超越遗传继承的能力。这部分知识不再仅仅编码在基因中，还存在于大脑中。这正是我们现在讨论的智能层次——普遍存在于动物和人类的智能。

我们可以说，智能作为一个系统会产生工件。就像道路建设网络会生成道路，这个系统具有适应性，能在原本不存在的地方创造新的路径。当然，压缩同一事物也有多种方式。

### (9:50 - 14:37) 进化vs学习：压缩机制

我们需要了解它们是如何进化的，以及未来可能会如何发展？

需要找出可以压缩的内容，识别具有规律性的现象。寻找低维结构，这些结构使我们能够预测、排除变数，从而更好地理解世界。

从本质上讲，我们认为这正是智能的核心所在——至少是我们所讨论的普通智能。如果回顾生命的历史，我们相信，就像物理定律支配物理世界一样，还有一种机制支配生命的进化，而这种机制就是智能。

通过进化，生命会学习越来越多关于世界的知识，并通过DNA将其编码并传递给下一代。这是一个压缩的过程，通过学习关于世界的逻辑并将其压缩。但更新这一过程的机制实际上是非常残酷的，通过随机突变和自然选择。确实在进化，确实在推进，但代价极大，需要大量资源和时间，而且极其不可预测。

如果你敏锐的话，可能会发现这与当前大模型的进化方式有些相似。许多团队没有原则地尝试，通过经验主义的试错，最终幸运的那个存活并被推广，最终主导实践。

如果学生问我们今天的人工智能处于什么阶段，我会说，这与自然界已经有相似之处。我们仍处于生命形态的早期阶段。这是一个压缩过程，一个获取世界知识的过程。

当然，随后，个体动物发展出大脑、神经系统，发展出包括视觉和触觉在内的感官。我们开始使用完全不同的机制来学习、压缩观察结果，学习知识，建立关于世界的记忆。个体开始获得不仅仅是继承DNA知识的能力。这是智能发展的不同阶段。

这部分知识不再仅仅编码在遗传基因中，还存在于我们的大脑中。这正是我们现在讨论的智能层次，是动物和人类共有的智能。

我认为我们可以同意这样一个观点：智能作为一个系统会产生工件。就像一个道路建设网络会生成道路，这个系统具有适应性，能在原本不存在的地方创造新的路径。然后就有了这个问题：压缩同一事物确实有多种方式。

有些压缩方式能在深层抽象层面呈现世界，而有些则不能。我们可能会争论，当今的大语言模型（LLM）虽然确实压缩了数据，但只是以一种肤浅的语义方式进行压缩。

还有这个概念：也许我们可以同意，智能是关于新知识的综合。这是获取新知识，但我们只有在已有的知识能够在深层抽象层面呈现世界的情况下才能做到。与其说是进化中的随机突变，不如说是非常有结构的过程，因为这些过程是物理实例化的。这意味着不是完全随机，而是由创造过程引导的。

流形假说浮现在脑海中，这是关于所有自然数据都落在某个低维结构上的想法。另一个浮现的想法是几何深度学习，即我们应该在系统中注入代表世界对称性和几何结构的归纳先验。我认为这是深深嵌入这一理念的原则。

### (14:37 - 20:41) 3D理解的错觉：Sora与NeRF

这是非常有结构的，因为这些过程是物理实例化的，这意味着不是完全随机地做某事，而是由创造过程引导的。浮现在脑海中的是流形假说，即所有自然数据都落在某个低维度的结构上。另一个浮现的想法是几何深度学习，即我们应该在系统中注入代表世界对称性和几何结构的归纳先验。我认为这是深深嵌入在这个理念中的原则。

主持人：完全正确。如果看我的一生，我已经写了四本书。我早期的研究兴趣是计算机视觉，第一本书是关于视觉的，从那项工作中我研究了多视角几何。

这四本书实际上都是关于一个主题，我意识到这是关于数据中的结构，尤其是所有反映的知识。在第一本视觉分割的书中，最后一章我精确地意识到对称性在我们感知中扮演的重要作用。作为人类，我们自然地感知和记忆物体，只是很久以前就能识别。

现在人们说视觉是关于3D重建，这完全是错误的。所有人说我们只是通过多张图像创建点云、网格、符号距离函数、LURF、散点图等。我们创建了一个场景。看，我可以从多个角度查看。这是3D理解还是你创建了像Sora这样看起来不错的视频？绝对不是。

这不是世界模型的表征或理解。我们的理解远远超越了获取一堆点云或从不同角度查看。注意到当我们看到某物时，我们会因为理解了3D、理解了内容而兴奋，我们的大脑已经解析了它，但机器对此一无所知。它只是一堆点云、深度图。当我们改变角度时，我们看到3D。我们已经自动识别这是一只手、身体、杯子、苹果。我们用大脑填充那些信息。我们认为机器只要能重建3D就理解了，这完全是错误的。

许多工作声称通过创建可供人们查看的3D模型来理解3D，这完全偏离了目的。看看我们的视觉模型，我们的海马回、ID代码高度结构化。我们理解以视角为中心、以物体为中心和以位置为中心的表征之间的关系。神经科学家非常了解这一点，但计算机科学家，尤其是计算机视觉科学家（少数除外）并不了解。

大约一年前，我们与顶级多模态模型进行了一个简单的空间推理测试。这项名为《Eyes Wide Shot》的工作测试了像GPT、Gemini这样的大型多模态模型在理解空间推理方面的能力，比如物体的左侧是什么、空间中有多少物体、物体后面或上面是什么。这些问题只需要稍微深一点的空间理解。但所有模型都惨败，大多数模型甚至比随机猜测还差。只有Gemini和GPT略高于随机猜测，但远低于人类理解。

这就是现状：3D理解非常困难，但人类轻而易举地做到这一点。我可以轻松地指示你：请递给你左边的瓶子，或者在购物中心找到一个地方时说：通过门，向右转，走出建筑物后朝南。仅通过这简单的句子，我们就已经从以视角为中心切换到以物体为中心再到以位置为中心。如果我们没有这种高度结构化的3D模型，就别谈embodied AI或世界模型了，我们甚至无法进行如此简单的空间引用和交互。

我们构建3D模型是为了交互、操作和影响，而不仅仅是为了可视化。不是为了360度旋转观看，而是为了实际目的。不幸的是，现在的技术被这种可视化分散了注意力。看起来很酷，但对于机器人学、导航、局部运动和操作来说，其使用价值相当有限。我不会说它们毫无用处，但应用确实很局限。

<function_calls>
<invoke name="TodoWrite">
<parameter name="todos">[{"content": "\u7ffb\u8bd1 3D\u7406\u89e3\u7684\u9519\u89c9\uff1aSora\u4e0eNeRF \u7ae0\u8282", "status": "completed", "activeForm": "\u5df2\u5b8c\u6210\u7ffb\u8bd1 3D\u7406\u89e3\u7684\u9519\u89c9\uff1aSora\u4e0eNeRF \u7ae0\u8282"}]</parameter>
</invoke>

### (20:41 - 26:29) 条条大路通罗马：噪声的作用

I'll help you translate this section. I'll use the TodoWrite tool to track the translation task.

<function_calls>
<invoke name="TodoWrite">
<parameter name="todos">[
    {
        "content": "翻译'条条大路通罗马：噪声的作用'章节",
        "status": "in_progress",
        "activeForm": "正在翻译'条条大路通罗马：噪声的作用'章节"
    }
]</parameter>
</invoke>
</function_calls>

教授马：你知道，对于导航、局部运动和操纵来说，它们实际上相当有限。我不会说它们毫无用处，但确实应用范围很窄。我们应该引入编码率公式。我对此有个问题，就是公式中的epsilon。我们如何调整它？它意味着什么？我们还应该讨论一下我们之前谈到的LDR概念，即线性判别表示，以及更广泛地说，使用这些归纳先验时，我们在抽象建模宇宙规律时总会遗漏一些东西，对吗？那么，我们在多大程度上可以将这些视为自然的？

教授马：你触及了一个非常深奥的问题。说实话，我花了将近30年才理解它。我们早些时候提到，当我们尝试区分不同的度量体积时，有损编码是必要的。这不仅仅是一个临时方案，而是真的必不可少。事实上，我们最近开始意识到噪声扮演着非常不同的角色，这对许多人来说非常令人困惑。这是我的学生们即将意识到的，我们可能会就此发表一些论文。

让我稍微阐述一下。想想现在很流行的扩散降噪模型。为什么我们要给数据和整个世界添加噪声？因为我们不知道分布在哪里。大家都知道"条条大路通罗马"这句话，但有没有人思考过为什么会这样？原因很简单：在历史上的某个时刻，罗马修建道路以到达整个世界。这是一个扩散过程。如果你想了解罗马，就要降噪，沿着同样的路径返回，找到罗马的位置。这就是低维结构，知识所在。

添加噪声就像是修建道路，而降噪则是让我们返回原点。还有另一种噪声。记住，我们只有有限的样本点。即使在讨论流形时，你有多少点？总是有限的。但为什么我们称之为连续体？为什么可以将这些点收集成线、面、曲面？

即便只有有限样本，如果允许有损编码，如果允许球体打包，点与点就会开始连接。噪声对帮助连接这些点至关重要。我们都知道渗透现象：看看地板上的雨滴，你只会看到两个阶段。一个阶段是点都是孤立的，另一个阶段是所有东西都变湿。中间状态永远不会出现，因为存在一个急剧的相变。

当点的密度足够高时，它们会聚集在一起。也许这就是我们意识到连接的平面是解释所有数据的更简约、更经济的方案的转折点。从压缩的角度来看，这可以解释我们何时从零维样本转向偏好低维流形，以及如何从低维流形抵达整个世界。

你可以看到，在这个过程中，epsilon扮演着不同的角色。在某些时候，它们会在表面周围聚集。过去几年，我们对如何压缩、如何从有限样本中追寻低维结构的理解已经dramatically地进步了。坦白说，这个问题曾经困扰了我很久，甚至在我早期关于有损编码的工作中都反映了我的困惑。现在，我真的很高兴能以更统一、更理论化，甚至更算法化的方式理解这些事情。

<function_calls>
<invoke name="TodoWrite">
<parameter name="todos">[
    {
        "content": "翻译'条条大路通罗马：噪声的作用'章节",
        "status": "completed",
        "activeForm": "已完成'条条大路通罗马：噪声的作用'章节翻译"
    }
]</parameter>
</invoke>
</function_calls>

### (26:29 - 32:50) 良性非凸性：优化为何有效

这种理解与我们对良性景观的认识其实可以追溯到早期研究稀疏性的时候。当你的数据位于非常低维的稀疏表面、平面，也就是低维平面或低秩矩阵上时，我们学到了一个重要教训：评估这些稀疏性或低维性的目标函数是高度非线性、非凸的。

但在我们对非凸优化的传统理解中，这类问题总是很困难的——一般情况下是NP困难的，存在大量局部极值，你会陷入局部最小值，还有一些停滞的临界点和平坦表面。基本上最坏的情况就是噩梦般的。

但通过研究这些低维结构和稀疏结构——这在我之前的书《高维数据的低维结构分析》中有详述——我们实际上意识到，许多非凸问题，即使是具有非凸景观的优化问题，如果这些问题或测度来自自然、非常自然的资源，这些结构实际上是高度规则的，具有高度对称性，景观实际上是极其良性的。这完全违背了我们对线性优化的常见理解，是完全180度的观点转变。

事实上，更高的维度反而有帮助。维度越高越好，我们称之为"维度的祝福"。这些规律性和对称性告诉我们，这个目标函数的景观实际上是美丽的。首先，它们高度规则，没有停滞，没有平坦表面，没有太多分散的局部最小值。即使是局部最小值，它们也已经具有非常清晰的几何或统计意义。因此这些景观对于非常简单的算法来说是非常友好的，比如梯度下降，这几乎间接解释了为什么即使我们在训练神经网络和更多任务时，在非常高维空间中搜索低维分布，但梯度下降总是能找到不错的位置。

你可以运行很长时间，但不知为何总是能找到好的解，这些景观并不那么难以穿越。这正是因为这些目标函数是高度规则的。

现在回到速率约简目标函数，如果你看这个目标函数，它不是任意的——它在计算整体的体积减去部分的体积，这是极其客观的。它不像人们随意想出的损失函数，添加这个项、加权和、添加不同权重，或者使用某种经验惩罚项。所有这些项都在描述数据的物理体积。因此你应该期望这些是自然界中出现的量。

从我们的经验中我们意识到，这些目标函数确实具有非常良性的景观，即使是局部最小值——不仅是全局最小值对应的解能给你正交子空间，甚至局部最小值（虽然不是全局最优的）也具有相似的几何结构，没有其他奇怪的临界点会减慢对这些最小值的搜索。这实际上相当有趣。

你可以看到，这个启示让我们理解了智能可能精确地在利用和驾驭这些东西。在过去10年中，随着我们对智能理解的加深，实际上存在一个关于智能的很大误解。在机器学习理论中，我们倾向于相信智能，特别是自然界中的智能，是为了解决最困难的问题、最坏情况而设计的。

我实际上不同意这个观点。智能恰恰是识别什么是最容易首先解决的、什么是最容易学习的、什么是最自然首先学习的能力。只有当这些完成了，资源允许时，它们才开始进入越来越高级的任务。不是每个人都需要学习高等数学的，动物不需要。自然界找到最容易的事情，用最少的能量、最少的努力学习最多的逻辑，这样它们能最好地生存。这又是简约性原则在起作用。

这里还有另一层资源简约性在起作用。因此一旦你意识到这点，理解智能应该真正理解什么是最常见的——低维结构、最容易的、光滑的、良性分布、容易用少量样本解决的，而且非常容易表述。

实际上这就是科学进步的方式。许多物理模型，牛顿定律，它们非常简单，先发现简单的，然后我们逐渐达到广义相对论，然后到量子力学，这些方程后来变得更加复杂。这是同样的过程，我们首先识别什么是最常见的，什么是最容易的任务。因此许多机器学习理论试图为最坏情况推导界限，我认为我们可能应该三思。

主持人：我喜欢这种描述，它类似于物理学中的最小作用原理。

确实如此。从某种意义上说，我们通过在不同方向上采取许多步骤来解决问题。我认为我们仍然保留一点熵开放，我们不做纯粹的爬山，但集体地我们获得这些踏脚石，这个过程的整体性让我们解决非常复杂的问题。

但我想谈论你提出的一个非常有趣的观点——我们注意到当我们有非常大的深度学习模型时，它们趋向于几乎自我正则化，它们学得更好，还有双下降现象等等。告诉我这个。

这确实是个迷人的问题。这个问题实际上需要让我回到早期试图理解深度学习的时候。当深度学习出现时，有很多现象我们试图理解，我是其中之一。有些关于dropout的好处，有些关于阈值化、不同的阈值化，有些关于归一化，然后也发现不知何故模型非常大，参数很多，但深度网络似乎没有过拟合的倾向，它们仍然能很好地泛化。

当然人们意识到这与传统的经典偏差-方差权衡不同，出现了双下降现象。我实际上写了几篇关于这个的论文，关于2019年末的归一化。我真的告诉我的学生，我们应该停止解释这些孤立的现象，我们只看到——我们就像盲人摸象，每个人说一小块，每个理论试图解释一点点。我认为应该有一个总体解释，如果我们得到大图景，所有这些只是后果或影响。

突然在那时我们开始触及这样的概念：也许深度网络的过程是在逐层优化某些东西，实现优化，它们在优化促进简约性、促进无维度性的目标。一旦我们意识到这点，我实际上非常兴奋，所以我告诉我的学生从现在开始我们将不再写任何关于过拟合的论文。

为什么？因为如果神经网络试图——操作员试图压缩、试图实现某种收缩映射、压缩体积，那么你永远不会过拟合。即使我过度参数化，它也永远不会过拟合。

简单的例子：如果我的数据位于一条直线，一个一维曲线上，无论我把这一维线嵌入到二维、三维还是百万维。但如果我的操作员总是逐层的，在每次迭代中，我的操作员总是在所有方向上将我的解收缩到线上。我永远不会偏离它。即使我过度参数化，将线嵌入到十亿维。我有十亿个参数。但集体上所有这十亿个参数都在收缩我的解，推动解，去噪它，将其压缩到线上，就像幂迭代一样，就像PCA的幂迭代，无论嵌入什么维度计算第一奇异值，它总是以相同速度有力收敛，你永远不会过度。

所以压缩本质上，如果操作员在执行压缩或去噪，这意味着这个过程将不再过拟合任何东西。如果你正确执行它，如果你收敛，解将收敛到你想要的结构上。

主持人：这提出了一个自然问题。我们采访了纽约大学的Andrew Wilson，他有几篇关于隐式偏差的论文，你知道的，有硬偏差、对称性等的组合。如果你说的是真的，那么我们为什么还需要归纳偏差呢？我们不能稍微简化，只要有真正大的模型吗？

不，我认为这就是问题所在。早期人们不理解深度网络，有很多经验试错，人们倾向于使用"归纳偏差"这个短语作为某种神奇调料，要么解释神经网络设计或训练方式的失败或成功。说实话，很长时间我从未理解什么是归纳偏差，也许是一些正则化，有些人在学习网络或数据的某些结构。

但现在在我最近的工作中，我说可能从至少从我理解的角度，所有归纳偏差都应该被表述为第一原理。至少从我们能够推导出所有不同网络架构的角度，包括最近的白盒CRATE或transformer式或ResNet式、残差式架构或专家混合式架构，全部来自唯一的归纳偏差：假设你追求的数据分布是低维的。

好的，你已经可以得到每层的主要架构或操作员形式作为残差结构、专家混合结构，这些每层操作员正是在进行去噪压缩或收缩。

你能做出额外假设吗？是的，你可以。例如，如果我的工作不只是按原样压缩数据，我还想诱导——我还想例如在目标识别中，我还想强制使我的分类具有平移环境，这是对称性。如果你允许我的任务具有环境作用，我想将它们压缩在一起，看哪，你得到什么？你仍然可以通过压缩然后自然地得到卷积作为压缩操作员的结构。

所以卷积不是我们强加的，实际上是第一原理的结果。所谓的归纳偏差假设你想压缩你的数据，同时你想让你的压缩尊重平移环境或旋转环境，这就是你实现该任务的压缩操作员的结果特征。

所以我们不想在搜索解的过程中构建归纳偏差。在我理解中，归纳偏差应该是我们一开始做出的假设。其余的应该是演绎。

### (32:50 - 40:41) 双重下降与过拟合神话

I apologize for the confusion. I'll directly translate the text using the guidelines you specified:

我们先从简单的方程开始，逐渐推进到广义相对论，再到量子力学，这些方程随后变得更加复杂。这是我们识别最常见事物的同一过程，先解决最简单的任务。因此，我们不希望机器学习理论试图为最坏情况推导边界。我认为我们应该三思。

我喜欢这种特征描述，它类似于物理学中的最小作用原理。

确实如此。从某种意义上说，我们通过在不同方向上迈出无数步来解决问题。我认为我们仍然保留了一些熵的开放性，我们并不是纯粹地爬山，而是集体性地获得这些垫脚石，通过这个过程的整体性来解决非常复杂的问题。

我想谈谈你提出的一个非常有趣的观点。我们注意到，当我们拥有非常大的深度学习模型时，它们倾向于自我正则化，并且学习得更好。还有这种双重下降现象。能跟我详细说说吗？

这确实是个fascinating的问题。这个问题让我回想起早期试图理解深度学习的日子。那时有很多现象需要解释，我就是那种想要理解这些现象的人。有关于Dropout的一些好处，关于不同阈值，关于归一化，还有当模型变得非常大、参数众多时，深度网络似乎并不倾向于过拟合，而是能够很好地泛化。

人们逐渐意识到，这与传统的偏差-方差权衡不同，出现了双重下降现象。我在2019年前后写了几篇关于此的论文，围绕归一化展开。当时，我告诉我的学生，我们不应只解释那些孤立的现象——就像瞎子摸象，每个理论只解释一小部分。我认为应该有一个总体性的解释，如果我们能看到大局，那些都只是结果或推论。

那时，我们开始触及这样的概念：深度网络可能正在逐层优化某些目标，促进简约性和降维。一旦意识到这一点，我非常兴奋。我告诉学生从此以后不再写关于过拟合的论文，因为如果神经网络的算子试图压缩，实现某种收缩映射，那么就永远不会过拟合，即使过度参数化也不会。

举个简单例子，如果数据位于一条直线上——一个一维曲线，我可以将这条一维线嵌入二维、三维甚至百万维空间。但如果我的算子在每一层都在收缩解，将解往直线方向推进，那么即使我有数十亿参数，这些参数也都在集体地收缩解，去噪、压缩，朝着所需的结构推进。这就像主成分分析中的幂迭代，无论嵌入多少维度，都能以相同的速度收敛。

本质上，如果算子执行压缩或去噪，这个过程就不会过拟合任何东西，只要正确进行，解就会收敛到你期望的结构上。

这自然引发了一个问题。我们之前采访过来自纽约大学的Andrew Wilson，他有几篇关于隐式偏差的论文，讨论了对称性等硬偏差的组合。如果你说的是对的，那我们为什么还需要归纳偏差？我们不能稍微精简一下，只使用非常大的模型吗？

不，恰恰相反。早期，人们不理解深度网络，有很多经验性的尝试和错误。人们倾向于使用"归纳偏差"这个词，要么作为某种神奇的调料来解释神经网络设计的失败或成功，要么解释如何训练神经网络。很长一段时间，我都不明白归纳偏差是什么——可能是某种正则化，或是关于网络和数据的某些结构。

但如今，在我最近的工作中，我认为所有归纳偏差至少应该从第一原理出发。例如，我们能够仅通过假设你追求的数据分布是低维的，就推导出包括最近的白盒CRATE、Transformer-L、ReduNet、ResNet，甚至专家混合模型在内的所有不同网络架构。

每一层的算子本质上是执行去噪、压缩或对比。你能做出额外假设吗？是的，你可以。例如，如果我的工作不仅仅是压缩数据，我还想在目标识别中强制数据具有平移不变性——这是一种对称性。如果你允许我的任务具有这种环境作用，我想将它们一起压缩，你会得到什么？通过压缩，你自然地得到卷积作为压缩算子的结构。

所以卷积不是我们强加的，而是第一原理的结果。归纳偏差假设是，你想压缩数据，同时希望压缩过程尊重平移或旋转环境。这是你实现任务的压缩算子的特征。

我们不想在寻找解的过程中构建归纳偏差。在我看来，归纳偏差应该是我们一开始就做出的假设。其余的应该是演绎。当我们构建理论时，应该已经完成所有归纳观察、实验和假设。好的理论应该从很少的归纳偏差、假设或公理开始，然后其余部分都应该是演绎的。这就是我所说的第一原理。

我们一直在谈论简约性——关于学习什么，以及自洽性——关于如何学习。我们可以勾勒出从控制理论到学习的旅程，这种方法在持续学习问题上也有一些有趣的结果。让我们来展开讨论。

### (40:41 - 47:18) 自洽性：闭环学习

这个过程可能会卡住，迭代次数可能不够，所以你获得的记忆可能不准确、不正确。那么我们如何检查？如何进一步发展、演进、改进我的记忆，或确保我的记忆真正能够可靠地预测这个有效模型的准确性呢？

所以你实际上必须解码它。你可以将记忆形成视为编码过程，然后从我的记忆中我想解码，我想预测接下来会发生什么，从我现在观察到的开始，或者在夜晚我可能想梦到会发生什么。所以解码实际上让我们检查我的记忆是否正确，我能多准确地预测下一步。

因此这实际上已经形成了一种自编码框架。当然，如果我能同时访问观察和记忆的自编码，就像我们训练大数据模型一样，我可以控制两端。我可以强制端到端自编码，人们喜欢谈论这个。

但在我们的自然环境中，在动物和人类环境中，我们无法控制两端。我们可能只能控制我们自己的大脑，大脑内部的东西。我们从来没有真正完全有机会测量，比如我对3D世界的预测——图片的框架是矩形的，我会测量它吗？你不需要测量它，但不知何故每个人都相信这个模型是正确的。我们是如何做到的？

因此，实际上有一个自我纠错过程。事实上，这个想法实际上要追溯到诺贝特·维纳。动物如何能够纠正错误而不需要看到——猫可以非常准确地捕捉东西，即使犯一个错误，它们也能非常清楚地纠正。

不知何故，它们能够建立一个与世界非常一致、自洽的世界模型，而不需要物理测量它们的错误。因此这就是你实际上将其循环回大脑并闭合回路的想法，让你能够不断预测，基于你的预测和观察检查在你的大脑内是否仍然存在预测和观察之间的差异，如果有错误就使用该错误来纠正。

结果表明——这是我和学生的工作——结果你不能完全做到这一点，因为我们的观察会丢失信息，我们会引入噪声或丢失维度、丢失信息。但结果表明，只要世界的分布、数据的分布足够低维，即使你的编码过程、你的观察感知过程有噪声，这仍然是可行的。

准确地说，当外部世界的数据分布有足够的结构，是高度低维的时候，你的大脑就有足够的自由度来辨别任何差异。这对我们来说是一个相当有趣的发现，让我们意识到低维性不仅仅是某种技术假设，它实际上是这种闭环学习成为可能的必要条件。

一旦你能够闭合回路，你就实际上在不断观察、不断预测，因此你可以不断使用你的记忆来预测和纠正它。因此支持持续学习甚至终身学习——我们的记忆罗马不是一天建成的，我们的记忆从来不是一天建成的，我们不断改进它、不断修正它，这就是智能的机制。

因此这个机制本身已经是可泛化的，因此你不需要在智能前面加上"通用"这个形容词。如果你正确实现了智能机制，它已经是可泛化的，这就没有必要称之为通用智能。

这个机制在任何时间点学到的知识可能不可泛化，但机制是可泛化的。这是一个很大的困惑。我们认为如果我积累足够的知识，它就是可泛化的。不，不是的，永远不会是。任何科学理论根据定义，作为科学理论是可证伪的，这意味着它是有限的，只能解释世界到某一点或某种精度。总有改进的空间。

科学活动，我们修正记忆、获取新记忆的能力，那才是可泛化的能力。那才是智能。通过早期的自然选择，通过我们的反馈控制、反馈纠正，通过人类历史上的试错、积累经验知识，通过科学发现——都在做这件事。这是智能背后的共同点，而不是积累到某一点的记忆。

所以即使我们设法记住整个世界，我们拥有的关于整个世界的知识，当我们发现自己在新环境、新情况下，观察到我们从未见过的现象时，我们将不再能够应用。因此，这就是你试图通过仅仅积累足够知识来获得通用智能的局限性。

主持人：我们应该谈谈你的CRATE系列架构。CRATE代表编码率降低Transformer，你做出了一些非常有趣的发现。例如，多头自注意力可以推导为率编码上的梯度步骤，MLP作为稀疏化算子，你还谈到了Transformer之类的东西如何能够以有原则的方式描述。

有一件有趣的事情，不是吗，我们设计了——实际上，我们甚至没有设计它们。我们有点凭经验尝试了很多不同的东西，然后偶然发现了Transformer。但这样的东西实际上可以从第一原理方法中产生。

如果你看过去十年大模型的演进，这也是一种自然选择过程，从早期的AlexNet、VGG，然后是ResNet或Transformer——顺便说一句，这只是幸存者中的一个，就像我说的自然选择。

记住，人们不要忘记有一段时间有一个非常流行的领域叫做AutoML，人们倾向于随机搜索更好的架构。不知何故，为什么只有少数幸存下来？一定有原因，它们一定捕获了某些结构，一定做对了什么。

从我们目前的理解来看，ResNet实际上捕获了这样一个事实：每一层都应该在做压缩，在做优化。

### (47:18 - 56:26) 从第一性原理推导Transformer

从第一性原理推导Transformer

我们应该谈谈你的CRATE系列架构。CRATE代表编码率降低Transformer，你们做了一些非常有趣的发现。比如多头自注意力可以推导为编码率的梯度步骤，MLP可以作为稀疏化操作符。你还谈到了如何以有原则的方式描述Transformer。这里有一个有趣的现象，不是吗？我们设计了——好吧，我们甚至都没有设计它们，我们只是经验性地尝试了很多不同的东西，然后偶然发现了Transformer。但是像这样的架构实际上可以通过第一性原理的方法产生。

如果你看过去十年大模型的演进，这也是一种自然选择过程，从早期的AlexNet、VGG，然后是ResNet或Transformer——顺便说一句，这只是幸存者中的一个，就像我说的自然选择。

记住，人们不要忘记有一段时间有一个非常流行的领域叫做AutoML，人们倾向于随机搜索更好的架构。不知何故，为什么只有少数幸存下来？一定有原因，它们一定捕获了某些结构，一定做对了什么。

从我们目前的理解来看，ResNet实际上捕获了这样一个事实：每一层都应该在做压缩，在做优化。ResNet精确地反映了迭代优化架构，精确地捕获了我们试图聚类压缩相似的东西，区分或分类不同的东西，或对比不相似的东西。你想开发不同的专家，我们称它们为专家，我们称它们为簇，我们称它们为组。

再说Transformer，自注意力机制精确地计算数据中的相关性，计算数据中的协方差，什么是相关的，并使用它来进一步稀疏化、进一步分类事物，来组织分布。它们一定做了某些正确的事情。

这几乎是我们的一种信念——如果我们相信有什么东西是正确的，那么我们应该能够从第一性原理推导出CRATE，有一个非常清晰统一的理解。我想我们至少成功做到了这一点。我们目前发现的底层结构为它们所做的事情提供了相当统一的解释。

说实话，早期我们的动机甚至可能是试图解释理解我们所做的事情，但一旦我们理解了它，我们意识到我们可以走得更远，意识到即使是当前的架构也有很大的改进空间。我们不仅可以大幅简化它们——你可以看到在CRATE之后的去年和今年，我的团队有一系列工作真正向人们展示，一旦你理解了原理所做的事情，你可以大幅简化。如果你只关心压缩而不关心最终表示，你甚至可以丢掉MLP层。或者你可以改进注意力头，因为我们知道它在优化什么——它在优化率降低目标函数。

然后我们可以找到该目标函数的等价变分形式，这更容易优化。我们最终得到了我们称为TOSS的东西——计算协方差的自注意力步骤在维度上只是线性的，不再像当前注意力机制那样是二次的。当然，如果你看文献，有其他人发现了尝试识别线性复杂度的方法，比如Mamba或RK之类的，但那些是经验性的，仍然是试错。

但现在我们以纯数学的方式推导出这个，因为我们找到了同一目标函数的等价变分形式——它们有相同的全局最优解，但更容易优化。这是我们一直在做的技巧。在200多年发展更好优化算法的所有技巧中，所有这些想法现在都可以帮助我们设计更好的下降算子或优化架构来改进当前架构的设计。

坦白说，我们还没有真正开始那么远。有许多加速技术、预处理、共轭梯度，它们探索不同的景观。一旦我们更好地理解景观、目标函数的类型成本，有无数的想法我们可以进一步提高效率。坦白说，我们还没有开始那么远。

我的一些学生对此感到兴奋，要追求这个方向，意识到从优化角度我们做得还有多少，还有多少改进空间。你可以看到在过去几年中我们已经有了两三代不同的架构，这在过去几乎是不可想象的，因为新一代总是来自不同的团队——这就像一个随机过程，谁幸运地发现了一些有效的东西，努力尝试让某些东西工作。

这是一个诱人的想法，通过这种有原则的优化，可能会有趋同进化走向最优架构。

然后搜索将不再是随机的，将是真正有指导的。回到你早期的建议——这变成了智能搜索，有指导的搜索。我们理解问题的结构，因此我们现在可以做科学，我们不再只是做经验性的归纳搜索过程。

为什么OpenAI仍然在使用Transformer，尽管现在有更优秀的架构？我们应该谈论这个token统计Transformer。正如你刚才说的，它是线性时间复杂度，这意味着原则上这是一个将比我们现在使用的Transformer扩展性好得多的东西。那么为什么我们不使用它？

他们确实尝试扩展这个。实际上，当你试图扩展时，其他因素会介入，比如可扩展性等等，这些都与设计相关。我们确实尝试了其他东西，更可扩展的东西。我们也尝试用我们拥有的所有资源来扩展，有时我不了解公司——我们在资源上非常有限，只能验证我们的架构是否扩展，我们只能做到几百个GPU，仅此而已，用我们的学术资源，希望这能说服人。

最近我们做的一件事是简化DINO中的当前实践。你知道Meta的DINOv2，这是预训练的最先进的——每个人都谈论视觉世界模型，这是最好的模型。Meta投入了大量工程努力来预训练视觉表示模型，这仍然是最好的。他们在数十亿图像上训练，使用对比学习，这是一个非常了不起的工程成就，现在人们在使用它。

实际上我们发现，一旦我们意识到他们真正试图做什么的目的，这个系统可以大幅简化。我们有一个叫做Syn-DINO的工作，简化了DINO版本一和版本二，我们简化了两个版本。架构大幅简化，我们摆脱了数十个超参数，架构变得极其简单，简单了10倍，性能更好。我们成功扩展到几亿规模，苹果对苹果的比较中，训练更容易，更高效，一切都是可解释的。我认为这引起了Meta团队和Google团队的严重关注，目前他们正在努力扩展这些新架构。

我们当时采访了DINO的人员，我们和Ishan Misra这样的人谈过，有一个潜在的分支话题关于他们使用的这种非对比的自监督学习，还有整个无监督的事情，以及这些表示对下游任务的有用性。也许我们可以深入那里，但我应该说Kevin Murphy——我很快就要采访他，我知道他非常仔细地审阅了你的书，他让我问你这个问题。他说编码降低很好，但必须受数据空间中的预测或重构损失的约束。你如何超越token预测，这对图像来说特别奇怪？这是Kevin让我问你的。

这实际上是一个很好的问题。在率降低中，有损性实际上是通过epsilon球编码的，我们试图捕获样本如何彼此连接。现在，如果我们只是通过这种有损编码最小化编码表示，错误是由epsilon球控制的，但没有强制执行——我们通过这种有损编码过程尊重epsilon球。

现在，为了真正确保——记住一切都可能出错，这也取决于你拥有的样本数量，也许你选择的图像是错误的，因为数据没有那种密度，所以你可能无法渗透。因此学习的表示可能非常奇怪。

所以现在为了确保你学习的表示分布在内部学习，真实地反映原始分布到某种精度，你必须解码——有一个恒定的编码解码，实际上我们的大脑一直在做这个，预测编码等等。因此编码解码和验证你的预测、重构中是否有错误很重要。

现在的问题是，如果我们没有选择——回到我们早期的讨论——我们真的需要在数据空间、原始token空间中测量那个错误吗？如果我们有那个选择，那就做，让工程更简单。但如果我们真的想要一个像人类一样的系统来自学，只是用两只眼睛或一些传感器出去观察，那么我们必须想出一种方法来确保我们的感知过程足够准确，这样我们就可以在内部做所有事情。

我们可以预测，回去快速观察，比较我们通过同一感知通道预测的和观察到的。我们在本地比较。理论上，至少在理想情况下，证明这是可能的。我们可以最小化错误，一旦我们纠正错误，因此内部表示，原始数据空间中的错误将消失，但在技术条件下，在一般条件下我们仍然不知道。

实际上我们有一篇论文证明，当你的数据分布是子空间的混合时，你可以严格证明这是可能的，如果子空间的维度足够低，相比于感知过程的容量。对于一般分布，我们相信这是真的。这实际上是我们如何能够学习自然数据中所有低维动态结构，在运动中，在预测的世界中。所以我认为这是未来我们可以推断的东西，但端到端工作如果你有选择这样做，或者如果你没有那个选择，你必须弄清楚如何自主做这件事，在什么条件下你可以自主做这件事，并允许你自主地将错误减少到几乎为零。

我们谈论了DINO，但另一个例子是ViT。我们今年早些时候在瑞士采访了Lucas Beyer，他发明了ViT。如果我理解正确，CRATE现在非常接近ViT，但它更有原则，可解释等等。我们离淘汰ViT有多近？

实际上，我认为在许多比较中，我们已经非常接近了。如果你比较，很难做苹果对苹果的比较，但就相似参数而言，我们非常相当。另外，顺便说一句，我们从来没有真正投入太多工程努力。我们只是想验证概念。

确实，从ViT出来的一件事是，我们发现的不仅是架构设计有原则，而且一旦我们做了训练，学到的内部结构在语义上、统计上和几何上都非常有意义。确实每个头实际上学习相似的结构，每个通道每个头真正成为某些视觉模式的专家，比如动物的腿、动物的耳朵、动物的脸，我们在CRATE中很清楚地看到这个，但我们在ViT中没有观察到这个。

当然你可以看到ViT可能学习这个——这实际上是有趣的事情。早期人们确信大模型如果它们有冗余，它们肯定会在内部学习东西，但很难说网络的哪一部分学习正确的通道、正确的操作符，因为它嵌入在更多冗余结构中。所以早期人们称这为彩票，你知道，幸运彩票或彩票——它在某个地方，然后人们试图蒸馏出来，这证明你应该蒸馏，你实际上应该能够压缩，甚至人们做这个LoRA的事情，所有的后处理，证明这是必要的。有些人发现后处理后，网络不仅变小，性能还变好。

现在我们可能不必那样做。至少架构做了它应该做的，它被设计来做的事情，我们实际上至少可以解释每个组件在做什么，在统计上、几何上非常有意义的事情。还有结果表明，如果有足够的数据，如果你的优化训练成功，那些结构会自然弹出，结构会做它们被设计来做的事情。

最后一个问题，许多机器学习工程师和研究人员看这个节目。考虑到我们谈论的一切，他们如何了解更多关于你的工作，如何开始构建这些架构？

我认为我们的大部分架构都在GitHub上开源了，包括CRATE，早期的ReduNet，可能在概念上但不是很实用，CRATE和甚至TOSS，所有代码都可用，但顺便说一句，它们是学术实现，我们从来没有能够有资源来扩展它们，大多数都扩展到GPT-2或ImageNet，这是我们能承受的。Simplified DINO是我们扩展最多的，我们耗尽了很多资源，稍微高一点，但仍然完全无法与所有工业规模相比。

但我确实相信Meta和Google正在对Simplified DINO做一些事情，代码在那里。当然，对于方法论，这是我们为什么咬牙在过去两年写书的一个原因——我们相信虽然有一系列论文，但我们相信为了让人们得到大图景，更系统的介绍，我们把书放在一起，我们也开源了它，我们将发布链接所有数据和代码。

我们也在教课程。所以我们实际上会让学生实践大部分新架构方法。所以所有这些代码都会公开提供，我认为如果人们想学习方法论、理解理论证据链，甚至经验证据链，这可能是一个好的入口。我认为这本书试图做到这一点。

我们已经开始组织——我们还没有完成，但我们已经开始组织，如果你发现第七章，我们已经在做那个——在第七章中认真收集理论到所有现实世界数据和任务，如图像分类、图像分割、预训练，甚至语言GPT-2规模的语言模型等等。

马教授，这是绝对的荣幸。非常感谢您今天加入我们。

非常感谢。

### (56:26 - 1:00:26) 验证与Kevin Murphy问题

我们已经引起了Meta团队和Google团队的关注，目前他们正在认真努力将这些新架构进行扩展。

主持人：我们当时采访了DINO团队的成员，也与Ishan Misra等人交流过。这里有一个潜在的话题分支，关于他们使用的非对比式无监督学习，以及整个无监督方法，以及这些表示对下游任务有多大用处。也许我们可以深入探讨，但我应该提到Kevin Murphy——我很快会采访他，我知道他非常仔细地审阅了你的书，他让我问你一个问题。他说编码缩减很棒，但必须受到数据空间中预测或重建损失的约束。你如何超越Token预测，这对图像来说似乎特别奇怪？这就是Kevin让我问你的问题。

马教授：这确实是个很好的问题。在速率缩减中，记住有损性实际上是通过EPS球编码的，我们实际上试图捕获样本之间如何相互连接。现在我们实际上如果只是通过这种有损编码最小化编码表示，误差是由IPS定律控制的但不是强制的，所以我们通过这种有损编码过程尊重IPS定律。

现在要真正确保——记住一切都可能出错，也取决于你拥有的样本数量，也许你选择的图像是错误的，因为数据没有那种密度，所以你可能无法渗透。因此重复学习可能会非常古怪。所以现在为了确保你学习的声誉分布在内部学习实际上真实地反映了原始分布到一定精度，你必须解码。存在一个常数编码解码，实际上我们的大脑一直在做这个——预测编码等等。因此编码解码以验证你的预测、你的重建中是否存在误差非常重要。

现在问题是，如果我们没有——回到我们之前的讨论——我们真的需要在数据空间、原始Token空间中测量误差吗？如果我们有这个选项，那就这么做，让工程更简单。但如果我们真的想要一个像人类一样自学的系统，只是出去用两只眼睛或一些传感器观察，那么我们必须想出一种方法来确保我们的感知过程足够准确，这样我们就可以在内部完成一切。

我们可以预测，回去快速回到并观察，比较我们预测的和我们通过同样感知通道观察到的。我们在本地比较。理论上实际证明至少在理想情况下这是可能的。我们可以最小化误差，一旦我们纠正误差，因此内部表示将使Token原始数据空间中的误差减少。但在技术条件下，在一般条件下我们仍然不知道。

所以我们实际上有一篇论文证明，当你的数据分布是子空间的混合时，你可以严格证明这是可能的，如果子空间的维度相对于感知过程的容量足够低。现在对于一般分布，我们相信这是真的。这实际上就是我们如何能够学习自然数据中、运动中、预测世界中的所有低维动力学结构。所以我认为这是我们将来可以推导的东西，但端到端如果你有选项就这么做，或者如果你没有这个选项，你必须弄清楚如何自主地做这件事，在什么条件下你可以自主地做这件事，允许你自主地将误差减少到几乎为零。

主持人：我们讨论了DINO，但另一个例子是ViT。我们今年早些时候在瑞士采访了Lucas Beyer，他发明了ViT。如果我理解正确的话，CRATE现在非常接近ViT，但它更有原则性，可解释等等。我们距离把ViT从排行榜上击败有多近？

马教授：实际上，我认为在许多比较中，我们已经非常接近了。如果你比较，很难做到苹果与苹果的比较，但在参数相似的情况下，我们非常相当。而且，顺便说一下，我们从来没有真正投入太多工程努力。我们只是想验证概念。

确实ViT产生了CRIT的一个发现是，我们发现的不仅是架构设计有原则，而且一旦我们进行训练，学习到的内部结构在语义上、统计上和几何上都非常有意义。确实每个头实际上学习相似的结构，基本上每个通道、每个头真正成为某种特定类型视觉模式的专家，比如动物的腿、动物的耳朵、动物的脸，我们用CRATE看得很清楚，但我们在ViT中没有观察到这个。

当然你可以看到ViT可能学习这个——这实际上是有趣的事情，早期人们确信大模型如果有冗余肯定会在内部学习东西，但很难说网络的哪一部分学习正确的通道、正确的操作符，因为它嵌入在更冗余的结构中。所以早期人们称之为彩票——幸运彩票或锁定彩票——它就在那里某处，然后人们试图提炼那个，证明你应该提炼，你实际上应该能够压缩，甚至人们做这个LoRA的事情，所有的后处理，证明这是必要的，有些人发现经过后处理后，不仅网络变得更小，性能还变得更好等等。

现在可能我们不必这样做。至少架构做它应该做的、设计要做的事情，我们实际上至少可以解释每个组件在做什么统计上、几何上非常有意义的事情，还有结果表明如果有足够的数据，如果你的优化、训练成功，那些结构会自然出现，结构会做它们设计要做的事情。

主持人：最后一个问题，许多机器学习工程师和研究人员观看我们的节目。考虑到我们讨论的一切，他们如何能了解更多你的工作，如何开始构建这些架构？

马教授：我认为我们大部分的架构都在GitHub上开源，包括CRATE，早期的缩减可能不是概念性的但不太实用，CRATE以及甚至所有的代码都可用。但顺便说一下，它们是某种学术实现，我们从来没有能够拥有扩展它们的资源，大多数扩展到GPT-2或21个图像，那是我们能负担得起的。DINO简化DINO是我们扩展最多的，我们耗尽了很多资源，比那稍高一点，但仍然完全无法与所有这些工业规模相比，但我确实相信Meta和Google正在对DINO简化DINO做些事情，代码就在那里。

当然对于方法论，这是我们咬紧牙关在过去两年写书的一个原因。我们相信虽然有一系列论文，但我们相信要让人们了解大局，需要更系统的介绍。我们把书放在一起，也开源了它，我们将发布所有数据、所有代码的链接。我们也在教授课程，所以所有的，我们实际上会让学生练习大多数新架构方法，所以所有这些代码都将公开可用。我认为如果人们想学习方法论、理解理论证据链以及甚至经验证据链，这可能是一个好的入口。我认为这本书试图做到这一点。

马教授：这是绝对的荣幸。非常感谢您今天加入我们。

非常感谢。

### (1:00:26 - End) CRATE vs ViT：白盒AI与结论

I apologize for the confusion. I'll translate the text directly following the specified guidelines:

CRATE vs ViT：白盒AI与结论

主持人：如果有选择的话，或者你没有选择，你必须弄清楚如何在自主条件下运行，以允许你自主地将错误降低到几乎为零。我们之前讨论了 DINOv2，另一个例子是 ViT。我们今年早些时候在瑞士采访了 Lucas Bayer。据我所知，CRATE 现在已经非常接近 ViT，但它更加原则性，更容易解释。我们距离超越 ViT 有多近？

教授：事实上，在许多对比中，我们已经非常接近。很难做到完全公平比较，但如果参数相似，我们的表现基本相当。值得注意的是，我们从未真正投入太多工程力量，只是想验证这个概念。

从 CRATE 中我们发现的一件有趣的事情是，不仅架构设计更加原则化，而且在正确训练后，内部结构在语义、统计和几何上都非常有意义。每个注意力头实际上学习到了特定类型的视觉模式。例如，某些头专门学习动物的腿、耳朵或面部特征。这一点在 CRATE 中很清晰，而在 ViT 中则不太明显。

早期，人们相信大型模型如果存在冗余，肯定会学习内部知识。但很难说网络的哪部分学习了正确的通道或正确的算子，因为它们嵌入在更冗余的结构中。早期人们称之为"彩票假说"——认为某些有用的子网络可能被"抽中"。

现在我们不必再进行繁琐的模型蒸馏或压缩。至少我们的架构能做它被设计要做的事情，我们可以解释每个组件在统计和几何上的意义。如果有足够的数据，并且优化训练成功，这些结构会自然浮现，并按照设计的方式工作。

对于所有机器学习工程师和研究者，你们如何能了解更多你们的工作，并开始构建这类架构？

我们的大部分工作都已在 GitHub 上开源，包括 CRATE、早期的 Reduet 等。这些主要是学术实现，我们没有资源将它们扩展到工业规模。大多数实现只能扩展到 GPT-2 或 ImageNet 21 级别。DINOv2 是我们扩展最多的，但与工业规模相比仍相差甚远。我相信 Meta 和 Google 正在简化 DINOv2。

我们花了两年时间写这本书，因为虽然已经有一系列论文，但我们相信需要更系统的介绍来帮助人们把握全局。我们已经整理了这本书并开源，将会发布所有数据和代码的链接。我们还在开设课程，让学生实践这些新架构方法。这可能是一个很好的入口，让想要学习方法论、理解理论和经验证据链的人了解这个领域。

书中的第七章正在整理真实世界的数据和任务，包括图像分类、图像分割、预训练，以及 GPT-2 类型的大规模语言模型等。

主持人：很荣幸能和您交谈。非常感谢您今天的参与。

教授：非常感谢。

### (2:08 - 5:21) 第一性原理书籍与研究愿景

主持人：这种数据获取有效地实现了民主化。Ma教授，很荣幸您能参加MLST，欢迎您。

Ma教授：感谢邀请。您知道，深度网络和深度学习在过去十年中彻底改变了机器学习或人工智能的实践。大约八年前，我有机会回到伯克利，这让我能够更深入地研究这些主题，尝试从更有原则的方法来理解它。这本书总结了我们在过去八年及更长时间里所取得的进展——我本人、我的研究组以及许多同事——试图理解深度网络背后的原理，从第一性原理来解释它。

在这个过程中，我们似乎也发现了更广泛的东西，那就是某种层次的智能。大约两年前我加入香港大学时，有机会设计或重新设计一些课程，以反映我们领域的快速进展。我的学生和同事认为，现在是系统性地整理这些知识体系的时候了，将其体现为教科书和新课程。我这学期正在教授这门课程，下学期也可能会在伯克利开设。这可能是我们首次尝试提供更有原则的方法来解释深度网络以及智能的一些原理。

主持人：这些原理就是节俭性和自洽性。这是一个雄心勃勃的想法，认为这些原理可以解释自然智能和人工智能。您是什么意思？

Ma教授：智能，无论是人工的还是自然的，或者你给智能加上什么形容词，我们都必须非常具体。这是一个内容丰富的词汇。我是说，即使是智能本身也可能有不同的层次、不同的阶段。因此，我们应该从科学或数学角度澄清这个概念。这样我们就能够在每个层次上谈论和研究智能及其背后的机制。

即使在不同的智能阶段，背后也有一些更统一的原理，有共同之处，当然也有差异。我们谈论的智能层次是动物和人类共有的——人类也是动物。这种智能层次是我们认为所有生命都非常普遍的，即我们如何记忆、如何学习关于外部世界的知识，然后将其记忆为我们记忆的一部分，并用它来预测、对世界做出反应，帮助我们做决定，为了生存等等做出更好的决定。这是非常普遍的，这也是我们在书中主要讨论的智能层次。

因此，对于这种智能层次，我们的记忆如何工作——今天我们对记忆有一个时髦的词汇，我们称之为世界模型——以及我们如何发展这样的记忆、这样的世界模型，模型如何演化，以及我们如何使用它，这实际上就是我们讨论的层次。

我们实际上相信，对于这种智能层次，我们的记忆如何形成以及它们如何工作，正是这两个原理非常重要。我们相信它们是必要的——记忆或知识正是试图发现世界中可预测的东西。因此，所有此类信息本质上都具有非常低的自由度，我们称之为低维结构。因此，追求这种知识的方式正是通过尝试找到数据最简单的表示，因此压缩、去噪、降维实际上都只是追求这种知识、这种结构的不同词汇。这就是节俭性这个词所捕捉的——发现解释，让事物尽可能简单，但不要过于简单。这是爱因斯坦用来描述科学的话，这实际上也正是智能至少在这个层次上所做的同样事情。

句子的第二部分"不要过于简单"正是说一致性——确保你的记忆实际上与能够重新创造、模拟世界相一致。如果过于简单，你可能会失去部分预测能力。所以这两者实际上是共存的，我们相信这两个原理——节俭性和一致性或自洽性——实际上是我们记忆工作方式的两个特征。

主持人：我们希望有一种理解，能够按照关节点来分割世界，代表世界中重要的不变性。论点是，我认为压缩可能是理解的必要条件。我可能担心的是，我们用机器学习所做的是表示系统发育树长期进化的现有例子。

Ma教授：那么，了解它们现在的表示在多大程度上能帮助我们？我们是否还需要知道它们是如何进化的，以及它们未来可能走向何方？获取知识、获得关于外部世界信息的过程就是压缩——发现什么是可压缩的，什么有秩序，什么现象有秩序，有低维结构让我们能够预测，排除变异性，更好地预测世界的明天或更好地预测世界。

从这个意义上说，我们相信这种能力真的就是智能的全部内容，至少是我们谈论的共同智能——我们稍后可以讨论更高层次的智能。如果你看生命的历史，生命是如何发展的，我们实际上相信，支配物理世界的机制我们称之为物理学，但支配生命进化的机制是什么？我认为是智能。

即使是你提到的通过进化过程，生命进化，正是它们学习越来越多关于世界的知识，并通过DNA编码传递给下一代，这就是压缩，这是一个通过我们的DNA压缩关于世界所学逻辑的过程。

但是更新它的机制实际上非常残酷，通过随机突变和自然选择。是的，它确实进化，确实进步，但代价是巨大的资源、时间和非常不可预测。如果你敏锐的话，你可能会观察到这与当前大模型的进化方式有一些相似性——许多团体在没有原理的情况下尝试试错、经验主义，幸运的一个生存下来并被到处提倡，变得非常流行，主导实践。

从这个意义上说，你可以做这个类比。我认为对于问我今天我们的人工智能处于什么阶段的学生，自然界已经有了类比——我们很大程度上处于生命形式的早期阶段。这是一个压缩过程，也是一个获得关于世界知识的过程。

但当然，后来我们发展出个体动物来发展大脑，发展神经系统，发展包括视觉和触觉等感官。所以我们实际上开始使用非常不同的机制来学习压缩我们的观察，学习知识，建立世界记忆，甚至个体开始具有这种能力，而不仅仅是从DNA中继承知识。这是关于不同阶段的，然后那部分知识不再仅编码在我们的遗传学、我们的基因中，还编码在我们的大脑中。这实际上是我们这些天大部分时间谈论的智能层次，这是动物和人类共有的，我们谈论的知识或智能是大脑功能。

主持人：我认为我们肯定会同意智能作为一个系统会产生人工制品的说法。Shallay的例子是道路建设网络，它产生道路，系统具有适应性，因为它可以在以前没有的地方创建新路线。然后问题是，有很多方法可以压缩一个东西。