# AutoGrad Changed Everything (Not Transformers) [Dr. Jeff Beck]

## 📹 视频信息

- **频道**: Machine Learning Street Talk
- **发布日期**: 2025-12-31
- **时长**: 1:16:35
- **原始链接**: [https://www.youtube.com/watch?v=9suqiofCiwM](https://www.youtube.com/watch?v=9suqiofCiwM)

---

> 本文内容整理自 Northwestern University 数学博士杰夫·贝克（Jeff Beck）在 Machine Learning Street Talk 频道的深度技术访谈。

## TL;DR

杰夫·贝克认为，AutoGrad 而非 Transformer 才是 AI 爆发的真正催化剂，将 AI 开发从手工构建神经网络转变为工程问题。未来 AI 需要回归认知科学，构建类脑的稀疏结构化模型，而非纯粹的函数逼近器，才能实现真正的系统工程能力和创新。

## 📑 章节导航表

| 时间戳 | 章节标题 | 一句话概括 |
|--------|----------|-----------|
| 00:00-05:08 | 贝叶斯推理的哲学基础 | 贝叶斯推理如何体现科学方法的本质，以及大脑高效处理信息的证据 |
| 05:09-12:18 | 因果模型的优势 | 为什么因果关系简化建模，以及宏观与微观因果关系的区别 |
| 12:19-19:00 | Active Inference 社区的多样性 | Carl Friston 的统一数学框架如何吸引跨领域研究者 |
| 19:01-25:09 | AutoGrad 改变一切 | 自动微分如何将 AI 从理论研究转变为工程实践，以及当前方法的局限 |
| 25:10-34:22 | 物理世界中的体现智能 | 真正的 AI 需要基于物理世界的对象中心模型，而非语言表征 |
| 34:23-43:31 | 系统工程与创新能力 | 稀疏结构化模型如何实现组合创新，类似人类的系统工程思维 |
| 43:32-50:40 | 游戏引擎启发的架构 | 基于"大量小模型"的分布式 AI 架构，实现高效的对象发现和交互建模 |
| 50:41-57:45 | 仿真到现实的迁移 | 如何通过准确的物理仿真和结构化世界模型解决 sim-to-real 问题 |
| 57:46-1:06:55 | 贝叶斯推理的工程化 | 归一化流等现代技术如何让贝叶斯推理变得可扩展 |
| 1:06:56-1:16:35 | 对齐与细胞自动机 | AI 对齐的信念-价值分离问题，以及细胞自动机作为通用计算平台的潜力 |

## 📊 核心论点

#### AutoGrad 是 AI 革命的真正推手，而非 Transformer

- **核心内容**：贝克认为过去几年 AI 爆发有三个关键因素：AutoGrad（自动微分）、Transformer 架构、以及超大规模计算。但他特别强调 AutoGrad 的重要性被低估了。AutoGrad 将 AI 开发从"仔细手工构建神经网络和学习规则"的繁琐过程转变为工程问题，让研究者能够快速实验不同架构、非线性函数和结构。证据是 Mamba（状态空间模型）通过纯粹的扩展也能达到类似 Transformer 的效果，说明成功更多来自规模化而非特定架构。
- **关键概念**：自动微分、反向传播、梯度消失、工程化转型、架构无关性
- **实际意义**：这表明 AI 的未来发展应该专注于工程工具和方法论的改进，而不是过分迷恋特定的架构创新。同时暗示当前基于函数逼近的范式可能已达到瓶颈。

#### 当前 AI 只是函数逼近器，缺乏真正的智能结构

- **核心内容**：现有的大型模型本质上只是非常强大的函数逼近器，但"功能逼近并不等于智能"。真正的 AI 需要像大脑一样结构化的模型，需要反映我们对世界结构化理解的模型。证据是 AGI 不再是顶级公司的优先级，因为他们意识到纯粹的函数逼近无法实现真正的类人智能。人类能够进行系统工程和创新，是因为我们有对象中心的世界模型，能够理解组件之间的关系并创造新的组合。
- **关键概念**：函数逼近、结构化建模、对象中心表征、系统工程、创新能力
- **实际意义**：这意味着 AI 研究需要从追求更大的模型转向构建更智能的架构，需要融入认知科学和神经科学的洞察来设计真正类脑的 AI 系统。

#### 语言是糟糕的世界表征，物理世界才是正确的基础

- **核心内容**：当前 AI 将所有模型都接地在语言空间中（如 LangChain），但语言是"对我们思维过程和现实的极其糟糕的描述"。贝克引用认知实验证据：人们对自己行为的自我报告与实际行为模型完全不一致，"自我报告是认知实验中最不可靠的数据形式"。真正的 AI 应该接地在宏观物理世界中，因为这是我们思维的"原子元素"所来自的领域，也是我们为了生存而必须理解的环境。
- **关键概念**：语言接地、物理世界接地、自我报告偏差、宏观物理学、体现认知
- **实际意义**：这要求 AI 开发需要从文本中心转向物理世界中心的训练范式，机器人学和体现智能可能比纯语言模型更接近 AGI 的正确路径。

#### 稀疏结构化模型实现真正的系统工程能力

- **核心内容**：Transformer 和视觉模型在像素或词汇级别进行密集计算，虽然能隐式学到宏观概念，但缺乏真实世界的稀疏因果结构。人类的创新能力来自系统工程思维：知道机翼如何产生升力、喷气发动机如何产生推力，就能组合发明飞机。这需要对象中心的关系理解，知道如何将不同组件连接起来。AI 如果要具备真正的创新能力，必须有稀疏的、结构化的世界模型，能够进行组合实验而非仅仅"重新包装旧解决方案"。
- **关键概念**：稀疏结构、对象中心建模、系统工程、组合创新、关系推理
- **实际意义**：未来 AI 架构应该明确建模对象和关系，使用图神经网络或类似结构，而非依赖密集的注意力机制来隐式学习结构。

#### "大量小模型"架构比单一大模型更高效灵活

- **核心内容**：相比训练一个包含所有知识的超大模型，更好的方法是训练数千个专门的小模型，每个模型理解特定的对象类别（如书本模型、椅子模型）。这种方法的优势是：1）可组合性：在房屋数据上训练的模型和在公园数据上训练的模型，可以组合处理同时包含两种对象的环境；2）计算效率：部署时只需要加载相关对象模型；3）持续学习：遇到未知对象时可以动态从模型库中获取新模型。贝克举例：仓库机器人遇到猫时，通过惊讶信号检测未知对象，向服务器查询可能的模型，然后整合到本地环境中。
- **关键概念**：分布式模型、可组合性、动态模型加载、持续学习、惊讶检测
- **实际意义**：这种架构可能比当前的单体大模型更适合实际部署，特别是在资源受限和需要适应性的场景中。

#### 贝叶斯推理现在可以规模化，Active Inference 需要解决实际问题

- **核心内容**：贝克指出 Active Inference 社区过去20年主要在做"传福音"工作，证明框架的普适性但缺乏深度。大多数工作都是小规模的"玩具网格世界"模型，部分原因是贝叶斯推理历史上难以扩展。但现在有了新的数学工具：归一化流、自然梯度方法、快速采样技术等，使得近似贝叶斯推理变得可行。社区需要停止传福音，开始用这些方法解决真正困难的问题，证明 Active Inference 能够兑现其承诺。
- **关键概念**：贝叶斯推理扩展、归一化流、自然梯度、近似推理、实际应用
- **实际意义**：这表明贝叶斯 AI 可能迎来实用化的转折点，需要更多工程化的努力而非理论探索。

#### AI 对齐需要分离信念和价值，而非依赖奖励函数

- **核心内容**：当前强化学习中的奖励函数设计是任意的（松鼠-10分，猫-50分的例子），容易导致意想不到的后果。人类解决价值冲突的方式是通过对话分离信念差异和价值差异：先讨论事实信念，然后识别真正的价值分歧。但从行动中无法数学上分离信念和价值。贝克提出两个解决方案：1）将 AI 仅用作预测引擎而非决策者，由人类做最终决策；2）构建能够显式表达信念的 AI 系统，实现类人的信念-价值分离对话。
- **关键概念**：信念-价值分离、奖励函数问题、AI 对齐、预测vs决策、显式信念建模
- **实际意义**：这暗示当前的 RLHF 方法可能存在根本缺陷，需要开发能够进行元推理和价值对话的 AI 系统。

#### 仿真到现实迁移需要准确的物理建模和结构化世界表征

- **核心内容**：当前机器人学中仿真训练无法很好迁移到现实世界，主要原因有二：1）游戏引擎追求视觉效果而非物理准确性，包含很多技巧和 hack；2）AI 智能体的内部模型与真实世界结构不匹配。解决方案是：使用物理准确的仿真环境，训练具有结构化世界模型的机器人。这样的机器人学习的是环境的真实物理规律，而非模仿人类轨迹，因此能够泛化到新任务和新环境。这对机器人学的未来发展至关重要。
- **关键概念**：sim-to-real迁移、物理准确性、结构化世界模型、轨迹学习vs物理建模、泛化能力
- **实际意义**：这要求机器人学研究需要投资于更准确的物理仿真器和明确建模物理规律的 AI 架构。

#### 细胞自动机可能是通用 AI 计算平台

- **核心内容**：贝克对细胞自动机表现出浓厚兴趣，认为它们具有"奇迹般的任意扩展内存能力"。与传统计算机不同，细胞自动机能够用简单的局部规则产生复杂的全局行为，并且这种行为的复杂度可能超过规则本身的复杂度。虽然贝克承认这在某种程度上类似于普通计算机（都是基于简单逻辑门），但细胞自动机的涌现特性可能为 AI 提供新的计算范式，特别是在他们的"物理发现算法"中测试身份变化和重构的能力。
- **关键概念**：细胞自动机、涌现计算、身份变化、物理发现、可扩展内存
- **实际意义**：这可能为未来 AI 硬件和算法设计提供新思路，特别是在需要动态适应和自组织的场景中。

## 🏢 提及的公司/产品

| 公司名 | 讨论语境 | 重要性 |
|--------|----------|--------|
| Mistral | 基于 Mamba 架构开发的编程助手，证明非 Transformer 架构也能实现优秀性能 | ⭐⭐ |
| Meta/Facebook | Jeff Beck 当前工作地点，Carl Friston 理论的工业应用平台 | ⭐⭐ |
| LangChain | 将所有模型接地在语言空间的典型代表，被批评为错误的方向 | ⭐⭐ |
| OpenAI/Google | 顶级 AI 公司不再将 AGI 作为优先级的例子 | ⭐⭐ |
| GitHub | 拥有高质量程序数据集，对程序合成发展至关重要 | ⭐ |
| Northwestern University | Jeff Beck 的数学博士学位授予机构 | ⭐ |

## 💬 经典金句（3-5 句）

> "AutoGrad 将人工智能的开发从手工构建神经网络转变为工程问题。"
> — Jeff Beck

> "我们失去了人工智能不仅仅是函数逼近的概念。我们得到了非常好的函数逼近器，但这不是开发真正 AI 所需要的唯一东西。"
> — Jeff Beck

> "如果你想要能够思考得像我们一样的 AI，你需要让它接地在我们接地的同一个领域中。"
> — Jeff Beck

> "自我报告是认知或心理学实验中最不可靠的数据形式。"
> — Jeff Beck

> "语言是我们思维过程和现实的极其糟糕的描述。"
> — Jeff Beck

## 👤 主要人物

#### 杰夫·贝克（Jeff Beck）

**身份**：Northwestern University 数学博士；复杂系统和燃烧合成专家；贝叶斯认知科学研究者；Active Inference 社区成员
**背景**：专攻复杂系统中的模式形成，特别是燃烧合成（从不进入气相的燃烧物质）。在听到 Zoubin Ghahramani 关于狄利克雷过程的讲座后转向贝叶斯推理，认为这概括了科学方法的本质。对人脑贝叶斯假说有深入研究，特别关注行为实验中的最优线索组合证据。
**核心观点**：强烈主张 AutoGrad 而非 Transformer 是 AI 革命的真正推手；认为当前 AI 缺乏真正的智能结构，只是强大的函数逼近器；倡导基于物理世界而非语言的 AI 接地方式；提出"大量小模型"架构以实现真正的系统工程能力；坚持贝叶斯推理是大脑工作方式，现在技术条件已允许其规模化应用。

#### Carl Friston

**身份**：Active Inference 理论创始人；统一数学框架的建构者
**背景**：将信息论与统计物理学联系起来，创建了广泛适用的数学框架。通过在不同领域（流行病学、社会科学、物理学）的应用来证明框架的普适性。
**核心观点**：Active Inference 提供了描述对象和智能体的近乎统一适用的信息论框架，能够应用于从神经科学到社会科学的广泛领域。

#### Zoubin Ghahramani

**身份**：机器学习领域专家；狄利克雷过程权威
**背景**：在贝叶斯机器学习方面有重要贡献，特别是非参数贝叶斯方法。
**核心观点**：通过狄利克雷过程和中国餐厅过程等概念，为贝叶斯非参数学习奠定理论基础，这些工作深刻影响了 Jeff Beck 对贝叶斯推理的理解。

## 📺 视频类型判断

**访谈对话**：深度技术访谈，主要是主持人与 Jeff Beck 的对话形式，涵盖了从数学基础到 AI 哲学的广泛话题。

---

## 📝 完整翻译

### (0:00 - 5:08) 贝叶斯推理的哲学基础
> 贝叶斯推理如何体现科学方法的本质，以及大脑高效处理信息的证据

我的博士学位是西北大学的数学博士。我研究复杂系统中的模式形成，特别是燃烧合成，这是关于燃烧那些永远不进入气相的物质。贝叶斯推断为我们提供了经验探索的规范方法，并从整体上概括了科学方法。我就是相信这是思考经验世界的正确方式。我记得多年前我参加 Zuben Garammani 的一个讲座，他在解释狄利克雷过程先验。当时中国餐厅过程和所有这些东西都相对较新。他的解释深深震撼了我，我想，天哪，这就是总结科学方法实际运作方式的算法。

你获得一些数据，然后你获得一些新数据，你说，这与旧数据有什么相似之处？如果足够相似，你就把它们归为一类，然后你建立理论，并以这种方式适当地测试假设。这就是贝叶斯方法的本质——它关于明确的假设测试和明确的模型，特别是基于这些假设的世界生成模型。我相信这是思考世界运作方式的唯一正确方法，它概括了科学方法的结构。

老实说，真正说服我大脑是贝叶斯的，更多地与其他人进行的行为实验有关。我的主要关注点是，大脑实际上是如何做到这一点的？我指的是那些显示人类和动物进行最优线索组合的实验。就这些低级感觉运动任务而言，我们在利用进入大脑的信息方面非常高效。

主持人：有趣。所以几乎是我们如此高效，以至于唯一合理的解释是我们必须在进行贝叶斯分析。

大致如此。我的意思是，这比那个更精确一些。这不仅仅是效率。我认为线索组合实验真的很有说服力。线索组合实验的思路是，我给你关于同一事物的两条信息，其中一条信息比另一条更可靠。可靠性的程度在试验基础上变化。所以你永远不知道，比如说视觉线索相对于听觉线索会是更可靠的信息。然而，当人们结合这两条信息时，他们在试验基础上考虑相对可靠性，这意味着他们在某种意义上是最优的。

我们必须小心用词。他们是相对最优的，因为他们实际上没有使用计算机提供给你的 100% 信息。但你知道，在计算机屏幕和你的大脑之间有一些损失，原则上由此介导，但系统的行为就好像它已经最优地组合了这两个线索。它已经考虑了不确定性。这也是因为我们真正思考世界的方式——我们在决策中一直考虑不确定性。如果你曾经在雾中开车，你就会意识到这一点。

### (5:09 - 12:18) 因果模型的优势
> 为什么因果关系简化建模，以及宏观与微观因果关系的区别

大脑所做工作的 90% 是决定忽略什么。因为如果我们不这样做，我们就完了。我们接收到疯狂数量的信息，其中大部分我们甚至不费心处理。

主持人：这肯定是这样吗？你认为我们实际上可能在处理比我们知道的更多信息吗？

我们肯定在处理比行为中表现出来的更多信息。这很大程度上是因为我们在持续学习，学习需要——你闭上眼睛五年，你的视觉系统就会衰退。你失去保真度，它需要持续输入才能维持对视觉世界低级统计的理解。

没有输入，问题是这是在使用所有信息，还是只使用低级信息，这些信息我们不直接感知，但仍然在某种意义上被使用。但它被用来做什么？它被用来跟踪这些低级统计数据，我们有时需要但不总是需要。这就是为什么我说当我们说上下文很重要时，你可以认为这是我们能够灵活地在任务之间切换，这意味着拥有大量资源，维护大量资源，并且让它们保持良好的工作状态，以防我们需要它们。

这就是为什么这些自监督或无监督学习方法在开始时无处不在，让你的 LLM 给你一个关于语言的合理先验，这是你的大脑肯定在做的事情。所以在某种意义上，它在使用一切，但它实际上没有使用所有存在的信息。我想这就是我想要提出的论点。

让我们的系统运转需要处理这些复杂的人类并不立即吸引人。这么说吧。

本期节目由 Prolific 赞助。

让我们获得一些高质量的示例。让我们让合适的人类参与进来，以获得正确质量的人类反馈。所以我们试图制造人类数据或人类反馈，我们将其视为基础设施问题。我们试图让它变得可访问。我们让它更便宜。我们有效地民主化了对这些数据的访问。

主持人：你怎么看待这些广泛的隐喻性理想化？最大的一个是大脑是计算机。可能更流行的一个是大脑是预测机器。

我们对大脑如何工作的解释总是通过与我们拥有的最复杂技术的类比。这是一个非答案，对吧？几千年前，大脑是如何工作的？就像杠杆和滑轮，兄弟。当然了，别开玩笑。为什么？那是最先进的技术。在中世纪的某个时候，它变成了体液，因为流体动力学是当时最先进的技术，或者利用水力的技术是我们拥有的最先进的技术。现在最先进的技术是计算机。所以当然大脑就是这样工作的。

### (12:19 - 19:00) Active Inference 社区的多样性
> Carl Friston 的统一数学框架如何吸引跨领域研究者

主持人：哲学家过去常常认为宇宙是一台机器。我们也采访了乔姆斯基，因为他谈论机器中的幽灵，幽灵是机器中我们不理解的所有部分。但你认为现在我们可以将宇宙视为机器吗？

我认为这是思考宇宙的一种非常方便的方式。当我们将宇宙建模为具有因果结构时，我们这样做是因为它实际上具有因果结构，还是因为这是一类非常方便的模型？我认为它确实具有因果结构，但这也是一类方便的模型。

一个很好的例子是大语言模型。它们大多数（但不是全部）在预测方面都是自回归的。为什么是自回归？因为这在数学上很方便。这是利用过去并对未来做出预测的紧凑方式。这意味着这实际上就是语言的工作方式吗？不，我不认为这实际上是语言的工作方式，但这是一个计算上方便的模型。在物理学中，动量就是一个很好的例子——为什么我们需要动量来描述？我们不直接观察动量，我们只是看视频，只知道球的位置。你想推断速度，你只需取两个相邻位置的差值。

### (15:00 - 30:00) Part 2

我们确实会在某些情况下这样做。我们可能识别文化的某个方面或某个模因，并说它导致了暴力或其他问题。但你仍然需要证明它确实具有这种特性。我认为意向性是一个难题，因为它虽然具有很强的解释力，但它本身并不会演变。

当我思考一个好的宏观变量时，它应该是我能理解其随时间演变规律的变量，这才是好的宏观变量。我可以写下一个简单的方程，说明压强、体积、温度会如何随时间变化，任何微观测量都变得完全无关紧要。但让它有用的不仅仅是微观测量变得无关紧要，而是我有一个方程来描述它的行为方式，这也相当准确。所以我有一个很好的、相对确定性的宏观层面模型。

当我们谈论意向性时，它可以用作解释变量，但只有在我们理解这种意向性如何随时间变化时才有用，这涉及长期预测。这就是为什么法理学的例子让我很不舒服，因为它有点像在说，"这个人很坏"。我不知道我们如何能够识别这种意向性，除非通过非常间接的方式。但如果我们不能预测该变量如何随时间变化，它就不是一个好的宏观变量。我们只是说"你被困在这里了"，这让我感到不安。

主持人：我确实注意到主动推理社区相当多元化。

Chris：是的，在某种程度上，你会看到通常不会摩擦的人群相互碰撞，这可能会产生争论。

我认为这是卡尔的影响。卡尔实际发现了什么？他建立了信息论与统计物理学之间的联系，在某种程度上提供了一个统一的数学框架，可以广泛应用于大量情况。它将我们思考世界的方式内嵌其中，因此可以应用于许多不同领域。

卡尔花了大量时间向科学界的不同方面传播福音。他说："看，你可以将其应用于流行病学、社会科学、物理学等等。"他写了一系列文章——我认为他如此多产的原因之一是他基本上写的是同一篇论文的变体，只是应用于不同领域。这是有意的，因为他想展示这是一个统一适用的数学框架。我认为他基本上是对的。

结果是，来自所有这些不同社区的人们都被拉入他的圈子，他们对世界的思考方式截然不同，这让酒吧里的对话变得非常有趣。

### (19:01 - 25:09) AutoGrad 改变一切
> 自动微分如何将 AI 从理论研究转变为工程实践，以及当前方法的局限

主持人：是的，即使在我们的Discord服务器中，我们也有人从加密货币、基督教、现象学、心理学等角度思考问题。这真的很有趣。

Chris：这就是构建几乎通用适用的数学框架的美妙之处。你突然有了一个相对通用的语言来讨论各种不同的事物。这是我喜欢这个社区的原因——我们现在有了讨论各种事物的共同语言。当然，这意味着我们经常会话不投机，但这也是乐趣的一半。

我经常问业内人士，是什么改变了，为什么我们在过去几年中看到AI发展的大爆发。我得到三种常见回应，我都同意：自动微分、Transformer架构（尽管我对为什么是Transformer经常与人有分歧），以及我们以前从未见过的扩展能力。

我说Transformer带星号的原因是，很多人认为Transformer实现的功能，我认为更多来自于扩展。我喜欢引用的证据是Mamba——一个传统的状态空间模型，基本上是增强版的卡尔曼滤波器。他们大幅扩展了它，现在Mistral有很好的编码代理，效果相当不错。他们通过完全不同的架构，仅凭扩展就获得了许多相同的功能。

我认为最重要的是自动微分。自动微分将人工智能的发展从仔细构建神经网络、写下学习规则、经历痛苦过程这种费时费力的工作，转变为工程问题。它使得实验不同架构、不同网络、不同非线性、不同结构、不同内存方式成为可能，让人们能够以前所未有的方式尝试各种想法。

然后我们突然发现，原来反向传播确实有效。当我年轻时，反向传播被认为不可行，有两个原因：一是它不像大脑，这是对的——大脑不使用反向传播；二是梯度消失问题，人们说你永远解决不了梯度消失，它总是不稳定的。

然而，一旦我们将其转化为工程问题，开始尝试各种技巧和方法，我们发现实际上有解决方案，只是我们不会通过摆弄方程发现它们。我们必须将其转化为工程问题。一旦它成为工程问题，就实现了超大规模扩展，这导致了过去几年的所有重大发展。

但在这个过程中丢失的是，人工智能不仅仅是函数逼近。我们确实获得了很好的函数逼近器，但这不是开发真正AI所需的唯一东西。你需要像大脑一样结构化的模型，需要像我们构思世界那样结构化的模型，特别是如果你想要像我们一样思考的模型。

这在洗牌中丢失了，我们开始看到这些方法的局限性和缺陷。我们开始看到它们没有达到宣传的效果。我认为现在的标准是，根据该领域顶级公司专家的说法，AGI不再是一个巨大的优先级，他们正在减少围绕它的修辞，部分原因是他们开始意识到仅仅函数逼近无法实现目标，或者那只是炒作。

我们确实需要做些不同的事情。如果我们要达到类人智能，就需要开始引入我们对大脑工作原理的了解。这是我们大约一年前的出发点——为认知模型做同样的事情。利用我们对大脑实际工作方式的了解，利用我们对人们实际如何思考他们生活世界的了解，开始通过融合这些原理来构建像我们一样思考的人工智能。

### (25:10 - 34:22) 物理世界中的体现智能
> 真正的 AI 需要基于物理世界的对象中心模型，而非语言表征

这意味着为大规模构建类脑模型创建建模和编码框架。这是关键要素，因为显然扩展是解决方案的重要部分。现在主动推理领域的大部分工作都不是大规模的。很少有大规模的主动推理工作，大多数模型都是相对较小的玩具网格世界类型模型。部分原因是扩展贝叶斯方法确实困难。

但这也开始改变。我们现在有很多出色的数学工具和框架来近似贝叶斯推理。你永远无法精确做到，我们是在近似贝叶斯推理，我相信这就是大脑的工作方式——贝叶斯大脑理论。这让我们能够构建这种结构化模型，既按照大脑的结构，也按照我们生活世界的实际结构来构建。

因此，我们需要构建的是这个框架，它允许我们构建我们知道人们实际使用的模型类型，只是让它们更大、更复杂等等，然后利用超大规模贝叶斯推理。但这也涉及构建世界实际工作方式的模型。世界的实际工作方式为我们自己的思维提供了结构——我喜欢称之为思维的原子元素。

思维的原子元素是我们生活的物理世界的模型。我们生活的物理世界是由宏观对象组成的世界，这些对象具有特定关系并以我们理解的某种方式相互作用。比如，你坐在椅子上，这就是一种关系的例子，它支撑着你等等。

对物理世界的这种理解对我们的生存是必要的。狗也有这种理解。语言并不是那么特殊——好吧，它确实很特殊，但对我们生活世界的理解是我们获得构成思维原子元素的模型的来源，我们从中组合了更复杂的模型，让我们能够完成所有这些伟大的系统工程，构建我们拥有的伟大技术。

这就是我们想要做的——我们专注于构建基于认知启发的模型，这些模型基于我们对世界实际工作方式的理解，因为我们相信智能必须是具身的。为将这些模型组合在一起并在近似贝叶斯方式下大规模实验它们构建框架，因为我们相信这就是大脑的工作方式。

### (30:00 - 45:00) Part 3

系统将具有以物体为中心或以系统为中心的世界理解，并知道所有物体之间的关系，从而可以开始尝试不同的组合方式。这绝对是...你知道，没有这种理解，你唯一能做的就是为新目的重新调整解决方案，甚至这样做我认为也是对纯预测模型能力的慷慨解释。这就是我喜欢思考采用这种以物体为中心方法的主要优势的方式——它能够实现系统工程。

**主持人：** 什么是接地的世界模型？

**回答者：** 这真是个刁钻的问题。实际上前几天我和我的朋友 Maxi 及合作者讨论过这个话题。在某种意义上，每个模型都是接地的——它接地于给定的数据。现在，好吧，这是一个真实的陈述，但这不是我们想要的。当我们经常使用"接地的世界模型"这个词时，我们说它接地于某种东西，而这种东西不仅仅是它所看到的数据。

比如视觉语言模型。视觉语言模型是将视觉模型接地到语言空间的一种方式。这就是我们采用的方法，这就是 LangChain 所做的——它将模型和一切都转换为语言模型，视觉模型、其他所有东西都变成语言模型。当你这样做时，你实际上是在说将所有模型都接地到一个共同的语言空间中，这样它们就可以通过语言相互交流。

现在，为什么我们选择语言？老实说，我认为这是因为我们想要可以与之对话的模型。我们想要一个模型，真正的目标是让界面对我们来说方便，这很棒，这完全是你想要的。

但这引出了一个问题：什么是接地模型的正确领域？我喜欢接地模型，所以我们也使用"ground truth"这样的短语，当然 ground truth 是你在先验中编造并声称是 ground truth 的东西。什么是 ground truth？什么是接地模型的正确领域，以便让它们像我们一样思考？这是相关的问题。

### (34:23 - 43:31) 系统工程与创新能力
> 稀疏结构化模型如何实现组合创新，类似人类的系统工程思维

我的观点是，如果你想要像我们一样思考的 AI，你需要将它接地到我们所接地的同一个领域中。我们接地于这个领域。这就是为什么具身性如此重要。我们想要接地于我们进化所在的物理世界的模型。原因是这个世界为我们提供了思维的原子元素。

单个细胞生活在汤中，它拥有某种世界模型，或者表现得好像拥有一个模型——这个模型就是其环境的模型。如果它在某种程度上不理解它生活的环境，那么它就无法在该环境中继续存在和运作。所以你可以说细胞有一个接地于化学的模型——接地于它生活的汤的化学性质。这是其生存的先决条件。

当我们谈论哺乳动物和更大的动物以及生活在宏观世界中包括其他动物的生物时，那个模型是什么？至少我们可以说，我们拥有的模型中有很大一部分是接地于那个世界的，而我们知道那个世界具有我们可以理解的属性——它是以物体为中心的、关系性的，以及所有这些东西。

接地的部分更多是关于正确地接地——接地于我们所接地的领域，作为创造真正像我们一样思考的 AI 模型的途径。如果你必须选择接地模型的领域，你会选择什么？我不认为语言是正确的选择。语言对我们的思维过程和现实都是极其糟糕的描述。

我总是讲这个故事：你问任何一个与人类做过实验工作的认知科学家或心理学家，你让他们坐在椅子上，让他们做一些任务，仔细监控他们的行为，观察他们做了什么。如果实验做得好，你会有一个很好的模型来解释他们在整个实验过程中如何做出决定。然后你回去问他们为什么要这样做，他们给出的解释听起来完全合理，但与他们行为的准确模型完全不一致。

自我报告是认知或心理实验中最不可靠的数据形式。所以我们不想依赖它。我们不想将模型接地于我们知道的对世界和我们思维过程都不可靠的表示。我们想要将它接地于我们世界的良好模型中。这就是为什么我们选择专注于接地于宏观物理学领域而不是语言的模型。

**主持人：** 您能否谈谈当前主动推理的局限性？

**回答者：** 这是一个几乎普遍适用的信息理论框架，用于描述物体和智能体。它真正受到统计物理学及其与信息理论联系的启发。当你采用这两个数学结构，加上一点马尔可夫毯的概念，这样你就可以谈论宏观物体，你就有了一个非常通用、广泛适用的数学框架，可以应用于许多问题。

### (43:32 - 50:40) 游戏引擎启发的架构
> 基于"大量小模型"的分布式 AI 架构，实现高效的对象发现和交互建模

在过去20年的大部分时间里，主动推理社区所做的很多工作都是在证明它具有普遍适用性。所以有很多广度，但没有很多深度。部分原因是，如果你真的想要论证每个人都应该使用这个框架，你需要展示在这个领域的玩具示例上它确实有效。但做这件事的人，主动推理社区有这样的习惯——展示他们基本上可以处理这种心理现象，可以建模这种认知现象。看，它很好地描述了这个神经网络的行为等等。

他们一直在展示这些，但他们从未真正坐下来尝试解决任何真正重大、真正困难的问题，因为重点一直在于传教。再加上主动推理社区内部存在这种强烈的偏见，要尽可能地贝叶斯化。所以，当然，他们也回避真正困难的问题，因为贝叶斯推理在历史上一直难以扩展。

### (45:00 - 1:00:00) Part 4

没错。所以关键在于要有交互和交互类别。这不是只有一个邻接矩阵，对吧？还有一个邻接矩阵来指定——对于每种可能的交互类型都有一个矩阵。这就是给你额外灵活性的原因。另一个给你额外灵活性的因素是对事物采取稍微贝叶斯化的态度，对吧？很可能你对这个物体的所有观察，当它在房子里的时候，都非常简单。它只是放在架子上，对吧？

那么你知道什么？你知道的是那个物体放在架子上，但你必须——你知道，这是一种交互，对吧？就是有一个力向下推，有一个力向上推。你不知道关于重量的任何事情，虽然很好，但如果你对此保持误差范围，如果你对其他你见过的交互类型保持误差范围，但对这个特定物体的具体细节保持不可知态度，这给了你灵活性说，好吧，我要把它放在这个环境中，我可以对它的行为做一些预测，对吧？

但如果我向它扔一个保龄球，我会对它可能的行为做一些假设。但一旦保龄球撞到它，对吧，我可能就必须修正这些假设。这是我们采用方法的另一个关键要素，就是持续性，你必须要有某种持续学习元素。这在当代AI中真的不存在，对吧？你知道，当你构建你的大模型时，你花费数百万美元训练它，然后就完成了，对吧？是的，其他人可以来为特定任务对它进行微调，对吧？这很好，但归根结底，当你处于部署阶段时，你会关闭学习。

而在我们的方法中，我们说不，不，你认为世界的方式和学习世界的方式的一个关键方面是它是持续的和交互式的，对吧？所以，你知道，这也需要适用于我们发现的物体。我们已经学习了交互的类别，但仅仅因为我们之前没有见过特定类别的交互，并不意味着我们说其他的永远不会发生，对吧？我们仍然允许这种可能性，对吧？

然后当我们看到新的交互时，进行持续学习的快速更新。让这个起作用的原因是，你已经指定了有某些类型的交互，其中一些你之前观察过，一些你仍然不知道但可能很快会观察到，然后你可以更新你关于那个物体是否以那种方式交互的后验信念。

主持人：这样一个系统的架构会是什么样子？我想象它会是分布式的，对吧？所以，你知道，我们有所有这些不同的代理，然后我们有一致性问题，因为也许这个代理通过经验学习了这两个东西是一本书，但那边的代理，你知道，只是认为这一个东西是一本书，然后有多少物体？这会变得难以处理吗？你知道，现实地说，我不知道什么...

所以，从仿真的角度来看，这个被仿真的方式非常像视频游戏引擎仿真世界的方式。唯一的不同是力的抽象概念。那么视频游戏如何表示世界？你有所有这些资产，对吧？每个资产基本上是一个形状。也许是一个纹理、颜色，像叉子这样的东西是一个资产，对吧？或者一个小三条腿的凳子是一个资产。它有一堆属性，但基本上，你知道，这些与它的形状、颜色、质量以及所有这些东西相关联。

然后它有一套交互规则，就像牛顿力、力向量。然后你有其他东西，如水和沙子，它们有特殊的规则，因为如果你只是尝试——否则你知道你需要宏观规则来描述它们，否则计算会很疯狂。所以这非常相似，对吧？我们，你知道，当你采用这种大量小模型方法时，你最终得到的是一个巨大的视频游戏资产列表的道德等价物，对吧？

然后当它去建模一个特定环境时，对吧？当你找到你谈论的那个代理，它头脑中有这个大量小模型模型，它所做的是它看着场景说，"哦，好吧。我现在需要担心这10,000个小模型，就是这样。我不需要其他的。对吧？然后它只是在那个空间中操作，运行看起来很像视频游戏仿真的东西。对吧？所以这种稀疏性是让这种大量小模型方法起作用的原因。对吧？你可能有一百万个小模型，但在任何给定时间你只需要其中的一小部分，你只是实例化那些。

主持人：不过我想到的是，在游戏引擎中，所有这些粒子都在引擎中。我可以说这两个粒子之间的力是什么。

Jeff：是的，这叫作弊。

主持人：嗯，是的。因为你知道当你在现实世界中部署一个代理时，你不能只是问，嗯，Jeff和灯之间的力向量是什么？

### (50:41 - 57:45) 仿真到现实的迁移
> 如何通过准确的物理仿真和结构化世界模型解决 sim-to-real 问题

Jeff：没错。是的。你必须学习那些。你知道，这个模型发现，你知道，如果你把视频游戏引擎作为基准真理？我们是否能够发现视频游戏资产及其在那个游戏引擎中的属性？

主持人：那么，你的输入会是什么？会只是像素吗？

Jeff：是的，为什么不让它变得困难？如果你知道，从某种已经为你分割图像的东西开始会是作弊，对吧？如果你不能从，你知道，从底层解决难题，那么它就不是一个难题。你为什么要做它？

主持人：如果我理解正确，你谈论的技术的成功实现将是让我们从游戏引擎开始，我们几乎把AI当作一个黑盒子。所以它有输入，你知道，比如我可以向左移动，我可以向右移动，平移，上下，我可以与物体交互，然后也许有某种评分函数。我不确定，但你知道，它可以在游戏引擎中学习，它将构建这个内部模型库，代表游戏引擎世界中的事物。

如果它学习了一个稀疏的健壮模型库，你原则上可以采用相同的学习模型并将其应用到现实世界中的机器人，它会泛化。

Jeff：这就是想法。这就是我们试图——这是机器人空间中缺失的关键元素之一，你知道，如果你在仿真环境中训练模型，并不能很好地转换到现实世界环境。这可能是仿真环境过于贫瘠的结果，但也可能是人工环境实际上不是对现实世界的非常准确表示的结果，对吧？我认为主要是后者，对吧？就是说这些你知道，这些与机器人的人工代理的内部模型看起来什么都不像，不是按照它实际被训练要在其中运行的世界的结构化。我认为这些是两个最大的问题。

但也可能是你知道，为了解决这些问题你需要什么？一个是你需要为机器人的大脑建立一个好模型，它具有它生活的世界的结构。另一件事是你需要从现实世界数据到仿真数据的映射，现在我们通常使用的是视频游戏引擎。

现在，视频游戏引擎很棒。我知道我当然在每周10小时的基础上享受它们。但问题是它们不是被训练来成为现实物理的，对吧？它们中的大多数被设计成看似合理的。它们被设计成对用户看起来好。部分原因是，你知道，有很多技巧和hack被扔进去处理牛顿力学方程非常刚性的事实，对吧？当碰撞发生时，如果你对此稍微错误，你知道，然后事情可能，你知道，然后奇怪的事情可能发生，非物理现实的事情可能发生。

所以如果你有能力构建一个具有足够好的物理的环境，准确地代表现实世界，并在那个领域训练你的机器人，它们头脑中有这些模型，所以它们实际上能够学习，你知道，你在仿真世界中实现的所谓基准真理，那么我相信它们会更好地泛化到在现实世界中运行。我认为这对机器人的未来发展绝对关键，如果没有其他原因的话，现在就是这样。我的意思是，像大语言模型，所有这些自监督模型，我们目前训练机器人像收拾你的杂货之类事情的方式都是通过训练它们模仿人类行为，对吧？这是专家轨迹学习。

它们不是真正学习它们环境的物理。它们学习模仿人类行为而不压碎鸡蛋，对吧？所以如果你想让它们能够跨领域跨任务泛化，你需要摆脱对专家轨迹学习的依赖。所以这就是——这只有当你转向明确基于模型的东西，用一个准确代表它们生活的世界的模型时才会发生。

主持人：一旦你有了在世界中工作的核心模型集，那就是AI的价值吗？

Jeff：是的。所以一旦你有了核心集，那么你就有能力在现实世界中部署你的代理，它可以处理它之前无法处理的情况。我的合作者之一喜欢谈论仓库中的猫问题。对吧？那么我们有什么？现在我们有一个AI代理被训练来管理仓库，对吧？所以它理解叉车、箱子、工人等等，希望，你知道，它知道如何。然后有一天，有一天有什么东西来了它以前从未见过。那是一只猫，对吧？猫不属于任何地方。

一只猫来了，对吧？所以模型以前从未见过猫，对吧？因为那是它被训练的环境。这是这个方法的美妙之处之一。所以猫进入仓库，它想，"这到底是什么？"它搞乱了我的系统，因为我们采用这种基于自由能的方法，对吧？一个关键要素是追踪惊讶度。所以当一只猫来了，不知道猫是什么，惊讶度信号疯狂。然后它说，"好，停下。"对吧？不要碾过猫，对吧？让我们弄清楚发生了什么。

### (57:46 - 1:06:55) 贝叶斯推理的工程化
> 归一化流等现代技术如何让贝叶斯推理变得可扩展

它能做的是它可以给猫拍张照片，可以把它发送到某个有巨大模型库的服务器，并且在模型选择上已经预训练到一定程度。它说，"这到底是什么？"然后大模型库说，"哦，我认为它是，你知道，这里有七八种它可能的东西。"是不同种类的猫。也许还有一只狗扔进去，无论什么。然后它把那些小模型移植到仓库模型。然后它做一些适当的假设检验，观察猫的行为一会儿。啊，它是一只猫。把其他模型，发送其他模型回去，因为它不再需要它们了，对吧？它已经弄清楚这是什么。现在它把对猫的理解纳入到系统中。

这是采用明确的——这是采用明确以对象为中心的方法的另一个美妙之处。它给模型知道自己不知道什么的能力。这来自主动推理组件。知道自己不知道什么。当它不知道时，它可以去"打电话给朋友"。这是描述它的另一种方式。朋友会通过说"哦，那是一只猫"来回应。然后它可以采用猫的模型，将其纳入到它的仓库模型中，对吧？现在它理解了那个。

从计算角度来看，这真的很棒。这有巨大的计算优势，对吧？如果我们从一个已经知道猫是什么的大模型开始，想想我会有多少参数。会是巨大的。这个模型非常节俭，从某种意义上说，它只知道——它只需要知道两件事。它需要知道关于它存在的环境，对吧？当它看到它不知道的东西时，然后它就可以去拉取。所以这个想法是你有这个巨大的模型库。但当你为特定用例实例化一个特定的时候，你不需要它们全部。

主持人：是的。

Jeff：对吧。你只需要与那个环境相关的那些。但你可以——但这些模型持续追踪惊讶或不确定性。当它看到之前不知道的东西时，它足够聪明地说我不知道那是什么。

### (1:00:00 - 1:15:00) Part 5

并且它们和它们的——它们为这些人工智能体指定的奖励函数绝对不同于我们的奖励函数。当然，也有一些例外情况。比如像围棋、象棋这样的游戏，任何你要么赢要么输的游戏，奖励函数都很明显。但总的来说，在复杂情况下，奖励函数其实并不那么明显应该是什么。我知道有一种明确的信念认为奖励就是一切，这确实有一定道理，但问题是，你的奖励函数从哪里来？

从哲学角度来看，奖励函数选择问题并没有规范性的解决方案。除非有神的干预。这只是另一种花哨的说法，即你的价值观和我的价值观可能不同，很难说谁的更好。从实用角度来看，我喜欢指出的一个情况是，如果你在谈论自动驾驶汽车，显然你希望如果它压过一只松鼠会受到惩罚。但如果它必须在松鼠和猫之间选择，大多数人可能会希望它选择松鼠。在强化学习模型中，你会设置压死松鼠扣10分，压死猫扣50分。这些数字从哪里来？完全是模糊的，相对任意的。它们基本上是编造的。

因此依赖任意选择的奖励函数似乎是一个糟糕的想法。我们也知道事情可能会严重出错。我知道大家都厌倦了这个例子，但当你依赖奖励时，你实际上就像是在向恶意精灵许愿，或者你面临这样的风险：说"嘿，天网，结束世界饥荒。"然后它说，"没问题，杀死所有人类。"如果你不非常小心地指定奖励函数，你可能会得到非常退化的行为。

因此在强化学习环境中，对齐的目标是以某种方式将我的奖励函数，或者也许是人类的集体奖励函数，正确地融入AI智能体中。这真的真的真的很难。这真的真的真的很难，因为测量奖励函数真的真的真的很有挑战性。我们采取的方法是，我们说那么人们实际上是如何做到这一点的？作为人类，我们如何构建对齐？我们做的第一件事是试图弄清楚其他人的奖励函数是什么。奖励函数识别的问题被人们有不同信念这一事实复杂化了。

行动，也就是我们能观察到其他人在做什么，是他们的信念和他们的奖励函数或价值观的结合。问题当然是你只能观察到人们的行动。对于该做什么存在意见分歧，你想弄清楚为什么。这可能是因为你们的信念不同，也可能是因为你们的价值观不同。但这很模糊，你无法分辨。从数学上讲，甚至不可能将这两者分离。当你观察到的只是行动或决策时，信念和价值观在根本上是混淆的。

我们作为人类解决这个问题的方式是讨论我们的信念。我试图问你，你为什么认为这是正确的行动？然后你告诉我，哦，是因为这个事实、这个事实和这个事实表明，如果我这样做，那么就会发生那样的事情。然后我可以进去说，啊，我明白了，所以也许我们在信念或决策上分歧的原因是因为你不知道这个事实，而我忘记了那个事实。所以我们做的是将所有这些东西结合起来，然后看看，然后你仍然会说，嗯，我仍然认为我们应该做X，而我说不，绝对应该是Y，我们继续这种对话，直到我们每个人都对对方的信念形成机制有一个非常合理的模型，此时分歧的唯一原因就是对奖励函数的分歧。

### (1:06:56 - 1:16:35) 对齐与细胞自动机
> AI 对齐的信念-价值分离问题，以及细胞自动机作为通用计算平台的潜力

AI系统完全不可理解，这几乎是件好事，因为如果我们真的理解了它们有多缺陷，它们就会被禁止。它们是非道德的。我们不知道如何将道德放入其中。明智且安全的做法是剥夺它们的决策能力，仅仅将它们用作预言机或预测引擎。然后我们可以说，嘿，如果我做X、Y、Z会发生什么？然后它只是告诉你这是最终结果，然后我们说，哦好的，那么也许A、B、C是更好的选择。这样就将它们从参与价值观、行动中排除了——这阻止了它们使用自己的奖励函数，你可以通过训练它们只做好预测来实现这一点，这非常好，但这并没有给我们真正想要的那种自动化。

我们真正想要的是决策型人工智能体，能代表我们行动的决策者。所以要么是人在环路中，要么是像我提出的那样，我们找出如何以这种方式解决对齐问题。

但是Jeff，你是个老派的认知学家。对于像你这样的人，在缺乏明确的认知模型时，你是否总是认为我们永远无法说这些东西真的有信念或意图？我认为目前让我们能说它们没有信念或意图的原因很大程度上源于我们对它们实际工作方式的了解。比如，我毫不犹豫地得出结论说你有信念和意图，尽管很可能这个结论来自于我真的不知道你是如何工作的这一事实。我对此有直觉的感受。我假设你的工作方式和我一样。我有信念和意图，这是我对自己的看法。所以我对你得出同样的结论。

这有点像涌现。涌现是一个很有趣的概念。涌现文献中有整整一个分支将涌现现象定义为任何我没有预测到的东西，这是一个极其以人类为中心、我认为是基于无知的涌现定义，我不喜欢它。同样的事情也发生在这里。就像我们知道这些算法除了预测之外没有能力做任何其他事情，所以我们不相信它们有意图。但强涌现通常意味着因果不可约性。

无论你最终采用什么涌现定义，它都不应该基于无知。它不应该基于"哦，我发现这个的唯一方法是通过模拟它，因此它是一个涌现现象"。我甚至不喜欢那样。我对此更同情一些，但我更喜欢更实用的涌现定义。这就是为什么我喜欢向下因果作为涌现行为的基本特征。主要是因为向下因果不仅很好地解释了何时可以说现象是涌现的，它还带来了一个实用工具。它告诉你不需要对微观现象建模。

上次我们谈到了生命游戏中的Lenia，不是吗？

是的，顺便说一下，我仍在玩那个。是的，Lenia是我最喜欢的模拟之一。这不是粒子Lenia，这是传统的Lenia。他们有一个场地，有障碍物、正方形、圆形等等。然后他们有这些小生物，有点像小变形虫游泳者，背部有鳍之类的，它们游泳时会撞到这些障碍物之一，这会导致它们变形，看起来像是要死了，哦，太悲伤了。然后它重新形成并再次成为自己。

我们认为这是一个真正不错的抽象环境，可以测试物理发现算法的一些属性，因为我们采用的方法的一个好处是，当这个小游泳者撞到某个东西时，当它变形成新东西然后重新形成自己时，它可能会失去身份。我们想看看我们采用的方法是否能捕捉到这一点。它基本上做到了。它撞到障碍物，以太，它将身份改变为不同类型的对象，然后重新形成并从另一边出来，然后重新获得身份。

很有趣。顺便提一下，我们上次谈到了Alex Mor Vinsurf，他有这个卷积细胞自动机壁虎，自我修复壁虎，他现在和Google的朋友们写了一篇新论文，使用逻辑门。所以这是一个涌现逻辑门的东西，可以绘制Google标志，我还没有详细阅读，但看起来很棒。一定要看看。现在你将你的系统应用到类似生命游戏的东西中，但你仍然期望它会工作。

是的。嗯，在Lenia中有力量，对吧？有导致像素变化的规则，具有几个属性，它是径向对称的。它可以翻转符号，但任何径向对称都可以工作。然后它有极性，你可以认为这在某种意义上是一种力量，甚至是一种类似真实力量的力量。这就像一种奇怪的带电粒子。所以我仍然认为你可以——我们采用的方法基本上只是发现有效粒子之间的有效力量。我们不担心微观力量。我们不在乎。这就是宏观物理学的全部要点。你知道有微观力量控制系统整体的行为，但你感兴趣的是在你关心的尺度上做出预测的东西。所以你正在做的是发现描述不仅仅是组成小漂浮物的粒子或像素之间相互作用的有效规则，而是控制它与其他漂浮物或物理对象（如领域中的障碍物）相互作用的规则。

### (1:15:00 - End) Part 6

有一些方法可以解决这个问题，这些方法与你的AI代码代理的实际工作方式有关。例如，当他们在进行程序合成时，他们目前无法访问的是GitHub能够访问的那种数据集。他们无法访问大量编写良好的程序，这些程序完全按照预期功能运行。

《自然》杂志上有一篇论文，这实际上是神经科学对机器学习做出有趣论述的情况之一，来自Tony Zador。他所做的是拿了一堆执行各种不同任务的神经网络，然后想出了一种对它们进行基因编码的方法，目的是看看是否能够理解"我必须有一个做这个的层，然后有一个做那个的层"，然后我要做的就是紧凑地表示每层中的权重，并为此提出一个表示方法。


---

*生成时间: 2026-01-02 05:44:14*
*由 YouTube Monitor & Translator (Claude CLI) 生成*