# The Real Reason Huge AI Models Actually Work [Prof. Andrew Wilson]

## 📹 视频信息

- **频道**: Machine Learning Street Talk
- **发布日期**: 2025-09-19
- **时长**: 2:03:49
- **原始链接**: [https://www.youtube.com/watch?v=M-jTeBCEGHc](https://www.youtube.com/watch?v=M-jTeBCEGHc)

---

> 本文内容整理自纽约大学（NYU）柯朗数学科学研究所和数据科学中心教授安德鲁·威尔逊（Andrew Wilson）在 Machine Learning Street Talk 频道的技术访谈。

## TL;DR

Andrew Wilson 挑战深度学习中的传统智慧：大模型不仅更灵活，反而具有更强的简单性偏好（simplicity bias），这解释了为什么它们能更好地泛化。这种反直觉的现象通过双下降（double descent）等证据表明，参数数量并不是模型复杂度的好指标，真正重要的是函数分布的属性。

## 📑 章节导航表

| 时间戳 | 章节标题 | 一句话概括 |
|--------|----------|-----------|
| 00:00-05:00 | 挑战传统观念的开场 | 深度学习的神秘之处往往不在人们认为的地方 |
| 05:00-10:00 | 错误认知与研究动机 | 为何挑战传统智慧如此重要但充满阻力 |
| 10:00-20:00 | 模型构建的新视角 | 拥抱表达能力与软约束而非硬限制 |
| 20:00-30:00 | 偏差-方差权衡的误解 | 大模型可同时实现低偏差和低方差 |
| 30:00-45:00 | 贝叶斯视角与边际化 | 表达不确定性比选择单一解决方案更诚实 |
| 45:00-60:00 | 双下降现象的深入分析 | 更大的模型具有更强的简单性偏好 |
| 60:00-75:00 | 压缩、智能与科尔莫戈洛夫复杂度 | 智能与压缩紧密相关但需要区分结构复杂性 |
| 75:00-90:00 | 训练动态与模式连接 | 损失景观中存在连接不同解的平坦区域 |
| 90:00-105:00 | 实际应用与未来方向 | 如何在实践中实现灵活性与简单性的平衡 |
| 105:00-123:00 | AI的未来：科学发现 | 期待AI能发现相对论级别的科学理论 |

## 📊 核心论点

### 1. 大模型的简单性偏好悖论

- **核心内容**：传统观念认为更多参数意味着更复杂的模型和更高的过拟合风险。然而，Wilson 通过双下降现象展示了相反的事实：在第二次下降阶段，所有模型都完美拟合训练数据（训练损失≈0），但更大的模型泛化更好。这只能解释为大模型具有更强的简单性偏好，而非更强的表达能力。这种偏好可能源于损失景观的几何特性——平坦解的体积随维度指数级增长。
- **关键概念**：双下降（double descent）、良性过拟合（benign overfitting）、平坦性（flatness）、压缩偏好（compression bias）、损失景观几何
- **实际意义**：彻底改变模型选择策略——"如果参数解决不了问题，说明用得还不够多"。这为大规模语言模型的成功提供了理论支撑，并建议实践者应该尽可能使用更大的模型。

### 2. 诚实表达信念的模型构建哲学

- **核心内容**：Wilson 提出应该"诚实地表达我们的信念"来构建模型。现实世界是复杂的，我们的模型应该能够表达多种可能的解决方案，即使其中大部分被赋予极低概率。硬约束（如严格的等变性）是不诚实的，因为它们将某些解的概率设为零。相反，软约束允许模型在数据支持时偏离预设假设，同时在数据与约束一致时自然收敛到约束解。
- **关键概念**：软归纳偏置（soft inductive biases）、表达能力（expressiveness）、硬约束 vs 软约束、残差路径先验（residual pathway prior）、诚实信念表示
- **实际意义**：为几何深度学习等领域提供新视角——不必完全编码已知对称性，软偏置往往能达到相同效果且更具适应性。这种方法在开放系统或约束不完全适用的现实场景中特别有价值。

### 3. 贝叶斯边际化的优雅性

- **核心内容**：贝叶斯方法的核心不是先验，而是边际化——承认对正确解的不确定性。通过对所有可能解进行加权平均（按后验概率），自动实现奥卡姆剃刀原则。边际似然 P(D|M) 展示了简单模型如何自然获得更高概率：它们能生成的数据集较少，但对能生成的数据集赋予更高概率。深度集成（deep ensembles）实际上是对贝叶斯理想的更好近似，而非"非贝叶斯替代方案"。
- **关键概念**：边际化（marginalization）、认知不确定性（epistemic uncertainty）、边际似然（marginal likelihood）、自动奥卡姆剃刀、深度集成
- **实际意义**：即使完全贝叶斯推断不可行，任何形式的近似边际化（从简单集成到更复杂的 MCMC）都能改善泛化。这在高参数模型中尤其重要，因为存在更多与数据一致的解。

### 4. 无免费午餐定理的现实局限性

- **核心内容**：无免费午餐定理在数学上正确但实际上误导——它假设问题均匀分布在所有可能数据集上，这会产生大量噪声。现实世界是"所有可能数据集的一小角落"，偏向低科尔莫戈洛夫复杂度。这解释了为什么单一架构（如 Transformers）能在多个领域成功，以及为什么卷积神经网络即使在表格数据上也显示出归纳偏置——它们共享对低复杂度的偏好。
- **关键概念**：无免费午餐定理、科尔莫戈洛夫复杂度、真实世界数据分布、通用性（universality）、共享结构
- **实际意义**：支持构建越来越通用的模型而非特定领域模型的趋势。这一洞察推动了从特征工程到模态特定架构再到通用 Transformers 的演进。

### 5. 规模产生简单性偏好的几何直觉

- **核心内容**：大模型为何偏好简单解？几何直觉：平坦解（参数扰动后损失保持低值）比尖锐解更可压缩。在 D 维参数空间中，半径 R_flat 的平坦区域体积为 R_flat^D，远大于尖锐区域的 R_sharp^D（当 R_flat >> R_sharp）。随机采样更可能落在平坦区域。实验证据：即使用"猜测检查"（随机采样直到损失低于阈值）也能达到与 SGD 相当的泛化性能。
- **关键概念**：损失景观几何、平坦性与泛化、有效维度、体积主导效应、压缩与精度
- **实际意义**：SGD 的隐式偏置可能被高估——大模型的几何特性本身就偏向良好泛化。这启发了新的训练方法，如随机权重平均（SWA），通过在平坦区域内居中来改善泛化。

### 6. 模式连接性革命

- **核心内容**：传统认为神经网络的不同局部最优解是孤立的。Wilson 团队发现可以用简单参数化曲线（如二次贝塞尔曲线）连接不同初始化找到的解，且路径上训练损失保持恒定。更大模型中，连接路径接近直线。路径上不同点对应的模型在测试集上预测不同，可以集成获得更好性能。这表明存在大片相连的零损失区域。
- **关键概念**：模式连接性（mode connectivity）、损失景观拓扑、参数化曲线、集成机会、线积分优化
- **实际意义**：揭示了深度学习优化的全新图景——从孤立局部最优到连通流形。启发了随机权重平均等实用方法，通过在平坦区域内"旋转"找到更居中的解。

### 7. 大语言模型的意外迁移能力

- **核心内容**：纯文本预训练的 LLM 在看似无关任务上表现出色。实验：将 GPT 直接应用于时间序列预测（数字编码为字符串），性能超越专门模型；LLaMA 2 微调后在材料生成上超越专门的基础模型。原因：预测下一个词的过程中学会了归纳原则（如奥卡姆剃刀），这些原则在发现可压缩表示（如对称性）时普遍适用。文本预训练成为学习通用归纳原则的途径。
- **关键概念**：跨模态迁移、归纳原则学习、压缩作为通用原则、上下文学习、基础模型普遍性
- **实际意义**：支持构建通用基础模型而非领域特定模型。暗示看似不同的问题可能在某个抽象层次上共享结构，压缩可能是连接它们的桥梁。

### 8. 矩阵运算与算法发现

- **核心内容**：测试 Transformers 是否能学习基本算法而非仅做统计插值。在高斯随机矩阵上训练的模型对分布内矩阵运算良好，但对简单的恒等矩阵完全失败。通过极大丰富训练分布（各种结构化矩阵），模型开始泛化到真正的分布外矩阵，暗示从统计学习转向算法学习。这表明数据多样性可以推动从记忆到算法发现的相变。
- **关键概念**：算法学习 vs 统计插值、分布外泛化、结构化矩阵、训练分布丰富度、相变
- **实际意义**：为 AI 系统学习基本运算（如算术）提供希望——不仅仅给它们计算器，而是让它们发现算法。这种能力可能是发现新科学理论的先决条件。

### 9. 超越科尔莫戈洛夫复杂度

- **核心内容**：科尔莫戈洛夫复杂度不区分随机性导致的不可压缩性和结构复杂性。Scott Aaronson 的咖啡搅拌类比：熵单调增加，但"直观复杂度"先增后减。对机器学习的影响：均匀随机数据不可压缩但无用；复杂细胞自动机数据不可压缩但极有价值。需要新的信息度量来区分结构复杂性和随机复杂性，这将帮助评估数据价值和开发更好的先验。
- **关键概念**：结构 vs 随机复杂度、计算受限复杂度、数据价值评估、索洛莫诺夫先验局限性、混沌边缘的智能
- **实际意义**：当前的压缩偏好可能过于简单。理解不同类型的复杂性可能导致更复杂的归纳偏置，既寻求简单解释又能捕捉有意义的结构复杂性。

### 10. 通向科学发现 AI 的愿景

- **核心内容**：最终目标是开发能发现广义相对论或量子力学级别新理论的 AI。当前 AI 主要作为特定任务的黑箱函数逼近器，而非理论发现者。爱因斯坦不是通过曲线拟合发现相对论——这个过程可能不完全是数据驱动的，可能涉及符号推理。压缩性可能在选择科学假说中发挥作用，但需要超越当前范式。理论的价值在于其普遍性和生成新应用的能力。
- **关键概念**：科学理论发现、超越曲线拟合、符号与神经混合、理论的普遍价值、千年视角
- **实际意义**：呼吁 AI 研究的范式转变——从解决特定问题到发现普遍原理。这需要数值计算和符号推理的新综合，可能需要全新的架构和训练范式。

## 🏢 提及的公司/产品

| 公司名 | 讨论语境 | 重要性 |
|--------|----------|--------|
| OpenAI/Anthropic | 使用人类数据进行模型后训练的行业实践 | ⭐⭐ |
| Prolific (赞助商) | 研究 AI 中人类数据使用的调查平台 | ⭐ |
| Twofer AI Labs | 苏黎世研究实验室，专注推理和 ARC 挑战 | ⭐ |
| Meta/Facebook | Yann LeCun 的雇主，LLaMA 模型开发者 | ⭐⭐ |
| DeepMind | AlphaGo 等强化学习突破的开发者 | ⭐⭐ |

## 💬 经典金句

> "如果参数解决不了你的问题，说明你用得还不够多。"
> — Keith（主持人）对 Wilson 理论的总结

> "贝叶斯方法的定义特征不是先验，而是你想诚实地表达对正确解的不确定性。"
> — Andrew Wilson

> "压缩偏好是表面上截然不同的问题之间的桥梁。"
> — Andrew Wilson

> "现实世界是所有可能数据集的一小角落。"
> — Andrew Wilson

> "理论是首要兴趣所在，应用虽重要但不是我们关心理论的主要原因。"
> — Andrew Wilson（论科学发现）

## 👤 主要人物

### Andrew Wilson

**身份**：纽约大学柯朗数学科学研究所和数据科学中心教授  
**背景**：原康奈尔大学教员，专注于构建智能系统的原则性方法。在贝叶斯深度学习、模型构建和泛化理论方面做出了重要贡献  
**核心观点**：挑战深度学习中的多个传统观念，特别是关于模型复杂度、过拟合和泛化的理解。提出更大的模型反而具有更强的简单性偏好，通过软约束而非硬约束来诚实地表达信念。强调贝叶斯边际化在深度学习中被低估的重要性

### Keith（共同主持人）

**身份**：Machine Learning Street Talk 共同主持人  
**背景**：有丰富的机器学习实践经验，特别是在预测专家意见和集成学习方面  
**角色**：通过分享个人经验和提出实际问题来推动讨论，帮助将理论概念与实践联系起来

### Tim（主持人）

**身份**：Machine Learning Street Talk 主要主持人  
**背景**：受几何深度学习影响，采访过该领域的主要人物  
**角色**：引导深入的技术讨论，将 Wilson 的观点与更广泛的机器学习社区联系起来

## 📺 视频类型判断

**访谈对话**：深入的技术访谈，主持人们与 Wilson 教授进行多轮问答和讨论，探讨深度学习的基础理论和实践意义

---

## 📝 完整翻译

### (0:00 - 5:00) Part 1

**(0:00 - 1:15)**

当我说深度学习并没有那么神秘或特殊时，我并不是说深度学习不神秘或不特殊。我认为它实际上既神秘又特殊。只是人们通常认为它神秘的那些方面，可以通过软归纳偏置的直观概念得到相对清楚的理解，也可以通过实际上已经存在几十年的严格泛化框架得到形式化的解释。而且这些现象也可以用其他模型类别重现。

**(1:15 - 2:30)**

我认为深度学习真正的区别在于它相对的普适性——相比其他模型类别，它的适用范围有多广。这并不意味着它接近完全普适，但它朝着普适性方向迈出了重要一步。深度学习还能极其有效地进行表征学习。它的优化目标和损失地形具有相对不同且令人惊讶的特性，比如模式连通性。所以我认为深度学习确实是不同的、神秘的，但往往不是人们可能认为的那些方面。

**(2:30 - 3:45)**

我很高兴能与你们两位交谈，尽管知道有这么多人在观看会让人感到挑战。但我认为人们对泛化、模型构建和人工智能的理解存在太多根本性的误解。听到不同的观点非常重要，比如，构建一个巨大的模型是完全没问题的，这样的模型对简单解决方案会有更强的偏置，比小模型更具有奥卡姆剃刀般的行为。

**(3:45 - 5:00)**

这些观点实际上帮助我们理解那些通常被视为非常神秘的现象，如双重下降、良性过拟合和过度参数化，并为我们思考如何为感兴趣的任何属性构建模型提供了原则性方法。

Keith：存在偏置和方差之间的基本权衡。感觉你在说你可以鱼和熊掌兼得，可以将它们混合在一起仍然获胜。这与大多数人的直觉相违背。

Andrew：我认为偏置-方差权衡是一个令人难以置信的误称。实际上并不一定要有权衡。

### (5:00 - 10:00) Part 2

**(5:00 - 6:15)**

我认为这真的很重要，因为太多的进步都被停滞了，我觉得就是被困在错误认知上。一旦一定数量的人相信了某事，就很难改变他们的想法，无论你说什么。因此，我认为我们在机器学习和AI研究中陷入了各种局部最优，因为我们无法摆脱这些错误的信念。

有很多这样的例子，比如随机优化中隐式偏置在泛化中的作用，我认为很重要但也被显著夸大了。我们如何能拥有真正大型的模型，即使在数据点较少时也能很好地泛化，这一点还没有得到很好的认识。实际上，我认为这是规模对实现良好泛化很重要的主要驱动因素之一。不仅仅是灵活性，还有通过规模产生的简单性偏置。

**(6:15 - 7:30)**

我认为另一个误解是，我们应该根据可用数据点的数量来改变我们的模型。这可能是最具争议的观点。我认为我们不应该这样做的原因是，我们应该始终诚实地表示我们的信念，而我们对生成数据过程的信念通常不应该因为我们碰巧拥有的数据点数量而改变。

你实际上可以证明这些原则在实践中是有效的。你可以拥有在数据点少时表现很好，在数据点多时也表现很好的模型。这与不一定需要硬约束有关，而是将表达性与奥卡姆剃刀相结合。

Keith：是的。你知道，你只是慢慢开始说服我放弃"一万次多项式不好"的想法，我开始改变是因为你像我一样重视简单性偏置。对我来说，真正的关键是理解规模在某种程度上对简单性有偏置。我不知道为什么或它来自哪里，但我相信它。这很奇怪。

**(7:30 - 8:45)**

Andrew：我们能建立一下这个背景吗？在你去年的演讲中，你的第一张幻灯片，房间里有一群学生，你展示了一个相当简单的线性相关数据。

Keith：航空乘客数据。

Andrew：对，航空乘客数据。它有相当明显的线性季节性。你说这里有三个模型。一个基本上是 y=mx+c 之类的，就是一条直线。我想第二个是大约10个参数，第三个是10,000个参数。房间里几乎每个人都说他们更喜欢第一个或第二个。你说在这次对话结束时，我会说服你们更喜欢第三个，也就是10,000个参数的模型。

**(8:45 - 10:00)**

Keith：我在最后做了一次投票，确实发生了转变。这很有希望。我有时开玩笑说，如果我没有遇到航空乘客数据集，我不知道我的生活会是什么样子，因为它驱动了我这么多的研究。

令人惊讶的是，人们偏向于选择线性函数或三次多项式，即使在实践中他们并没有做出这样的选择。比如，用有数千万参数的神经网络来拟合有数万个数据点的训练集并不罕见。即使在深度学习流行之前，我们就在做非参数统计，我们使用像高斯过程这样的模型，这些模型受到神经网络无限极限的启发，比你能在内存中拟合的任何神经网络都更灵活。其他流行的协方差函数，比如RBF核，实际上就像在说我想使用无限阶多项式。

### (10:00 - 15:00) Part 3

**(10:00 - 11:15)**

它确实能做正确的事情。当你有大数据集时，它也能做正确的事情。所以你不需要太多人工干预。可以说，这正是机器学习真正试图实现的定义。它试图构建一个不需要手动干预的智能系统。所以我认为这是朝着这个目标的一个重要原则。

主持人：你发表过一篇论文，揭开了深度学习的一些神秘面纱，但我认为公平地说，简单性偏见在规模化时的来源仍然有些神秘，不是吗？

Andrew：确实如此。关于损失景观有一些粗略的直觉。我认为这在经验上得到了证实。比如我们可以理解，当我们构建更大模型时找到的解决方案更可压缩、更平坦等等。但这真的是正在进行的研究，我认为这是目前需要理解的最重要问题之一——为什么规模严格意义上产生简单性偏见，我们能否以比仅仅构建更大模型更优雅的方式获得这种偏见。

**(11:15 - 12:30)**

主持人：我想问你，你是理论派吗？因为我知道你是个理论人。你是理论派还是工程师？想必你两者都是，但从内心深处，你是工程师还是科学家？

Andrew：真的很难选择。在某种意义上，两者都是。我主要被试图理解事物所驱动。这可以通过各种方式来完成。我们很多论文都是从经验上试图理解模型行为。所以我觉得这是机器学习的科学方法。这种方法真正激励我的一点是，你学到的任何东西都不会过时。

**(12:30 - 13:45)**

经常有新人进入这个领域，甚至是非常有经验的研究者，都会对这个学科的快速发展感到困扰，你会看到方法在会议上发表，然后在一个月内就变得过时，或者当你去参加会议时，你看到的一切都已经被其他算法取代了，你会想好吧，如果我知道它不会被任何人长期使用，那我大量投入自己去构建一个模型还有什么意义吗？

我认为解决这个问题的一种方法是真正尝试将你正在做的事情与理解为什么事情有效结合起来。所以如果你正在构建一个在某个问题上获得更好性能的模型，这是有原因的。如果你能理解这个原因，这种理解将比那个特定模型及其使用范围更持久。

**(13:45 - 15:00)**

我真的希望做能在数百年后仍然相关的研究。所以我认为这些关于模型选择的问题，比如奥卡姆剃刀原理，人们永远不会停止询问，希望他们能够回顾阅读不仅是我的工作，还有在这个领域已经完成的工作，并认为这对我思考如何处理其中一些问题很有用。在这方面我会说我是一个科学家，我试图结合经典理论与经验主义来理解模型行为。我认为如果你真正理解某些东西，希望这是你能在实践中展示的东西。

所以我也尝试将某种实际演示与我做的很多工作结合起来。这个过程也涉及工程。有时理解那些低层次工程细节变得真正令人着迷，并导致对模型构建背后原则的意外直觉。我认为这是也许被低估的东西。很多时候你可以有一个很棒的想法，但它是否有效很大程度上取决于所有低层次细节，比如数值稳定性和其他类似的东西。当你真正深入这些细节时，有时你可以在更高层次发现对我们应该如何思考模型构建和算法设计也非常重要的东西。

### (15:00 - 20:00) Part 4

**(15:00 - 16:15)**

如何构建智能系统有一个处方。模型构建涉及的关键原则是什么？我认为尽管该领域在构建更高性能的机器学习系统方面取得了非凡的经验进展，但我们对于在处理自己的问题时应该广泛接受什么原则仍处于理解的早期阶段。这涉及理解归纳偏置的工作。我们应该做什么假设。这涉及对称性，如等变性。也许我们在建模分子或旋转不变性。图像可能是平移不变的。我们如何表示这些不变性？我们如何自动学习它们？我们如何在数据中发现可解释的科学结构，告诉我们一些也许令人惊讶的、我们以前不知道的、将超越特定应用的东西？我们如何表示决策中的不确定性？

**(16:15 - 17:30)**

可以说，一个只是点估计而没有任何误差条的预测在现实世界中并不真正可行。你知道，如果你有一辆自动驾驶汽车，它说前方5英尺有一个停车标志，误差为正负10,000英尺，你真的无法处理这些信息。但如果误差是正负1英尺，那么你真的可以根据这些信息采取行动。你知道，观察到这一点几乎让你变得偏执，好吧，现在我真的需要表示不确定性，因为如果我没有那种不确定性，那么机器学习就无法有意义地与现实世界互动，贝叶斯方法我认为是推理不确定性的一个很好的方式，所以这也构成了我研究计划的一大部分。

主持人：太棒了。

**(17:30 - 18:45)**

主持人：欢迎来到MLST。我们请到了Dugar博士。这是我们第一次面对面见面，我们已经做这个节目八年了。

Andrew：是的。

主持人：在这个频道上五年了，但我们之前也有另一个频道。是的。

主持人：Keith上周五来参加了我的婚礼。很高兴你在这里，兄弟。

Keith：是的。很疯狂。我们直到现在才见面。这将会是一次爆炸性的体验。

主持人：绝对的。是的，我们准备了一些好东西。嗯，我想开始这个话题，Andrew，我受到几何深度学习的启发。我采访过Michael Bronstein、Taka Cohen、Juan Bruner、Peta Vilichovich。他们有这个几何深度学习蓝图。我们关于那个的视频获得了50万次观看。那是一个令人惊叹的视频。

**(18:45 - 20:00)**

主持人：基本假设就像Jan概述的机器学习中的三个诅咒。有统计诅咒，就是你只有这么多数据点，到这些数据点的距离，或者这些数据点的密度，被你的数据维度所诅咒。有优化诅咒，就是你陷入这些局部最小值。还有近似诅咒。这就是他们所驱动的地方，你有这个函数类，你可以在如何构造那个函数类方面非常有主见。但如果你让它太小，你会产生近似误差，实际测试样本距离近似类有某个epsilon距离。他们说所有这些东西都被诅咒了。我想他们的处方是这种柏拉图式的想法，如果我们约束模型，如果我们用这些对称性给模型添加偏置，因为宇宙的生成函数无论如何都在使用这些对称性，那么这样做就没有明显的近似误差。那么我们为什么不这样做呢？我认为你的想法与此有些相关。你仍然认为我们应该有偏置，但你也认为我们可以兼得两者。

### (20:00 - 25:00) Part 5

**(20:00 - 21:20)**

Andrew：我们拥抱表达能力，但同时保持简洁性偏置，这可以通过压缩来形式化。这确实是对我们信念的诚实表达。我构建模型哲学的另一种描述方式就是诚实地表达你的信念。我们相信现实世界是一个复杂的地方。如果我们将这种信念与简单解决方案更可能为真的想法相结合（前提是它们与我们的观察一致），那么我们经常能在各种不同的设置中看到理想的行为。

**(21:20 - 22:30)**

所以在既要又要的问题上，我认为我们和其他人发现的最令人惊讶的发现之一是，你经常可以在增加模型表达能力的同时增加其偏置。因此，更大的模型往往更倾向于简单的解决方案。有一些关于这个的演示一直就摆在眼前，比如双下降现象。这个想法是，当你增加模型灵活性时，你的泛化错误首先会降低。所以当你捕获数据中更多结构时，它会改善。当你开始过拟合时它会变差，然后又会变好。

**(22:30 - 23:40)**

在第二次下降中，你考虑的所有不同模型通常都完美拟合了训练数据。因此，更大的模型能够更好地泛化的唯一可能方式是因为它们有某种其他类型的偏置，比如简洁性偏置，而不是更具表达能力。所以我认为研究人员一次又一次地对这样的事实表示惊讶：他们可以拥有这些大规模模型，十亿参数以上的模型在相对较小的数据集上训练却没有过拟合。但实际上，如果他们让模型更大，它们过拟合的可能性会更小。所以表达能力和软约束经常可以对齐。

**(23:40 - 24:10)**

主持人：所以如果参数不能解决你的问题，那就是你用的不够多。

Andrew：我们总是想要更多。

主持人：在专家建议预测中，我们从理论上知道，对我来说从经验上也知道，通过在混合中保留所有这些其他专家，你要为此付出代价。

**(24:10 - 25:00)**

在我的特定情况下，混合中有历史专家，每一次预测，它们仍然有一些权重。你必须给它们一些epsilon权重，否则它们会死掉，这实际上会损害你的性能。所以问题是，当新机制到来时，对你来说是学习新机制的成本更好，还是将旧机制带回来的切换成本更好？这与任何集成或任何约束偏置的限制集合都是一样的，在偏置和方差之间存在这种根本的权衡。感觉你在说你可以既要又要，你可以将它们保留在混合中并且仍然获胜。这与大多数人的直觉相反。

### (25:00 - 30:00) Part 6

**(25:00 - 26:15)**

机器人采取某些行动可能会导致失控，在这种情况下我实际上需要它节约能量，避免那种正反馈。所以我想我们可能仍在与过拟合这个问题作斗争。这是一个真实存在的问题，是一个已知的问题。我们如何知道自己是否在以不良方式过拟合？也许我们没有足够的参数，我们被困在到达双下降之前的区域，或者在实践中如何避免不良过拟合的实际后果？

主持人：过拟合确实存在，绝对如此，但我认为关于我们应该如何处理它的传统智慧从根本上是错误的。这植根于偏差-方差权衡等理论，比如让我们约束假设空间，这样我们就不会对数据产生糟糕的拟合，从而做出糟糕的预测等等。

**(26:15 - 27:30)**

而相反，我认为如果我们只是坦诚地相信存在许多可能的解决方案——即使对于任何给定问题它们可能性不大——结合这种简单性偏置，我们就不会倾向于过拟合。有趣的是，解决方案几乎与人们认为原则上应该采用的方法相反。比如构建更小的模型通常是避免过拟合的处方。

主持人：或者强制简化。

嘉宾：完全正确。而实际上，当我们构建更大的模型时，我们通常实际上开始缓解过拟合，双下降就是一个很好的例子，因为第一次上升是由于对数据的过拟合，但随着我们不断增大模型，过拟合得到了缓解。

**(27:30 - 28:45)**

主持人：通过某种我们仍然不完全理解的现象，比如随着模型变得更大，简单性重新回到画面中的能力。

嘉宾：对的。所以在第二次下降中，模型通常完美拟合训练数据。因此损失不再是我们选择模型之间的决定性因素。而是其他东西。所以那些其他偏置开始占主导地位。我认为这在人们谈论平坦性等现象时非常重要。平坦性是这样一个概念：如果你扰动参数，你仍然可以得到相对较低的损失值。关于平坦性的作用以及它在理解泛化等方面应该有多相关，存在各种各样的争论。

**(28:45 - 30:00)**

但我认为很多这些讨论忽略的是，它只是控制泛化的众多属性之一。如果我必须在损失很高但非常平坦的模型与找到低损失但相对尖锐的解决方案的模型之间做选择，我几乎肯定会选择低损失解决方案。所以当你处于第二次下降区域时，你现在控制了损失值，只是解决方案的平坦性在增加。这是知道你可能在曲线哪一侧以及思考应该让模型多大的一种方法。但我也想说，总是让你的模型尽可能大。只需尝试将你所做的与某种简单性或压缩偏置结合起来。关于如何做到这一点存在问题，但我认为我们有很好的方法来思考如何做到这一点。

### (30:00 - 35:00) Part 7

**(30:00 - 31:20)**

嘉宾：是的。但你能给个例子吗？什么时候对抗一种错误观念是困难的，为什么这很重要，以及这个过程涉及什么？

有一种方法是采用一些近似贝叶斯推理程序，并将其与深度集成作为非贝叶斯替代方案进行对比。通常我实际上并不太在意什么被称为贝叶斯或不是。就像智能一样，什么是智能，某些东西是否是一个好的表示，所有这些东西。让我们只是将这与我们试图解决的任何问题联系起来。

但这实际上有些问题，因为得出的结论似乎是，如果深度集成比某种变分近似或某种MCMC程序工作得更好，那么答案就是要非贝叶斯，比我们历史上更不贝叶斯。事实证明这完全是我们应该如何思考模型构建的错误方向。

**(31:20 - 32:45)**

因为在给定的计算预算下，这些深度集成程序实际上在近似后验贝叶斯预测分布方面做得更好。所以在做边际化，实际上处方应该是我们实际上需要更加贝叶斯。这是一件令人沮丧的事情，但也很难处理，因为已经有很多论文，人们基本上写道这些深度集成是非贝叶斯替代方案。

所以出来说实际上它们在做比所有这些被称为贝叶斯的方法更好的贝叶斯理想近似，某种程度上是在同时对抗数百篇论文。但感觉这是一件非常重要的事情。我们实际上在很多论文中都微妙地做过这件事，在某篇论文的某个小节中会提到这样的事情，但从未真正被内化，因为它从未成为焦点。

**(32:45 - 34:00)**

所以我想，好吧，博客文章是做这件事的正确方式。让我们全部关注这个。我认为最终实际上是博客文章改变了人们的想法。在那之后我再也没有看到过人们做出这种分离的论文。但我也认为这确实有点触及了神经。

主持人：是的。但我们应该如何处理模型构建？我们如何在不过拟合的情况下拥抱表达性？

嘉宾：当我说我想拥抱表达性时，这个想法有一些微妙性。这基本上意味着在某些情况下，也许我们想要表示很多解决方案，但我们给它们分配几乎为零的概率，但不是零概率。所以在我们看来，它们是可能的但不合理的解决方案。

**(34:00 - 35:00)**

然后如果数据告诉我们一些事情，比如我们真的应该关注某种可能会让我们惊讶的结构类型，模型实际上可以对此做出响应。如果那种结构实际上不存在，那么你的模型不会比在这些方面受到精确约束的模型表现差很多。

就我们应该如何一般性地处理模型构建而言，如果你有一个软偏置，对某些类型的约束相对于其他约束的温和鼓励，通常你可以做得和完全受约束的模型一样好。原因是你要为偏离那个约束付出某种代价，即使它很小。所以如果你能在约束下完美地拟合数据，你就会坍缩到那个模型上。

### (35:00 - 40:00) Part 8

**(35:00 - 36:15)**

你知道，你仍然要为偏离约束付出某种代价，所以如果它是对数据的良好描述，你可以完美地拟合它，那么你经常会坍缩到那个约束上。虽然我不想忽视尝试校准这些偏置的重要性，它在某些情况下可能很重要，但在很多情况下，一个非常温和的偏置就足够了。

所以也许为了让其他贝叶斯学者更熟悉这个领域，你知道参数的先验分配。目标总是尝试找到一个相对无知但编码某些非常软约束类型的先验，比如也许它是一个尺度不变参数或位置不变的先验。

**(36:15 - 37:30)**

总的来说，很多时候这些先验可能只相当于一个或两个数据点的价值，但它们足够小，可以很容易被足够的数据覆盖。但即使是那么小的量也足以避免愚蠢的答案，比如你知道正面朝上的概率是无穷大或类似的东西。这是类似的吗？

我认为这是一个合理的类比。我还要补充的是，我们无法摆脱做假设。所以尽管我支持拥抱表达性，并对某些类型的解决方案有相对软的偏置而不是硬约束，但机器学习意味着通过例子学习。

**(37:30 - 38:45)**

我们不能在不做假设的情况下做到这一点。问题只是我们应该做什么假设，在什么抽象层次上？也许在令人惊讶的大量不同问题中，拥抱表达性结合某种简单性就足够了——某种奥卡姆剃刀偏置，可以用压缩来形式化。

经验上，简单模型效果更好。

具有讽刺意味的是，考虑到人们经常对这种想要总是拥抱灵活性的想法表示惊讶，在深度学习之前，社区已经开始接受这样一个概念，即我们想要任意灵活的模型。

**(38:45 - 40:00)**

事实上，我在博士期间研究的模型类别——机器学习中的高斯过程——某种程度上受到这样一个想法的启发，即我们想要真正大的神经网络。拉德福德·尼尔，当时在多伦多杰夫·辛顿组的统计学家，说，好的，我们想要建造房子那么大的模型，我是贝叶斯主义者，我将真正拥抱表达性。

所以我将采用具有无限隐藏单元数的神经网络的无限极限，使用中心极限定理论证和特定类型的协方差函数，这实际上会收敛到高斯过程。人们想，哦，好吧，那太棒了。让我们只使用高斯过程，因为它们在很多其他方面更有原则性，比如它们对一堆设计决策不太敏感，等等。

### (40:00 - 45:00) Part 9

**(40:00 - 41:15)**

这使得它具有极其出色的数据效率。因此，高斯过程如今的主要用例之一是在一种叫做贝叶斯优化的领域，你试图最大化某种黑盒目标。这不是你有闭式表达式的东西，比如它可能是神经网络的泛化性能作为其某些超参数的函数，或者某些真正昂贵的物理仿真作为某些参数的函数，你基本上想要尽可能少地查询这个目标以获得良好的结果。高斯过程是这个目标的惊人代理模型，你使用不确定性来有效地进行探索。

**(41:15 - 42:30)**

我认为你可以拥有表达性强但未必复杂的模型。它们仍然有非常强的简单性偏差，对某些类型的解决方案有非常强的偏好，但同时它们代表了问题的广泛可能解决方案。我认为这就是你如何调和拉德福德·尼尔所说的和我们在过拟合等实践中看到的东西。我认为有一个常见的误解，即模型的表达性和其归纳偏差是矛盾的。模型越有表达性，其假设就越弱，某种意义上它拥有的归纳偏差越少，数据效率就越低。

**(42:30 - 43:45)**

我们发现的令人兴奋的事情是，当你把大型Transformer做得越大时，实际上其归纳偏差就越强，模型变得更有表达性，同时拥有更强的简单性偏差。因此我认为你可以在某种意义上将这两者一起扩展，这就是你如何避免过拟合和其他无法实现良好泛化的问题。我认为这最清晰的证明之一是一种叫做双重下降的现象。

**(43:45 - 45:00)**

双重下降是这样一种现象：通常在横轴上你有模型的表达性，比如残差神经网络每层的单元数，在纵轴上你有泛化误差。最初，当你增加模型的表达性时，泛化误差会减少，它能够更好地拟合数据并捕获更多结构。然后它开始下降，开始上升，这对应于某种过拟合，然后它再次下降，这就是为什么它被称为双重下降，因为有第二次下降。在第二次下降中，所有模型通常都有大约零的训练损失。因此，随着你增加模型的表达性，训练损失持续下降，直到大致参数数量等于数据点数量。这意味着第二次下降中更大的模型不能因为更灵活而泛化得更好。它们都完美地拟合训练数据。更大的模型必须有某种偏差来实现更好的泛化。事实证明，这是一种简单性偏差，一种我们可以测量的压缩偏差。

主持人：让我们深入讨论这一点。据我理解，你的论文认为宇宙存在某种生成函数，在某种意义上它是相当简单的。France谈论过这个，他谈到万花筒效应，你知道我们有生成函数，然后它以无数不同的方式组合在一起，我们看到万花筒，聪明的人可以将万花筒分解回原始的生成函数。你还说过自然数据特别是相当低维的或相当简单的，神经网络偏好简单数据，甚至我想对此稍微质疑一下，因为我发现神经网络在训练早期阶段偏好简单数据，但当你继续训练它们时，它们似乎会复杂化和复杂化，学习更多高频数据。你如何看待这个问题？

**Marc Raibert：** 这是一个很好的问题。神经网络倾向于在学习噪音之前学习结构是一个非常重要的观察。有一个问题是，拟合噪音的能力在多大程度上损害了它们的泛化能力。有另一种叫做良性过拟合的现象，模型通常拟合信号和噪音的混合，但拟合噪音并不会显著降低其泛化性能。这通常被视为深度学习特有的东西。面对我们对泛化了解的一切，这部分是因为试图理解泛化的经典框架，如VC维度和Rademacher复杂性，本质上是在测量模型拟合噪音的能力。

然而，还有其他泛化框架，比如我们探索的PAC-Bayes和可数假设界限，它们不会惩罚表达性假设空间，而是试图理解模型对某些解决方案相对于其他解决方案有什么样的软偏好。我们已经能够使用一种叫做Solomonoff先验的东西对这些大型模型的泛化性能实现相当严格的界限。Solomonoff先验说我们实际上有一个最大过参数化的模型。我们可以表示计算机上的每一个可能程序，但我们对具有所谓低Kolmogorov复杂性的解决方案有指数级更强的偏好，因此它们是非常可压缩的。Kolmogorov复杂性是能够生成我们假设的最短可能程序。

### (45:00 - 50:00) Part 10

**(45:00 - 46:15)**

我们已经能够对这些大型模型的泛化性能实现相当严格的界限，使用一种叫做Solomonoff先验的方法。Solomonoff先验说我们实际上有一个最大过参数化的模型。我们可以表示计算机上的每一个可能程序，但我们对具有所谓低Kolmogorov复杂性的解决方案有指数级更强的偏好，因此它们是非常可压缩的。

**(46:15 - 47:30)**

我们能够为这些非常大的模型得到这些严格的泛化界限，事实上当我们让模型变得更大时，泛化界限会变得更好，这表明这并不是对这些模型实际行为的糟糕描述。因此，使用Solomonoff先验进行归纳被称为Solomonoff归纳。看起来当我们使这些transformer变得非常大时，我们将这种表达性与对低宏观复杂性解决方案的强烈偏好相结合。

**(47:30 - 48:45)**

另一个观察是模型正变得越来越通用。在20或30年前，典型的做法是将尽可能多的专家知识编码到你正在构建的模型中，并将其非常具体地定制到你正在考虑的问题，因为像"没有免费午餐"定理这样的结果表明，在从所有问题的分布中均匀采样的所有问题上，每个模型在期望上都是同样好的。有几个"没有免费午餐"定理。另一个说单个学习者不会在所有问题上都表现良好。

**(48:45 - 50:00)**

现在，这些结果在数学上是正确的，但它们并不真正对应于现实世界的数据生成分布。现实世界是所有可能数据集的一个小角落。它不是从那个分布中均匀抽取的。如果你从那个分布中抽取数据集，你主要会得到噪音。所以我想问题是，现实世界的数据生成分布真正是什么样的？看起来有一种偏向于生成具有低Kolmogorov复杂性的数据的倾向，而我们的模型共享这种偏向，这就是为什么我们看到了越来越通用的系统。

### (50:00 - 55:00) Part 11

**(50:00 - 51:15)**

关于为什么扁平解的相对体积会随着神经网络规模增长而呈指数级主导尖锐解的体积，我们可以这样理解：想象损失表面上有一个半径为RA的扁平区域，你在该半径内扰动参数仍能保持低损失值；另一个区域半径为RB，且RB远小于RA。当你增加模型中的参数数量D时，RA的D次方开始相对于RB的D次方占据主导地位。

**(51:15 - 52:30)**

我们在实践中确实观察到了这一现象。马里兰大学Tom Goldstein团队有一个研究结果，他们试图理解SGD和随机优化的隐式偏置在泛化中的作用。通常SGD被认为是深度学习中实现泛化的重要组成部分。人们认为我们有这些非常复杂的非凸目标函数要最小化，而SGD以某种方式拯救了我们，SGD的隐式偏置引导我们的过程穿越损失景观的某个区域，该区域代表既有低损失又能泛化的解，而不是低损失但不能泛化的解。

**(52:30 - 53:45)**

但事实证明，你实际上可以使用全批量梯度下降并获得与使用SGD相当的泛化效果，即使你不尝试在损失函数中明确地加入隐式正则化。另一篇论文显示，即使你只是猜测和检验——随机采样解向量，然后在损失低于某个阈值时停止——泛化效果也与使用SGD或Adam相当。这对应于我们的几何直觉：如果你只是向损失景观投掷飞镖，一旦损失低于某个阈值就停止，随着模型参数数量的增加，你更可能落在低损失且良好泛化的区域，而不是低损失但糟糕泛化的区域。

**(53:45 - 55:00)**

当然，这不是一个严密的论证。增加模型参数的方式有很多种，不一定会真正影响损失景观的几何性质。然而，这确实与我们的实证观察相符，不仅仅是像猜测和检验这样的结果。如果我们观察双重下降现象，在第二次下降中，我们可以测量这些模型的有效维度，即Hessian矩阵中相对较大值的数量，本质上是损失景观中尖锐方向的数量。随着模型变大，这个数量会减少。

关于明确引入Kolmogorov复杂性惩罚项的问题，我一直在思考这个问题，但很难操作化。你可以通过计算模型训练后压缩文件大小的上界来评估这些界限，但为了将其用作某种正则化器，你需要考虑对某个假设集合的压缩，而不仅仅是模型找到的单个假设。

### (55:00 - 1:00:00) Part 12

**(55:00 - 55:50)**

我看过那篇文章。

那篇文章最近在我们的Discord上分享过。

很好，欢迎加入我们的Discord。

我很乐意。我们确实有一个想法来解决这个问题，但这篇博文将此与熵增进行了比较。系统的熵在增加，Kolmogorov复杂性也在增加。但该系统的直观复杂程度实际上是非单调的。最初它具有低熵、低复杂程度，然后是中等复杂程度和熵，最后是高熵和低复杂程度。

**(55:50 - 57:15)**

你可以在机器学习的语境下思考这个问题，从数据价值的角度来推理。如果我从均匀随机分布中采样数据，那数据将非常难以压缩。我需要记住所有内容，这些数据是不相关的，对于学习表征、训练模型来说可能毫无用处。相比之下，我可以想象某种复杂的细胞自动机问题，某种具有非常复杂的泛化或生成规则的生命游戏问题。这样的数据实际上对于学习表征可能具有巨大的价值。有一篇论文简要研究了类似内容，叫做"混沌边缘的智能"。我认为还有其他类似的结果表明，即使你最终希望模型具有某种奥卡姆剃刀偏好等，你实际上可能也想在具有大量结构复杂性的数据上训练模型。

**(57:15 - 58:30)**

我们一直在思考可能将结构复杂性和随机复杂性区分开来的信息度量方法。这将帮助我们更好地推理数据的价值，并发展类似Solomonoff先验但可能更直接地解决我们感兴趣的不可压缩性类型的先验。

你说了很多有趣的观点。首先，针对Keith的观点，你说这还不是一个惩罚项。你的假设是神经网络隐式地进行这种压缩，这可能与Kolmogorov复杂性相关或相关联。许多人将智能等同于压缩，当我与David Krakauer交谈时，他对此表示反对。他说压缩是智能的一个组成部分，但还有很多其他方面。

**(58:30 - 59:45)**

当我们观察ARC挑战等问题时，存在很多可能的解决方案。仅仅选择最简单程序的朴素启发式方法并不总是最好的做法。你可以做出许多可能的选择。你展示了使用复杂性项的上界，从某种意义上说，这表明结果可能不会比这更差，而不是说它可能会更好，但实际上可能会好得多。我们在深度学习模型方面的经验表明，它们似乎找到了某种表面的泛化规律，这符合你提到的没有免费午餐定理时所说的一切。你可以将CNN用于表格数据，可以将transformer用于音频数据。

**(59:45 - 1:00:00)**

我们似乎遇到了局部最小值，感觉我们需要更多东西才能真正理解这些问题。这说得通吗？

压缩就是智能吗？我认为这是目前一个重大争议。我认为它在很多方面与智能密切相关。如果我们能够非常有效地压缩数据，那么为了做到这一点，我们正在发现通常有助于实现泛化的规律性。从某种意义上说，物理定律就是现实的一种很好的压缩表征。

### (1:00:00 - 1:05:00) Part 13

**(1:00:00 - 1:01:15)**

压缩在更广泛的分布之外实际上不会给你想要的结果。但在缺乏额外信息的情况下，似乎你真的无法做得更好，作为对正确策略的猜测。所以我仍然认为奥卡姆剃刀是一个非常稳健的归纳原理，也许一个答案就是更多数据。我认为这在某些情况下会很有效，在其他情况下则不然。

**(1:01:15 - 1:02:30)**

我们在尝试为矩阵运算构建 Transformer 方面有一些正在进行的工作。这实际上类似于人们在 Transformer 用于乘法、加法等方面所做的工作。这些系统 LLM 在某些情况下似乎非常有效，能够编写代码并解决我们没有真正期望它们能够解决的各种不同问题。

**(1:02:30 - 1:03:45)**

在其他情况下，它们就是令人震惊的糟糕。比如"strawberry"中有多少个 R，字符串反转、计数以及基本的加法和乘法等。所以有这样一个争论：我们是否应该给它们工具来做这些事情。比如为什么不直接给它们一个计算器？我是说，无论它们学会在加法和乘法方面做什么，仍然不会像给它们访问计算器那样高效。

**(1:03:45 - 1:05:00)**

那么我们为什么不这样做呢？或者说，学习一个能够做某些事情的表征是否有某种更大的价值？因为也许即使我们在乘法或加法时总是想使用计算器，能够合理地做这样的事情可能会转移到我们真正没有预料到的其他环境中。我可能更倾向于这个类别，我只是在智力上认为我们应该尝试弄清楚如何在没有工具的情况下做到这一点。所以我们在矩阵运算 Transformer 方面所做的工作我认为是相当类似的。

### (1:05:00 - 1:10:00) Part 14

**(1:05:00 - 1:06:15)**

关于为什么不直接给它们工具的问题，我的答案是因为这些工具必须由人类编程和构建。而这里的整个重点是让机器自己进行编程，也就是机器学习。如果它们连可靠地学会乘法运算都做不到，无法从十进制乘法泛化到二进制或十六进制，从九位数泛化到三十六位数，那我们还能指望它们发现相对论或非牛顿力学或其他任何前沿领域的东西吗？我是说，这难道不是我们的目标之一吗？

**(1:06:15 - 1:07:30)**

绝对是的。我认为能够很好地完成某些事情，我们发现可能会出人意料地与很好地完成其他事情相关。我们在大语言模型上已经大幅度地看到了这一点。我们有一篇论文，我们就是直接拿了一个文本预训练的LLM，将其应用到时间序列预测上。我们所有的做法都很朴素，甚至没有真正打算把这做成一个正式的项目或论文。我们只是好奇，如果你只是给GPT一串朴素地编码为字符串的数字序列，让它推断下一个字符串标记序列，它与专门构建的时间序列预测程序相比会如何？

**(1:07:30 - 1:08:45)**

结果它的效果比我们认为可能的要好得多。这甚至没有什么道理。所以我们确实将此转化为了一个正式项目。我们在改进标记化和考虑不确定性表示等方面做了一些工作。但那篇论文的大部分内容——它叫《大语言模型是零样本时间序列预测器》——主要专注于试图理解这怎么可能。最终，这开始感觉更像是，也许这不仅仅是你可以这样做，也许在某些情况下你应该这样做。它们在各种基准测试上都表现得很好。

**(1:08:45 - 1:10:00)**

对我来说，这表明通过对LLM在时间序列方面的适当专门研究努力，我们可以看到这些系统实际上比专门构建的模型工作得更好。这表明能够预测句子中的下一个词实际上可以转移到能够很好地完成其他事情，比如时间序列预测。我们还有另一篇关于LLM用于材料生成的论文，这有点类似。我们拿了一个现成的文本预训练LM，比如当时的Llama 2模型，在这种情况下我们在以文本表示的原子数据上对其进行微调——原子的位置、能量等等。结果系统能够生成具有良好性质的无机晶体，比那些专门构建的方法甚至是在该领域特定数据上训练的基础模型方法都要好。

### (1:10:00 - 1:15:00) Part 15

**(1:10:00 - 1:11:15)**

我们发现了一个非常令人惊讶的结果，即视觉Transformer实际上在训练后比卷积神经网络具有更好的平移等变性。这听起来不可能，因为卷积网络在设计上就是平移等变的，但它们并不是完全的平移等变，因为存在混叠伪影和边界效应等问题。而这个其他模型——这个没有任何显式约束的Transformer，只有一个在规模增大时越来越明显的软偏置——能够发现比卷积神经网络等变误差更低的解决方案，这绝对令人惊叹。

**(1:11:15 - 1:12:30)**

回到你的问题，我认为我们越来越多地发现，能够很好地解决某些问题将以可能意想不到的方式转化为能够很好地解决其他问题。特别是当涉及到加法、乘法和矩阵运算等操作时，这些甚至是构建智能系统的基本原语。即使我们可以使用工具来完成这些任务，我们也希望我们的表示在这些方面有一定的能力，因为这对我们可能还没有预料到的各种其他事情都会有用。

**主持人：** 奥卡姆剃刀在我们最近几段讨论中多次被提及。我想深入探讨这一点，因为我喜欢奥卡姆剃刀，当我成为贝叶斯主义者时，我第一次真正理解了它。很高兴有一位贝叶斯主义者同伴在这里讨论。因为在贝叶斯推理中，奥卡姆剃刀有一个非常明确的形式——数学形式，那就是边缘化。

**(1:12:30 - 1:13:45)**

它说的是，如果你有所有这些参数，你计算平均值，对所有这些参数进行积分，这实际上告诉你模型的概率——在你的完整参数空间被积分掉的情况下。这就是复杂性惩罚通过边缘化发挥作用的地方。如果你扩展模型的灵活性或让它变得更复杂，但在推理上没有任何收益，或者没有在某种奇怪的简洁性形式上获得收益（比如更少的曲率等），那么这就会对你不利。

我看了你几年前的一些演讲，非常精彩，是关于贝叶斯深度学习的教程，我想是你刚到NYU时的。我很享受那些内容。其中有很多关于边缘化及其重要性的讨论，以及你从中获得的直觉。

**(1:13:45 - 1:15:00)**

但我觉得最近这在对话中扮演的角色减少了，或者人们已经放弃了尝试做积分，又回到了最大似然估计，也许在目标函数中加一些技巧。所以我很好奇，作为一个贝叶斯主义者，你从理解边缘化的美妙和贝叶斯推理中内置的奥卡姆剃刀，到作为实践者你所做的以及你看到人们在实践中做的事情之间的历程。这在该领域是如何发展或没有发展的？也许未来边缘化和处理这些计算上难以处理的积分可能在推动更好的机器学习和推理方面发挥作用？

**Andrew Wilson：** 我很高兴你问这个问题。几乎没有什么比谈论贝叶斯推理更让我喜欢的了。我很高兴你提到了边缘化，因为我觉得这经常被忽视。当有人说贝叶斯时，大多数人想到的词可能是先验，以及先验是否好，我们如何知道什么是好的先验等等，他们会担心这个。但实际上先验并不是贝叶斯的定义特征。

### (1:15:00 - 1:20:00) Part 16

**(1:15:00 - 1:16:15)**

实际上你可以把那看作是一种非常粗糙的边缘化形式，你在说，好吧，我把后验表示为围绕最可能参数设置的点质量。然后我们可以说，好吧，也许后验——它实际上就像——我们正在最小化的损失函数基本上是负对数后验。也许后验看起来完全不像点质量，也完全不像高斯分布。它是非常多峰的。它非常混乱。但我们仍然可以用高斯分布比用点质量更好地表示它。所以让我们使用高斯近似。

**(1:16:15 - 1:17:30)**

确实，当我们这样做时，我们通常会看到更好的泛化，因为我们正在表示所有这些其他互补的、令人信服的问题解释。然后我们可以从那里继续前进。好吧，也许我们可以开发一些MCMC程序，它将探索损失景观并捕获比仅仅单峰高斯结构等更丰富的东西。再一次，我们看到了在这样做中的性能改进。所以我实际上认为贝叶斯方法在深度学习及其他领域已经是一个非凡的成功故事。

**(1:17:30 - 1:18:45)**

但我们现在听到的关于它们的消息没有像也许10年前那么多。我认为有很多原因。在某种程度上，它们是自己成功的受害者。我认为在2015年左右，在神经网络中能够做更好的近似边缘化方面有一些低垂的果实，在大约2015年到2020年之间确实有很多进展，在取得越来越好的结果方面也是计算高效的。

**(1:18:45 - 1:20:00)**

所以有一些程序，比如我们开发的一个叫做SWAG的程序，它基于我们对这些损失景观结构的一些洞察，它允许你做贝叶斯边缘化而不需要在训练上有任何显著的额外成本。它在测试时有点更昂贵等等。还有深度核学习，它基本上只需要通过模型的单次前向传递，你就能得到某种认知确定性的表示。这些程序在实践中被采用了。所以如果我去一些更特定领域的会议，比如材料工程的某个研讨会或会议之类的，我会看到大量使用贝叶斯优化、高斯过程、具有认知不确定性表示的神经网络等的讲座。

### (1:20:00 - 1:25:00) Part 17

**(1:20:00 - 1:21:15)**

确实知道投掷的力度、空气中的风力、桌子上的摩擦力，并且我有正确的物理模型，我应该能够准确预测每次投掷后硬币会落在哪一面。这只是在说，我们收集的信息越多，即使对于这个看似本质随机的过程，我们的不确定性就越少。现代物理学家现在可能确实相信宇宙的某些方面是本质随机的，比如放射性衰变等等。但许多其他科学家历史上并不这样认为，比如爱因斯坦是一个决定论者，所以他会相信唯一存在的不确定性就是认知不确定性。我认为出于实际目的，这并不是一个不合理的信念。因此，我们尝试以某种方式对其进行建模是绝对关键的，不这样做就是在做数学上不正确的事情，可能会带来巨大的成本。

**(1:21:15 - 1:22:30)**

我认为在向大语言模型转变的过程中，人们对数据的思考方式也发生了变化。过去的情况是，你有一个固定的数据集，然后你竭尽所能地利用它来获得最佳性能。也许你有一些科学问题，你真的想做得很好，你在某种程度上受到计算和其他因素的限制，但并不存在在给定计算预算下在数据规模和模型规模之间管理权衡的情况。这就是由这些缩放定律（如Chinchilla缩放定律）描述的，这开始成为主流机器学习的假设：你有几乎任意数量的数据，你有固定的计算预算，你希望在该计算预算下获得最佳性能。在这种情况下，与其尝试更贝叶斯化或类似的方法，实际上使用更多数据可能更有意义。

**(1:22:30 - 1:23:45)**

但另一个巨大的好处是，正如你提到的，出于我们仍在试图理解的原因，这些大型神经网络，深度神经网络对简单性有这种简单性偏好，对吧？边缘化是终极的奥卡姆剃刀。这就像奥卡姆的断头台或类似的东西，真正能够强制模型，强制你选择在某种意义上与数据一致的最简单模型。所以，我认为那里可能有更多收益，比如试图理解如何以计算可行的方式引入更多这些边缘化效应，比如在推理上。我的意思是，这是真的吗？

绝对是的。所以贝叶斯边缘化具有这种自动的奥卡姆剃刀偏差，我实际上是在看到一个关于优化的演讲后开始研究贝叶斯深度学习的，这可能被视为几乎与贝叶斯相反。

**(1:23:45 - 1:25:00)**

Jorge Nosadol在我最初任教的康奈尔大学做了一个演讲，他展示的是随机优化器的小批量偏差，他有一个图，对比了平坦最优解和尖锐最优解，他展示了损失景观的水平平移，在那种平移下，平坦最小值仍然具有相当好的测试损失，但尖锐最小值具有非常糟糕的测试损失。所以他说这就是为什么我们想要用小批量做随机优化，因为它更可能找到这些平坦的解决方案。在某种意义上，像L-BFGS等其他优化器太好了，它们收敛到这些尖锐最小值，如果你只关心最小化损失，那么这可能不是糟糕的行为，但泛化不仅仅依赖于在损失上获得低值，至少对于我们使用的损失函数来说是这样。所以我看到那个图，我想，这实际上是贝叶斯的绝佳动机，因为如果你是贝叶斯的，你不是把一切都押在一个解决方案上，你是在那条曲线的翻转版本下进行积分。因此，大部分体积会自动出现在这些平坦区域中。

### (1:25:00 - 1:30:00) Part 18

**(1:25:00 - 1:26:15)**

我们实际上写了一篇关于贝叶斯模型选择和边缘似然的论文。这是对自动奥卡姆剃刀的非常美妙的描述。他有一些非凡的可视化来展示这是如何实现的。他还有一些日常例子，比如也许你有一个藏在树后面的积木，但如果你有透视能力，它看起来可能是两个高度和颜色相同的积木，或者10个积木之类的。但考虑到你没有透视能力，也不认为这是个陷阱问题，你会相当确信那就是一个积木。这似乎是奥卡姆剃刀的某种体现，你可能会试图通过说"两个高度和颜色完全相同的积木恰好挨在一起，这太巧合了"来合理化解释。

**(1:26:15 - 1:27:30)**

但他认为这实际上是进行贝叶斯边缘化的可量化结果。所以他基本上有这样一个概念化：在水平轴上有所有可能的数据集，在垂直轴上有在你的模型下生成特定数据集的概率。这就是边缘似然，即在你的模型先验下生成训练数据的概率。如果你有一个积木模型，你无法生成很多不同的数据集。所以水平轴上的大多数数据集都没有支撑，没有给定M的概率密度。但对于它能生成的那些数据集，它必须给出很高的概率，因为这是一个适当的可归一化概率密度。

**(1:27:30 - 1:28:45)**

同样，如果你有10个积木模型，你可以生成各种不同类型的观察结果，但你必须将这种质量分布得更稀薄，因为这是一个适当的可归一化概率密度。因此，对于与这两个模型都一致的特定数据集，比如树后面的积木例子，一个积木模型实际上会有显著更高的概率。这甚至没有考虑到我们可能对简单性有某种先验偏好的想法，即我们认为一个积木比10个积木更可能之类的。他只是说让我们忘记这个先验比值比，只考虑边缘似然比。这是贝叶斯推理如何自动囊括奥卡姆剃刀概念的美妙展示。

**(1:28:45 - 1:30:00)**

这是科学中的一个基本问题：如果你有任意多个与你能记录的任意数量观察一致的假设，你如何在它们之间选择？解决这个问题的原则性方法是什么？我认为答案在某种程度上是由贝叶斯边缘似然给出的。我认为在实现这一点的某些方式上存在非常微妙的问题，所以我们写了一篇关于这个的论文，但总的来说，这是人们应该熟悉的东西，因为它触及了非常基本的东西，并且具有非凡的实用价值。

主持人：那篇论文是什么，我们之前看的那一篇吗？

### (1:30:00 - 1:35:00) Part 19

**(1:30:00 - 1:31:15)**

因为广义相对论具有极强的可证伪性，它的预测如此精确并与我们观察到的现象一致，所以相比于对牛顿物理的某种修正，广义相对论的边缘似然要高出几个数量级。对牛顿物理的修正需要对可能的修正方式有某种分布，虽然这种修正可能能够解释我们看到的现象，但它也会产生其他数据集，所以它的概率质量会分布得更稀薄。我认为这实际上是一个很好的例子，展示了边缘似然如何用于科学假设检验。

**(1:31:15 - 1:32:30)**

主持人：还有其他启发式方法吗？我们已经讨论了边缘似然和模型复杂性等等，我想到了康威生命游戏，你知道它有所有这些简单规则，我们在那里做的是一系列计算，正如Wolfram所说这是不可简化的，我们只是观察其动态。我的直觉是，仅仅孤立地看待事物并不能告诉你什么，实际上需要在真实世界中运行它，经过几个计算步骤，这才是关于模型好坏的信息所在。这种直觉合理吗？

**(1:32:30 - 1:34:00)**

这是一个很好的直觉，它与边缘似然、序列编码以及信息论中的想法相关。这实际上是我们一直在思考的问题，试图超越Kolmogorov复杂性，这与你之前关于良性过拟合的问题密切相关——模型首先倾向于拟合结构，然后开始拟合噪声。如果我们能够考虑某种计算受限的复杂性，也许我们就能开始了解如何进行模型选择。边缘似然实际上可以写成在给定模型条件下数据的概率。你可以使用概率的链式法则将其写成P(Di|D<i)的乘积。取对数后，它看起来就像你观察越来越多数据时的训练曲线的对数。

**(1:34:00 - 1:35:00)**

所以这些东西都是相互关联的。我认为这是理解如何正确进行模型选择的一种非常合理的方式——既要考虑可压缩性，也要考虑训练的动态，以及模型表示如何随着计算的增加而演化。

主持人：当David Krakauer谈论智能时，他说是推理、适应性和表示，但当他谈论涌现时，他说这是微观基底的根本重组。比如拿纳维-斯托克斯方程来说，这是一种重组，新的更高层次描述现在比分子层面的描述更好。在训练动态中肯定也存在类似的东西，如果存在某种涌现行为，就会有根本性重组，然后通过某种关注宏观行为的涌现优化，你实际上会选择产生这种行为的底层模型。

### (1:35:00 - 1:40:00) Part 20

**(1:35:00 - 1:36:15)**

在那篇论文中提出的泛化界限现在正被我们和其他人用来理解缩放定律的根源。这些定律看起来几乎像是自然法则——如果你增加一定数量的计算，就能可预测地提升在一系列任务上的泛化能力。但这只是一个经验定律，所以我们想要理解其原因，这关系到为什么更大的模型可能具有更强的简单性偏差等问题。因此，我在那篇论文中提出的泛化框架确实可以用来阐明缩放定律的行为。

至于顿悟现象，这不是我特别思考过的问题，但确实看起来通过更长时间的训练，模型会进行某种重组，从而实现更可压缩的解决方案。这会很有趣，我确信已经有人做过这样的研究，比如测量在顿悟过程中解的平坦度等指标。

**(1:36:15 - 1:37:30)**

我认为这实际上比人们意识到的更古老。比如双重下降被认为是现代深度学习的现象，但它实际上最早在1980年代就被提出了。所以这已经存在了一段时间，我记得Ilya Sutskever等人谈论过与顿悟非常相似的行为——训练损失并没有真正改变，但更长时间的训练实际上会带来更好的泛化。

这与我们称为随机权重平均的程序有些关系。基本思想是你要将学习率提高到一个相对较高的恒定学习率，然后在使用SGD或Adam或其他方法遍历这个损失景观时，维护参数的运行平均值。

**(1:37:30 - 1:38:45)**

当你这样做时，你实际上在平坦解决方案的周围旋转。通过取等权重平均，你可以移动到该区域内部并获得更加平坦的解决方案。这可靠地带来了更好的泛化，而且非常方便，因为你可以加载一个预训练模型，然后提高学习率，进行一定数量的epochs，从而获得更好的泛化效果。所以我认为顿悟可能也与这种行为有关。

主持人：我认为这种在优化过程中在参数空间中移动的能力，我个人认为这也是双重下降现象的部分解释，因为当你提供越来越多的灵活性时，它可以四处移动。让我给你解释一下我为什么这样认为。

**(1:38:45 - 1:40:00)**

你熟悉整数编程，就是你试图求解某个方程组，但只能在整数中寻找解——比如有数千个整数的极其困难的组合优化问题。你要做什么？尝试所有不同的整数？这里没有平滑性等。所以人们很早就发现，我们将参数空间从整数扩展到浮点数，然后进行浮点优化，到最后再将其具体化为最接近的整数解，结果证明这相当好。正是这种在数值空间内平滑移动的能力，让它能够找到合理的整数解决方案。我认为双重下降也是这样发生的。

嘉宾：你说得对。增加灵活性。

主持人：是的，我们可以有灵活性和偏差。你可以更多地四处移动，然后几乎偶然发现，或者可能是由于结构、景观或SGD的某种特性，但仅仅是这种能力——我想有一篇关于虫洞的论文，能够通过虫洞到达更好的解决方案，因为你有了更复杂的空间，维度越高，越有可能存在通往附近好解的虫洞。

嘉宾：这听起来有点像模式连通性。

### (1:40:00 - 1:45:00) Part 21

**(1:40:00 - 1:41:15)**

通过重新训练我们的模型，这些解是彼此孤立的。你朝任何方向走都会在路上大幅增加损失。Goodfellow 等人的一些结果也支持这种直觉。我们证明了你可以引入非常简单的参数曲线，比如只有一个转折点的多边形链或二次贝塞尔曲线。你可以用这个过程找到的任何解来锚定端点，这个过程找到你的两个参数向量 w1 hat 和 w2 hat，然后当你将曲线的参数 t 从 0 变化到 1 时，你就从一个解走向另一个解。

**(1:41:15 - 1:42:30)**

这个想法是，如何学习这条曲线？你可以通过在曲线上均匀地最小化期望损失来发现这些曲线。如果你在做分类任务，这看起来就像是按弧长归一化的交叉熵损失的线积分。这实际上是一个相当简单的优化目标，因为你可以沿着曲线 t 均匀采样，然后对你试图学习的曲线参数 theta 进行梯度下降。你总是可以做到这一点，模型越大，你需要的弧长弯曲或转折就越少，它看起来几乎像是两个解之间的直线路径。

**(1:42:30 - 1:43:45)**

这表明在损失景观中存在这些异常平坦的区域，它们都有接近零的损失。特别有趣的是，这些模式连接曲线上的不同参数实际上会产生在测试集上做出非常不同预测的模型。当然，它们在训练集上做出相同的预测以获得相同的损失，但在测试集上它们是不同的表示。这意味着你可以集成它们并获得更好的性能，例如仅仅在曲线上均匀采样。

**(1:43:45 - 1:45:00)**

这导致了随机权重平均程序，我们在思考如何在这些连续的平坦解区域中旋转，并找到位于它们中心的东西，这最终证明是相当实用的。

主持人：但即使与 grocking 问题相关，梯度来自哪里？因为你刚说它在训练数据上是相同的，但在测试数据上表现不同。信号从哪里来？当你继续训练一个表面上已经收敛的模型时会发生什么，但它在验证集上表现不同？

嘉宾：我有一个想法。我是 Randall Balestriero 的忠实粉丝，他通过深度神经网络的样条理论研究帮助我更好地理解它们。我认为正在发生的是，如果你同意这个观点并将这些样条视为极其高维的蜂窝结构，所有这些共享的超平面都在激活。我认为它们实际上在非常缓慢地移动，这些斜率在略微变化，然后它们碰巧遇到了一个相变，突然间它们可以将所有这些超平面组合成更低复杂度或更简洁的组合。这就是正在发生的事情——缓慢移动然后突然卡入位置。

### (1:45:00 - 1:50:00) Part 22

**(1:45:00 - 1:46:15)**

是的，这非常有趣。这让我在模式连通性发现后开始思考，这些损失地形到底是什么样的？我们最初考虑的路径只是一维的，最终我们开始思考多维损失体积。我们有一篇论文创建了一个单纯形，基本上是向单纯形添加顶点，并在结果单纯形内均匀采样，试图添加顶点，这样当我们这样做时，我们会有低损失，同时最大化单纯形的体积。

**(1:46:15 - 1:47:30)**

这使我们能够找到这些多维损失表面，它们都有相对较低的损失。我们在那篇论文的前面有一张图片，从最初对所有局部最优解都是孤立的理解，到不同最优解之间的虫洞状隧道，再到这样的想法：也许一切都只是在这个嵌入在高维空间中的某个流形中连接在一起。看起来尖锐或平坦的最优解实际上可能只是你在那个流形内收敛到什么程度，因为如果你在边缘，它看起来会很尖锐，因为你朝大多数方向移动时损失会大幅增加，但如果你朝特定方向移动，它就非常平坦。

**(1:47:30 - 1:48:45)**

我认为我们仍然没有完全理解它的样子，我认为这对泛化行为有非常有趣的意义。在十亿维度中思考真的很困难。

主持人：Andrew，让我们总结一下。你的理念是我们应该有具有软正则化的最大灵活性模型。这对实践者来说如何操作？因为你也给出了许多实际的经验例子，比如模型集成，你谈到了这种残差路径先验等等。

**(1:48:45 - 1:50:00)**

Andrew：我的理念是我们应该诚实地在模型构建的方式中表达我们的信念。我们诚实的信念通常是现实世界是一个微妙的地方，我们需要模型表达能力来表示那种微妙性。同时，它不能只是灵活性。它必须是灵活性与某种简洁性偏置的结合。它应该有某种奥卡姆剃刀偏置。也许令人惊讶的是，使 Transformer 和其他类型的神经网络模型更大，实际上经常会增强而不是减少简洁性偏置。在许多情况下，这主要是更大模型具有更好泛化行为的原因。我们在双重下降的例子中看到，在第二次下降中，所有模型基本上都有零训练损失，但更大的模型泛化得更好。这不可能是因为它们更灵活，而必须是因为它们有其他偏置，某种简洁性偏置。

### (1:50:00 - 1:55:00) Part 23

**(1:50:00 - 1:51:20)**

有许多方法可以干预训练过程。比如我们讨论过的随机权重平均，它有助于找到更平坦、更可压缩的解决方案。当然还有各种正则化器，在某些情况下可能很有用。贝叶斯边际化可以非常有效地编码我们所做工作中的自动简洁性偏置。所以有各种干预措施可以帮助我们解决这个问题。但我认为理想状况是，也许在15到20年后，我们可以通过构建这些非参数模型来拥抱灵活性，这些模型确实具有无限数量的参数，比我们现在使用的任何模型都更具表达力，但它们具有这种更明确的压缩偏置，这种偏置是可解释的，能够给我们现在构建巨大模型所不够优雅地提供的东西。

主持人：很有趣。我的意思是，根据你所说的，家里的一些人可能会有另一种解释，回到Rich Sutton的痛苦教训，对吧？他说设计东西是不好的，不要在那里放入你的对称性，不要创建这些多方面的系统，只要扩展和大量计算就是前进的道路。因为看起来你所说的一种可能的解释是，我们应该创建混合系统，通过结合不同模态让模型更灵活，而你所说的是我们应该只要更大的模型。那么你是Sutton派的吗？

**(1:51:20 - 1:52:40)**

Andrew：我认为痛苦教训被广泛误解且不完整。痛苦教训描述的是在短时间尺度上，试图将我们的知识编码到我们的程序中以取得良好结果是很有吸引力的，这也是人们的一种认知偏见。他们喜欢编码专业知识和诸如此类的东西，在解决问题时要深思熟虑和优雅。但在比典型研究项目更长的时间尺度上，计算变得更便宜。因此，基于搜索和学习的更加暴力的方法往往比优雅地编码我们的先验和约束等要好得多。

文章中有许多例子，比如90年代末用于下国际象棋的深蓝，语音识别领域，一些研究人员试图对声箱的生理学等进行建模以获得任何可能的优势，但随后被统计程序如隐马尔可夫模型击败，当然还有AlphaGo和其他类似程序。

**(1:52:40 - 1:53:55)**

因此，由于计算在更长时间尺度上变得更便宜，通常尝试构建基于搜索加学习的程序而不是特征工程会更实用。我认为这在很大程度上是正确的。但它没有说的是，为了学习，你需要做出假设。正如我们讨论的，机器学习是通过例子学习。我们不能在不做假设的情况下做到这一点。如果我们回到硬币抛掷例子，我们试图估计硬币的偏置，你必须做一些假设，比如在我开始做那个实验之前，我们假设均匀偏置吗？我们是否认为它看起来更像是以0.5为中心的，也就是无偏的，但我们支持其他情况。这些假设会影响我们如何进行归纳。

我们就是无法避免做出假设。所以问题只是我们应该做什么假设，以及它们在多大程度上可以是通用的？当涉及到描述我们如何通过增加计算可靠地改善性能的缩放定律时，如果我们能够做出更好的假设，我们实际上可以改变缩放指数，这意味着我们将通过增加计算获得指数级的性能改进，这为尝试这样做提供了显著的动机。

**(1:53:55 - 1:55:00)**

这不仅仅是一个可能的论点，我们实际上开始看到一些证据。在我们自己的工作中，我们非常感兴趣于如何为神经网络中的线性层产生结构化表示。这可能听起来非常抽象，但有一个非常著名的例子。你实际上可以从一个全连接层开始，在两层之间的节点之间具有每个可能的连接，移除一堆连接并强制参数共享，你就得到了一个卷积层。所以从数学上讲，你所做的是用一个具有稀疏性和局部性的矩阵替换密集矩阵乘法，那是一个Toeplitz矩阵。

所以有一个问题，你能否真正系统化这个创建结构化层的过程，以实现更好的计算最优效率？如果你要这样做，我们应该拥抱什么样的原则？我们应该拥抱参数共享吗，因为例如卷积具有参数共享。我们应该拥抱稀疏性吗？我们应该拥抱其他类型的特征吗？所以我们引入了这种结构化矩阵上的Einstein求和公式，它包含各种不同的结构作为特殊情况，以及各种不同的新结构，以及这种可解释超参数的分类法，控制这些结构的属性。矩阵乘法的速度如何？矩阵的秩是多少？有多少参数共享？我们对这些参数有连续值来控制这些事情。我们发现，实际上通常朝向计算最优效率，假设我们拥有尽可能多的数据，参数共享实际上不是一个好原则。这有点令人惊讶。你还希望有满秩结构，这从令人惊讶变成了有点令人失望。

### (1:55:00 - 2:00:00) Part 24

**(1:55:00 - 1:56:15)**

实际上，一般来说，朝着计算最优效率的方向发展，假设我们拥有尽可能多的数据，参数共享实际上不是一个好原则。这有点令人惊讶。你还希望有满秩结构，这从令人惊讶变成了有点令人失望。就像，我们能超越目前使用的密集矩阵吗？因为这是我们现在使用的。答案是肯定的，如果你能获得更快的乘法运算。所以我们提出了一种叫做块张量链的结构，它与另一种叫做张量链的结构相关，还有另一种叫做monarch矩阵的结构。它基本上是monarch矩阵的和。

**(1:56:15 - 1:57:30)**

这种结构是满秩的，没有参数共享，但你可以比密集矩阵更快地进行乘法运算，这允许你在给定的计算预算下构建更宽的层。这确实对缩放指数产生了有意义的影响。所以这处于概念验证级别，需要大量工作来实现这些结构的并行化实现等等。但它证明了这是可能的，我们不是唯一的一个。还有其他团队一直在研究神经切线核启发的想法，来理解不同的学习机制，比如简单与困难的特征学习等等，并试图思考什么原则实际上会修改这些缩放指数。

**(1:57:30 - 1:58:45)**

还有其他工作，比如我认为Albert Goo和其他人一直在研究transformer中的分块以及随之而来的归纳偏置，以及我们是否可以改变这些归纳偏置以获得更好的缩放指数。所以我想简而言之，学习需要假设，因此我不认为我们可以将优雅的想法与成功的学习结合计算整齐地分开。我们确实需要这些东西，它们不仅不相互矛盾，实际上紧密结合在一起。

主持人：当我们交谈时，顺便说一下，在所有这些假设中，稀疏性似乎是一个非常好的假设，总有一些东西让你觉得那似乎是一个非常好的假设。Daniel Roberts说，你知道，在物理学的许多有效理论中，稀疏性是最早的假设之一。

**(1:58:45 - 2:00:00)**

但是你会考虑到其他因素，比如计算复杂性和训练的可处理性等等，因为在理想世界中，我们会让这些东西变得稀疏。是什么阻止了我们？

这是一个很好的问题。我要说的是，我认为卷积是一个很好的想法。如果你处于我之前描述的情况，你有一个固定的数据集，你想做一些合理的事情来实现最佳性能，这通常会工作得很好。即使我们正在从硬约束转向软归纳偏置，我通常也会主张拥有某种卷积归纳偏置，即使它不再是硬约束。这就是我们在残差路径先验中所做的。在卷积视觉Transformer等方面有一些有趣的工作，试图为更高效的学习提供这类软偏置。

### (2:00:00 - End) Part 25

**(2:00:00 - 2:01:15)**

这也让人想起 ViT 让所有人都大吃一惊，它的表现比 CNN 要好得多。但最后一个问题，我们在来的路上也聊过，Andrew。房间里的大象是 GPT-5，我们有所有这些巨大的过参数化模型，表面上它们似乎表现得很好。它们在基准测试中表现出色，使用起来也很棒，但感觉缺少了什么。我认为它们并不智能。我相信你会同意这个说法。缺少的是什么？下一步是什么？

**(2:01:15 - 2:02:30)**

我最兴奋的事情之一是开发能够发现新科学理论的 AI 系统，比如广义相对论或量子力学这样的理论。在这方面我们甚至还没有真正触及表面。

甚至不清楚这个过程会有多数据驱动，如果我们要思考爱因斯坦提出相对论时的做法，以及我们可能希望如何将其写成算法并在计算机上自动化，它会有多像符号逻辑。所以我很希望看到这个方向的进展。

**(2:02:30 - 2:03:45)**

我认为我们讨论过的一些关于可压缩性的想法在我们思考如何选择科学假设方面可能发挥重要作用。同样，关于普遍性的想法，比如什么样的假设可能比其他假设更普遍，以及在什么抽象层次上。

但这是我们根本没有取得进展的领域，尽管有许多非常令人兴奋的 AI 科学研究项目，例如神经网络被用作某种针对特定应用的管道中的黑盒函数近似器。我认为这是非凡的工作，确实是机器学习在世界上明显发挥很多作用的方式。

**(2:03:45 - 2:05:00)**

但我认为是时候尝试超越这种范式，真正为我们提供对数据的新科学洞察，这些洞察是我们以前没有的。事实上，这是我在技术未来发展方面最感兴趣的事情。如果我要去到一千年后的未来，我首先要问的问题之一就是，我们对物理学的理解是否有了以前没有的认识？我们是否理解了大脑是如何工作的？

**(2:05:00 - 2:06:15)**

这是一种传统的科学方法，理论确实是主要关注的量，应用当然很重要，但它们并不是我们关心理论的主要原因。就像如果我们不考虑引力时间膨胀和广义相对论，GPS 会在几分钟内失效。但爱因斯坦提出相对论时并没有想到 GPS。如果你有了理论，那么你就可以提出各种原本不在视野范围内的应用。

**(2:06:15 - 2:07:00)**

我们可能可以训练一个神经网络来校正引力时间膨胀而不理解正在发生什么，但这远不如拥有相对论理论那样令人兴奋或有用。

威尔逊教授，非常感谢您今天加入我们。这真是太棒了。

非常感谢。这真是一种享受。如果您想了解更多 Andrew 的这项工作，请查看论文《深度学习并非如此神秘》，还有他们的论文《贝叶斯深度学习和泛化的概率视角》，该文还讨论了深度学习中的贝叶斯原理。还有他们最近的论文《计算最优的 LLM 可证明地随规模更好地泛化》，该文进一步分析了规模产生简单性偏差的根源。谢谢。

---

*生成时间: 2026-01-11 06:23:34*
*由 YouTube Monitor & Translator (Claude CLI) 生成*