# He Co-Invented the Transformer. Now: Continuous Thought Machines [Llion Jones / Luke Darlow]

## 📹 视频信息

- **频道**: Machine Learning Street Talk
- **发布日期**: 2025-11-23
- **时长**: 1:12:38
- **原始链接**: [https://www.youtube.com/watch?v=DtePicx_kFY](https://www.youtube.com/watch?v=DtePicx_kFY)

---

本文内容整理自变压器(Transformer)共同发明者利恩·琼斯（Llion Jones）和研究科学家卢克·达洛（Luke Darlow）在Machine Learning Street Talk频道的技术访谈。

## TL;DR

Transformer架构共同发明者琼斯认为该领域已过度饱和，转而探索"连续思维机"(CTM)——一种具有原生自适应计算能力的新型循环架构，通过神经元同步实现更接近人类的推理方式，在迷宫求解等需要序列推理的任务上展现出独特优势。

## 📑 章节导航表

| 时间戳 | 章节标题 | 一句话概括 |
|--------|----------|-----------|
| 00:00-05:00 | 开场介绍与研究自由度 | 琼斯决定减少Transformer研究，转向探索新方向 |
| 05:00-15:00 | 技术锁定与历史回顾 | 从RNN到Transformer的范式转变及当前AI研究的困境 |
| 15:00-25:00 | 架构创新的必要性 | 新架构需要"碾压性优势"才能取代已建立的技术栈 |
| 25:00-35:00 | 连续思维机核心概念 | CTM的三大创新：内部思维维度、神经元级模型、同步表征 |
| 35:00-45:00 | 自适应计算与生物启发 | 模型自然产生的自适应计算时间和近乎完美的校准性 |
| 45:00-55:00 | 实验发现与哲学思考 | 迷宫求解中的回溯行为和时间约束下的跳跃算法 |
| 55:00-65:00 | 记忆系统与集体智能 | 共享记忆结构和多智能体协作的未来方向 |
| 65:00-72:38 | Sudoku-Bench基准测试 | 变体数独作为真正的推理挑战，当前AI仅达15%准确率 |

## 📊 核心论点

### 1. Transformer研究的过度饱和与创新困境

- **核心内容**：尽管参与发明了Transformer，琼斯认为该领域已成为"过度饱和空间"。当前研究多是微小调整（归一化层位置、训练技巧等），类似当年RNN时期的边际改进（1.26→1.25 bits/字符）。而Transformer当年直接达到1.1 bits/字符的突破性进展，使所有RNN研究瞬间过时。这种"技术俘获"现象限制了真正的创新。
- **关键概念**：技术锁定、局部最小值、边际改进、范式转变、研究自由度
- **实际意义**：AI研究需要跳出当前范式，探索全新架构。学术界和工业界的发表压力导致研究者选择安全的增量改进而非高风险创新，这可能延缓下一次AI突破的到来。

### 2. 连续思维机的三大架构创新

- **核心内容**：CTM引入三个关键创新：(1)内部思维维度——在潜在空间中进行序列计算，而非一次性处理；(2)神经元级模型(NLM)——每个神经元是一个小型MLP，接收激活历史并输出单个激活值；(3)同步表征——使用神经元对之间的时间序列点积作为思维表征，创造d²/2维的丰富表示空间，远超传统d维状态向量。
- **关键概念**：内部思维维度、神经元级模型、同步机制、时间序列表征、生物合理性
- **实际意义**：这种架构天然支持自适应计算，简单问题1-2步解决，复杂问题自动使用更多计算步骤。在ImageNet分类上展现近乎完美的模型校准性，无需后处理技巧。

### 3. 序列推理的本质与人类认知对齐

- **核心内容**：迷宫求解展示了CTM的独特能力。传统CNN可一次性输出整个路径图像，但这不符合人类的序列决策过程（上、右、左...）。CTM通过自举课程学习，从预测1步逐渐扩展到100+步。训练中观察到类人行为：尝试路径→发现错误→回溯→选择新路径。时间受限时，模型发展出"跳跃式"策略：快速跳到目标附近，反向填充路径。
- **关键概念**：序列决策、自举学习、路径回溯、跳跃算法、认知对齐
- **实际意义**：CTM不仅解决问题，还以类人方式解决问题。这种过程透明性和可解释性对构建可信赖的AI系统至关重要，特别是在需要理解推理过程的关键应用中。

### 4. 表征学习的哲学：螺旋应该被表示为螺旋

- **核心内容**：引用"智能矩阵指数化"论文的螺旋数据集案例：ReLU网络通过无数分段线性边界"强行"拟合螺旋，虽然分类准确但毫无理解；而该论文的方法将螺旋表示为螺旋，自然支持外推。琼斯认为当前神经网络"太强大"——给足计算和数据可以拟合任何函数，但这种暴力拟合掩盖了表征质量问题。
- **关键概念**：表征质量、构造性学习、外推能力、理解vs拟合、归纳偏置
- **实际意义**：视频生成模型从"手指数量错误"到"通常五个手指"的进步，可能只是更多数据的暴力拟合，而非真正理解人体结构。下一代AI需要正确的表征空间，而非更大的模型。

### 5. 研究自由度的重要性与Kenneth Stanley哲学

- **核心内容**：琼斯深受《为什么伟大不能被规划》影响，认为研究者应该"追随兴趣梯度"而非目标导向。Sakana AI的核心理念是保护研究自由度。随着公司成长，投资回报压力、产品化需求会压缩创造力。CTM项目历时8个月，团队"不担心被抢先发表"，因此能做扎实的科学研究，最终获得NeurIPS 2025 Spotlight。
- **关键概念**：兴趣梯度、认知觅食、目标vs探索、研究自由度、长期主义
- **实际意义**：当前AI领域的竞争压力导致研究同质化。真正的突破需要时间、自由和对"有趣但可能失败"想法的宽容。学术界和工业界都需要重新思考激励机制。

### 6. 同步机制与多时间尺度表征

- **核心内容**：CTM使用指数衰减率创建多时间尺度的同步表征。快速衰减捕捉神经元的即时同步（类似高频脑波），慢速衰减捕捉长期全局模式（类似低频脑波）。这创造了丰富的d²/2维表征空间，每个神经元对可以有不同的时间特征。这种设计无需手动设置，自然产生自适应计算行为。
- **关键概念**：多时间尺度、指数衰减、脑波类比、表征丰富度、涌现行为
- **实际意义**：生物大脑在多个时间尺度上运作，这种机制可能是智能的关键。CTM展示了如何在工程系统中实现类似功能，为构建更复杂的认知架构开辟道路。

### 7. 记忆系统与集体智能的未来

- **核心内容**：团队正探索长期记忆机制：智能体在迷宫中只能看到5×5局部区域，需要构建和检索记忆来避免重复错误。多智能体可共享"文化记忆"解决全局任务。这类似人类集体智能——不同个体掌握"推理树"的不同部分，通过协作实现知识跳跃。记忆不仅是存储，更是智能体间的协调机制。
- **关键概念**：局部感知、记忆构建、文化记忆、集体智能、知识树
- **实际意义**：未来AI系统需要超越单体智能，通过共享记忆和经验形成集体智能。这对解决复杂现实问题（科学研究、工程设计）至关重要。

### 8. Sudoku-Bench：真正的推理基准

- **核心内容**：变体数独不是普通9×9填数，而是包含任意额外规则的手工设计谜题。例如：描述中故意包含一个错误数字（需要元推理）；叠加迷宫约束，老鼠路径的数字和有限制。每个谜题都有独特的"突破口"需要发现。最佳模型仅达15%准确率，且只能解决最简单的谜题。数据集包含Cracking the Cryptic频道数千小时的人类推理轨迹。
- **关键概念**：变体规则、元推理、突破口发现、思维轨迹、推理多样性
- **实际意义**：当前AI的"推理"可能只是模式匹配。真正的推理需要理解规则、发现例外、创造性组合不同推理模块。这个基准的突破将标志着AI推理的真正进步。

### 9. 从foundation model到真正的智能

- **核心内容**：当前"基础模型"概念暗示一个模型可以做所有事情，导致企业从ML工程师（架构调整）转向AI工程师（提示工程）。但"锯齿状智能"现象（PhD级问题vs明显错误并存）表明当前架构存在根本缺陷。真正的智能需要正确的归纳偏置，而非无限数据和计算。CTM等新架构探索虽然"局部偏离"不远，但可能开启全新方向。
- **关键概念**：基础模型批判、锯齿状智能、归纳偏置、架构多样性、技能退化
- **实际意义**：AI领域需要保持架构创新能力，不能因为Transformer"足够好"就停止探索。下一次突破可能来自看似简单但本质不同的想法。

### 10. 生物启发的工程实现

- **核心内容**：CTM在生物合理性和工程可行性之间找到平衡。不追求完全的生物模拟（大脑神经元并非真的全连接来计算同步），而是提取核心原则（同步作为计算基础）并用深度学习友好的方式实现（可反向传播、高度并行化）。这种方法让团队在ImageNet分类等标准任务上发现意外特性：近乎完美的校准、自然的自适应计算、类人的问题解决行为。
- **关键概念**：生物启发、工程约束、原则提取、可训练性、涌现特性
- **实际意义**：AI不需要完全模拟生物系统，但可以从生物学获得架构灵感。关键是识别哪些生物原则对智能至关重要，然后找到computationally高效的实现方式。

### 11. AI驱动的科学研究未来

- **核心内容**：Sakana AI的"AI科学家"系统可以端到端完成研究：从想法生成→代码编写→实验运行→结果收集→论文撰写，甚至有100% AI生成的论文被研讨会接收。但琼斯设想的未来是交互式的：AI提出想法→人类讨论→AI编码→人类检查→共同分析结果。类似国际象棋，曾有"人机组合"打败纯AI的阶段，但现在人类加入反而降低性能。
- **关键概念**：自动化研究、人机协作、交互式发现、能力超越点、研究民主化
- **实际意义**：AI将改变科学研究范式，但短期内人类的直觉、品味和方向把控仍然关键。长期看，需要思考当AI研究能力超越人类时，人类在科学发现中的角色。

### 12. 开放式探索的价值

- **核心内容**：CTM项目始于简单的生物启发想法（神经元同步），没有特定问题要解决，只是"追随有趣性梯度"。8个月的探索产生了14个"奇怪发现"写入补充材料。这种研究方式在当前环境下罕见——没有被抢先发表的压力，有时间做扎实科学，打磨论文质量。结果不仅获得顶会认可，更开启了众多研究方向。
- **关键概念**：好奇心驱动、涌现发现、非目标导向、深度探索、知识创造
- **实际意义**：真正的科学突破往往来自开放探索而非解决预设问题。AI研究需要平衡短期应用压力和长期知识创造，为"可能失败但有趣"的想法留出空间。

## 🏢 提及的公司/产品

| 公司名 | 讨论语境 | 重要性 |
|--------|----------|--------|
| Sakana AI | 琼斯联合创立的AI研究公司，践行研究自由理念 | ⭐⭐⭐ |
| Google/DeepMind | Transformer发明地，当前扩散语言模型研究 | ⭐⭐⭐ |
| OpenAI | 大规模Transformer应用，但未采用新架构创新 | ⭐⭐ |
| Meta | LeCun的自监督学习研究方向参考 | ⭐ |
| Anthropic | 生物学论文中的规划研究提及 | ⭐ |

## 💬 经典金句

> "尽管我参与发明了Transformer，但我今年决定大幅减少在Transformer上的研究，因为这是一个过度饱和的空间。"
> — Llion Jones

> "你需要的不是'更好'，而是'碾压性的更好'，才能让整个行业从已建立的架构转移。"
> — Llion Jones

> "如果数据是螺旋，我们难道不应该把它表示为螺旋吗？"
> — Llion Jones

> "当前神经网络太强大了——给足耐心、计算和数据，你可以让它们做任何事。但我不认为它们想要这样做。"
> — Llion Jones

> "真正的智能不是解决问题，而是以正确的方式解决问题。"
> — Luke Darlow

## 👤 主要人物

### Llion Jones（利恩·琼斯）

**身份**：Sakana AI联合创始人；Transformer架构共同发明者（2017年"Attention is All You Need"论文七位作者之一）
**背景**：在Google Brain/Research期间参与Transformer的发明，见证了从RNN到Transformer的范式转变。深受Kenneth Stanley的《为什么伟大不能被规划》影响，坚信研究自由和开放探索的重要性
**核心观点**：认为AI研究陷入局部最优，需要跳出Transformer范式。创立Sakana AI以保护研究者的创造自由，支持高风险、长周期的探索性研究。倡导"追随兴趣梯度"而非目标导向的研究方法

### Luke Darlow（卢克·达洛）

**身份**：Sakana AI研究科学家；连续思维机(CTM)项目负责人
**背景**：专注于生物启发的AI架构研究，在CTM项目上工作8个月，负责技术实现和实验设计
**核心观点**：主张理解模型的"行为"而非仅关注性能指标。认为生物启发和工程约束的平衡是创新的关键。强调序列推理和自适应计算对真正智能的重要性

## 📺 视频类型判断

**访谈对话**：多人技术深度对话，涵盖AI研究哲学、技术细节和未来展望

---

## 📝 完整翻译

### (0:00 - 5:00) Part 1

**(0:00 - 1:10)**
尽管我参与了 Transformer 的发明，但幸运的是，可能除了其他七位作者外，没有人像我这样长期研究它们。今年早些时候，我做出了一个决定，要大幅减少在 Transformer 上的研究，因为我感觉这是一个已经饱和的领域。这并不是说没有更有趣的事情可以做，而是我想抓住机会做些不同的事情，增加我研究中的探索程度。

**(1:10 - 2:25)**
我们刚刚发布了连续思考机器。这是今年欧洲的一个亮点。你应该关注它，因为它具有原生自适应计算能力。这是一种构建循环模型的新方式，它使用更高级的神经元概念，并以同步作为一种表征，让我们以更接近人类的方式，通过生物和自然启发来解决问题。

**(2:25 - 3:40)**
在 Transformer 年代，AI 研究的氛围实际上是完全不同的。现在看起来似乎很难发生类似的事情，因为我们拥有的自由程度已经大大降低。Transformer 是非常自下而上的，并不是有人从高层制定了宏伟的计划，告诉我们应该研究什么。这是一群人在午餐时讨论当前的问题和解决方案，有足够的自由可以花几个月的时间尝试一个新想法，并最终形成这种新架构。

**(3:40 - 5:00)**
我们已经花费了数亿美元。最大规模的基于进化的搜索可能仅在数万级别。我们拥有如此多的计算资源。如果扩大这些搜索算法会发生什么？我相信当有人最终真正扩大这些进化式实验时，一定会发现有趣的东西。我在一个所有人都专注于某项技术的环境中提出了这个想法，却得到了零兴趣。所以现在我有了自己的公司，可以追求这些方向。

### (5:00 - 10:00) Part 2

**(5:00 - 6:10)**
我对公司在成长过程中会限制自由的那些过程很感兴趣。我的意思是，你会如何描述这一点？当然，业内从未有过如此多的兴趣、人才、资源和资金，但不幸的是，这恰恰增加了人们为了与其他从事相同技术并试图从中获取价值和赚钱的人竞争而承受的压力。

**(6:10 - 7:20)**
我认为这就是不可避免发生的事情。作为一家初创公司，你会有一种兴奋和尝试新事物的感觉。在一开始，你有一定的发展空间。所以你可以自由地尝试不同的事情。但不可避免地，人们开始要求投资回报，或者期望你推出某些产品。这不幸地减少了研究人员的创造力，因为发表论文的压力或为现有产品创造实际有用技术的压力越来越大，因此自主感也开始下降。

**(7:20 - 8:30)**
但是，我确实告诉员工在加入公司时，我希望他们从事他们认为有趣且重要的工作，我是认真的。就像YouTube上有一种现象叫"受众俘获"，我认为可能还存在一种"技术俘获"。在Google早期，情况是相当开放的。变换器（Transformer）现在已经成为所有AI技术的无处不在的骨干，这是一个巨大的成就，而你们正是其中的参与者。

**(8:30 - 9:40)**
以OpenAI为例，他们现在开始看到所有商业化的机会。他们可能会成为LinkedIn，成为一个应用平台，成为搜索平台，成为社交网络。我猜这可能也会发生在你们身上，特别是考虑到今天我们要讨论的新论文——连续思考机器。这可能是一项革命性技术，但随后就会显而易见它如何被商业化。这就是压力产生的方式。

### (10:00 - 15:00) Part 3

**(10:00 - 11:20)**
在 Transformer 之后，我转到的团队首次将非常深度的 Transformer 解码器模型应用于语言建模，我们立即得到了大约 1.1 的结果。情况非常好，以至于人们会礼貌地来到我们的办公桌前，询问我们是否可能在计算中犯了错误，是不是不应该用比特/字符而是其他单位。但我们坚持，这确实是正确的数字。

**(11:20 - 12:40)**
后来让我感到震惊的是，所有那些研究——且要清楚，这些都是非常好的研究——突然变得完全多余。所有对 RNN 的无穷尽排列似乎都成了浪费时间。我们现在处于这样一种情况：许多论文只是在使用相同的架构，并对其进行无穷无尽的微调，比如在不同位置放置归一化层，以稍微不同的方式训练它们。我们可能正在以完全相同的方式浪费时间。

**(12:40 - 14:00)**
我个人认为我们还没有完成。我不认为这是最终架构，我们只需要继续扩大规模。某个时候会出现突破，到那时就会变得显而易见，我们现在正在浪费大量时间。我们正成为自身成功的牺牲品，这里有很多吸引盆地。Sarah Hooker 谈到了硬件抽奖，这实际上是一种架构抽奖，这让我想起了农业革命。那时发生了一种阶段性变化，所有曾经对生存至关重要的多样化技能的人都消失了。这实际上相当矛盾，因为我们需要这些技能来迈向下一步。

**(14:00 - 15:00)**
现在我们进入了一个新阶段，我们有了"基础模型"这个术语，在企业世界中，这意味着你可以用基础模型做任何事情。过去我们有数据科学家，有 ML 工程师在进行架构微调，即使在中等规模的企业中，现在我们只有 AI 工程师在做提示工程等工作。你说那些帮助我们思考新解决方案和新架构所需的基础技能正在消失。但我认为恰恰相反。问题不在于缺乏人才，而是人才没有被充分利用。

### (15:00 - 20:00) Part 4

**(15:00 - 16:20)**
如果你想推动行业远离现状，仅仅变得更好是不够的。它必须明显地、压倒性地更好。Transformer 比 RNN 好得多。当你将 Transformer 应用到一个新问题时，训练速度更快，准确率更高，以至于你不得不转向它。

我认为深度学习革命也是另一个例子，对吧？那时有很多怀疑论者，有人仍在推动神经网络，而其他人说："不，我们认为符号方法会更好。"但后来他们证明神经网络好得让人无法忽视。这个事实使得寻找下一个突破变得更加困难。这就是那种总是将你拉回到"哦，Transformer 已经足够好了"的引力场。

没错，你在这里做了一个很酷的小架构，看起来准确率更高，但 OpenAI 直接把模型做大了10倍，就超越了你。所以，就这样继续下去吧。

**(16:20 - 17:40)**
我还想补充一个可能的原因。我很喜欢那篇《分形缠绕表征》论文。这里存在一个捷径学习问题，我认为这里有点像海市蜃楼，这些语言模型可能存在我们尚未完全意识到的问题。我们正在开始篡改架构。我们知道推理需要自适应计算，我们希望有不确定性量化，但我们正在将这些功能简单地堆砌在上面，而不是设计一个内在就能完成所有这些我们知道需要的事情的架构。

**(17:40 - 19:00)**
是的。我认为我们的连续思考机器正是试图更直接地解决这些问题，Luke 稍后会详细告诉你。当前技术还是有些不太对劲。现在流行一个短语："参差不齐的智能"，意思是你可以问大语言模型一个相当于博士级别的问题，它能完美解答，但下一秒它又会说一些明显错误的话，这真是令人震惊。

我认为这反映了当前架构可能存在一些根本性的问题。尽管它们已经很惊人，但当前技术实在是太好了。这也是难以摆脱它们的另一个原因。它们太好了，以至于如果你有足够的耐心、计算能力和数据，就可以让它们做任何事情。

**(19:00 - 20:00)**
但我不一定认为它们想这么做。我们就像是在强迫它们，它们确实是通用函数逼近器，但我认为可能存在一类函数逼近器，更倾向于像人类那样表征事物。关于这一点，有一篇相当晦涩的论文是我的典型代表，叫做"智能矩阵指数"。这篇论文好像还被拒绝了。

### (20:00 - 25:00) Part 5

**(20:00 - 21:15)**
关于这一点，我们正在触及一个非常有趣的话题，因为我们一直在讨论对自适应性和自适应计算的需求。我深受兰德尔·比斯里罗的样条理论启发，这个理论关于神经网络。你可以在 TensorFlow playground 上看到当在螺旋流形上使用 ReLU 网络时会发生什么。你可能会原谅人们认为这些东西基本上就是一个局部敏感哈希表，因为它们确实会对空间进行分区，并且能够预测螺旋流形。

但我们想做一些稍微不同的事情。这也与"冒名顶替"的概念有关，仅仅追踪螺旋流形而不延续模式，这两者之间存在巨大的差异。从冒名顶替的角度来看，仅仅追踪模式并不意味着抽象地或构造性地学习它。

**(21:15 - 22:30)**
如果我们以构造性的方式学习，正如你在论文中讨论的复杂化和抽象构建模块，你就可以进行自适应计算。这意味着通过自适应计算，你可以继续这个螺旋，并可以更新模型的权重，赋予其自适应性，这对于智能来说极其重要。

我们知道我们需要能够做这些事情的模型。但出于某种原因，它们几乎比自适应智能系统更令人着迷，因为它们能准确地告诉我们想听的东西。它们看起来如此智能，但我们知道它们缺少这些基本特性。

**(22:30 - 23:45)**
我对视频生成模型依然相当怀疑。我们经历过这样一个阶段，你可以通过手上的手指数量来检测它们。是的，通过更多数据、更多计算能力和更好的训练技巧，它们确实有所改进。现在它们通常确实有五个手指。但我们是真的解决了问题，还是仅仅使用了更多蛮力，迫使神经网络知道是五个手指？

这是否是一个更好的表示空间？说我们应该像螺旋一样表示螺旋，这似乎很有争议。但如果它能以我可能表示人手的方式来表示人手，那么计算手指数量可能会容易得多。

**(23:45 - 25:00)**
很不幸，它们表现得如此出色。很不幸，规模化扩展效果如此好，因为这使得人们太容易将这些问题掩盖过去。你们可能创造了今年最好的论文。这可能是真正能带我们进入下一步的创新。

这篇持续思考机器（CTM）的论文实际上并不远离我们目前所处的局部最小值。我们并没有发现完全全新的技术。我们只是采用了一个相当简单的、受生物学启发的想法——神经元同步的事实，甚至不一定是生物学上可能的方式。大脑并不会真的将所有神经元以一种能够协调的方式连接在一起。

但这正是我想鼓励人们去做的研究。推销它其实很容易。我们完全不必担心被抢先一步，这种压力被完全消除了。因为我们相信可能有人正在研究完全相同的想法。我认为我们能获得聚光灯，是因为我们能够创作出如此精美的论文。我们花时间正确地做科学研究，获得我们想要的基准，并尝试我们想尝试的所有任务。

鼓励研究者承担稍微多一点风险，尝试这些稍微更具投机性的长期想法，我认为这是令人遗憾的。我不认为这是一件很难推销的事情。我希望 CTM 能成为一个成功的范例。这确实是一个冒险的尝试。

### (25:00 - 30:00) Part 6

**(25:00 - 26:15)**
我认为推销这种想法并不特别困难。我希望将连续思考机器（CTM）作为一个成功的范例，证明它确实有效。这确实是一次冒险。我们当时并不确定是否能找到有趣的东西，但这是我们的第一次尝试，最终我们确实发现了一些有趣的内容，并且这成为了一篇成功的论文。

如果我们找到了一个可以获取知识、设计新架构、进行你所说的开放式科学研究的系统，你能否想象在未来某个时候，进步的动力将主要由模型本身驱动？

**(26:15 - 27:30)**
>> 我觉得是这样。至于是否会完全取代我们，我的想法有时会摇摆。强大的算法正在帮助我们进行研究。我认为这最终可能只是一个更强大的版本。我们发布的AI科学家就是一个例子，我们展示了端到端的可能性：从为一篇研究论文提供初始想法，然后放手不管，让它自主运行。想想这个过程：构思想法、编写代码、运行代码、收集结果，最后撰写论文。我们最近甚至成功让一篇100%由AI生成的论文被研讨会接受。

但我认为我们这样做是为了展示在真实系统中确实可以实现这一点。我希望这个过程能更具交互性。我希望能提供一个初始想法，然后AI返回更多想法，与我进行讨论，然后去写代码。我想查看代码、检查它，并在结果出现时讨论结果。这就是我设想的近期未来，或者说我希望与AI一起进行研究的方式。

**(27:30 - 28:45)**
>> 你能对此进行反思吗？这是因为你觉得我们需要监督，因为模型还不能完全理解？你知道路径依赖的概念。所以我们需要进行监督，以便引导语言模型的生成。也许在未来，语言模型本身会理解得更好。但从输出的角度来看，我们希望生成能够扩展人类兴趣范围的成果。我们希望它与人类相关。

**(28:45 - 30:00)**
>> 是的。我认为主要是因为在最初的种子想法中，几乎不可能准确描述你到底想要什么。这就像我带实习生时完全一样。我不可能让一个实习生来到公司，我说："我有个疯狂的想法"，然后就解释一下就把他晾在一边4个月。

之所以需要来回讨论，是因为我有一个特定的想法要探索，我需要不断引导他们朝着我最初构想的方向发展。基本上就是这样。你（实习生）拥有如此深刻的理解。你有丰富的溯源、历史和路径依赖，这意味着你可以采取创造性和直觉性的步骤，尊重人类的认知边界。而实习生还没有这种深度抽象理解。

### (30:00 - 35:00) Part 7

**(30:00 - 31:15)**
我们所说的内部思维维度并不一定是全新的概念。它在概念上与潜在推理的想法相关。本质上是在序列维度上应用计算。当你开始在这个领域和框架中思考想法和问题时，你会开始理解，看似智能的解决方案往往具有序列性质。

例如，我们在连续思维机（CTM）中测试的主要任务之一是迷宫解决问题。对于深度学习来说，解决迷宫相当简单，只要你为机器简化任务。其中一种方法是将迷宫图像输入卷积神经网络，它会输出与迷宫大小相同的图像，路径处为1，非路径处为0。有一些非常出色的工作展示了如何谨慎地训练这类模型并实质上可以无限扩展。这是一个非常有趣且令人着迷的解决方案。

**(31:15 - 32:30)**
然而，当你摆脱这种方法，思考解决这个问题更人性化的方式时，它就变成了一个序列性问题。你必须说：向上走，向右走，向上走，向左走，无论具体情况如何，以追踪从起点到终点的路线。当你约束这个简单的问题空间，并要求机器学习系统按此方式解决时，问题实际上变得更加具有挑战性。所以这成为我们连续思维机（CTM）的"Hello World"问题，我们通过应用内部序列思维维度来解决这个问题。

**(32:30 - 33:45)**
我们重新思考了神经元应该是什么。在认知神经科学领域，特别是探索生物系统中神经元工作方式方面，已经有大量出色的研究。另一方面，深度学习中的神经元，典型代表是ReLU，从本质上说是开或关。这种对大脑神经元的高度抽象感觉有些短视。所以我们处理这个问题的方式是，在逐个神经元的基础上，让每个神经元本身成为一个小型模型。这最终在系统中建立动态方面做了很多有趣的工作。

**(33:45 - 35:00)**
第三个新颖之处是，正如我之前所说，我们有一个进行思考的内部维度。我们提出这样一个问题：生物系统思考时的表征是什么？仅仅是任何给定时刻神经元的状态吗？这能捕捉一个想法吗？如果我可以稍微有争议地使用"思考"和"想法"这些词，我的观点是：不能。一个想法的概念是随时间存在的。

那么，用工程语言如何捕捉这一点？我们不是测量循环模型的状态，而是测量神经元如何成对同步，并与其他神经元同步。这为我们可以用这种表征做的事情开辟了广阔的可能性。

### (35:00 - 40:00) Part 8

**(35:00 - 36:15)**
我们需要实际构建一个自动课程系统，模型首先预测第一步，当它能够预测第一步时，我们开始训练它的第二步、第三步和第四步。这种由此产生的行为是最有趣的地方。我喜欢并鼓励与我一起工作的人进行研究的方式之一是理解模型的行为。我们现在正处于一个阶段，我们构建的模型以令人惊讶的方式展现出明显的智能，将这种智能归结为一组单一的指标，甚至是关于性能的有限单一指标，似乎并不是正确的方式。理解当你将这些模型置于某个系统并以特定方式训练时，它们所表现出的行为和动作，似乎更能揭示底层到底发生了什么。

**(36:15 - 37:30)**
主持人：非常酷。我想我没有完全理解。所以你是在做固定数量的步骤，你有一个上下文窗口，你是说你将其设置在大约100步吗？

研究者：对于迷宫任务，模型在每一步都会观察完整的图像。CTM将观察完整的图像，这些图像可以是语言模型的标记，也可以是模型需要排序的数字，无论是什么情况。我们尝试让它对数据保持不可知论，但在迷宫任务中，模型可以持续观察数据，可以同时查看整个图像，但它使用注意力机制从数据中检索信息，并且有大约100步的思考空间。

**(37:30 - 38:45)**
当我们发现模型解决了迷宫的三个步骤时。比如它说我要向上、向上、然后向右。而且是正确的。但随后它做了一个错误的转向。就在那一点，我们停止监督。我们只训练它解决第四步。实际上我们做的是五步，但原理是一样的。当你这样做时，这是一种自举机制。直观的听众会理解这种方法如何扩展到其他领域，比如语言预测、预测更多标记等。

**(38:45 - 40:00)**
主持人：我对这种自适应计算的想法很感兴趣。所以我想问的第一个问题是，性能对步数的敏感度如何？下一个问题是，你能否使用任意数量的步骤，这意味着也许根据不确定性或某种标准，你可以减少步骤？最后的问题是，你是否可以有潜在的任意或无限的步骤数？

### (40:00 - 45:00) Part 9

**(40:00 - 41:15)**
在神经元级别的模型中，它们通过接收有限历史（如神经元激活的有限队列）来运作。它们不仅仅是简单的激活，而是使用这个历史作为信息来处理单个激活，这就是从我们称之为"预激活"转变到"后激活"的过程。这个原理看起来可能有些随意，但它是否有助于性能？事实证明确实有帮助，但这并不是我们的全部解决方案。

**(41:15 - 42:30)**
我们的目标是尝试做一些生物学上可信的事情。在生物学（大脑在生物基质中如何实现事物）和深度学习（高度并行、学习速度快、可反向传播，所有这些优良特性让我们走到今天）之间找到一个平衡点。我们希望在深度学习中加入一些生物学灵感，但同时保持可训练性。事实证明，神经元级别的模型是一个很好的过渡方案。同步的概念被应用在这些神经元级模型的输出之上。

**(42:30 - 43:45)**
关于规模问题，我认为同步矩阵的时间复杂度是维度的二次方。在你们的论文中，你们提到通过子采样来提高性能，但这如何影响稳定性？有没有什么代价？这是个很好的问题。在稳定性方面，我们发现了一些有趣的事情。无论我们尝试什么，它似乎都能在各种超参数下工作。通常，像RNN和LSTM这样的循环模型在通过时间反向传播时会遇到问题，随着内部步骤的增加，学习似乎会崩溃。但我们使用的同步机制在某种程度上触及了所有时间步的所有神经元，这真的有助于梯度传播。

**(43:45 - 45:00)**
我们有一个由d个神经元组成的系统，正如我之前提到的，存在d/2的平方种可能的组合。这基本意味着我们系统的底层状态或表示要比仅仅取这d个神经元大得多。至于这意味着什么样的下游计算和性能，以及我们可以用它做什么，这正是我们目前正在积极探索的。

### (45:00 - 50:00) Part 10

**(45:00 - 46:15)**
这实际上可以称为一个新的规模维度。我从某种意义上将持续的、链式思考推理视为向系统添加更多计算能力的一种方式。这显然只是其真正内容和意义的一小部分。但我认为这在某种程度上是一个相当深刻的突破。现在我们正在尝试的是让这个推理组件完全内部化，同时仍以某种顺序的方式运行。我认为这一点相当重要。你之前提到过Gemini的扩散语言建模，我认为目前有很多不同的方向正在探索这一领域。

**(46:15 - 47:30)**
我确实认为，具有同步和多层次时间表征思想的连续思考机器，在这个空间中提供了一种其他人尚未探索的灵活性。这个空间的丰富性使得能够预测下一步来解决弧形挑战，并将接下来的100步、200步分解为一个过程，模型随后可以非常快速地在其高维潜在空间中搜索这个过程，这似乎是一个值得尝试的好方法。

**(47:30 - 48:45)**
问：你认为这种架构与Alex Graves的神经图灵机有什么关系吗？

答：是的，这真的很有趣。我确实这么认为。我认为使用神经图灵机最具挑战性的部分之一是写入内存和读取内存的概念，因为这是一个离散的动作。这确实有其自身的挑战。是的，我不会说连续思考机器绝对接近图灵完备，但是在潜在空间中进行推理，并让这个空间以对不同任务来说丰富的方式展开的概念，确实很有意思。

**(48:45 - 50:00)**
这实际上让我想到了一个我觉得非常有趣的观点。再次考虑图像分类任务或任何分类任务。这是一个很好的测试平台。有许多图像非常容易分类，也有许多图像非常难分类。当我们训练一个ViT或CNN来完成这个任务时，它必须在同一空间中嵌套所有推理过程。它必须将决策过程并行地嵌套在一起，从简单明显的猫的图像到数据集中一些复杂、奇怪的代表性不足的类别，最终到达最后一层进行分类。我认为，可以将其分解，在不同的时间点上，你可以说"现在我完成了，可以停止"，这让你可以将数据集或任务自然地分割成容易到困难的组件。我认为我们知道，课程学习和这种持续意义上的学习似乎是个好主意。这正是人类学习的方式。如果我们能在架构上实现这一点，让它自然地在模型中呈现出来，这似乎是值得探索的东西。

### (50:00 - 55:00) Part 11

**(50:00 - 51:15)**
每当你尝试进行某种自适应计算时间研究，你面临的挑战就是神经网络是贪婪的。显然，获得最低损失的方法就是使用所有可用的计算资源。除非你有一个额外的损失惩罚，明确规定你不允许使用所有计算资源，并非常仔细地平衡损失，否则你很难从模型中获得有趣的动态计算时间行为。

在连续思考机器中，令人欣慰的是，由于我们按照卢克之前描述的方式设置损失函数，自适应计算时间似乎就自然而然地出现了。这更接近我认为研究应该发展的方向。

**(51:15 - 52:30)**
我们实际上并没有一个特定的目标，或者一个我们试图解决的具体问题，或者想要发明的东西。我们更多的是拥有这个有趣的架构，并且正在追随"有趣性"的梯度。

关于这一点，我认为你们论文最激动人心的地方在于，我们正在谈论路径依赖性，以及通过逐步构建的理解——这个复杂化的过程。这可能与世界模型和主动推理（打引号的那种）的主题相关。我们想要构建可以持续学习的智能体，可以更新其参数，最重要的是可以构建路径依赖的理解。因为这与仅仅理解事物的本质完全不同，重要的是你是如何到达那里的。这种架构可能允许使用这种算法的智能体在空间中探索轨迹，找到最佳轨迹，并实际构建一种将世界按其关节切割的理解。

**(52:30 - 53:45)**
这是一个非常巧妙的视角。我之前没有这样思考过，但是是的，当你考虑模糊问题时，这种特定的立场变得非常有趣。以一种方式切割世界和以另一种方式切割世界可能同样有效。

是的，语言模型中的幻觉可能只是以某种精细的方式切割世界，但在我们的衡量标准中并不高效，实际上并非如此。但在追求通过自回归生成标记来切割世界的过程中，你最终可能以不同的方式切割世界。能够训练一个模型，使其隐式地意识到它正在以不同的方式切割世界，并探索这些方式、这些切割世界的路径，这正是我们追求的。

**(53:45 - 55:00)**
我认为这是一种相当令人兴奋的方法，让我们将问题分解为可解决的小部分，并以自然的方式学习解决它，不使用太多的技巧。这是我一直在思考的问题。尽管我很喜欢舍莱特关于智能的衡量标准，但对他来说，适应新事物意味着得到正确答案，而你给出这个答案的原因非常重要。

在机器学习中，我们遇到这样的问题：我们提出的代价函数往往导致捷径问题。我们可以构建一个符号系统，我们可以说我们需要以维护语义的原则性方式构建知识。但我们没有这样做。我们正在构建一个混合系统。但必须有某种自然的推理方式，尽管最终目标是这个代价函数，但因为我们遍历这些开放式空间的方式，我们实际上可以更有信心地机械地认为我们正在进行与世界对齐的推理。

### (55:00 - 1:00:00) Part 12

**(55:00 - 56:15)**
事实上，我们以一种看似自然的方式进行推理。相反，我们所做的是向大脑致敬，向自然致敬，并说，好吧，如果我们构建这些受到启发的事物，会发生什么？会出现什么不同的解决问题的方式？当这些不同的解决问题的方式出现时，我们可以开始提出哪些重大的哲学和智能相关的问题？这就是我们现在所处的阶段。对我来说，有时可能会感觉问题太多，而用来回答这些问题的手段太少。但我认为有趣且令人鼓舞的是，我可以鼓励那些年轻的研究者：去做你热爱的事情，想办法构建你关心的事物，然后看看会发生什么。看看这会打开什么样的大门，看看如何在这些领域中更深入地探索。

**(56:15 - 57:30)**
>> 我们昨天不是还在讨论这个吗？你可以把语言想象成一种迷宫。

>> 是的。有什么能阻止我们用这种架构构建下一代语言模型呢？坦白说，这正是我现在正在积极探索的内容。我认为当你在迷宫中添加歧义时，迷宫任务变得真的很有趣，因为有多种解决方法。老实说，这是我还没有尝试过的，也许下周我应该尝试一下。本质上，你可以想象一个智能体或CTM观察迷宫并采取轨迹。令人惊讶的是，我们看到了这一点，在我们最近更新的arXiv上的论文的最终摄像机就绪版本中，我们添加了一个额外的补充章节，这个补充章节不在主要技术报告中。那个补充章节基本上是：嘿，我们看到了一些很酷的事情，我们列出了大约14个在研究过程中发生的有趣事情，这些显然没有进入论文，但我们希望人们知道发生的这些奇怪事情。这就是其中一件奇怪的事情。

**(57:30 - 58:45)**
在训练期间，我们观察到了正在发生的事情。在训练运行的某个时刻，大概在训练过程的中间，我们可以看到模型会沿着迷宫的一条路径前进，然后突然意识到，哦不，该死，我错了。然后会回溯并尝试另一条路径。但最终它变得非常擅长，并通过分布式学习做到这一点，因为它有多头注意力机制。所以它实际上可以很好地找出解决方法并完善解决方案。但在学习early阶段，它会尝试多条路径并返回。

**(58:45 - 1:00:00)**
我们有一组非常有趣的实验，还展示了一些内容，这些内容我们在线上有补充材料，关于如果你试图解决一个迷宫但没有足够的时间。事实证明有一种Foster算法可以解决它。当我看到这个时，这让我大开眼界。如果我们限制模型的思考时间，但仍然让它尝试解决一个长迷宫，它不是跟踪那个迷宫，而是快速跳到它需要到达的大致位置，然后向后跟踪，填充那条路径，然后再次向前跳跃并跨越顶部，然后向后跟踪那一部分，然后再次跳跃。它展现出这种基于系统约束的迷人的跳跃行为。再次强调，这只是我们观察到的现象，从深层意义上讲，这意味着什么？它与给模型思考时间有什么关系？是否有足够的思考时间？当你以这种方式约束它时，模型会学习什么不同的算法？我觉得这非常有趣，值得探索。它告诉我们关于人类如何思考的什么？它告诉我们在受约束的设置与开放式设置下我们如何思考的什么？在这方面有很多有趣的问题可以探讨。

### (1:00:00 - 1:05:00) Part 13

**(1:00:00 - 1:02:00)**
如果你希望完成这个任务，就是要解决那个迷宫，找到通往终点的路，模型需要学习如何构建记忆，使其能够返回到之前见过的某个点，并知道上次走错了路，然后选择不同的路线。你可以通过在同一个迷宫中使用并行代理来观察这一点，它们共享一个内存结构，并看看当所有代理都可以访问那个内存结构，拥有一个共享的全局"文化记忆"时会发生什么。通过让许多代理尝试使用这个内存系统来解决全局任务，我认为记忆将成为我们未来需要在人工智能领域做的最关键元素之一。

**(1:02:00 - 1:04:00)**
推理这个主题刚刚被提到，我认为人们普遍有一种看法，就是我们最近在推理方面取得了很大进展。这实际上是人们正在研究的主要内容之一。我们最近发布了一个名为 Sudoku bench 的数据集，很高兴看到它几周前在你的播客中自然地被提及。

Chris Moore，对吗？是的。我想告诉你一些关于这个基准测试的情况，因为我在推广它时有点困难，因为从表面上看它听起来并不特别有趣。Sudoku似乎已经被解决了，所以一组数独对推理能力有多有趣呢？但我们不是在讨论普通的数独。我们讨论的是变体数独。这些变体数独通常是普通数独，即在行、列和宫格中放置1到9的数字，但在此基础上增加了任何额外的规则。

**(1:04:00 - 1:05:00)**
这些规则都是手工制作的，具有极其不同的约束条件。实际上需要非常强的自然语言理解能力。例如，数据集中有一个谜题，它用自然语言描述了谜题的约束条件，然后说："顺便说一句，描述中的一个数字是错误的。"所以在开始解谜之前，你必须对规则本身进行元推理。还有一些谜题是在数独上覆盖了一个迷宫，老鼠必须通过跟随路径到达奶酪，但路径上有数字的约束条件。

### (1:05:00 - 1:10:00) Part 14

**(1:05:00 - 1:06:30)**
然后当我没有专注于此事，正在休闲时，我正在观看一个名为"破解密码"的YouTube频道。

是的。他们是两位英国绅士，为你解决极其困难的数独谜题。没错。有时他们的视频长达四小时，他们确实是专业人士，这就是他们的工作。我意识到完美的地方在于，他们会以令人痛苦的细节告诉你他们用什么推理来解决这些特定的谜题。对吧？所以经过他们的允许，我们提取了他们所有的视频，这代表了数千小时非常高质量的人类推理轨迹，并将其抓取并提供用于模仿学习。

**(1:06:30 - 1:08:00)**
对此我们内部也尝试过。事实证明我在创建一个非常困难的基准测试方面做得有点太过了。我们仍在尝试使这些内容发挥作用，如果有成功的话，我们会发表出来。我真的很想强调这个推理基准测试的与众不同之处。

不仅你能得到一些非常扎实的东西，你能准确地知道对错，所以你可以尽情地进行强化学习，但你很难泛化。每个谜题都是经过精心设计，为规则添加了一个新的独特转折，称为"破关"，你必须理解这一点。尽管我们取得了所有进展，但现在的人工智能模型无法跨越这一步。它们无法找到这些"破关"点，它们只会回退到尝试各种数字：好，我试试4，我试试5，我试试6，7，这样的推理变得非常乏味，与我们从YouTube频道开源的成绩单中看到的完全不同。

**(1:08:00 - 1:09:30)**
所以我想向大家发出挑战，这是一个真正困难的基准测试，我认为在这个基准测试上的进展，实际上就是人工智能整体的进展。

主持人：在观看这个"破解密码"YouTube频道后，你能反思一下模式的多样性吗？Chris曾对我说，哦，这些人会去Discord服务器，他们会得到一些富有创意的疯狂想法，我很着迷。也许我只是过于理想化了，但我非常喜欢知识的演绎闭包这个想法。有一棵庞大的推理树，我们每个人都拥有这棵树的不同部分和不同深度。你越聪明、知识越丰富，你就能越深入这棵树。但在这个理想化的形式中，存在一棵树，所有知识都源于或产生于这些抽象原则。

**(1:09:30 - 1:10:00)**
从原则出发，我们原则上可以构建能够进行推理的引擎，这可能是计算上不可约简的。因为我们没有完整的树，所以我们必须四处寻找。寻找乐高积木。哦，这是个好的乐高积木。我可以将它应用到这个问题中。也许对于人工智能来说，目前我们需要做的就是尽可能多地获取这棵树。但是我们能一直这样做下去吗？

### (1:10:00 - End) Part 15

**(1:10:00 - 1:11:15)**
尽管这些方法并非完美。你可以看到它们会采用某种推理方式并开始逐步构建。比如，我们可能会这样解决问题：先尝试一种方案，然后发现这种方案无法充分消除歧义，于是回退并尝试另一条路径。这是当前人工智能在尝试解决基准测试时未能展现的能力。

这棵推理树实在太大了，而且树中许多模式之间的进化距离如此之远，以至于在不同分支之间跳跃变得极其困难。这可能就是为什么作为集体智能，我们能如此出色地协作——因为我们实际上找到了在树的不同部分之间跳跃的方法。

**(1:11:15 - 1:12:30)**
目前的强化学习（RL）算法之所以无法奏效，正是因为要获得这些突破性进展，理解这种细微的推理方式来解决这些谜题，你必须对它们进行采样。这是一个极其罕见的空间，需要一种非常特定的推理方式来实现特定的突破。当前的技术对此根本行不通。

在研究社区中确实存在一种普遍观点，认为现在解决问题的方式就是这样：我们有了强化学习，可以让语言模型按我们的意愿运作。但对于这个数据集，这种方法完全不起作用。

**(1:12:30 - 1:13:45)**
主持人：能否谈谈招聘情况？我们的观众中有很多机器学习工程师和科学家，我相信为 Zakano 工作将是梦寐以求的工作。

嘉宾：非常感谢你的好意。是的，我们目前确实在招聘。正如我之前在采访中提到的，我真诚地希望能给员工尽可能多的研究自由。我愿意押注于此。我相信很有趣的事情将会由此产生，而且我们已经看到了许多有趣的成果。所以，如果你想研究你认为有趣和重要的内容，那就来日本吧。

主持人：而且日本恰好是世界上最文明的文化。

**(1:13:45 - 1:14:30)**
（众人笑）

这可能是一生的机会，各位。所以，请联系我们。衷心感谢你们。能邀请你们两位来节目，这是我们的荣幸。

嘉宾们：非常感谢。

主持人：非常感谢。这真是太棒了。

---

*生成时间: 2026-01-12 02:24:47*
*由 YouTube Monitor & Translator (Claude CLI) 生成*