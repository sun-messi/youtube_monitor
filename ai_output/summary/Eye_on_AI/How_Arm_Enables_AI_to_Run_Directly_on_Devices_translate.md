# How Arm Enables AI to Run Directly on Devices

## 📹 视频信息

- **频道**: Eye on AI
- **发布日期**: 2025-12-19
- **时长**: 51:38
- **原始链接**: [https://www.youtube.com/watch?v=sYFxKyCO1u4](https://www.youtube.com/watch?v=sYFxKyCO1u4)

---

> 本文内容整理自 ARM 客户端业务线高级副总裁兼总经理克里斯·伯吉（Chris Bergie）在 Eye on AI 频道的技术访谈。

---

## TL;DR

ARM V9 架构通过 SME（可扩展矩阵扩展）将 AI 推理能力直接嵌入边缘设备，解决云端 AI 的延迟、连接性和隐私问题，正在重新定义从智能手机到可穿戴设备的 AI 交互体验。

---

## 📑 章节导航表

| 时间戳 | 章节标题 | 一句话概括 |
|--------|----------|-----------|
| 00:00-08:30 | ARM 架构发展历程 | 从 30 年前的早期投资到 V9 架构的安全性、性能和 AI 三大核心特性 |
| 08:30-14:30 | 异构计算与编程挑战 | CPU、GPU、NPU 协同工作，平衡性能与开发者友好性 |
| 14:30-22:35 | 边缘 AI 的必要性 | 解决云端 AI 的连接性、延迟和隐私问题，实现真正的实时交互 |
| 22:35-27:45 | 功耗与内存优化策略 | Big.LITTLE 架构动态调度，HBM 内存技术，模型压缩创新 |
| 27:45-34:00 | 应用场景与技术突破 | 从助听器到 XR 眼镜，AI 将无处不在如同触屏技术 |
| 34:00-40:00 | 全球市场与开发者生态 | IP 授权模式，2200 万开发者生态，全球化挑战与机遇 |
| 40:00-47:30 | 智能化交互的未来愿景 | 超越当前预期的智能交互，从设置菜单到代理式 AI 体验 |
| 47:30-51:38 | 物理 AI 与机器人技术 | 视觉传感器推动物理 AI，从自动驾驶到日常设备的智能化 |

---

## 📊 核心论点

#### ARM V9：为 AI 时代设计的新架构

- **核心内容**：ARM V9 架构在 5-6 年前推出时就前瞻性地聚焦于安全性、性能和 AI 三大核心特性。目前大部分 iOS 和 Android 设备都搭载了 V9 CPU，正在向数据中心、汽车和 AI IoT 等领域扩展。V9 的 SME（可扩展矩阵扩展）技术通过传统 CPU 编程模型实现 AI 加速，降低开发门槛。
- **关键概念**：V9 架构、可扩展矩阵扩展（SME）、异构计算、CPU 编程模型、前瞻性设计
- **实际意义**：为开发者提供了熟悉的编程环境来部署 AI 应用，避免了学习新加速器编程语言的障碍，加速了 AI 技术在边缘设备上的普及。

#### 异构计算：CPU、GPU、NPU 的协同优化

- **核心内容**：现代 AI 系统需要 CPU、GPU 和 NPU 的协同工作。ARM 已出货超过 90 亿个 GPU 核心，主要通过移动设备。工作负载会在不同计算单元间动态调度——CPU 启动任务，可能转移到 GPU 或 NPU 执行，最后回到 CPU 完成。这种异构架构平衡了性能、功耗和编程复杂度。
- **关键概念**：异构计算、动态工作负载调度、GPU 核心出货量、SOC 集成、内存带宽压力
- **实际意义**：为不同类型的 AI 任务提供了最优化的硬件资源分配，同时保持了系统的灵活性和可编程性，是未来 AI 设备的核心架构模式。

#### 边缘 AI：解决云端计算的根本限制

- **核心内容**：尽管云端 AI 服务如 ChatGPT、Gemini 表现优秀，但边缘 AI 是必然趋势。关键驱动因素包括：连接性问题（如高速公路死角导致 APP 体验中断）、隐私保护、实时性要求。AI 将像触屏技术一样成为基础体验——没有 AI 的设备将被视为"不会用"。所有参与方（超大规模云服务商、应用开发者、设备制造商）都有强烈动机将 AI 推向边缘。
- **关键概念**：连接性死角、实时交互、隐私保护、触屏类比、基础体验期望
- **实际意义**：推动整个科技生态系统重新设计产品和服务，从依赖云端转向边缘优先，创造更可靠、更私密、更快速的 AI 体验。

#### Big.LITTLE 架构：智能功耗管理的创新

- **核心内容**：ARM 十多年前发明的 Big.LITTLE 概念通过大核和小核的动态切换实现智能功耗管理。在门铃摄像头等场景中，系统首先用小核检测运动，一旦触发事件再启动大核进行人脸识别等复杂计算。这种分层唤醒机制最大化了电池寿命，同时保证了必要时的计算性能。
- **关键概念**：Big.LITTLE 架构、动态核心切换、分层唤醒、事件驱动计算、功耗优化
- **实际意义**：为物联网设备和可穿戴设备的长续航运行奠定了基础，使得复杂 AI 功能能够在功耗受限的环境中实际部署。

#### 内存带宽：AI 时代的核心瓶颈

- **核心内容**：AI 推理对内存带宽的需求极其巨大，这比单纯的计算性能更关键。云端采用 HBM（高带宽内存）堆叠 DRAM 技术，边缘设备也在探索类似创新。当前最大挑战不是算力，而是模型尺寸与内存容量的平衡。好消息是模型压缩技术以每年约 50% 的速度改进，同时相同参数量的模型性能也在快速提升。
- **关键概念**：HBM 内存技术、内存带宽瓶颈、模型尺寸压缩、DRAM 堆叠、参数效率提升
- **实际意义**：内存技术创新将成为 AI 芯片竞争的关键，决定了哪些复杂模型能够在边缘设备上运行，直接影响用户体验的上限。

#### 开发者生态：2200 万人的庞大社区

- **核心内容**：ARM 拥有全球最大的开发者生态系统，超过 2200 万软件开发者在 ARM 架构上开发应用。这得益于 ARM 在从 iOS 到 Windows on ARM，再到 Chrome、Android 和 Linux 等主要软件生态系统中的广泛存在。ARM 提供 Compute Library 框架，让开发者能够无缝利用 AI 硬件能力，无需深入了解底层硬件细节。
- **关键概念**：2200 万开发者、跨平台生态、Compute Library 框架、硬件抽象、开发者体验优化
- **实际意义**：庞大的开发者基础确保了 ARM 架构在 AI 时代的软件生态优势，降低了新技术采用的门槛，加速了 AI 应用的创新和普及。

#### 极小型 AI：从智能手机到智能可穿戴

- **核心内容**：AI 芯片的尺寸可以小到集成在助听器、智能手表等微型设备中。Meta 的 XR 眼镜配套腕带使用 ARM 的 Ethos NPU，电池续航数周，通过检测手腕肌肉变化实现手势控制。关键在于针对特定用例优化模型——助听器不需要运行大语言模型，只需降噪和声音增强，但未来可能集成实时翻译功能。
- **关键概念**：Ethos NPU、特定用例优化、手势识别、肌肉信号检测、微型设备集成
- **实际意义**：开辟了全新的人机交互模式，让 AI 能够渗透到日常生活的每个角落，创造了从未有过的便携式智能体验。

#### 代理式 AI：超越搜索的智能交互

- **核心内容**：未来的 AI 交互将从当前的搜索式（给出关键词等待结果）转向代理式（自然对话完成任务）。微软在 Windows 11 中的设置体验是很好的例子——不再需要点击多个菜单寻找选项，而是直接说"我想添加屏幕"，系统就能理解并执行。这种体验将扩展到所有设备和应用，改变人们对技术的基本期望。
- **关键概念**：代理式交互、自然语言控制、意图理解、任务自动化、期望值重塑
- **实际意义**：将彻底改变软件界面设计和用户体验，从菜单导航时代进入对话交互时代，大大降低技术使用门槛。

#### 物理 AI：视觉传感器的革命性应用

- **核心内容**：摄像头传感器技术的进步为物理 AI 打开了巨大空间。智能手机摄像头的图像捕获能力已经非常强大，现在 AI 的视觉识别能力让这些传感器能够理解物理世界。从医疗影像的 MRI 辅助诊断到自动驾驶汽车的环境感知，视觉 AI 正在各个领域发挥作用。ARM 驱动的特斯拉在自动驾驶方面已经达到了很高的水平。
- **关键概念**：摄像头传感器进步、视觉识别能力、医疗影像辅助、自动驾驶技术、物理世界理解
- **实际意义**：让 AI 从虚拟世界走向物理世界，为机器人技术、自动化系统和智能监控等领域提供了技术基础。

#### 全球化 IP 授权模式的挑战与机遇

- **核心内容**：ARM 采用 IP 授权模式，向全球半导体生态系统提供知识产权。由于半导体开发成本巨大（最新工艺节点的掩膜费用就达数千万美元，开发成本常超过一亿美元），需要全球化市场来分摊成本。ARM 与美国、欧洲、台湾、韩国以及中国的半导体公司都有合作。地缘政治制裁主要影响制造环节，对 IP 授权影响相对较小。
- **关键概念**：IP 授权模式、半导体开发成本、全球化市场、地缘政治影响、制造与设计分离
- **实际意义**：展现了半导体行业全球化分工的复杂性，IP 设计与制造的分离为技术创新提供了相对稳定的发展环境。

---

## 🏢 提及的公司/产品

| 公司名 | 讨论语境 | 重要性 |
|--------|----------|--------|
| ARM | 核心主角，V9 架构设计者和 IP 授权商 | ⭐⭐⭐ |
| Apple | ARM 架构早期投资者，V9 M5 芯片发布 | ⭐⭐⭐ |
| NVIDIA | GPU 市场对比，GB10 产品合作伙伴 | ⭐⭐⭐ |
| Meta | XR 眼镜和腕带产品，Ethos NPU 采用者 | ⭐⭐ |
| Tesla | ARM 驱动的自动驾驶成功案例 | ⭐⭐ |
| Microsoft | Windows 11 代理式 AI 体验的领先者 | ⭐⭐ |
| Google | Android 生态合作伙伴，Gemini AI 服务 | ⭐⭐ |
| Amazon | Alexa 智能音箱，AI 交互体验改进 | ⭐⭐ |
| OpenAI | ChatGPT 云端 AI 服务代表 | ⭐ |
| Nintendo/Nokia | ARM 架构早期采用者，历史贡献 | ⭐ |

---

## 💬 经典金句

> "如果你给一个 10 岁以下的孩子一个屏幕，他们会直接开始触摸，因为他们不知道还有不是触屏的屏幕。AI 也将如此——如果设备没有 AI，孩子们会说'这东西怎么不智能？我不知道怎么用。'"
> — Chris Bergie

> "人们不会向运营商抱怨'101 高速公路上有死角，你们什么时候修复？'他们会说'Craig 的应用体验很糟糕，一天三次都用不了。'"
> — Chris Bergie

> "我们正处于创新周期中，有两种解决方案：你可以缩小模型获得相同性能，这个速度大约每年 50%；或者说我要一个 30 亿参数的模型，它每六个月、每年都变得更加智能。"
> — Chris Bergie

> "ARM 现在拥有世界上最大的开发者生态系统，我们有超过 2200 万软件开发者在 ARM 上开发软件。"
> — Chris Bergie

---

## 👤 主要人物

#### Craig（主持人）

**身份**：Eye on AI 频道主持人
**背景**：科技媒体从业者，对 AI 和半导体行业有深入了解，开发过基于 GPS 的历史讲解应用
**核心观点**：关注 AI 技术从云端向边缘的迁移趋势，特别关心连接性和用户体验问题，对物理 AI 和机器人技术的实际应用持谨慎乐观态度

#### Chris Bergie（克里斯·伯吉）

**身份**：ARM 客户端业务线高级副总裁兼总经理（Senior Vice President, General Manager of Client Line of Business）
**背景**：半导体行业近 30 年从业经验，从 AMD 起步，曾在 Broadcom 工作近十年，参与过多家初创公司。专注于边缘设备和丰富终端设备领域，包括智能手机、PC、智能电视、智能音箱等 AI 设备
**核心观点**：坚信 AI 将像触屏技术一样成为所有设备的基础功能，边缘 AI 是必然趋势。强调异构计算的重要性，认为未来需要 CPU、GPU 和专用加速器的协同工作。重视开发者体验，致力于让 AI 开发变得更简单易用

---

## 📺 视频类型判断

**访谈对话**：主持人 Craig 与 ARM 高管 Chris Bergie 的深度技术访谈，探讨边缘 AI 技术发展趋势和 ARM 在其中的战略布局。

---

## 📝 完整翻译

### (0:00 - 15:00) Part 1

ARM 架构已经存在近 30 年了，这始于苹果等公司的早期投资。ARM 架构的早期采用者包括任天堂、诺基亚等公司，这些公司在 80 和 90 年代让 ARM 成为了坚实的基础。智能手机革命以及所有相关技术真正开始围绕 ARM 发展，这推动我们发展到今天的地位。我们有大核 CPU 和小核 CPU，实际上我们会根据需求来回移动工作负载，因为某些时候你需要性能，某些时候则不需要。这就是这些设备的工作方式，比如你的门铃示例，你在寻找一些运动，寻找某些东西，然后一旦触发该事件，好的，现在让我们启动更多计算元素。

**广告部分（略）**

主持人：很高兴你来到这里，Craig。感谢邀请我。我叫 Chris Bergie，是 ARM 客户端业务线的高级副总裁兼总经理。这意味着我非常专注于 ARM 在其中非常突出的所有丰富的边缘设备。比如智能手机，但显然我们也在 PC 等领域取得了相当大的进展。我们参与你家中的各个部分，无论是电视、智能音箱，还是你拥有的各种丰富终端设备，这些设备正在快速变得支持 AI，我认为这就是我们今天要讨论的内容。Craig，关于我的背景简单介绍一下。我在半导体行业已经工作了近 30 年，在各种大公司工作过，毕业后从 AMD 开始，然后在 Broadcom 工作了近十年，期间也做过一些初创公司。很长时间了，我不敢相信时间过得这么快。但我想，半导体从未像现在这样酷，政府和每个人都真的很关心半导体。所以我想我的职业选择非常幸运。

Craig：是的，这很有趣，不是吗，事情就是这样发生的。特别是边缘半导体，这就是现在一切的核心所在。所以 ARM，我们正在谈论 AI 推理芯片。ARM 的 ARM 版本 9 边缘 AI 平台有几个新的处理器，专门设计用于启用复杂的 AI 模型。你能谈谈这些吗？或者有什么更新的你想谈的吗？

Chris Bergie：我认为这是个很好的起点，Craig。我们实际上在边缘演进的旅程中走了很长的路，实际上不仅仅是在边缘的 AI 演进，我们实际上也是数据中心基础设施建设的重要组成部分。这真正利用了我们的商业模式和能力，所以我们在那里也做得很好。但今天我想主要谈论边缘。所以我们创建了我们的 Lumix 平台，这主要是围绕高端智能手机、边缘的高端多媒体体验。我们在九月推出了它，已经有几个产品芯片组推出了，现在不同领先手机制造商正在推出基于 Lumix 的手机。酷的是，这是第一个，它是 V9 平台的补充，正如你提到的，开始推出 SME，这是 V9 架构的矩阵扩展，并开始将其引入生态系统，让人们能够在这些设备中真正利用边缘 AI，并使用传统的 CPU 编程模型来实现。

显然关于加速器有很多讨论。加速器很棒，在数据中心中占主导地位，也在边缘找到了它们的位置。但这总是一个平衡问题，你知道加速器在每瓦 TOPS 等指标方面有很好的表现。但它们在编程方面确实更具挑战性，相比之下 CPU 就简单多了。所以你真正需要理解的现实是，我们谈论异构计算是因为我认为答案是一切都重要。我认为在 AI 世界中，这关乎 CPU 能力、GPU 能力，可能还有专用加速器能力，然后是内存带宽，坦率地说，AI 真的给整个系统带来了压力。

Craig：好的，让我们为不深入芯片领域的听众退一步。我想让你谈一谈 V9 以及它是什么。但当你谈论异构计算时，还有编程语言，NVIDIA 之所以有如此强势的地位，原因之一是它很早就开发了一种非常用户友好的编程语言叫 CUDA，每个人都采用了它来在 GPU 处理器上编程 AI，这已经成为标准。所以很多新芯片正在到来，但你需要学习新的编程语言，这是一个障碍。但在这种异构计算中，特别是在边缘，我理解的是你仍然使用传统处理器和你熟悉的编程语言，然后有某种转换将一些工作负载发送到边缘芯片，它可能都打包在一起，但这样对吗？

Chris Bergie：是的，我认为是这样。你把很多东西都包装进去了。所以，让我先从 V9 开始。ARM 架构已经存在近 30 年了。这始于苹果等公司的早期投资。ARM 架构的早期采用者让它成为今天的支柱，这些公司包括任天堂、80 和 90 年代的诺基亚，智能手机革命以及所有这些东西真正开始围绕 ARM 发展，这推动我们发展到今天的位置。所以 V9 是我们大约五六年前推出的架构，这是下一代架构，专注于几个不同的方面。一个是安全性，另一个是性能，第三个是 AI。我们非常前瞻地看待这些下一代系统将需要什么。这就是 V9 的真正意义。在这个时候，很大比例的 iOS 和 Android 手机都配备了 V9 CPU。你会看到这在未来几年继续加速。现在 V9 也开始渗透到 ARM 参与的其他市场，无论是数据中心、汽车，还有 AI IoT。这就是 V9。

关于你提到的编程评论。你说得对，CUDA 是一种了不起的语言。我实际上很荣幸与 Ian Buck 密切合作过，他基本上是斯坦福学生，真正开始了这一切，显然现在已经成为 NVIDIA 故事的重要组成部分，直到今天仍然在那里。这是一个很棒的程序，基本上用于编程 GPU，特别是利用加速器中的一些能力，但它是一种加速器语言，而不是 CPU 语言。人们做的是，你基本上必须开始进行驱动程序调用，你必须将工作负载从 CPU 移动到那里。如果你要获得比如说，我和 Ian 实际上曾经在高性能计算方面做过相当多的工作，为高性能计算实验室工作，我们会有这样的规则，当你移动工作负载时，几乎希望有 100 倍的提升。至少你需要 10 倍，但你真的希望有那样的提升，相比于保持在 CPU 上的便利性，因为你真的需要加载并在加速器上流式处理该工作负载。

所以当你考虑这种异构性时，你真正在基于需求移动这些工作负载。是延迟吗？是高性能吗？是低功耗吗？所有这些事情。这就是我要说的生态系统正在做的，ARM 专注的是我们真正专注于让所有这些部分，CPU 在 AI 工作负载上尽可能高性能，并且对开发者超级友好，它确实是这样的。还将一些工作负载移动到 GPU。ARM 实际上，很多人不知道这一点，但 ARM 实际上是出货量最高的 GPU。我们已经出货了超过 90 亿个 GPU 核心，因为移动手机以及移动行业中如此多基于 ARM GPU 的产品。然后也通过 ARM 架构扩展支持加速器，许多这些加速器挂在 chai 总线或 ARM 架构的一部分上。

Craig：当你说 ARM 出货 GPU 时，NPU 在这一切中处于什么位置？

Chris Bergie：是的。在移动手机中，让我们谈论这个，因为这是我们开始的地方。传统上有两个大型计算元素，CPU 和 GPU，对吧？它们的主要功能是 CPU 运行操作系统然后最终运行应用程序。GPU 功能是显示、玩游戏以及做所有这些事情。随着其他工作负载变得重要，无论是相机成像显然变得超级重要，你拍摄的视频量，我们开始放置小的加速器，可能为不同的视频编解码器做一些压缩等等。所以 NPU 已经发展成为一种有效地进行矩阵乘法或 CNN 和不同类型模型的加速器方式。系统可以选择发送它，但在现实世界中真正发生的是这种异构性，你实际上最终通常在 CPU 上启动作业。你可能实际上将它运行到 GPU。你可能将它发送到 NPU，然后它通常回到 CPU 来结束，这就是这些工作负载在系统中实际工作的方式。用户显然看不到这一切。但作为软件开发者，开发者必须做出一些决定，思考手机中有什么样的能力。他们也在决定是否要在云端还是边缘上做，我们今天也应该进行这个对话。所以这些工作负载会移动，它们移动有很多原因，但我们让边缘的 CPU 尽可能对 AI 友好，AI 性能强，并在良好的功耗范围内。

Craig：这些都打包在一起吗，CPU、GPU，如果你使用 NPU 的话还有 NPU？

Chris Bergie：这取决于系统。在今天的手机芯片中，是的，它们基本上都在单个 SOC 中。所以所有这些计算元素都存在于 SOC 中。当你进入有更大电池窗口的设备时，在 PC 中，许多 NPU 都集成在 SOC 中。我们看到人们添加加速器的趋势。显然，人们也在使用笔记本电脑或类似设备中的 GPU。同样，这可能是集成的，也可能是分立的。我想说在许多这些市场中有集成的趋势。这是因为 AI 的内存压力和内存大小要求。所以我认为如果你看一些最新的，我要说放在你桌子上的计算平台。我们特别为与 NVIDIA 在 GB10 上的合作伙伴关系感到自豪，这个产品他们实际上刚刚在上周开始发货。它把，Jensen 喜欢说它把超级计算机放在你的桌子上，对吧？他们实际上提供我认为是一个 petaflop 的 AI 性能在你的桌子上，这是因为你有这些 ARM CPU，20 个，与这个加速器紧密耦合，单一内存系统提供高达 128 GB 的 DRAM 和非常高的带宽，所以你有这个开发者可以使用的整个系统，我们看到这是一个趋势。无论你看苹果本周刚刚宣布的最新 V9 M5，我想是上周。同样，你看到利用 ARM CPU、GPU 和其他加速器以及巨大内存系统的惊人 AI 性能。这就是我们看到正在发生的事情。这些是集成的。但其中一些随着变得更大一点，它们变成分立的。但分立的问题是你必须拆分内存系统，这就变得复杂了。

### (15:00 - 30:00) Part 2

Chris Bergie：我们特别为与 NVIDIA 在 GB10 上的合作伙伴关系感到自豪，这个产品他们实际上刚刚在上周开始发货。Jensen 喜欢说它把超级计算机放在你的桌子上，他们实际上提供一个 petaflop 的 AI 性能在你的桌子上，这是因为你有这些 ARM CPU，20 个，与这个加速器紧密耦合，单一内存系统提供高达 128 GB 的 DRAM 和非常高的带宽，所以你有这个完整的系统供开发者使用，我们看到这是一个趋势。无论你看苹果本周刚刚宣布的最新 M4，还是上周的发布，同样，你看到利用 ARM CPU、GPU 和其他加速器以及巨大内存系统的惊人 AI 性能。这就是我们看到正在发生的事情。这些是集成的。但其中一些随着变得更大一点，它们变成分立的。但分立的问题是你必须拆分内存系统，这就变得复杂了。

Craig：是的。

Chris Bergie：AI 是如此内存密集型，这就是一个平衡行为。

Craig：我想到不深入芯片领域的听众。SOC 是片上系统，就是你将不同类型的芯片组合成一个。从消费者的角度看，它看起来像一个芯片，对吧？都压缩在一个外壳里。这很重要的原因是，我现在有一个为自己构建的应用，当我开车时它会告诉我所在地方的历史。声音经常中断，因为它必须读取我的 GPS，将数据发送到云端，然后在模型中查找，获取模型的文本，转换为语音，发回手机。也许文本转语音是在手机上。但整个链条有一百万种方式可能被中断。如果你让这一切都在设备上发生，你就不会有这些连接性问题。你能谈谈你如何看待 V9 或这些 SOC 改变我们与 AI 交互的方式吗？

Chris Bergie：当然 Craig，你处在前沿。我的工作超级有趣，因为我能与许多行业领导者和远见者交谈，无论是我们密切合作的 Google 这样的公司，还是所有芯片组公司，以及所有真正将这些东西放到你手中的消费电子公司。这很有趣，因为我始终是边缘计算的支持者。我希望边缘计算能实现。但我确实经常去找这些合作伙伴说："为什么不能在云端运行？为什么不能这样做？看起来工作得很好。人们喜欢 ChatGPT，他们喜欢 Gemini，他们开始真正利用这些服务。"

你知道，他们基本上说让我安心的是，所有这些公司都说不不不，我们需要把这些放到设备中。其中一个原因就是你刚才说的 Craig，AI 的目标是我们看到一些早期的酷用例，实时翻译，一些开始做事情的智能代理，但我们还处在非常早期的阶段。我喜欢用的一个类比是触控。如果你给一个不到 10 岁的孩子一个屏幕，他们就开始触摸，因为他们不知道任何不是触摸屏的东西。而你我，鼠标曾经是个大事，我们认为那很酷。我用这个类比是因为 AI 就会是这样。如果某样东西没有 AI，你不能与它交互，它不能开始弄清楚你想做什么，那就像那个孩子说这东西没有触摸屏，我不知道怎么用，我不想用。

所以首先，你需要相信这就是多么重要。就像应用启动时间长会让人烦恼，应用崩溃或类似情况会让人烦恼，我们解决了这些边缘问题，它们不再经常发生，但技术是新的，AI 也是如此。在与其中一个合作伙伴交谈时，他们说："Chris，好的，也许云端的 AI 90% 的时间工作得很好，但你在 101 号公路上开车，我在硅谷圣何塞这里，你在高速公路上开车，有个信号盲区。基本上，你会遇到大量延迟，它不会变得像对话一样，你会一直等待。现实是人们不会向运营商抱怨说'嘿，你在 101 号公路上有这个盲区，什么时候修复？'他们会说'嘿，Craig 的应用，我不喜欢那种体验，令人沮丧，不工作，一天三次我试图使用它。'就像做这些视频通话，对吧？当有人连接不稳定时，你会想'嘿，我们下周再谈或者在办公室谈吧，太令人沮丧了。'"

这只是一个例子。还有隐私、性能以及各种其他真正推动边缘计算的因素。另一面是模型必须变小。由于计算和内存计算压力，这有真正的成本，所以这是一个平衡，但它正在发生。再次，训练和在云端仍会有相当多的推理，但尽可能多地转移到边缘，我认为无论你是超大规模云服务商、应用开发者还是设备制造商，都有动机试图让它在边缘设备上运行得非常好。

Craig：但正如你所说，有挑战和权衡。一个是功耗问题，以及由此产生的散热问题。你如何管理这个？我提到了 BrainChip 公司，我与他们交谈过，他们使用神经形态芯片，只有在有足够活动唤醒它们时才会触发。例如，在门铃摄像头中，当场景中什么都没发生时，你不希望门铃吸收视频，发送到云端，计算，再发回来。但事实上就是这样发生的。你如何管理这个？

Chris Bergie：我认为我们有这些管理技术，几乎在计算设备的每个方面都会使用。我们有非常聪明的工程师，他们弄清楚如何让你以为设备在全功率运行，但我们在后台非常积极地改变事情。这实际上是 ARM 10 多年前的一个创新，我们提出了大小核概念，我们有大 CPU 和小 CPU，我们实际上在工作负载之间来回移动，因为某些时候你需要性能，某些时候不需要。

这就是这些设备的工作方式，对于你的门铃例子，你在寻找一些运动，寻找某些东西，然后一旦你触发那个事件，好的，现在让我们启动更多计算元素。让我们弄清楚，哦，这是一张脸。好的，这是一张脸吗？我们知道我们不认识，让我们触发云端或其他。这就是这些系统的工作方式。

所以我认为这是关于这些更智能的计算平台，在如何做这些加速器方面变得更聪明，这就是我提到的主题 2 的一部分，V9 的一部分。这是一个紧密耦合的加速器，但我们以非常高效的方式来做，它实际上在多个 CPU 核心之间共享，所以你也在面积效率方面非常高效，这真正推动了成本。

还有大量创新。我不想过于技术化，但你的听众可能听说过 HBM，对吧？HBM 内存是具有非常高带宽接口的堆叠 DRAM，它已成为云端 AI 的巨大推动者，因为我们必须拥有所有这些内存带宽，我们将这些 HBM 堆栈放在这些加速器旁边。我们在边缘看类似的东西，相对于功率在哪里？是在计算元素中吗？是在每比特内存传输的焦耳中吗？所有这些都是创新的机会，有大量研究和投资投入其中。

所以我不担心功率。我实际上认为相对于推理，功率是相当可管理的。我认为我们现在面临的更大压力实际上是内存，内存大小。模型大小以及如何让它足够小，因为归根结底这推动成本、功率和其他各种事情。所以它正在发生，好消息是我们处在这个创新周期中，你可以做两件事。你可以缩小模型并获得相同的性能，这似乎每年缩小 50%，如果不是更快的话。另一方面，你可以说，我想要一个 30 亿参数的模型，它每六个月、每年都变得越来越智能。有不同的方法解决问题，但这真的是推动因素。

Craig：我只是为听众考虑，SME 是可扩展矩阵扩展，这是一种优化数学运算的方法，对吧？在模型方面，你们有在探索优化内存使用的状态空间模型吗？我是说有不同的处理内存方式。

Chris Bergie：我个人对状态空间不太熟悉。我想我理解它的一般概念。我会说我们提供这个平台，许多这些创新都在其之上。比如我们的矩阵扩展引擎，我们基本上在其之上构建了我们称为 Kleidi 框架的东西，这些库现在开发者基本上可以利用，所以它在硬件中做正确的事，相对于利用你是否有最新的 ARM V9 等等。

很多模型如何工作以及状态空间，它们是使用 KV 缓存还是如何做不同的更新，这些实际上位于堆栈中稍微高一点的级别，我们更像是管道推动者。我们支持所有这些，我们让开发者非常容易地探索并在其之上构建他们的创新。但至少在这个时间点，我们在 CPU 中从状态空间的角度没有做任何独特的事情。

Craig：你能谈谈一些当前应用以及你看到的边缘计算发展方向吗？显然自动驾驶汽车是一个你不能承担通过向云端发送数据而产生连接性和延迟风险的地方，它必须在平台上或车内计算。你们目前将芯片放入哪些其他应用或设备中，你认为会如何发展？这些芯片的外形尺寸能有多小，以便它们能够，我在和一个戴助听器的人交谈，你知道你能够在助听器中安装这些芯片来过滤或隔离声音等等。你能谈谈这个吗？

Chris Bergie：这是个很好的问题。我认为可扩展性几乎无处不在。你的助听器例子是个好例子，这是 ARM 构建我们所做的巨大产品组合的原因之一，因为我们在许多助听器和类似设备中，我们实际上已经宣布了 AI，我提到了 Lumix，但我们也有在二月宣布的边缘 AI 平台。所以我们在推动这个。

如果你知道你想要做的任务，你可以让东西相当小且高效。在助听器中，你可能不是在尝试运行大语言模型，至少现在还没有，你在做减少噪音或挑选放大你想听的有趣内容。现在，显然添加翻译这些功能可能很快就会成为可能。如果我知道我要翻译成什么语言，那我可以让我的模型更小。

我喜欢思考的一件事是今天我们使用多少应用来配置东西。一个好例子是安全摄像头。今天你可能在过去安装安全摄像头时会去你的笔记本电脑连接它，现在可能用你的智能手机来做。这是一个使用模式，我们已经习惯了。但为什么不能直接用你的声音呢？为什么摄像头不能有大语言模型并与你交谈，你说它问你的 SSID 是什么？这些是我看到的。它说，这是我看到的 SSID。现在这可能是也可能不是更好的用户体验，但我们看到了跨领域的适用性。

我再次使用触控类比，因为触控已经变得如此普及。AI 将比今天的触控更普及，改变使用模式，改变你与这些东西的交互方式。我给你举个很好的例子 Craig，我们与 Meta 密切合作，他们真的在做很棒的工作。我认为他们在眼镜方面的一些进展，XR 眼镜以及他们两三周前刚宣布的产品，他们现在有一个与该产品配套的腕带，实际上使用了我们的 Ethos NPU 之一，它又是超小、超低功耗的，你可以有这个腕带，基本上有很长的电池寿命。我忘了你可以戴多少天或多少周。它就是通过像这样移动你的手指来操纵东西。它感知你手腕中的变化和皮肤下发生的事情，使用 AI 基本上弄清楚，哦，你刚做了第二个手指，所以那会做这个，或者你刚做了这个，所以或者你在做这个。基本上这是一个有 AI 的腕带的新 UI，有很长的电池寿命和很小的电池。这就是我们可以为非常特定的用例让 AI 有多小。

### (30:00 - 45:00) Part 3

在各个地方，对吧？我是说你的助听器例子是一个很好的例子，这是 ARM 构建庞大产品组合的原因之一，因为我们在许多助听器和这类设备中都有应用。我们实际上已经在各个领域宣布了 AI，我提到了 Lumix，但我们也在二月份宣布了边缘 AI 平台。所以我们正在实现这一切。

归根结底，如果你知道要执行的任务，你可以让东西变得相当小且高效。在助听器中，你可能不是在尝试运行大语言模型，至少现在还没有，你在做的是减少噪音或挑选放大你想听的有趣内容。现在，显然添加翻译这些功能很快就会成为可能。如果我知道要翻译成什么语言，那我就可以让我的模型更小。

我喜欢思考的一件事是今天我们使用多少应用来配置东西。一个好例子是安全摄像头。今天你在安装安全摄像头时，过去你可能会去你的笔记本电脑连接它，现在可能用你的智能手机来做。这是一个使用模式，我们已经习惯了。但为什么不能直接用你的声音呢？为什么摄像头不能有大语言模型并与你交谈，当它询问你的 SSID 是什么时，你说这些是我看到的？这可能是也可能不是更好的用户体验，但我们看到了跨领域的适用性。

我再次使用触控类比，因为触控已经变得如此普及。AI 将比今天的触控更普及，改变使用模式，改变你与这些东西的交互方式。Craig，我给你举个很好的例子，我们与 Meta 密切合作，他们真的在做很棒的工作。我认为他们在眼镜方面的一些进展，XR 眼镜以及他们两三周前刚宣布的产品，他们现在有一个与该产品配套的腕带，实际上使用了我们的 Ethos NPU 之一，它又是超小、超低功耗的，你可以有这个腕带，基本上有很长的电池寿命。我忘了你可以戴多少天或多少周。它就是通过像这样移动你的手指来操纵东西。它感知你手腕中的变化和皮肤下发生的事情，使用 AI 基本上弄清楚你刚做了第二个手指，所以那会做这个，或者你刚做了这个。基本上这是一个有 AI 的腕带的新 UI，有很长的电池寿命和很小的电池。这就是我们可以为非常特定的用例让 AI 有多小。

主持人：ARM 现在的重点是什么？我是说显然会涉及所有这些方面，但你认为下一个突破在哪里？是减少尺寸、降低功耗，还是增加这些芯片上可以运行的模型大小？你认为发展方向是什么？

这是个很好的问题，Craig，说实话，这是一个非常开放的设计空间。过去确实有对功耗的关注，这是我们 Ethos 产品线的来源，但很多都是围绕 CNN 网络和一些早期的东西。现在你开始看到向 Transformer 网络的转变。下一步是什么？我不认为 Transformer 实际上是最终目标。所以我们也需要允许灵活性，因为这些模型在变化，回到教育用户的话题。设计硅片并将其投入到发货产品中几乎至少需要两年时间，你可以看到 AI 发展有多快。

所以也有这个灵活性方面，但我认为大部分是性能。这实际上是内存性能，是 TOPS 和 CPU 性能，然后试图在任何功率包络下尽可能缩小，你知道，你能获得多少计算能力。我认为这在数据中心也发生了，对吧，我们现在在建造千兆瓦数据中心，但你能创建多少 Token？在那里你能获得多少性能？所以在这个领域的几乎任何地方，都是告诉我你的功率包络是什么。这里是千兆瓦，在手机中是六七瓦，在我的手腕例子中，实际上只是几百毫瓦。你能获得多少 AI 性能？所以它确实跨越了一个很大的空间。

主持人：你们不是在生产 IP 吗？你们没有晶圆厂。你们不是把设计发送到晶圆厂来制造芯片。你们是向其他芯片制造商授权这个。

是的。我们的商业模式是向半导体生态系统的很大一部分提供 IP。然后我们的合作伙伴在此基础上构建并创建硅解决方案，可以涵盖我们谈到的从腕带或助听器到下一辆自动驾驶汽车的任何东西。

主持人：大部分是在哪里？我是说显然大部分是进入美国，但你有合作伙伴在授权你的 IP 吗？你们在运营的其他市场是什么？

我要说的是，传统上半导体一直是相当全球化的。开发半导体的成本是巨大的，显然是晶圆厂成本，我甚至不谈晶圆厂成本，但实际上构建一个芯片，如果你使用最新节点之一，仅仅是完成设计后的掩膜成本就要数千万美元。前期开发成本通常可能在一亿美元以上。所以你在谈论获得第一个单元的巨额成本。但让半导体如此伟大的是你可以扩展它，因为我们有这些惊人的制造能力等等。所以它们往往是非常大的市场，所以对我们来说这通常是一个全球市场。

显然，美国有许多优秀的 IC 或半导体公司做设计。我们也与欧洲、台湾、韩国的半导体公司密切合作。我们还有 ARM 中国，一个合资企业，基于我们的 IP 在中国制造半导体。所以这是一个相当全球化的市场。

主持人：我想象中国关系已经因为制裁而紧张。这如何影响你们？

我们始终确保遵循当地法律，显然是我们所在的地方。大多数限制都是围绕制造过程，不一定是一些 IP。IP 启用方面有一些限制，但这是我们始终非常小心的事情，确保我们遵守所需的要求，我们会看看事情如何发展。

主持人：你们主要销售 IP，你们与大型开发者社区合作吗？这种关系是什么样的？比如有多少是开源的？然后你能谈谈你认为的地方吗？你提到了可穿戴设备，可穿戴设备将会是热点，你认为边缘在哪里真正爆发，公众与 AI 的互动或体验。

让我们先谈谈开发者。ARM 对开发者来说非常重要，实际上我们现在拥有世界上最大的开发者生态系统。我们相信我们有超过 2200 万软件开发者在 ARM 上开发软件。这只是因为我们的足迹从 iOS 到现在的 Windows on ARM，当然还有 Chrome、Android 和 Linux 等。我们一直是长期支持者，所以世界上最大的软件生态系统与 ARM 密切合作，我们支持他们，我们真的专注于开发者体验以及如何改善开发者体验。我之前在这次对话中提到了 CID，这实际上是为了让开发者无缝使用 AI，因为你谈到了 CUDA，AI 在许多编程元素方面并不简单，我要说我们仍然看不到我们让其他软件生态系统获得的硬件抽象。我们仍然看到今天的模型与它们运行的硬件之间相当紧密的耦合，无论是它们支持的操作符，还是它们假设模型传播的方式等等。

但我们显然专注于支持这些开发者，看看他们能构建什么，我认为这回到了你的第二个问题，关于什么是前沿，这就是让我的工作如此有趣的原因，因为我可以与这么多超级创新的人互动，无论是初创公司还是成熟公司，关于下一步是什么或什么是可能的。如果我只是使用一个一般概念，那就是智能。能够以超出你当前期望的方式与你互动的想法。

也许我会用另一个产品例子。我是 Amazon 的超级粉丝。但我注意到的一件事是，在我升级到 Alexa Plus 之前，因为我使用聊天机器人或 ChatGPT 或 Gemini 的方式，我开始以更对话的方式与它交谈，因为那是我能做的。但当我回家使用 Alexa 时，它不一定期待更多的搜索类型，给我，你真的要把它分解得很简单，我给你三个词，试图将这三个词情境化。顺便说一下，我认为 Amazon 在 Alexa Plus 方面做得很好，我认为他们走在正确的道路上。但这只是期望的改变，我认为这只会通过屋顶，相对于我们认为与设备互动让它变聪明的想法。

人们问我的一件事是什么是生成式 AI 或那种感觉如何？我喜欢使用的一个例子，我认为 Microsoft 作为一家如此大的公司，在将 AI 真正整合到他们的产品中方面做了惊人的工作，他们推动 Copilot 的方式，所有这些事情。但我喜欢的是设置的一个愚蠢例子。当你在 Windows 设置中使用 Windows 时，我们都做过，你必须弄清楚，我想添加一个屏幕或我不喜欢这个分辨率屏幕。你必须点击多少个窗口才能弄清楚如何做出这个改变？他们已经将其改变为在 Windows 11 中更具代理性的体验，你只需说，你想做什么？我想添加一个屏幕。我想减少这个。它就说，好吧，这是你怎么做的，或者我为你做。

对我来说，这是一个触摸感觉的事情，我们有多少次点击三个应用。我要剪切这个。我必须去我的航班应用。然后我必须去我的租车应用。我们被训练去思考，哦，这工作得足够好。但这种想法是事情如此聪明，当你叫 Uber 时，它当然知道你要去哪里，它已经告诉人们你什么时候出现，所有这些事情。当然这些是消费者例子。有大量的企业例子，团队不分享数据，人们不理解，或者他们在寻找他们找不到的信息。所以我认为这只是让事情变得超级聪明的一般想法，真正超越今天技术限制的期望。

主持人：机器人技术是另一个。我不是人形机器人技术的伟大信仰者。我认为我们离那还很远。但你所描述的，我是说总有一天我们的孩子或孙子会回顾并说，你能相信你知道任何你日常使用的物体在那时都是愚蠢的物体，而不是能够与它交谈并让它自己配置或其他什么。这相当令人兴奋。

### (45:00 - End) Part 4

什么是机器人技术？我的意思是，显然你们也参与其中。

Jensen： 是的，那里发生的事情非常令人惊讶。在虚拟世界和真实世界中训练机器人的能力都很强。我们非常相信这一点，并且与许多生态系统都有很大的参与。你知道，我认为这真的是在利用所有的优势，相机传感器一直是一个令人惊讶的推动因素，对吧？如果你只是看看我们的手机在拍摄图像方面能够做什么，但实际上相机传感器现在释放了这种物理 AI 的想法，以及你如何使用视觉系统，AI 在视觉系统方面非常出色，无论是查看 MRI 还是增强医生对此的阅读，或者在系统中试图理解正在发生的事情。所以这是一个巨大的领域。我认为我们将看到很多创新。

你知道，对于你的机器人技术例子，我认为我不知道回到《杰森一家》或其他什么。我的意思是人们说我们将拥有飞行汽车，他们将能够做所有这些自主的事情。这花了很长时间，但你知道，另一个很棒的 ARM 驱动设备，我的 Tesla，它在自动驾驶方面已经变得相当不错，我真的很喜欢在许多场景中让它来增强我。正如你所说，这将只是一种期望，当它不能做一些他们今天显然不能做的事情时，你会感到失望。但这些事情很难。我的意思是，你知道，我认为物理和你知道的那种融合将是一件困难的事情，但就像任何事情一样，这可能，你知道，我回到我在早期参与了蓝牙，哦，这将是惊人的。你将拥有所有这些蓝牙设备，但它在开始时并没有很好地工作。体验不是很好，但只要看看蓝牙今天是多么根本。再次，当我走向我的 Tesla 时，它就解锁了。它就像锁定一样。

这一切都通过蓝牙并由 UWB 增强，所以这些技术有时炒作周期会稍微超前于期望，这是我们作为技术专家的错，但最终技术会兑现，对我们的孩子和孙子来说，这将是一个令人兴奋的未来。

主持人： 是的，绝对如此。是的，转向物理领域，挑战实际上不是 AI，而是机械、执行器、磨损、灰尘和油脂以及所有那些人们容易忘记的东西。

Jensen： 那还有很长的路要走。好的，所以 ARM 是否即将宣布任何新东西，还是说这真的是 V9，你们专注于什么？

我们有相当广泛的产品集，所以是的，我有我的责任，但我们有一个完整的汽车和机器人技术团队，我们有一个专注于数据中心的完整团队，边缘 AI 和额外智能也是如此。所以，我认为你会继续看到我们的很多东西。有很多很棒的东西正在进行，我们对能够合作的伙伴关系以及开发者的数量感到非常兴奋。

希望你的一些听众受到启发，在 ARM 架构之上构建东西，并帮助让未来成为可能，向我们展示什么是可能的。

主持人： 是的。在这个问题上，我们将以此结束。开发者如果他们感兴趣，你们有开发者门户网站吗？

Jensen： 我们有。developer.arm.com。这是一个很好的资源，可以找出更多信息，弄清楚如何构建和探索许多这些新技术。显然，许多制造商都熟悉 Raspberry Pi。这也是 ARM 驱动的，许多孩子和教育工作者开始他们的旅程，现在这些东西在机器人技术和其他方面变得非常令人兴奋。

广告： 在商业中，他们说你可以拥有更好、更便宜或更快，但你只能选择两个。如果你可以同时拥有三个会怎样？这正是 Cohair、Thompson、Reuters 和 Specialized Bikes 自从升级到下一代云 Oracle Cloud Infrastructure 以来所拥有的。OCI 是用于基础设施、数据库、应用程序开发和 AI 需求的超快平台，你可以在高可用性、始终高性能的环境中运行任何工作负载，花费比其他云更少。

为什么更快？OCI 的块存储为你提供更多每秒操作次数，更便宜。OCI 在计算方面成本低 50%，存储低 70%，网络低 80%。在一次又一次的测试中，OCI 客户报告与其他云相比延迟更低，带宽更高。这是为 AI 和所有最大工作负载构建的云，现在零承诺。免费试用 OCI。访问 oracle.com/ai。

---

*生成时间: 2025-12-21 20:56:25*
*由 YouTube Monitor & Translator (Claude CLI) 生成*