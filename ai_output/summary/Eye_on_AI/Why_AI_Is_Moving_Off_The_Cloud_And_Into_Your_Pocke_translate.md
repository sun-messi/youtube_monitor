# Why AI Is Moving Off The Cloud And Into Your Pocket

本文内容整理自 **Eye on AI** 频道的视频。

原始链接：https://www.youtube.com/watch?v=7HhVCVGpblI

---

# YouTube 视频分析报告：脑芯片（Brainchip）的神经形态计算革命

## 📋 背景信息

> 本文内容整理自脑芯片（Brainchip）首席营销官史蒂夫·布莱特菲尔德（Steve Brightfield）在技术访谈节目中关于神经形态计算的深入探讨。

## 📌 TL;DR

神经形态计算将AI从数据中心推向边缘，以类脑计算模式显著降低功耗并提升边缘设备智能。

## 📊 内容提要

### 1. 神经形态计算：模仿大脑的计算架构

- **具体内容**：神经形态计算通过模仿生物神经元的脉冲通信方式，实现高效低功耗的计算。与传统AI的暴力矩阵运算不同，它只在真正需要时触发计算，宛如大脑的神经网络。

- **投资启示**：
  - ⭐ 对NVIDIA长期GPU战略的挑战
  - 边缘AI芯片市场（如Brainchip）具有重大投资价值
  - 关注低功耗、高效AI计算的创新公司

### 2. 边缘AI的革命：从云端到设备

- **具体内容**：神经形态计算使AI从巨型数据中心转移到可穿戴设备、智能眼镜、助听器等边缘设备，显著降低功耗和延迟，提升隐私保护。

- **投资启示**：
  - ⭐ 看好Apple、Meta在可穿戴设备AI领域的布局
  - 关注Tesla Optimus等边缘AI机器人项目
  - 医疗、工业、国防领域的边缘AI应用前景广阔

### 3. 技术突破：将传统模型转换为事件驱动网络

- **具体内容**：Brainchip开发了将传统神经网络转换为事件驱动的尖端工具，降低计算复杂度，提升模型效率。

- **投资启示**：
  - AI模型转换工具市场潜力巨大
  - 开源模型和工具生态系统发展迅速

### 4. 未来应用展望：从智能可穿戴到自动驾驶

- **具体内容**：神经形态计算有望在智能眼镜、助听器、医疗设备、自动驾驶等领域实现革命性突破。

- **投资启示**：
  - ⭐ 看好NVIDIA、Tesla在自动驾驶AI领域的布局
  - 关注Brainchip、Intel等神经形态计算先驱

## 🏢 提及的公司/产品

| 公司 | 讨论语境 | 值得关注 |
|------|----------|----------|
| Brainchip | 神经形态计算技术领先者 | ⭐ |
| NVIDIA | 传统GPU计算模式 | 需关注战略调整 |
| Intel | 神经形态计算研究 | 中性 |
| ARM | 异构计算合作 | 中性 |

## 💬 金句摘录

1. "神经形态计算是大脑启发的优雅计算，而不是传统AI的蛮力数学。"
2. "未来，每个人的口袋、衣领或帽子都将有一个脑芯片。"
3. "AI正从大型数据中心悄然转移到我们日常的每一个设备中。"

## 👤 主要人物

### 史蒂夫·布莱特菲尔德（Steve Brightfield）

脑芯片首席营销官，半导体行业资深专家，在数字信号处理和芯片设计领域拥有30多年经验。

## 📺 视频类型

- **访谈对话**：技术深度解析、行业趋势探讨

这份分析报告突出了神经形态计算作为边缘AI的关键技术，为投资者和技术爱好者提供了深入洞察。

---

## 📝 完整翻译

### (0:00 - 15:00) Part 1

神经形态计算实际上是我们的大脑是如何进行计算的。我们没有传统的电路，而是有生物神经元，它们与其他神经元高度连接。它们通过脉冲相互通信。我们可以称之为尖峰信号。你会看到一个信号从一个神经元传递到下一个神经元。如果这个尖峰信号足够强，并且有其他尖峰信号进入同一个神经元，就会触发该神经元向下游发送尖峰。这是一个每个神经元接收尖峰输入并决定是否输出尖峰的简单概念。但是当你将数十亿个这样的神经元连接在一起时，你就得到了大脑的本质。

我们正在调整我们的商业模式，让客户在做出可能花费数千万美元的芯片开发集成决策之前，就能看到我们知识产权的价值。

使用Agency构建多智能体软件的未来。这是 Agency，现在是一个开源的Linux基金会项目。Agency正在构建智能体互联网。这是一个协作层，AI智能体可以在任何框架中发现、连接和工作。工程师部署多智能体系统所需的所有组件现在都属于在Agency上构建的每个人，包括确保每个智能体在交互之前经过身份验证和信任的强大身份和访问管理。

Agency还提供开放的标准化工具，用于智能体发现、智能体之间通信的无缝协议以及可扩展工作流的模块化组件。与Cisco、Dell Technologies、Google Cloud、Oracle、Red Hat以及其他75多家支持公司的开发者合作，共同构建下一代AI基础设施。Agency正在发布代码、规范和服务，没有任何附加条件。访问 agency.org 参与贡献。

主持人： 嗨，我是史蒂夫·布莱特菲尔德。我是Brainchip的首席营销官，我在半导体行业已经工作了三十多年。我在中西部的普渡大学接受电气工程训练，职业生涯的前三分之二专注于在半导体中设计数字信号处理器，并解决从消费到军事领域的用例问题。

我在许多大型半导体公司工作过，但工作时间最长的是在高通。在高通，我负责推出他们的第一款智能手机芯片。有趣的是，当时我在产品管理部门，你永远不知道哪个产品将来会成功。当时有很多争论和讨论，为什么要构建智能手机芯片，因为没人会想在手机上看视频，而且现在的手机已经能打电话了。我们与管理层争论并最终推出了这款产品，现在每个人口袋里都有一部智能手机。

我认为在Brainchip，未来每个人都会在口袋、翻领或帽子里有一个脑芯片，现在人们可能会想，为什么我需要这个？这对我来说是一段令人兴奋的旅程，看着我曾经工作的产品从占据一个大冰箱的尺寸，变成一个盒子，然后是一块电路板，再到一个芯片，最后变成芯片内部的一小块IP。这是我从事GPS工作时的旅程，一开始GPS接收器大得像一台打印机，然后我们不断缩小它的尺寸，现在它几乎存在于所有设备中。谁能想到会这样呢？

我认为AI也会经历同样的过程。我们现在看到的AI是大型数据中心，超级计算机旁边还有核电站，但行业的真正趋势是AI正在渗透到我们日常的所有产品中。你的Fitbit、智能手表、手机，以及你接触的每一个消费产品都将内置一些AI。这就是我对Brainchip感到兴奋的原因，因为Brainchip专注于那些为佩戴者提供帮助的小型消费设备，而不是那些吸收人们信息用于销售广告的大型AI数据中心。

### (15:00 - 30:00) Part 2

在边缘进行推理，不断地推断你正在观察、听到或感知的内容。这种推理总是在边缘进行，在边缘进行计算很有意义，这样就不必将数据从边缘一路传送到云端计算，然后再传送回来。这样做有三个原因。首先是延迟，这是一个来回的过程。其次是成本，在服务器上运行和传输数据需要花钱。第三是隐私，数据被发送到某个地方，而你并不知道它去了哪里。

我认为我们已经看到了很多大公司这样做，他们并不尊重数据和隐私权。关于AI，我看到的最有趣的调查是，70%的人认为AI是好的，能帮助他们更好、更容易地做事。但同样的人群中，72%表示他们担心使用AI会泄露自己的数据。这就像一把双刃剑。你知道它会帮助你，但同时也知道它在暴露你。当你在边缘进行计算，不发送数据出去时，这在某种程度上帮助解决了这个问题。

整个行业确实正在向边缘计算转移，但这需要时间。因为在数据中心，你不需要规划任何事情，它就像是一个计算的海洋。但如果在边缘只有一个浴缸大小的计算空间，你必须确保能将你的问题塞进去。这就是将推理问题适配到你拥有的计算量中。

你说过有一天每个人口袋里都会有一个脑芯片。它计算的数据来自边缘的传感器，对吧？可以是视觉、音频、热量、压力或任何其他数据。是这样吗？你们看到了哪些使用场景？我们可以支持任何传感器数据。从振动到麦克风，从摄像头到雷达、激光雷达、超声波，甚至化学传感器。我们曾经有一个演示，可以通过AI进行气味检测，通过品尝啤酒并分析其化学采样来识别啤酒的种类。

当我们说边缘，有时也称为"设备上"，意味着就在你手中的设备上，不需要离开设备。现在流行的另一个术语是"物理AI"，意思是与物理世界交互的AI。它不在某个塔楼里大量计算数据，而是不断从传感器获取数据并实时计算。我们称之为流数据。当数据不断流入时，你只有两个选择（或者说三个）：计算它，存储它，或者将其传输到其他地方计算和存储。在边缘直接计算显然更便宜。

是否有一些计算太重，无法处理？确实如此。我们设计的架构主要关注使用神经形态原理进行检测和分类。对于现在很流行的大语言模型和生成式AI算法，它们并不是很好的目标，因为它们有不同的计算特征。它们有效地部署矩阵乘法。我们在Brainchip有一项不同的技术，使用与Transformer不同的神经网络架构。Transformer是当今大语言模型和生成式AI的基础，但我们采用了状态空间模型，这是Transformer的一种创新，计算效率更高。

是的，这是目前的前沿技术。很多人正在转向状态空间模型，因为它具有更好的记忆和召回能力。而且计算量也更少。人们需要理解的是，边缘设备上的麦克风或摄像头并不总是在工作。有时没有任何声音，或者只是噪音，没有人说话。摄像头可能正盯着一块空白屏幕，等待有东西飞过。摄像头的活动水平远低于其输出的数据量。这就是我们通过神经形态计算利用的数据流信息量。

我常用的类比是，如果你盯着一个空白屏幕，你的电脑不会拼命计算每个像素。你的大脑会过热，对吧？但当屏幕上有东西移动时，你可以立即检测、处理和分类。现在的摄像头是按照电视机的方式设计的，每30分之一秒放一张新图像，骗过你的大脑以为它在移动。当我们进行推理时，人们将摄像头连接到AI，以同样的方式每30分之一秒给出一整帧数据并让它计算。即使在那30分之一秒内没有任何变化，它也会计算每个像素，就像它们是金子一样，然后回来说"我们没看到任何东西"。

神经形态计算的做法是"计算场景变化"。如果看到变化，就产生一个脉冲。所以空白屏幕在AI处理中几乎不消耗电力，因为没有脉冲进入处理器。一旦脉冲进入，网络就会点亮，开始生成脉冲和脉冲。这些脉冲在网络中传播的方式决定了场景中识别出什么。麦克风也是同样的道理。

### (30:00 - 45:00) Part 3

I apologize for the confusion. The translation text was actually provided in the original request. Here's the translation:

>> 我们在美国的Global Foundaries生产芯片。他们在纽约州北部有一个22纳米工艺的晶圆厂。我想这原来是IBM的设施，对吧？在Fishkill。

这款产品的美妙之处在于它是一种蓝宝石基底硅半导体。这意味着两个重要特点：首先，我们获得了低泄漏特性，这些芯片功耗非常低。其次，我们可以进行辐射硬化处理。我们的一个客户正在进行太空任务，他们正在开发第一款将用于卫星、航天器，以及任何进入太空的设备的辐射硬化AI芯片。

>> 没错。在太空中，功耗显然是一个关键问题。而且你们还与其他芯片设计商，如ARM和Intel合作，

>> 没错。我们拥有一个伙伴生态系统。Intel是我们的合作伙伴。我们曾与日本半导体制造商瑞萨（Renas）合作，他们是Aikita的授权商。还有一家美国公司Frontgrade Gistler，他们正在为太空开发辐射硬化芯片。

>> 所以你们是神经形态IP的首个商业生产商，很快还将生产芯片本身。你认为工业界需要多长时间才会采用这项技术？现在他们还在使用车载后备箱里的超级计算机。

>> 确实如此。我们是神经形态IP和芯片的首个商业提供商。我们已经拥有芯片五年了，但主要是作为开发平台。客户说："我等不及要定制芯片了。我能直接购买这种芯片并用于第一代产品吗？"我们最初有些犹豫，但最终同意了。

目前有其他公司生产模拟神经形态芯片，但它们通常针对特定市场细分，比如语音唤醒或生物唤醒。它们是为特定功能设计的神经形态芯片。而我们的芯片是数字可编程的，可以使用任何类型的传感器，在这一点上我们是独一无二的。

>> Build the future of multi-agent software with agency。这是一个开源的Linux基金会项目。Agency正在构建代理互联网，一个AI代理可以发现、连接和跨任何框架工作的协作层。工程师部署多代理系统所需的所有组件现在都属于Agency构建者，包括强大的身份和访问管理，确保每个代理在交互前都经过认证和信任。

Agency还提供开放的标准化工具用于代理发现、代理间通信的无缝协议以及可扩展工作流的模块化组件。

与来自思科、戴尔科技、谷歌云、甲骨文、红帽以及其他75家支持公司的开发者共同构建下一代AI基础设施。Agency正在发布代码、规范和服务，无任何附加条件。访问agency.org参与贡献。那是a gncy.org。

>> 但是，我们看到正在向设备边缘计算发展。这是解决功耗问题的方案，系统更小，传输系统也更高效。但现在它还没有进入我的家里。我有智能温控器、智能手机和助听器。我想谈谈助听器。你认为这项技术何时会真正进入我们周围的计算基础设施？

>> 我认为现在正在快速普及。最初的挑战是我们没有使用传统网络，这造成了编程门槛。AI以前是这样：有大量开源代码，你只需按下按钮，使用暴力计算，然后得到一个好结果。就像现在的ChatGPT，不费吹灰之力，一切都是现成的。你输入内容，就能得到答案。但这仍然非常昂贵，风投正在免费提供一个尝试，希望你最终付费。

关于你的问题，我们正试图搭乘神经形态计算和BrainChip的顺风车，整个市场正在向边缘计算转移。市场研究报告显示，目前大约10%的边缘产品和嵌入式设备在运行AI软件。但在未来四到五年内，30%到35%的产品将配备AI。我预计再过五年，90%的设备都将嵌入AI，其中大约一半可能使用神经形态计算。这是因为技术将变得更加普遍，更容易理解。人们需要一个可以直接购买和使用的产品，而我们正在通过提供芯片和IP来改变这一现状。

>> NVIDIA在GPU市场的垄断很大程度上归功于CUDA编程语言，人们对此非常熟悉。我和Cerebrus、Samanova以及其他新的GPU或推理芯片制造商交谈过，他们面临的障碍是人们不想学习新的编程语言。事实上，Cerebrus已经转向在云中提供芯片和推理服务。你们面临同样的挑战吗？

>> 整个行业都面临这个问题。关键在于易用性和一键式功能，让大量工程师轻松采用。CUDA最初并非为AI开发，而是为那些试图预测天气、设计武器或分析建筑结构完整性的科学计算人员而创建。科学计算是CUDA诞生的领域，恰好AI的主要运算符恰好可以用CUDA语言描述。

业内人士关注的是如何从CUDA编程环境过渡到Aikita编程环境。但现实是，工程师不会轻易做出这种转变。他们在CUDA上已经投入了大量代码。因此，业界正在做的，我认为NVIDIA也在支持，是创建类似CUDA的软件API，使开发者能够在边缘设备上运行部分代码，无论是BrainChip设备还是其他边缘AI设备。这将加速边缘计算的采用，因为它将从大型NVIDIA环境中转移一系列新功能到超低功耗的边缘环境。

对NVIDIA来说，这实际上是有利的，因为他们确保了CUDA的主导地位，同时让边缘市场也为他们背书。他们必须选择是专注于边缘还是云端，最终决定专注于云端，并允许分散的边缘市场由其他公司服务。

>> 解释一下具体是如何实现的。假设你的设备中有一个BrainChip，你想在上面部署模型或进行模型计算，可能是在芯片上或内存中。为此，你需要使用Aikita的专有编程语言。那么NVIDIA是如何通过CUDA支持这一过程的？

>> 他们并没有直接这么做，但他们正在使开发者能够在NVIDIA不太感兴趣的领域，在不同的硬件上运行用CUDA编写的代码。关于神经形态计算在Aikita中的局限性，我们确实无法支持所有不同类型的运算符，这曾是CUDA的优势——它支持各种数学运算符。

我们的解决方案是将Aikita与主机CPU结合，在Aikita上运行某些功能，如果无法运行，就传递给CPU。事实上，NVIDIA也是这么做的。并非所有计算都在GPU上进行，有些在嵌入式的ARM CPU上运行。这就是所谓的异构计算：并非每个处理器单元都适合所有任务，但如果你有不同类型的计算单元，就可以将任务分配给最有效的单元。

例如，我正在RISC-V大会上，与授权RISC-V内核的Andes合作。我们可以为客户组合RISC-V内核、传统加速器和Aikita，构建一个整体平台，并提供一个编程接口，可以将部分代码存根，然后用Aikita替换，或者simply在CPU上运行。这并非我们首创，而是业界趋势。

回想我的移动电话时代，高通就是这样工作的。他们今天的AI运行在CPU、GPU和NPU上。现在我们可以与Andes的CPU协作，可以卸载到GPU，甚至卸载到Aikita旁边的另一个AI加速器。如果边缘数据不稀疏，Aikita可能并非最佳加速器，那就将任务发送到旁边的单元。这样我们可以平衡系统，以最优方式执行复杂模型。

>> 那么，让我们来聊聊具体应用。谈谈助听器。解释一下神经形态技术如何让耳塞变成助听器。

>> 我们已经开发了唤醒技术。比如唤醒词，就像"OK Google"或"Hey Siri"，手机有特殊电路以低功耗持续监听。但在助听器中，功耗更低，因此需要更高效的技术。

我们还开发了状态空间模型和降噪算法，可以显著减少噪音。去年在CES展会上，我们展示了降噪技术。在嘈杂环境中，戴上这些设备，通过AI算法处理后，声音清晰得令人惊叹。

许多助听器的关键在于有选择地向人耳传递正确信息。这些降噪算法就是其中之一。还有一点很多人不理解：大语言模型（LLM）实际上可以用于这些处理。如果LLM知道正在说什么，它可以预测接下来的词。即使声音嘈杂，它也能识别并更清晰地重现词语。

这是业界的一个趋势：用机器学习和AI算法替代传统的数字信号处理算法。助听器是一个明显的应用场景。过去是使用数字信号处理器进行滤波，调整滤波器以匹配和定制。而使用AI机器学习，你根本不需要这么做，反而能获得更好的效果。事实上，我的一个朋友正在创业，就是基于我们在移动手机上的工作。

### (45:00 - End) Part 4

业界有一个趋势，就是用机器学习和AI算法替代数字信号处理算法。助听器是一个很明显的应用场景。目前，数字信号处理器通过调整滤波器来优化匹配和定制。但使用机器学习，你根本不需要这么做，反而能获得更好的效果。事实上，我的一个朋友正在创业，就是基于我们在移动手机上的工作。

我想这对翻译会有很大帮助。翻译速度正在提高，大家对同声传译非常兴奋。我猜测，这可能是神经形态计算的一个应用场景，比如在耳机、耳塞或助听器这样的监听设备上。关键是看它是否能处理这种负载。

我们正在使用神经形态计算处理输入信号，因为稀疏数据有优势。但是对于大型语言模型，我们不使用神经形态算法，而是使用状态空间模型。我们正在研究如何将这两种技术整合到一个平台中。这样可以增强语音识别的信号处理，大语言模型可以预测下一个将要说的词，从而提高识别准确性。你甚至可以在耳机中放置一个本地大语言模型，其信息可能非常有限，但恰好是你需要的。

一个有趣的应用场景是为老年人提供记忆辅助的大语言模型。它可以提醒你："你的孙女叫谢莉，今年4岁"，这样即使你忘记了，也能通过一些提示找回记忆。美国国家卫生研究院认为这非常有价值，因为如果听力不好，可能会导致老年痴呆和认知问题。保持听力和视力对保持大脑健康至关重要。当大脑接收不到这些信号时，就会开始产生幻觉，就像大语言模型一样。