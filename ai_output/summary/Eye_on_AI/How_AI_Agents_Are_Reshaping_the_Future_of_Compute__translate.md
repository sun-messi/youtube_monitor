# How AI Agents Are Reshaping the Future of Compute Infrastructure

## 📹 视频信息

- **频道**: Eye on AI
- **发布日期**: 2026-01-11
- **时长**: 52:03
- **原始链接**: [https://www.youtube.com/watch?v=SzVQJ1-EC0M](https://www.youtube.com/watch?v=SzVQJ1-EC0M)

---

I'll analyze this transcript and provide a comprehensive summary following the required format.

## 视频开头信息

> 本文内容整理自 Run Loop AI 创始人兼CEO 乔纳森·沃尔（Jonathan Wall）在 Eye on AI 频道的技术访谈。

## TL;DR（一句话核心洞察）

> AI 智能体需要全新的计算基础设施：Run Loop 通过为每个智能体提供独立的"虚拟计算机"（Dev Box），让智能体能像人类一样灵活使用工具、访问网络、执行代码，从而彻底改变了 AI 应用的开发和部署方式 —— 这是继互联网、移动计算之后的第三次平台革命。

## 📑 章节导航表

| 时间戳 | 章节标题 | 一句话概括 |
|--------|----------|-----------|
| 00:00-05:00 | 智能体基础设施的新需求 | 智能体需要独立的虚拟机环境，而非传统的网页或浏览器运行方式 |
| 05:00-10:00 | Run Loop 的定位与架构 | 专注于智能体运行时层，为智能体提供隔离的执行环境（Dev Box） |
| 10:00-15:00 | 智能体的虚拟机模式 | 每个智能体拥有独立的容器和微虚拟机，确保安全隔离和完整计算能力 |
| 15:00-20:00 | 智能体的多样化应用 | 从编码、安全审计到金融分析，智能体应用场景正在快速扩展 |
| 20:00-25:00 | 企业级智能体部署模式 | 混合人机协作、事件触发、Slack 集成等多种部署模式并存 |
| 25:00-30:00 | 智能体改变计算范式 | 从结构化 API 到开放式任务执行，智能体需要全新的计算原语 |
| 30:00-35:00 | 基准测试与准确性保障 | 通过 Benchmarks 产品帮助开发者验证和提升智能体的准确性 |
| 35:00-40:00 | 强化学习与模型优化 | 将 RL 和微调周期从数周缩短到数小时，支持并行实验 |
| 40:00-45:00 | 目标市场与企业策略 | 从初创公司到大企业，推出 VPC 部署满足合规需求 |
| 45:00-52:00 | 智能体经济的未来 | 每个员工将拥有多个智能体协作伙伴，改变工作方式 |

## 📊 核心论点

### 1. 智能体需要全新的计算基础设施

- **核心内容**：传统服务器处理结构化 API 请求，执行确定性代码，而智能体的行为是开放式的、不可预测的。它们需要访问各种工具、可能消耗大量资源、甚至为自己编写代码。Run Loop 提供的 Dev Box 本质上是给每个智能体一个独立的计算机，配备完整的文件系统、网络访问、Shell 环境等。这种隔离的沙箱环境既保证了安全（防止恶意代码扩散），又赋予了智能体最强大的工具集。
- **关键概念**：Dev Box、执行沙箱、容器化、微虚拟机、隔离边界
- **实际意义**：催生了智能体基础设施这一新赛道，类似于互联网时代的 AWS/GCP，为智能体经济提供底层支撑；使企业能够安全地大规模部署智能体，无需担心安全风险。

### 2. 智能体正在改变软件开发生命周期

- **核心内容**：18个月前工程师还在手写 100% 的代码，现在智能体已经能编写 60-90% 的代码。不同工程师使用不同的智能体（Gemini、Claude、自定义智能体），形成个性化的工作流程。简单的完整应用（如预订系统）智能体已经能从零开始独立完成。Run Loop 的客户通过 GitHub webhooks 触发代码审查智能体，实现自动化的代码质量控制。
- **关键概念**：代码生成比例、个性化工作流、自动代码审查、CI/CD 集成
- **实际意义**：软件开发效率呈指数级提升；工程师角色从"编码者"转变为"智能体指导者"；小团队能够完成以前需要大团队的工作量。

### 3. 基准测试是智能体可靠性的关键

- **核心内容**：Run Loop 的 Benchmarks 产品允许开发者创建特定领域的测试场景，验证智能体在已知条件下的表现。当切换模型（如升级到 Claude Opus 4.5）或调整提示词时，可以通过基准测试量化性能变化。即使是看似无害的改变（如让智能体更友好）也可能影响其核心功能，因为这改变了模型的输入扰动。多个智能体可以级联工作，一个执行任务，另一个验证结果。
- **关键概念**：领域特定测试、模型切换验证、提示词工程、级联验证、准确性度量
- **实际意义**：解决了企业对智能体可靠性的核心担忧；使智能体开发从"黑盒调试"转向"数据驱动优化"；为智能体的生产部署扫清障碍。

### 4. 智能体的多样化触发和部署模式

- **核心内容**：智能体部署已形成多种成熟模式：人机协作（Claude Code、Cursor）、事件驱动（Zendesk 工单自动处理）、Git 集成（每次代码推送触发审查）、Slack 机器人（@agent 触发）。一个客户曾同时启动 6000 个智能体处理并行任务。企业工作流正在引入"审查-批准"环节，智能体完成 70-80% 的工作后由人类审核。
- **关键概念**：人机协作、事件触发、批量处理、审查机制、工作流集成
- **实际意义**：智能体不再是独立工具，而是深度嵌入企业流程；形成了"智能体优先，人类把关"的新工作范式；为全面的企业自动化奠定基础。

### 5. 从 Series A 到企业级的市场扩展

- **核心内容**：Run Loop 最初服务 AI 原生的 Series A 初创公司（构建智能体产品），现在扩展到 Series B/C/D 公司（在现有产品中集成智能体）。即将推出"Deploy to VPC"功能，允许将平台部署到企业自己的云环境中，满足大企业的合规和数据隐私要求。像 Notion、Figma 这样的新锐公司正在快速集成 AI 功能以对抗传统巨头。
- **关键概念**：AI 原生 vs AI 增强、VPC 部署、企业合规、市场分层
- **实际意义**：智能体基础设施市场正在快速成熟，从服务创新者到服务主流企业；预示着智能体将成为所有企业的标配，而非少数先驱的专属。

### 6. 智能体专用的强化学习和微调平台

- **核心内容**：Run Loop 支持并行运行数千个 Dev Box，每个使用不同的模型变体进行实验。通过评分函数自动评估每个变体的表现，将强化学习（RFT）周期从数周缩短到数小时。监督微调（SFT）更简单且成本低一个数量级：收集智能体在基准测试中的成功和失败案例，作为标注数据训练 LoRA 适配器。建议优先使用最新模型和基准测试，只在高流量、高价值场景才考虑 RFT。
- **关键概念**：并行实验、自动评分、RFT vs SFT、LoRA 适配器、成本效益分析
- **实际意义**：democratize 了 AI 模型优化，中小企业也能针对特定任务优化模型；大幅降低了智能体性能优化的时间和成本门槛。

### 7. 个性化的智能体使用模式

- **核心内容**：即使在 Run Loop 这家只有 16 人的公司内部，相邻座位的工程师也使用完全不同的智能体和工作流程。有人喜欢先勾勒代码框架再让智能体填充细节，有人则让智能体主导。这种差异化使用模式将扩展到所有职能：HR、财务、运营等部门的员工都将根据个人偏好选择和使用智能体。未来的工作场景是人类与多个专业智能体组成的混合团队。
- **关键概念**：个性化工作流、智能体选择权、混合团队、职能专业化
- **实际意义**：智能体不会以"一刀切"的方式改变工作，而是适应每个人的独特风格；企业需要提供智能体选择的灵活性而非强制统一；预示着更加人性化的人机协作未来。

### 8. 智能体改变计算范式的本质

- **核心内容**：传统计算是"请求-响应"的确定性模式，而智能体更像人类解决问题：面对代码审查任务，智能体可能主动下载 GitHub 文档、解析内容、做笔记、编写验证脚本。这种开放式、探索性的计算模式需要完整的计算环境支持。给智能体一台计算机是最强大的赋能，让它能使用 50 年积累的 Unix 工具链。AWS 和 GCP 目前都没有"弹性沙箱"这种计算原语。
- **关键概念**：开放式计算、探索性行为、Unix 工具链、新计算原语、弹性沙箱
- **实际意义**：定义了继虚拟机、容器之后的第三代计算抽象；可能催生新的云计算巨头；为智能体经济提供了必要的基础设施创新。

### 9. 智能体生态系统的分层架构

- **核心内容**：智能体技术栈正在快速分层：底层有 Oracle、CoreWeave 等新云服务商整合 GPU 资源；中间层有 Run Loop 提供运行时基础设施；上层有 Claude Agent SDK、LangChain DeepAgents、Codex SDK 等智能体框架；最上层是 Cursor、Manos 等面向用户的智能体应用。每一层都有新玩家挑战现有格局，整个行业处于快速洗牌期。Vercel、Railway 等工具简化了前端开发，与 Run Loop 形成完整的开发链条。
- **关键概念**：技术栈分层、生态系统、框架选择、垂直整合、水平分工
- **实际意义**：智能体产业链正在快速成熟，各层都有巨大机会；创业者需要明确定位，选择合适的层次切入；预示着智能体将成为继 Web、Mobile 之后的第三个主要计算平台。

### 10. 智能体引发的经济结构重组

- **核心内容**：正如互联网时代淘汰了忽视数字化的传统企业，智能体时代也将重塑竞争格局。AI 原生的初创公司（如 Cursor）正在快速侵蚀传统软件巨头的市场。但成熟的科技公司（Google、Microsoft、Notion、Figma）也在积极转型，将智能体功能整合到现有产品中。形成了初创公司的颠覆性创新与成熟公司的渐进式创新之间的竞赛。最终，不采用智能体的企业将失去竞争力。
- **关键概念**：创新者困境、AI 原生、产品增强、市场重组、竞争窗口
- **实际意义**：为企业敲响警钟：立即行动或被淘汰；创造了巨大的创业机会窗口；预示着未来 5-10 年的商业格局重大调整。

### 11. 未来已来但分布不均

- **核心内容**：工程领域已经全面拥抱智能体，几乎没有工程师不使用 AI 辅助编码（除非公司政策禁止）。这种变革正在向其他领域扩散：HR、财务、运营等。不同行业和地区的采用速度差异巨大，创造了巨大的套利机会。Run Loop 团队从 2024 年初的 100% 手写代码，到现在智能体承担 60-90% 的编码工作，18 个月内发生了翻天覆地的变化。
- **关键概念**：采用曲线、行业差异、先发优势、生产力飞跃、代际更替
- **实际意义**：早期采用者将获得巨大的生产力优势；行业知识与 AI 能力的结合将成为核心竞争力；预示着工作方式的根本性转变即将席卷所有行业。

## 🏢 提及的公司/产品

| 公司名 | 讨论语境 | 重要性 |
|--------|----------|--------|
| Run Loop AI | 智能体基础设施平台的核心提供者，提供 Dev Box 和 Benchmarks | ⭐⭐⭐ |
| Google (GFS, Wallet) | Jonathan Wall 的职业背景，早期分布式系统和移动支付创新 | ⭐⭐ |
| Stripe (Terminal) | 收购 Index，Jonathan 的前一家公司，支付基础设施 | ⭐⭐ |
| Claude (Anthropic) | Agent SDK 提供者，Opus 4.5 模型，智能体框架 | ⭐⭐⭐ |
| LangChain | DeepAgents 框架，智能体构建工具，生态合作伙伴 | ⭐⭐ |
| OpenAI | Codex SDK，SFT 合作案例 | ⭐⭐ |
| AWS/GCP | 底层云基础设施，缺少"弹性沙箱"原语 | ⭐⭐ |
| Cursor | AI 原生 IDE，快速增长的智能体应用案例 | ⭐⭐ |
| Notion/Figma | 成功整合 AI 功能的新锐公司案例 | ⭐ |
| Manos | 中国的智能体平台，使用虚拟机+浏览器模式 | ⭐ |

## 💬 经典金句

> "Agents work differently enough and have different enough compute patterns that they need their own new compute primitive."
> — Jonathan Wall

> "Giving agents tools makes them more effective. There is no more powerful tool than a computer."
> — Jonathan Wall

> "The future's here. It's just not evenly distributed."
> — Jonathan Wall（引用 William Gibson）

> "I don't think this genie is going back in the bottle. It behooves everyone to have some touch and feel experience with agents."
> — Jonathan Wall

> "18 months ago I wrote 100% of my own code. Now these agents are capable of writing 60-90% of your code."
> — Jonathan Wall

## 👤 主要人物

### Jonathan Wall

**身份**：Run Loop AI 创始人兼 CEO
**背景**：早期职业生涯在 Google，担任 Google File System（GFS）技术负责人，见证了互联网规模化基础设施的诞生。2009 年创立 Google Wallet，开创了 NFC 移动支付技术。后创立支付基础设施公司 Index，被 Stripe 收购成为 Stripe Terminal 产品。
**核心观点**：智能体代表继互联网、移动之后的第三次平台革命，需要全新的计算基础设施。每个智能体都应该拥有自己的计算机（Dev Box），这是最强大的赋能工具。未来每个知识工作者都将与多个智能体协作，形成混合工作团队。

### Craig Smith

**身份**：Eye on AI 播客主持人
**背景**：资深 AI 行业观察者和访谈者
**核心贡献**：通过深入提问引导出智能体基础设施的关键洞察，特别是关于企业采用、可靠性保障、未来工作形态等核心议题

## 📺 视频类型判断

**访谈对话**：典型的一对一深度技术访谈，主持人通过结构化问题引导创始人分享产品理念、技术架构和行业洞察

---

## 📝 完整翻译

### (0:00 - 8:00) Part 1

**(0:00 - 1:20)**

我认为将基础设施的视角应用到即将到来的智能体革命中会很有趣。我与之前创业公司的一些前同事聚在一起，并雇佣了一些新人，创立了 Run Loop。智能体的工作方式和计算模式足够不同，它们需要自己全新的计算原语，这正是我们在 Run Loop 构建的核心。我们称之为我们的开发盒子。

**(1:20 - 2:40)**

有些公司专门制作智能体构建器，这非常有用和必要。其中一些与不同的框架配对，比如 Langchain 的团队有一个很酷的智能体构建器，它与 Langchain 紧密耦合。但我们的定位更底层一些，更接近基础设施层，我们最终希望成为智能体部署和执行的运行时。

**(2:40 - 3:50)**

克雷格：让我们先从介绍开始，请介绍一下你自己和你的背景，以及你是如何创立 Run Loop 的，然后谈谈 Run Loop 是什么。

乔纳森·沃尔：很高兴见到你，克雷格。我是乔纳森·沃尔，Run Loop AI 的创始人，同时也是 CEO。我在 Google 刚上市不久后就加入了，在那里我是 Google 文件系统的技术负责人。那是大规模分布式系统发展初期的重要时期，我亲眼见证了互联网爆发式发展和为此构建的新技术。

**(3:50 - 5:20)**

2009年，我和另一位工程师离开 Google 创建了 Google Wallet，这是第一个基于 NFC 技术的点击支付解决方案。当你看到人们用手机轻触支付时，那就是我们在2009年创造的技术。当时我没有考虑那么多细节，但实际上我们抓住了下一个重大的技术平台革命，也就是移动手机以及这种新形态所带来的新能力。

从互联网和大规模基础设施的构建转向支付和移动领域。之后，我离开并与 Google Wallet 项目的另一位同事创立了一家名为 Index 的公司，专门为一级零售商提供安全支付基础设施。这家公司最终被 Stripe 收购，成为了 Stripe Terminal 产品，也就是 Stripe 的实体卡支付产品。

**(5:20 - 6:50)**

我在 Stripe 待了一段时间，离开后发现了下一个重大的平台变革或技术革命——AI。考虑到我的背景主要是基础设施，我想如何参与这次特殊的革命。我认为将基础设施的视角应用到即将到来的智能体革命中会很有趣。我与之前创业公司的一些前同事聚在一起，并雇佣了一些新人，创立了 Run Loop。我们真正想要构建一个平台即服务，成为运行这些智能体的地方。

**(6:50 - 8:00)**

就像当年 GFS 的基础设施建设对互联网来说是必要的一样，我们认为智能体的工作方式和计算模式足够不同，它们需要自己全新的计算原语，这正是我们在 Run Loop 构建的核心。我们称之为我们的开发盒子。

### (8:00 - 16:00) Part 2

**(8:00 - 9:15)**

它拥有自己计算机的完全访问权限，让它能够做非常强大的事情。我不知道你对这些智能体的体验有多少，比如 Claude Code 或 Cursor 的 Langchain deep agents，但你会看到它们经常使用 shell、终端环境，这真正利用了 50 年来 Unix 编程的积累，让它们能够动态地按自己认为合适的方式完成任务。我们认为这是相当重要的。

**主持人：** 让我问一下，这是针对单个智能体的情况。我为引入其他公司而道歉，但这是我了解 Run Loop 当前位置的方式。比如 Manos，是我见过的第一个使用虚拟机的中国智能体平台，但它使用的是浏览器。

这是一个趋势吗？智能体不再使用用户计算机上的资源，而是在云端的某个地方，在独立的计算基础设施上运行？

**(9:15 - 11:00)**

**Marc：** 是的，当然。我认为有很多原因支持这种做法。澄清一下，我认为 Manos 实际上是在自己的虚拟机中运行智能体，然后他们有一个网页作为产品界面。

**主持人：** 我明白了。

**Marc：** 但我认为每个智能体可能都有自己的虚拟机。我认为这是人们将要采用的模式。你有一个很好的隔离执行单元。意思是，这是你的容器镜像，你在虚拟机中运行。我不担心你逃脱并造成麻烦，同时我可以将你需要的任何东西放入容器镜像中。我可以确保你有上下文，确保你有完成工作所需的所有正确工具。

**(11:00 - 12:20)**

我认为总的来说，我们开始看到或已经开始看到的是，人们有一些不错的基于网页的用户界面，然后路由到这些在自己虚拟机中运行的智能体。我确实认为你提到这些其他公司作为例子是很有用的，因为你指出在技术栈的不同层面涌现出很多公司。在我们上面的技术栈层面，有智能体构建者和不同的智能体框架。在我们下面的技术栈层面，我们主要运行在 AWS 和 GCP 上，但你可以看到像 Oracle 和 Corewave 这样的公司说，"这里发生的计算变革足够大，打包 GPU 现在也变得非常重要"，他们试图有效地竞争并构建新的云产品来与 AWS 和 GCP 正面竞争。

**(12:20 - 13:30)**

因此，在各个层面，现状可能都被颠覆了，在技术栈的所有不同层面，你都有不同的人试图提供新的原语来构建这个新经济。

**主持人：** 是的。你们正在构建的这个层面，就像采用了 Manos 的概念——不是说你们抄袭了 Manos 的概念，而是在我看来创建了一个不可知的基础设施层，然后所有这些智能体构建者都可以在其上运行。是这样吗？

**Marc：** 是的，这是一个很好的表述。我们相信在未来（现在正在发生），你会看到越来越多的人构建智能体并说："我将有一个产品前端。部署我的智能体的方式是为每个智能体配备自己的计算机。"这就是为什么我们的平台被设计来满足这个用例，并使其尽可能简单。

**(13:30 - 14:45)**

我们让指定你想要在容器镜像中的内容变得非常简单，然后启动这些东西并连接到它们。所以我们可以启动——我们的一些客户一次启动 6000 个这样的东西。然后在连接到智能体方面，让你的产品前端可以实际深入连接并与智能体交互。我们支持很酷的连接功能。我们有一个叫做"隧道"的产品功能，你可以通过 WebSocket 或 HTTP 连接到这些东西。你可以告诉我们打开隧道。默认情况下，除非你要求，我们不会打开隧道。但是，我们认为这是一个重要的新原语，很兴奋能成为其中的一部分。

**主持人：** 是的。所以你们自己不构建智能体，对吗？

**Marc：** 不，真正由我们的用户来构建他们自己的智能体。也许我们来走一遍有人如何做这件事的生命周期。

**主持人：** 那会很棒。

**(14:45 - 16:00)**

**Marc：** 是的。还有另一个趋势可能值得一提，它与我们有点正交关系，但我认为有些重要，那就是人们现在开始转向智能体工具。所以你有 Claude Code 的团队制作了 Claude Agent SDK。OpenAI 和 Cursor 制作了 Cursor SDK。然后 Langchain 的优秀团队——我们有幸在一些事情上与他们合作——制作了一个叫做 deep agents 的工具。这些工具是非常有能力的智能体构建模块，你可以在其上构建，可以为你的特定用例定制。

所以我认为人们未来构建智能体的一个非常自然的方式将是选择其中一个工具开始编码，将其作为依赖项包含在他们的智能体中，在本地编码并说"好的，太棒了，这个智能体准备好了"，然后你需要一种部署它的方式。

### (16:00 - 24:00) Part 3

**(16:00 - 17:15)**

**Marc：** 我们越来越多地看到人们构建金融科技智能体，他们试图解决金融类型的问题，比如给定一些来自S1文件或其他文件的文档集合，我能否提取有用的信息等等。所以这是相当开放式的，范围很广。我们看到有些人在加密货币领域，有些人在健康科技领域工作。所以应用范围在扩大，我们平台上的用例呈现分散化趋势。

但你提到了另一个非常重要的问题，我认为这是整个行业仍在努力解决的，那就是准确性问题，以及如何确信你的智能体正在产生有用的输出。我们平台的核心是一个叫做dev box的概念，它实际上是一个供智能体执行任务的隔离执行环境。我们在此基础上构建了一个叫做基准测试(benchmarks)的产品。

**(17:15 - 18:30)**

基准测试的目的是帮助人们解决准确性问题。基准测试的工作原理是这样的：假设我们的一位客户正在构建一个安全智能体。你基于一个已知状态的dev box创建基准测试，并设定已知的期望结果。意思是给定一个从这个状态开始的dev box和代码库，我提前知道存在两三个漏洞。让我反复对这个环境运行我的智能体，然后验证它总是能找到那些漏洞。

我们的基准测试解决方案让客户能够构建领域特定的测试，来验证他们的智能体在尝试完成的任务类型上能够持续成功，就像在野外、在生产环境、在实际生产流量中一样。

**(18:30 - 19:45)**

我认为这是开发生命周期中非常重要的一部分，因为Anthropic刚刚发布了Claude Opus 4.5，据推测它更好了。他们发布的所有基准测试似乎都表明它更好。但你怎么知道如果我切换模型或与该模型对话的智能体，它会表现得更好？如果你一直在运行这些基准测试作为生产生命周期的一部分，你可以改变使用的模型，看看你的分数是否会提高，或者谁知道，它们可能会变差。

所以我们认为基准测试对于正常开发来说实际上是非常重要的。即使你做一些简单的事情，比如说"我要改变我智能体的提示，试图让它更友好一些。也许有人说我的智能体有点突兀，让我们让他或她更友好一点。"

**(19:45 - 21:00)**

你会认为鼓励智能体友好不会改变它的底层行为，但你不知道，对吧？你所做的是把你智能体的入口点带入一个大型随机模型并扰动它。你在改变它，你在移动它如何进入那个大型随机模型。你真的不知道副作用会是什么。所以我们确实认为基准测试非常重要。

我会说我们平台上一些更高级的实践者使用基准测试这样的工具，但他们也有应用层面的措施来试图提高准确性。他们会有一个智能体尝试解决任务，当它认为完成时会说出来，然后他们会有另一个智能体在它之后运行，试图验证它确实完成了工作，如果认为它错了就告诉它重新开始。

**主持人：** 这很有道理。再次回到你所说的智能体社会，正如我采访的某人所称呼的那样，在一个企业中有一千个智能体或六千个智能体在做事情。你觉得这些智能体中的大多数是随时待命供员工使用的，比如编码智能体，它不是独立运行并在企业中执行任务的，还是有一些智能体确实独立持续运行，比如监控费用报告的到来然后处理它们？

**(21:00 - 22:15)**

**Marc：** 这是个很好的问题。我认为在外面你基本上看到各种情况的混合。我认为有人在循环中、人为驱动的、我们正在协作的模式是一个非常流行的模式。你在Claude Code、Cursor和Gemini CLI等工具中都能看到这种模式，可能有一个人真正驱动工作输入，评估工作结果，但智能体是代表一个人工作的。

但我认为正如你所建议的，有各种各样的系统会抛出事件。所以像票务系统可以触发事件。大多数票务系统，比如Zendesk之类的，当有人提交票据时，它会给支持团队发邮件之类的。这很容易成为调用智能体并让智能体尝试解决事件的触发器。我们看到一些客户有智能体，每次你向GitHub推送更改时都会触发，它会发起请求，启动智能体，让智能体也审查你的代码，看看是否有任何明显的错误。

**(22:15 - 23:30)**

我们也有客户将他们的智能体挂在Slack上。所以你可以说@智能体名称，你能帮我解决某个问题吗？这又是另一个触发源。我想这更多是人为驱动的，但我认为你真的看到各种情况的混合，我认为这种情况可能会继续下去。

**主持人：** 你的基准测试层对确保智能体准确执行非常重要。但假设准确性得到改善，你是否看到有一天智能体真的成为企业的底层架构，你知道让它们处理所有的后台工作、所有的质量保证，无论什么，取决于你的领域？

**Marc：** 我认为会的，但我认为这将是按工作流程来的。我的猜测是，可能首先会发生的是你会让智能体完成特定类型工作流程的70-80%，你可能仍然会有一个人来审计或批准最终结果。

**(23:30 - 24:00)**

一个有趣的观察是，在编码领域，如果我们暂时抛开智能体和AI，当我去写一些代码时，我心中有或者也许有人提交了票据并分配给我。我心中有某种想要做的改动。我会去做这个改动，我可能确保它能构建并通过所有测试，但然后我会把它分配给我的同事之一来审查。所以我团队中的其他人会说："好的，John认为他解决了这个问题，让我看看他的代码。"然后最终那个人批准它，然后代码被合并。我认为你可能会看到那些类型的模式，但不是我写代码或执行某些动作，而是可能一个智能体完成大部分工作，然后有一个审查者说好的，我大部分信任这个智能体，但我要查看它们得出的结论，我要查看它们如何完成这项工作。

### (24:00 - 32:00) Part 4

**(24:00 - 25:15)**

编程工具生态系统，但我认为它需要被添加到更广泛的企业生态系统中，比如可能会有一个Zendesk工单进来，也许一个智能体读取工单，查看一些知识库，做一堆工作，建议在Salesforce中更新客户记录。但在它真正执行之前，需要一个人来确认是否更改。所以我确实认为这即将到来，但我认为首先会是选择性的工作流程，并且在大部分时间里可能都需要人工审计。然后最终会有一些工作流程，你对它们有如此高的信心，以至于人类不需要审查每一件事情，他们只审查10%的事情，或者像那样进行抽查。

**主持人：** 是的。今天存在的大多数企业都在试图采用智能体，仅仅是因为竞争压力。但在一些有主导地位传统玩家的行业中，还有其他初创公司。你认为原生智能体公司会崛起吗？你觉得是否可能用主要由智能体组成的劳动力来挑战传统玩家？

**Marc：** 我认为是的。而且我认为这会变得越来越容易。

**(25:15 - 26:30)**

**主持人：** 是的，这很令人惊讶。就像互联网迫使经济格局重新塑造一样，那些早期采用它的人弄清楚了如何使用它，然后一些初创公司进来挑战传统玩家。真的，一些大玩家消失了，新玩家出现了。你认为我们会在经济中看到这种变化吗？

**Marc：** 我猜是这样的。我认为一个有趣的观察点是那些在AI之前诞生的C轮和D轮公司，你可以看看他们采用AI的速度有多快。你可以看看像Notion或Figma这样的公司。这两家公司都早于AI智能体真正成为一种现象，它们都在挑战更大的现有企业，但这两家公司仍然相当年轻和灵活，它们用AI补充了现有产品。Google在整个G Suite产品中都在这样做。Microsoft正试图用无处不在的Copilot来做这件事。

**(26:30 - 27:45)**

所以现有企业有点像在赛跑，说："好的，我如何用智能体来补充和改进我的产品以抵御那种挑战"，同时会有新的初创公司更纯粹地以智能体为先。它们可以快速增长，也许会稍微颠覆现状。Cursor就是一个例子，它们诞生于AI时代，它们有一个真正酷的IDE，是智能体优先的，它们正在掀起一些波澜并且增长得相当快。

**主持人：** 你能带我们了解一下Run Loop上智能体工作的具体例子吗？从启动到运行工具到关闭，这样人们可以想象平台在幕后实际做什么。

**Marc：** 好的，当然。也许我会给出一个例子，比如某个运行代码审查工具的人。我认为这里的重要部分是要指出，这些公司仍然有一个存在于Run Loop之外的产品层。这实际上是智能体运行的地方。

**(27:45 - 29:00)**

假设你明天要开始构建代码审查，这是你的代码审查智能体。你可能会使用Cloud Agent SDK或LangChain Deep Agent或CodeX SDK，或者你可能只是手写自己的智能体。一旦你构建了那个智能体，你就要让它准备好在Run Loop上运行。我们有一个智能体API，让你上传你的智能体并将其存储在我们的平台上。你也可以将其打包到容器镜像中。所以它只是容器镜像的一部分。

现在你已经构建了智能体，你弄清楚了如何将其部署到Run Loop运行时。任何时候你想要，你都可以启动一个开发盒子，将其指向一个代码仓库进行审查。你希望它去注释"这是好代码，这是坏代码，你应该做这个其他的事情"。但现在你需要为你的产品构建产品前端。

**(29:00 - 30:15)**

假设你也是Vercel和Next.js的粉丝。所以你可能会构建你的Web前端，人们在那里注册并输入他们的信用卡信息，然后他们授权你接收来自GitHub的webhooks。然后每当有人在GitHub仓库上打开拉取请求时，你在产品层收到一个webhook。你将接收那个webhook并说："哦，太好了。仓库FU拉取请求22。我要在Run Loop上建立一个开发盒子，告诉他们代码挂载这个仓库进行审查，我要调用我的智能体说：嘿，这是好是坏？提供反馈。"

智能体会开始做它的事情。你可能选择给智能体直接向GitHub推送更新的权限，你可能会的。所以它可以在拉取请求上评论，智能体会进行它的业务。它会在拉取请求上评论，在某个时候它会退出。

**(30:15 - 31:30)**

它会发出信号表示完成了，你的产品层可能正在与智能体对话，看到："哦，你推送了你的更新，你完成了。好的，很好。关闭开发盒子。"现在你有一个前端，有用户注册和一些用户体验，比如我在过去一小时处理了多少拉取请求之类的。所以你有你的前端和产品体验，但当涉及到实际启动和执行智能体时，你是在Run Loop之上做的。

**主持人：** 是的，这太棒了。在我读过的一些资料中，你说智能体改变了计算的形态。你能解释一下你的意思吗？智能体工作负载与经典LLM API调用的最大区别是什么？

**(31:30 - 32:00)**

**Marc：** 是的。我认为我们之前稍微涉及了这一点，但我认为真的值得深入探讨。如果你想想传统服务器，它有一个结构化的API，获取模式数据，以确定性的方式将输出存储在数据库中。这就是现在大多数人运行服务的方式。当你启动一个智能体并要求它做某事时，它是非常开放式的。它更像人类解决问题的方式。

### (32:00 - 40:00) Part 5

**(32:00 - 33:15)**

Marc：它可以完全访问网络、本地文件系统，甚至bash命令。如果你想写一个脚本来确保这个pull request中的代码是可解析的，写个脚本，运行它，没问题。你有自己的计算机。我认为这就是我们在这里讨论的重点——智能体具有不可预测的CPU和内存使用情况。它们可能会做一些有点危险或需要隔离的事情。但最终给它们一台计算机作为工具，这是你能给智能体的最强大的工具。

按任务基础随时启动随机计算实例，像这样的开放式计算实例有点不寻常。这就是为什么我们将这种沙盒视为一种新的计算原语，而这种原语目前在AWS或GCP中都不存在。我们认为在几年内，这将成为运行智能体的标准模式。

**(33:15 - 34:20)**

**主持人：** 当你说弹性时，意思是你可以启动任意数量的实例，或者你可以在容器中放入任意数量的资源？

**Marc：** 这有点讽刺的意味，因为AWS把所有东西都叫做弹性这个弹性那个。但这也是简洁且正确的，这确实是平台需要的一个功能。你希望能够启动一堆这样的实例，用完后丢弃它们，扩展或缩减规模。这是一个重要功能。也许这既是讽刺也是准确的。

**主持人：** 在你们的案例研究中，你谈到将强化学习和微调周期从数周缩短到数小时。一旦客户有了run loop和内置基准测试工具来减少RL和微调时间，他们的工作流程实际发生了什么变化？

**(34:20 - 35:40)**

**Marc：** 当你在做强化学习微调(RLHF)时，实际上是在用模型的微小变化尝试多次解决同一个问题。你想要搞清楚如果我将模型稍微调整一下，或者有效地调整我的权重，是否能改善模型解决问题的能力？

在你提到的特定案例研究中，我们通过能够同时运行多个开发环境的特性，使我们的合作伙伴能够同时尝试许多不同的模型变体。我们的基准测试产品让你从已知状态开始，让你的智能体尝试解决问题，然后我们应用评分函数。当我们的合作伙伴与我们一起进行这项RLHF工作时，他们会启动许多开发环境，每个都固定在不同的模型变体上，然后使用评分函数来确定模型变体是好是坏。它的得分更高吗？

**(35:40 - 36:50)**

从某种意义上说，你在尝试为特定问题找到模型的最优权重。这真的关乎我们能够并行运行许多开发环境，然后运行评分函数并返回结果的能力。

**主持人：** 这很有趣。因为这本身就是一个完整的用例，对吧？否则，有人如何优化RL和微调呢？

**Marc：** 他们必须构建一些替代框架或做大量我们开箱即用的工作。他们必须自己解决这些问题。我们还与OpenAI做了一个相当酷的SFT项目。监督微调(SFT)稍微简单一些，你对基准测试运行，将评分结果作为数据标注器，然后说"好的，这些是我尝试解决问题但得分为零或低分的所有时候。这些是我尝试解决问题并获得高分的所有时候。"

**(36:50 - 38:10)**

你可以收集那些标注数据，这就像一个监督数据集。这就像在参加期末考试前获得过去几年的一堆考试，看到正确答案和错误答案并从中学习。SFT稍微容易一些，因为你可以通过对基准测试运行被动地收集这些数据，然后用它在LLM上产生一个针对你特定问题集的LoRA微调。这稍微容易一些。它不如RLHF那么强大，但根据我的经验，做起来容易一些。

**主持人：** 这样做的成本如何？如果你想启动——我不知道你们在谈论多少个环境，但是...

**Marc：** 这取决于你想做多少个。我认为SFT可能比RLHF便宜一个数量级。而且SFT更容易做。我想这里表达一下我的个人观点。我认为总的来说，大多数构建智能体的人应该使用基准测试来调优他们的智能体，然后关注采用最新的模型，确保他们使用的是最新最好的模型。

**(38:10 - 39:25)**

我认为一旦你达到了可能有大量集中流量的程度，也许就是考虑做SFT的时候了。从复杂性和成本的角度来看，我认为只有对那些最高杠杆、高业务影响、高吞吐量的用例才值得做RLHF。这真的就是努力程度与我的改进将被如何高度利用之间的权衡，这是我个人的经验法则。我确信还有其他人有稍微不同的观点或会以不同方式做事，但这是我的经验法则。

**主持人：** 你们在构建这个产品。目标市场是谁？因为像Google、OpenAI、AWS、Microsoft这样的公司，他们在自己的系统中大概已经有了做这些事情的基础设施...

**Marc：** 程度不同，但确实如此。

**主持人：** 这些公司规模如此庞大，有这么多工程师。是的，他们可以搞清楚这个或类似的东西。但企业级客户...这不是为像我这样想要智能体做一两件事情并且可以使用现成解决方案的人准备的。这是为想要认真采用智能体工作流程的复杂企业准备的，对吧？

**(39:25 - 40:00)**

那些有专门的工程师团队来构建智能体、识别业务案例、构建智能体、部署它们，需要那个基础设施层的企业。我理解得对吗？

**Marc：** 是的，你理解得对。我会说当我们刚开始时，我们主要服务A轮类型的公司。那些试图将智能体作为新业务来构建的人。随着时间推移，我们在价值链上向上发展，开始有B轮、C轮和D轮公司采用我们的平台。明年我们的一个重点将是增加我们称为"部署到VPC"的功能，这意味着能够将我们的解决方案部署到另一个企业的云环境中。我们认为这对于解锁更大的企业客户来说非常重要。

更大的企业对此很感兴趣。许多大公司出于合规性、安全性和数据隐私的原因，对使用像我们这样的共享公共云平台有些担心。如果我们能够将我们的产品打包并投放到他们的环境中，我们认为他们就能在拥有安心感和所需合规性的同时享受所有好处。这对我们来说是一个重要重点。我认为明年我们将向企业客户方向发展。

### (40:00 - 48:00) Part 6

**(40:00 - 41:15)**

出于合规性、安全性和数据隐私的考虑，他们对使用我们这样的共享公共云平台有些担心。如果我们能够将产品进行封装并部署到他们的环境中，我们认为他们就能在享受所有好处的同时拥有安心感和所需的合规性保障。这对我们来说是一个重要重点。我认为明年我们将向企业客户方向发展。

**主持人：** 我明白。当你提到A轮、B轮、C轮公司时，你指的是那些正在构建智能体产品的公司，还是希望构建智能体企业来支持他们向市场提供的产品的公司？不一定是智能体产品。

**(41:15 - 42:30)**

**Marc：** 很多A轮公司是早期公司或AI原生的新公司，他们试图纯粹构建智能体产品。一些更成熟的后期公司会说："我有一个现有的成功产品，我想通过添加一些智能体的魔力来补充它。"

**主持人：** 随着这些系统的发展，我认为陪审团仍在观望五年后我们是否会生活在智能体经济中，还是智能体会在企业中变得有用但不具变革性。你如何看待这些力量的变化？因为如果智能体是未来，它将对企业中的劳动力结构产生巨大影响。

**(42:30 - 43:45)**

**Marc：** 实际上已经产生影响了。我们公司只有16个人，几乎都是工程师。每个人都使用编程智能体来帮助提高生产力。有趣的是，不同的人使用不同的智能体。有些人喜欢使用Gemini，有些人喜欢使用Claude，还有些人为特定的常见用例开发自己的智能体。我实际上构建了一些自己的智能体来评估事物。

这种情况已经在发生。正如那句话所说，未来已经到来，只是分布不均。工程领域已经首先发生了这种变化。我认为现在可能没有多少工程师不使用这些工具，除非他们的工作场所不允许。

**(43:45 - 45:00)**

我刚才从自己的经验得出的观点是有效的。如果你不是工程师，但如果你在人力资源或组织的某个行政部门工作，你可能会有几个不同的智能体，你旁边的人可能有相似的工作，使用不同的智能体并以稍微不同的方式与之合作，但他们完成更多工作是因为他们在与智能体协作。你可能会选择不同的智能体，有一个稍微不同但你满意的工作流程。

我认为这些东西最终会成为劳动力的一部分，成为同事的一部分，不同的团队也会使用不同的工具。如果你想想工程组织，它不是扁平的，对吧？有专注于前端的人员，有适合前端的智能体。有基础设施人员，他们可能使用不同的工具。还有安全工程师、运维人员，有许多专门针对运维的智能体。

**(45:00 - 46:15)**

所以，把它想象成有新同事。你可以选择与哪个新同事合作，这取决于你想要做什么。这是我的猜测。

**主持人：** 这确实很有趣。我之前没有想过这一点，因为当你说你会使用智能体时，我假设有相似工作的人可能会使用不同的智能体或以不同的方式使用智能体。

**Marc：** 我坐在这里。我们的桌子排成一列，我左右都有人，显然后面也有人，但没有人以相同的方式使用这些工具。

**主持人：** 这很有趣，因为我总是假设这会是某种高层企业政策。这些智能体要做这件事，员工必须与智能体合作做那件事。但实际上，这些智能体是可用的，它们会做事情，个别员工会找出如何最好地将它们用于自己的工作流程。

**(46:15 - 47:30)**

**Marc：** 是的，这归结于个人偏好。我确信在你的行业中，你有特定的方式来进行研究，然后选择如何构建你的写作。我敢打赌你的同事作家，可能是地位相似的同龄人，有完全不同的流程，但他们以完全不同的方式达到同样有价值的结果。

对我来说，当我与智能体工作时，我知道我想要做什么。我喜欢去勾画更大的代码变更，确保它对我来说看起来正确，然后说："好吧，智能体，在这里和这里填补空白。"在这个过程中，我在审查它的编写，我会在进行过程中审查代码，有时它会发现我没有预见到的东西。它会说："等等，你这样设置，但这另一个东西怎么工作？"我会说："哎呀。"其他人与智能体的工作方式完全不同。这让事情变得有趣。

**(47:30 - 48:00)**

**主持人：** Run Loop正在进入大型企业领域，一旦你有了私有部署。公司很棒，只有16个人。你如何看待未来？你认为这是广阔的天空，没有限制，还是你不确定市场下一步的方向，你在下注可能会出现不同的范式？

**Marc：** 我不知道企业需要多长时间。我们现在有一个所有客户都在运行的单体部署，我们肯定会继续支持并尝试在那里发展业务，吸引更多客户并添加更多功能。我确实认为对于更广泛的AI和智能体方面，最终获得一些企业成功将是非常重要的。我确实认为我之前提到的这些更完整的智能体框架，如Claude Agent SDK、LangChain和CrewAI的深度智能体以及CrewX SDK，这些都是重要的东西，让人们更容易构建成功的智能体。所以我们将继续尝试发展我们当前的核心业务，同时也尝试成为企业故事的一部分。

### (48:00 - End) Part 7

**(48:00 - 49:15)**

我认为每个对此感兴趣的人都应该去体验一下智能体。我想鼓励大家做的另一件事是选择我刚才提到的任何一个框架，比如LangChain、Deep Agent、Claude Agent SDK或者CodeX，或者直接使用那些现成的智能体，在本地尝试使用它们。然后思考一些你想要为自己定制的任务，去构建它并试一试，这并不难。我认为现在比以往任何时候都更需要这样做。我觉得这个精灵不会再回到瓶子里了，即使你不会成为那种一直在编写智能体的人，也应该对它们有所了解，获得一些实际操作的体验。

**主持人：** 我完全同意，这也是这个播客的目的之一。我以前在节目结尾有一句口号，现在不再说了，因为显得有点明显："AI正在改变你的世界，所以请关注。"即使你认为这与你无关，但这就是我们正在进入的世界。

**(49:15 - 50:30)**

**Marc：** 我们在2024年初创办了这家公司，当时我基本上100%自己编写代码。2024年是人们开始注意到"如果我问ChatGPT问题，它会生成代码，我可以复制粘贴出来"的一年。你可能有一些ChatGPT辅助编程的经验。从那时起发展到Cursor，它就在你的IDE中，但仍然是早期阶段，对吧？你仍然需要自己做很多事情，生成的代码质量可能不是很好。而现在，天哪，这些智能体能够编写大约70%的代码——这取决于工程师和你要解决的问题，在60%到90%之间。它们可以编写代码，你需要去指导和清理，有时需要重新开始并说"看，用这种方式做，这是正确的方式"。但在大约18个月的时间里发生的变化是惊人的。

**主持人：** 我预期这最终也会在其他学科和垂直领域发生。

**(50:30 - 51:45)**

**主持人：** 关于编程，我总是会问这个问题，因为我不是程序员。你认为多久之后会有一个产品，拥有一个由这些非常有能力的编程智能体组成的系统，它们可以互相检查彼此的工作？你用自然语言给出顶层指令，模型可能会进行一些来回交流来澄清它不理解的地方，然后去编程并回来提供干净的可执行代码，无需任何人工干预。

**Marc：** 根据你要做的事情的复杂程度，这种情况已经在发生了。如果你想建立一个预订足球场的网站，包含数据库和日历，人们可以输入邮箱来预订足球场，然后托管在Vercel上并连接数据库——它们现在就能做到这些，从一个酷炫的用户界面到所有的数据库持久化，甚至可能包括像OAuth这样的功能，需要用邮箱账户登录等等。它现在就能独立完成所有这些。所以你描述的情况已经是可能的了。问题是这种复杂性的前沿会以多快的速度扩展？

**(51:45 - End)**

**主持人：** 好的。Jonathan，这次对话非常精彩，我会去了解一下。我希望我们的听众也能从中受益。

---

*生成时间: 2026-01-12 23:39:22*
*由 YouTube Monitor & Translator (Claude CLI) 生成*