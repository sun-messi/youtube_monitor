# Adam Marblestone – AI is missing something fundamental about the brain

## 📹 视频信息

- **频道**: Dwarkesh Patel
- **发布日期**: 2025-12-30
- **时长**: 1:49:28
- **原始链接**: [https://www.youtube.com/watch?v=_9V_Hbe-N1A](https://www.youtube.com/watch?v=_9V_Hbe-N1A)

---

本文内容整理自计算神经科学家、专注研究组织(FRO)模式创始人亚当·马布尔斯通(Adam Marblestone)在 Dwarkesh Patel 频道的技术访谈。

## TL;DR

LLM虽然数据量巨大却远不及人脑能力，关键差异可能在于大脑独特的损失函数设计、全向推理能力和学习/引导双系统架构。理解大脑工作原理需要数十亿美元的连接组学研究，这对AI安全和效率至关重要。

## 📑 章节导航表

| 时间戳 | 章节标题 | 一句话概括 |
|--------|----------|-----------|
| 00:00-15:00 | 大脑vs LLM：根本差异 | 探讨大脑学习效率远超LLM的原因，引入损失函数和全向推理概念 |
| 15:00-30:00 | 学习与引导子系统 | Steve Byrnes理论：大脑如何将进化硬编码的本能与学习获得的知识连接 |
| 30:00-45:00 | 进化编码与基因组效率 | 解释为何仅3GB基因组能构建智能：关键在于紧凑的奖励函数设计 |
| 45:00-60:00 | 强化学习与价值函数 | 对比大脑与LLM的RL机制，探讨模型化vs无模型学习 |
| 60:00-75:00 | 生物vs数字硬件权衡 | 分析大脑的能效优势与数字系统的可复制性优势 |
| 75:00-90:00 | 连接组学愿景 | 介绍E11 Bio的百万美元鼠脑连接组计划及其对AI的潜在影响 |
| 90:00-105:00 | Lean与数学自动化 | 讨论形式化数学证明如何改变数学研究和软件验证 |
| 105:00-109:28 | 科学基础设施缺口 | Gap Map项目发现：每个科学领域都缺乏关键基础设施 |

## 📊 核心论点

### 大脑的独特损失函数架构

- **核心内容**：与LLM使用简单的下一个token预测不同，大脑可能使用了极其复杂的、特定任务的损失函数组合。进化在不同脑区、不同发育阶段编码了大量特定的损失函数——就像包含大量Python代码的程序，精确指定了何时学习什么。这解释了为何大脑能用少得多的数据达到更强的泛化能力。
- **关键概念**：多损失函数系统、发育阶段特异性、进化编码的学习课程、任务特定优化
- **实际意义**：提示AI研究应超越单一损失函数范式，探索多目标、阶段性的训练策略；可能需要重新思考预训练-微调的简单二阶段模式。

### 全向推理：超越单向预测

- **核心内容**：大脑皮层可能实现了"全向推理"——能够从任意变量子集推断其他任意子集，而非仅做单向预测。这类似于联合概率分布的学习，可以在测试时灵活选择推理方向。LLM只能预测下一个token，但大脑可以从声音预测图像、从概念预测感觉、从部分信息重建整体。这种灵活性可能是理解力和创造力的基础。
- **关键概念**：联合分布学习、能量模型、双向推理、概率AI、灵活的条件概率计算
- **实际意义**：未来AI可能需要从单向自回归模型转向更灵活的概率推理架构；多模态学习不应只是简单拼接，而需要真正的联合表示。

### 学习-引导双系统架构

- **核心内容**：基于Steve Byrnes的理论，大脑分为学习子系统(皮层)和引导子系统(下丘脑、脑干等)。引导系统包含进化硬编码的本能和奖励信号；学习系统通过预测引导系统的反应来学习哪些是重要的。这解决了进化如何编码抽象目标(如社交地位)的难题——通过让学习系统预测原始本能反应，自动将抽象概念与奖励关联。
- **关键概念**：双系统架构、思想评估器(Thought Assessors)、本能预测、奖励函数泛化、皮层-皮层下交互
- **实际意义**：AI对齐可能需要类似的双系统设计；解释了为何人类价值观既稳定又灵活；提示如何设计能够泛化的奖励系统。

### 基因组效率之谜

- **核心内容**：人类基因组仅3GB，其中编码大脑的部分更少，却能构建出极其复杂的智能。秘密在于：引导子系统中存在大量特异化细胞类型(蜘蛛恐惧细胞、社交奖励细胞等)，每种执行特定功能；而学习子系统则使用重复的通用架构。就像8层transformer和3层的代码差别不大，但每个特定奖励函数都需要独特实现。
- **关键概念**：细胞类型多样性、基因组压缩、架构复用vs功能特化、进化的代码效率
- **实际意义**：提示AI架构设计应区分通用学习组件和特定任务组件；解释了大脑快速演化的可能性；暗示紧凑的奖励函数设计可能是AGI的关键。

### 连接组学：解锁大脑算法的钥匙

- **核心内容**：E11 Bio正在将鼠脑连接组测绘成本从数十亿降至千万美元级别。通过光学显微镜替代电子显微镜，可获得"分子标注连接组"——不仅知道谁连接谁，还知道突触类型和强度。完整连接组将提供前所未有的约束条件，帮助区分大脑是做反向传播、能量模型还是其他算法。这是理解智能的"登月计划"。
- **关键概念**：连接组测绘、分子标注、光学vs电镜技术、结构-功能映射、技术成本曲线
- **实际意义**：需要数十亿美元投资但相比万亿GPU投资很值得；可能在10年内彻底改变我们对智能的理解；为AI安全和效率提供生物学依据。

### 持续学习与记忆巩固

- **核心内容**：大脑通过海马体-皮层系统实现持续学习：海马体快速存储新经验，通过重放将记忆逐步巩固到皮层的长期表示中。这涉及多时间尺度的可塑性、巧妙的重放策略、以及防止灾难性遗忘的机制。与冻结权重的神经网络训练形成鲜明对比。
- **关键概念**：系统巩固、海马体重放、多时间尺度可塑性、记忆转移、抗遗忘机制
- **实际意义**：解决AI的持续学习难题需要类似的分层记忆系统；提示如何设计既能快速学习又能保持稳定的架构。

### 形式化证明的AI革命

- **核心内容**：Lean等形式化证明语言正在改变数学研究。AI可以通过强化学习搜索证明空间，因为证明正确性提供了完美的奖励信号。这不仅加速定理证明，还可能改变软件验证、硬件设计、网络安全。挑战在于如何形式化"有趣"的猜想和"优雅"的证明。
- **关键概念**：形式化证明、RLHF for math、证明搜索、软件验证、规范问题
- **实际意义**：数十亿估值的数学AI公司正在涌现；可能产生可证明安全的AI系统；改变数学研究从个人英雄到人机协作模式。

### 生物硬件的优劣权衡

- **核心内容**：大脑以20瓦功率、200赫兹速度运行，却实现了惊人的计算效率。优势包括：存算一体避免数据搬运、神经元天然的随机采样能力、超低电压计算、稀疏激活。劣势是无法复制和直接编程。关键洞察：算法与硬件协同进化，大脑可能在做大量我们尚未理解的节能计算。
- **关键概念**：神经形态计算、存算一体、随机计算、能效极限、硬件-算法协同设计
- **实际意义**：下一代AI芯片应学习大脑的架构创新；某些概率推理算法可能只有在类脑硬件上才高效；提示能效可能成为AGI竞争的关键因素。

### 表征学习的新范式

- **核心内容**：行为克隆的延伸——不仅预测标签，还预测人类看到该输入时的大脑活动模式。这可能让AI学习人类的表征几何结构、注意力模式、概念组织方式。挑战是需要大规模脑活动数据，但如果每个iPhone都是脑扫描仪，这将改变AI训练范式。
- **关键概念**：脑活动增强学习、表征对齐、辅助损失函数、认知几何、数据瓶颈
- **实际意义**：提供了一种将人类认知结构直接传递给AI的方法；可能解决对抗样本等问题；需要推动便携式脑成像技术发展。

### 科学基础设施的普遍缺口

- **核心内容**：Gap Map项目调研发现，几乎每个科学领域都缺少关键基础设施——相当于该领域的"哈勃望远镜"。总共识别出数百个此类缺口，每个需要数千万到数亿美元。令人惊讶的是，连数学这样"只需要黑板"的领域都需要Lean这样的基础设施。解决这些缺口的总成本仅需数十亿美元，远低于预期。
- **关键概念**：科学基础设施、规模化工具、跨学科需求、投资效率、FRO模式
- **实际意义**：科学进步越来越依赖大规模基础设施；需要新的资助模式bridging学术界和工业界；暗示科学生产力可通过targeted投资大幅提升。

## 🏢 提及的公司/产品

| 公司名 | 讨论语境 | 重要性 |
|--------|----------|--------|
| E11 Bio | 开发光学连接组技术，将成本降低100倍的FRO | ⭐⭐⭐ |
| Anthropic/Claude | LLM能力边界、与大脑算法的对比讨论 | ⭐⭐⭐ |
| DeepMind | 神经科学启发的AI研究先驱、TD学习应用 | ⭐⭐ |
| Harmonic | 基于形式化证明的10亿美元估值AI数学公司 | ⭐⭐ |
| Lean FRO | 推动形式化数学证明语言的普及和工具开发 | ⭐⭐ |
| Convergent Research | 孵化科学基础设施FRO的元组织 | ⭐⭐ |
| Microsoft | Lean语言的原始开发者 | ⭐ |
| Wellcome Trust | 评估连接组学成本的研究报告 | ⭐ |

## 💬 经典金句

> "我们向LLM投入了远超人脑的数据，但它们仍只有人类能力的一小部分。这可能是万亿美元级别的问题。"
> — Adam Marblestone

> "机器学习喜欢数学上简单的损失函数。但进化可能在损失函数中构建了大量复杂性——许多不同的损失函数在发育的不同阶段为不同脑区开启。"
> — Adam Marblestone

> "如果每部iPhone都是脑扫描仪，我们就不会有这个问题，我们会用脑信号训练AI。只是技术发展的顺序恰好是我们先有了GPU，后有便携式脑扫描仪。"
> — Adam Marblestone

> "LLM使用的是最愚蠢的强化学习形式。我们没有价值函数，这很疯狂。"
> — Adam Marblestone (引用Ilya Sutskever)

> "学术界激励机制的问题在于：这类综合性理论很难发表论文、很难获得资助、很难指导研究生。但这可能恰恰是我们理解智能所需要的。"
> — Adam Marblestone

## 👤 主要人物

### Adam Marblestone（亚当·马布尔斯通）

**身份**：Convergent Research CEO；前MIT媒体实验室、哈佛合成生物学研究员；专注研究组织(FRO)模式创始人
**背景**：George Church实验室博士，专注于DNA技术与神经科学交叉；后转向科学基础设施和组织创新，推动了多个FRO的成立
**核心观点**：认为理解大脑需要大规模连接组学研究；主张科学需要新的组织形式来解决传统学术界无法解决的基础设施问题；相信神经科学将为AI安全和能力提供关键洞察

### Steve Byrnes（史蒂夫·伯恩斯）

**身份**：独立AI安全研究员；前物理学家；大脑算法理论综合者
**背景**：物理学博士转行研究AI安全，通过大量阅读神经科学文献构建了学习-引导双系统理论
**核心贡献**：提出大脑通过学习子系统预测引导子系统来实现复杂奖励函数的理论，解释了进化如何编码抽象价值观

### Yann LeCun（杨立昆）

**身份**：Meta首席AI科学家；图灵奖得主；深度学习先驱
**背景**：CNN发明者，长期倡导能量模型和世界模型
**核心观点**：文中多次引用其对能量模型和全向推理的支持，认为当前LLM路径可能不是通向AGI的正确道路

## 📺 视频类型判断

**访谈对话**：深度技术访谈，主持人Dwarkesh Patel与神经科学家Adam Marblestone探讨大脑算法、AI发展路径及科学基础设施等话题

---

## 📝 完整翻译

### (0:00 - 15:00) Part 1

主持人：我心中有一个价值百万美元的大问题，通过采访这么多 AI 研究者，我一直在试图找到答案：大脑是如何做到的？我们给大型语言模型投喂了海量数据，但它们的能力仍然只是人类的一小部分。这到底是怎么回事？

Adam：这可能是价值万亿美元的问题。你可以说这是科学界最重要的问题。我不敢说知道答案，我也不认为答案会仅仅来自于许多聪明人的深思熟虑。

我的整体看法是，我们必须赋能神经科学领域，让神经科学在技术和其他方面成为一个更强大的领域，才能真正破解这样的问题。也许用现代 AI、神经网络、深度学习的思维来看，其中有一些关键组成部分。有架构，可能还有层数的超参数或该架构的属性。还有学习算法本身——如何训练它？反向传播、梯度下降，还是其他方法？如何初始化？

如果我们看系统的学习部分，它仍然可能有权重的初始化。然后还有成本函数。它被训练来做什么？奖励信号是什么？损失函数、监督信号是什么？我个人的直觉是，在这个框架内，这个领域忽视了这些非常具体的损失函数、非常具体的成本函数的作用。

机器学习倾向于喜欢数学上简单的损失函数。预测下一个 token、交叉熵，这些简单的计算机科学家的损失函数。我认为进化可能在损失函数中构建了大量的复杂性，许多不同的损失函数针对不同的区域，在发展的不同阶段被激活。基本上就是大量的 Python 代码，为大脑不同部分需要学习的内容生成特定的课程。

因为进化已经多次见证了什么是成功的，什么是不成功的，进化可以编码学习课程的知识。在机器学习框架中，也许我们可以回过头来讨论大脑的损失函数从何而来？不同的损失函数能否导致不同的学习效率？

主持人：人们说皮层拥有人类通用的学习算法，这是人类拥有的特殊秘方。这是怎么回事？

Adam：这是一个巨大的问题，我们不知道答案。我见过一些模型，其中皮层...皮层通常具有六层结构，这里的层与神经网络中的层的含义略有不同。皮层的任何一个位置都有六层物理组织层，当你深入这些片层时。然后这些区域相互连接，这更像是网络的层。

我见过的一些版本试图解释的只是："它如何近似反向传播？"这个的成本函数是什么？如果你试图说它类似于反向传播，那么网络被要求做什么？它是在对下一个 token 预测做反向传播，还是在对图像分类做反向传播，或者它在做什么？没人知道。但对此的一个想法，一个可能性是，它只是这个令人难以置信的通用预测引擎。

所以皮层的任何一个区域都在试图预测...基本上它能否学会从它看到的任何子集预测所有变量的任何其他子集？全方位推理，或全方位预测。而 LLM 只是看到上下文窗口中的所有内容，然后计算一个非常特定的条件概率，即"给定最后几千个内容，下一个 token 的概率是什么。"

但对于大型语言模型来说，如果说 "the quick brown fox 空白 空白 the lazy dog" 并填充中间部分，而不是预测下一个 token，这会很奇怪，如果它只是向前进行的话。它可以在上下文窗口的涌现层面学习如何做这些事情，但原生地它只是在预测下一个 token。

如果皮层的原生设计是让任何皮层区域都可以预测其输入的任何子集中的任何模式，给定任何其他缺失的子集呢？这有点更像"概率 AI"。顺便说一下，我说的很多东西与 Yann LeCun 会说的极其相似。他对这些基于能量的模型非常感兴趣，类似的东西就像所有变量的联合分布。

任何变量组合的可能性或不可能性是什么？如果我固定其中一些变量并说这些变量肯定处于这些状态，那么我可以用概率采样来计算——在这些被设置为这种状态的条件下，这些可以是模型中任意的变量子集——我能预测任何其他子集会做什么并从任何其他子集中采样吗，给定固定这个子集？

我可以选择一个完全不同的子集并从该子集中采样。所以这是全方位推理。因此皮层的某些部分，可能有皮层的联合区域从听觉预测视觉。可能有些区域预测大脑更先天部分将要做的事情。因为记住，这整个东西是建立在蜥蜴脑和蜥蜴身体之上的。

那个东西也是值得预测的。你不只是在预测我看到这个还是那个。这块肌肉是否即将紧张？我是否即将有一个让我发笑的反射？我的心率是否会上升？我是否即将激活这种本能行为？基于我的高层理解...就像我可以将某人告诉我"你背上有蜘蛛"与如果我真的在面前看到蜘蛛时会激活的蜥蜴部分相匹配。你学会将两者联系起来，这样即使只是听到某人说"你背上有蜘蛛"...

### (15:00 - 30:00) Part 2

Steve 本质上回答了 Ilya 的问题，即大脑如何最终编码这些高层欲望并将它们与更原始的奖励联系起来？非常幼稚的问题，但为什么我们不能通过训练模型来实现这种全向推理，不仅仅是从一个 token 映射到下一个 token，而是在训练中移除掩码，使其将每个 token 映射到每个 token？或者在视频、音频和文本之间创建更多标签，以强制它将一个映射到每一个？

我的意思是，那可能就是方法。我不太清楚。有些人认为有一种不同的方法来进行概率推理，或者有一种不同的学习算法，而不是反向传播。可能还有其他的学习方式，基于能量的模型或其他类似的东西，你可以想象这参与了能够做到这一点，而大脑具有这种能力。

但我认为有一个版本是，大脑所做的是通过几层进行预测的粗糙版本的反向传播，这有点像多模态基础模型。LLM 可能只是预测下一个 token。但视觉模型可能是在学习填补空白或重建不同的部分或组合的训练中。但我认为它以一种极其灵活的方式做到这一点。

如果你训练一个模型只是填补中心的这个空白，好的，那很好。但如果你没有训练它填补左边的另一个空白呢？那它就不知道如何做到这一点。这不是它已经摊销到网络中的预测库的一部分。而有了一个真正强大的推理系统，你可以在测试时选择，它需要推断的变量子集是什么，哪些是固定的？

好的，两个子问题。第一，这让你想知道人工神经网络缺乏的东西是否更多关于编码器或嵌入，而不是奖励函数……也许问题在于你没有以正确的潜在抽象来表示视频、音频和文本，使它们能够相互混合和冲突。也许这也与为什么 LLM 似乎不擅长在不同想法之间建立联系有关。这些想法是否以一种你能够注意到不同联系的通用性水平来表示？

问题是这些问题都是混合在一起的。如果我们不知道它是否在进行类似反向传播的学习，我们不知道它是否在进行基于能量的模型，我们不知道这些区域首先是如何连接的，真的很难真正了解这个的真相。但是，是的，这是可能的。

我认为人们已经做了一些工作。我的朋友 Joel Dapello 实际上在几年前做了一些事情，他把一个模型——我认为是 V1 的模型，特别是早期视觉皮层如何表示图像——作为卷积神经网络的输入，这改善了一些东西。可能存在差异。视网膜也在进行运动检测，某些东西正在被过滤掉。可能对感官数据有一些预处理。

可能有一些巧妙的组合，哪些模态正在预测哪些，等等，这导致了更好的表示。可能有比这更巧妙的东西。有些人确实认为架构中内置了归纳偏置，这将以不同的方式塑造表示，或者你可以做一些巧妙的事情。

Astera，也就是雇用 Steve Byrnes 的同一个组织，刚刚基于 Doris Tsao 的工作启动了这个神经科学项目。她有一些关于如何构建基本上需要更少训练的视觉系统的想法。它们在架构设计的假设中构建了诸如物体由表面界定、表面具有某些类型的形状以及它们如何相互遮挡等关系的东西。

可能可以在网络中构建更多的假设。进化也可能放入了一些架构的变化。只是我认为成本函数等也可能是它所做的关键事情。

我想谈谈你刚才略过的这个想法，即摊销推理。也许我应该试着解释一下我认为它的意思，因为我认为它可能是错误的，这将帮助你纠正我。对我来说也已经有几年了。

现在，模型的工作方式是你有一个输入，它将其映射到一个输出，这是在摊销一个过程，即我们认为智能是什么的真实过程。你对世界可能是什么样子有一些先验，是什么原因使世界成为现在的样子。然后当你看到一些观察时，你应该像这样："好的，这里是世界可能的所有方式。这个原因最好地解释了正在发生的事情。"

现在，对每一个可能的原因进行这种计算在计算上是难以处理的。所以你只需要采样，比如："哦，这是一个潜在的原因。这能解释这个观察吗？不，算了。让我们继续采样。"然后最终你得到了原因，然后原因解释了观察，然后这成为你的后验。

那实际上相当好。一般来说，贝叶斯推理是这种非常难以处理的事情。我们用于此的算法往往需要采取大量样本，蒙特卡罗方法，采取大量样本。而采样需要时间。这就像最初的玻尔兹曼机之类的东西。它们使用这样的技术，仍然经常与概率编程、其他类型的方法一起使用。

贝叶斯推理问题基本上是感知问题，给定世界的某个模型和给定一些数据，我应该如何更新我的……我内部模型中缺失的变量是什么？我猜想法是神经网络希望……显然，从机制上讲，神经网络并不是从"这是我的世界模型，我将尝试解释这些数据"开始的。

但希望是，而不是从"嘿，这个原因能解释这个观察吗？不能。这个原因能解释这个观察吗？能。"你所做的只是观察……神经网络认为最好的原因是什么？观察到原因。所以前馈从观察到原因，然后到输出……你不必评估所有这些能量值或其他什么，并四处采样以使它们更高或更低。你只是说，大致上那个过程会导致这个成为最高的或类似的东西。

确切地说。思考它的一种方式可能是测试时间计算，推理时间计算实际上是在再次进行这种采样。你实际上阅读它的思维链。它实际上在做我们谈论的这个玩具例子，它就像："哦，我能通过做 X 来解决这个问题吗？不，我需要一种不同的方法。"

这提出了一个问题。我的意思是，随着时间的推移，需要推理时间计算才能引出的能力确实被提炼到模型中。所以你正在摊销以前需要做这些推出的东西，这些蒙特卡罗推出，来弄清楚。

一般来说，也许有这样一个原则，即可以复制的数字思维具有不同的权衡，这些权衡是相关的，与不能复制的生物思维不同。所以一般来说，摊销更多东西应该是有意义的，因为你可以真正复制摊销，或复制你已经内置的东西。

这是一个切题的问题，可能值得推测。在未来，随着这些东西变得更加智能，我们训练它们的方式变得更加经济理性，什么将有意义地摊销到这些思维中，而进化认为不值得摊销到生物思维中？你每次都必须重新训练。

首先，我认为概率 AI 人会说，当然你需要测试时间计算，因为这个推理问题真的很难，我们知道的唯一方法涉及大量的测试时间计算。否则，它只是这种永远不会……你必须做无限数据或其他什么才能做到这一点的糟糕近似。

我认为一些概率人会说："不，它本质上是概率性的，以这种方式摊销它只是没有意义。"他们可能还会指向大脑并说："好的，大脑，神经元是随机的，它们在采样，它们在做事情。所以也许大脑实际上更像是在做非摊销推理，真正的推理。"

但感知可以在几毫秒内工作，这也很奇怪。它似乎没有使用那么多采样。所以它显然也在将一些东西烘焙到近似的前向传递或类似的东西中来做到这一点。

在未来，我不知道。人们不得不使用测试时间计算的东西，在某种程度上已经是一种趋势，正在被用来训练基础模型吗？现在它可以一次完成。也许进化做了或没有做到这一点。

我认为进化仍然必须通过基因组传递一切来构建网络，人类生活的环境是非常动态的。所以也许，如果我们相信这是真的，每个 Steve Byrnes 都有一个学习子系统和一个引导子系统，学习子系统没有很多预初始化或预训练。它有一定的架构，但然后在生命周期内它学习。然后进化实际上并没有将那么多摊销到该网络中。它将其摊销到一组先天行为中，在一组这些引导成本函数中，或构建非常特定奖励信号的方式中。

### (30:00 - 45:00) Part 3

然后它必须指定所有关于蜘蛛、朋友、母亲、交配和社交群体以及共同眼神接触的Python代码。它必须指定所有这些东西。这真的是这样吗？我认为有一些证据支持这个观点。

Fei Chen和Evan Makosko以及其他研究人员一直在做这些单细胞图谱。通过BRAIN计划（一个大型神经科学资助项目）扩大神经科学技术规模所做的事情之一，是他们基本上已经遍历了不同的区域，特别是小鼠大脑，并绘制了不同细胞类型的位置。

皮层的不同区域有多少种不同类型的细胞？它们在不同区域是否相同？然后你再看看这些皮层下区域，它们更像是引导子系统或奖励函数生成区域。它们有多少种不同类型的细胞？它们有哪些神经元类型？

我们不知道它们是如何全部连接的，也不知道它们具体做什么，或者电路是什么，或者它们意味着什么，但你可以通过RNA测序来量化有多少种不同类型的细胞。在引导子系统中，基本上比学习子系统中有更多奇特、多样和定制的细胞类型。

就像皮层细胞类型，似乎有足够的类型来构建一个学习算法并指定一些超参数。而在这个引导子系统中，有成千上万种非常奇特的细胞，可能像是用于蜘蛛条件反射的细胞，或者用于"我即将尝到盐味"的细胞。

为什么每个奖励函数需要不同的细胞类型？这就是你获得先天连接电路的地方。在学习算法部分，在学习子系统中，你指定初始架构，你指定一个学习算法。所有的精华都是通过突触的可塑性发生的，在那个大网络内突触的变化。

但它是一个相对重复的架构，就是它如何初始化的。就像制作八层Transformer所需的Python代码量与制作三层Transformer的并没有太大不同。你只是在复制。而所有这些奖励函数的Python代码，如果上丘看到某个东西在快速移动，你的皮肤上起鸡皮疙瘩什么的，然后触发蜘蛛反射，那只是一堆定制的、物种特定的、情况特定的东西。

皮层不知道蜘蛛，它只知道层。但你是说编写这个奖励函数的唯一方法是有一个特殊的细胞类型？

是的，我认为是这样。我认为你要么必须有特殊的细胞类型，要么必须以某种方式获得特殊的连接规则，进化可以说这个神经元需要连接到那个神经元，而不需要任何学习。我认为最可能发生的方式是，这些细胞表达不同的受体和蛋白质，说"好的，当这个与那个接触时，让我们形成一个突触。"

所以这是遗传连接，需要细胞类型来实现。我确信如果我了解神经科学101，这会更有意义，但引导子系统似乎仍然有很多复杂性，或者说通用性。

如果引导子系统有自己的视觉系统，与视觉皮层分开，不同的特征仍然需要插入到那个视觉系统中。所以蜘蛛的东西需要插入其中，爱的东西也需要插入其中，等等。所以它看起来很复杂。

它仍然很复杂。这就是为什么基因组上的大量基因组资源，以及这些不同的细胞类型等等，都会用于连接引导子系统，预先连接它。

我们能判断基因组的多少部分在明显地工作吗？我猜你可以判断有多少与产生RNA相关，这些RNA在大脑的不同细胞类型中表现出来或表观遗传学表现出来。对吧？

是的。这就是细胞类型帮助你获得的东西。我不认为这完全是"哦，基因组的这个百分比在做这个"，但你可以说，"好的，在所有这些引导子系统子类型中，有多少不同的基因参与指定哪个是哪个以及它们如何连接？这些基因占用了多少基因组空间，相对于指定视觉皮层与听觉皮层的基因？"

你只是重复使用相同的基因来做相同的事情两次。而蜘蛛反射的连接...是的，你是对的。他们必须构建一个视觉系统，他们必须构建一些听觉系统和触觉系统以及导航类型的系统。

即使是输入到海马体等的东西，也有头部方向细胞。即使是苍蝇的大脑也有先天电路来确定它的方向并帮助它在世界中导航。它使用视觉，计算出它的光流，它是如何飞行的以及它的飞行与风向的关系。

它有所有这些先天的东西，我认为在哺乳动物大脑中，我们都会把这些归入引导子系统。有很多工作。所以基本上所有用于指定苍蝇必须做的所有事情的基因，我们也会有类似的东西，只是都在引导子系统中。

但我们是否有一些估计，比如"这是需要多少核苷酸，需要多少兆碱基来——"我不知道。我的意思是，我认为你可能可以与生物学家谈谈这个。

从基因的角度来看，我们与酵母有很多共同之处。酵母仍然被用作生物学中某些药物开发等的模型。基因组的很大一部分只是为了让你拥有一个细胞，它可以回收废物，可以获得能量，可以复制。

那我们与老鼠有什么共同之处？所以我们在某种程度上知道，我们与黑猩猩之间的差异——包括社交本能和皮层的更高级差异等等——制造八层Transformer而不是六层Transformer或调整奖励函数的额外基因数量很少。

这有助于解释为什么人科动物的大脑规模如此快速地爆炸式增长。据推测，告诉我这是否正确，但在这个故事中，社交学习或其他一些东西增加了从环境中学习的能力。它提高了我们的样本效率。你不必亲自去杀野猪并弄清楚如何做，你可以说"长者告诉我这是制作长矛的方法。"

现在它增加了拥有更大皮层的动机，可以学习这些东西。是的，这可以用相对较少的基因来完成，因为它真的是在复制老鼠已经拥有的东西，制造更多。从基因组的角度来看，它可能不完全相同，可能有调整，但你不必重新发明所有这些东西。

那么皮层在大脑进化史上可以追溯到多远？这个想法是皮层总是已经解决了这个全向推理的问题，这个问题已经解决了很长时间？然后灵长类动物的大突破是我们得到了奖励函数，这增加了拥有全向推理的回报？

这是一个好问题。或者全向推理也是花了一段时间才解锁的东西？我不确定对此是否有共识。

我认为可能有关于语言的具体问题。是否有调整，无论是通过听觉和记忆，听觉记忆区域的某种组合？也可能有宏观布线，你需要将听觉区域连接到记忆区域或类似的东西，并连接到一些社交本能中，例如让语言发生。

但这也可能是少量的基因变化，能够说"哦，我只需要从我这里的颞叶，到听觉皮层，某些东西。"有一些布罗卡区、韦尼克区的证据。它们与海马体等连接，以及前额皮质。所以可能有少量基因能让人类真正正确地使用语言。

这可能是一个重要因素。但是是皮层发生了一些变化，使得做这些事情成为可能？还是这种潜力已经存在，但没有动机去扩展这种能力，然后使用它，将其连接到这些社交本能并更多地使用它？

我倾向于后者。我认为老鼠在皮层方面与人类有很多相似之处。尽管有Suzana Herculano-Houzel关于神经元数量如何与灵长类动物大脑重量的比例关系比啮齿动物大脑更好的研究。那是否表明皮层的可扩展性实际上有了一些改进？

也许吧。我对此不是特别深入。架构可能有变化，折叠的变化，神经元特性的变化等等，以某种方式略微调整了这一点。但无论如何都有扩展性。

### (45:00 - 1:00:00) Part 4

基底神经节可能就是在说："让脊髓执行这个运动动作？是还是否。"或者可能是更复杂的认知型动作，比如"告诉丘脑允许皮层的这个部分与另一个部分对话"，或者"释放海马体中的记忆并开始一个新的记忆"等等。但基底神经节输出的是某种有限的动作集合，这只是一个非常简单的强化学习系统。所以其他大脑和我们的大脑中可能有一些部分只是在执行非常简单朴素的强化学习算法。

在此基础上的一层是神经科学的一些重要工作，比如Peter Dayan的工作，以及一系列工作，这也是我认为DeepMind最初做时序差分学习的部分原因。他们对神经科学非常感兴趣。有大量神经科学证据表明，多巴胺提供的是这种奖励预测误差信号，而不只是"是或否，在未来无数个时间步之后"的奖励。这是一个预测误差，这与学习这些价值函数是一致的。

除此之外，还有更高阶的东西。我们有皮层在构建这个世界模型。皮层世界模型可以包含的一件事是你何时会获得奖励的模型。它在预测Steering Subsystem会做什么。它可以预测基底神经节会做什么。你的皮层中有一个模型，具有更多泛化能力和更多概念，以及所有这些东西，它会说："好的，这些类型的计划，这些类型的行动将在这些类型的情况下导致奖励。"所以我有一个关于我的奖励的模型。

有些人还认为你可以反过来。这是推理图景的一部分。有一个强化学习作为推理的想法。你可以说："好吧，在我获得高奖励的条件下，采样一个我必须达到那里的计划。"这是从奖励部分推理计划部分。我将奖励固定为高，并推理计划，从可能导致该结果的计划中采样。如果你有这个非常通用的皮层系统，它就可以做到。如果你有这个非常通用的基于模型的系统，而模型除其他事物外还包括计划和奖励，那么你基本上就可以免费获得它。

在神经网络术语中，有一个与正在发生的全向推理相关联的价值头？

是的，或者有一个价值输入。

哦，好的。有趣。是的，它可以预测。它可以预测的几乎感官变量之一是它将获得什么奖励。

顺便说一下，谈到分摊事物，显然价值就像是查找奖励的分摊展开。

是的，类似于它的统计平均值或预测。

一个切题的想法。Joe Henrich和其他人有这样的想法，关于人类社会如何学会做事情，比如你如何弄清楚这种豆子（实际上几乎总是会让你中毒）在你执行这个十步极其复杂的过程后是可食用的，其中任何一步失败，豆子都会有毒？你如何弄清楚在特定的时间，用特定的武器，以特定的方式狩猎这种海豹？

除了一代代尝试之外别无他法。这让我想到，这实际上非常像在文明层面上发生的无模型强化学习。

不，不完全是。进化在某种意义上是最简单的算法。如果我们相信所有这些都可以来自进化，外部循环可以极其不具前瞻性。

对，这很有趣。只是层次结构...进化：无模型...那么这告诉你什么？也许简单的算法只要你做得足够多就能得到任何东西。

对。是的，我不知道。

所以，进化：无模型。基底神经节：无模型。皮层：基于模型。文化：可能是无模型的。我的意思是你会关注你的长辈或其他什么。也许这些东西的群体选择更像是无模型的。但现在我认为文化，嗯，它存储了一些模型。

退一步说，与现在的计算机相比，人类使用生物硬件是劣势还是优势？我这个问题的意思是，如果存在"算法"，如果刻在今天的硬件上，该算法的性能会明显更差还是更好？

这么想的原因是...我的意思是这样。显然，大脑不得不做出一系列与计算硬件无关的权衡。它必须在能量效率上高得多。也许因此它必须以较低的速度运行，以便有较小的电压差。所以大脑以200赫兹运行，必须在20瓦上运行。

另一方面，在机器人技术方面，我们清楚地体验到手指比我们迄今为止能制造的电机灵巧得多。所以也许大脑中有某种东西相当于认知灵巧性，这可能是由于我们可以进行非结构化稀疏性的事实。我们可以将内存和计算共同定位。

是的。

这一切最终如何权衡？你是觉得"该死，如果我们不必处理这些大脑，我们会聪明得多"还是...

我认为最终我们将以某种方式获得两全其美。我认为大脑的一个明显缺点是它不能被复制。你没有对每个神经元和突触的外部读写访问权限，而你有。我可以在Python或其他地方编辑权重矩阵中的某些内容，然后加载并复制它。

原则上是这样。所以它不能被复制和随机访问的事实非常烦人。但除此之外，它可能有很多优势。

它还告诉你，你想以某种方式进行算法的协同设计。它甚至可能不会从我们讨论的所有内容中改变太多，但你想以某种方式进行这种协同设计。所以是的，你如何用真正缓慢的低电压开关来做到这一点？

这对能源消耗非常重要。共同定位内存和计算。我认为硬件公司可能会尝试共同定位内存和计算。他们将尝试使用更低的电压，允许一些随机的东西。

有些人认为我们谈论的所有这些概率性的东西——"哦，它实际上是基于能量的模型，等等"——它正在进行大量采样。它不只是分摊一切。神经元对此也非常自然，因为它们天然是随机的。

所以你不必在一堆Python代码中做一个随机数生成器来生成样本。神经元只是生成样本，它可以调整不同的概率并学习这些调整。所以它可能与某种推理方法或其他东西非常协同设计。

这会很滑稽...我的意思是我从这次采访中得到的信息是，所有这些人们在Twitter上取笑的人，Yann LeCun和Beff Jezos等等，我不知道，也许他们是对的。

这实际上是一种解读。当然，自从LLMs起飞以来，我根本没有真正研究过AI，所以我只是不在圈内。但我很惊讶，我认为扩展是如何工作的以及一切都很神奇。但是的，我认为Yann LeCun和Beff Jezos对概率模型有所了解，或者至少可能有。

事实上，这就是所有神经科学家和所有AI人员在2021年之前的想法。

对。所以大脑中发生了许多细胞层面的事情，不仅仅是神经元之间的突触连接。其中有多少在功能上比突触本身做了更多的工作，而不仅仅是为了使突触工作而必须做的一堆杂事。

所以在数字思维中，你可以非常容易地推动突触，抱歉，参数。但对于一个细胞来说，要根据梯度信号调节突触，它只需要所有这些疯狂的机制。所以它实际上是否做得比用极少代码就能做的更多？

我不知道，但我不相信激进的"哦，实际上记忆主要不是突触，或者学习主要是遗传变化"之类的观点。我认为这更像是你说的第二件事，这很有道理。比如说你想对来自或进入神经元的所有权重进行权重归一化。你可能必须以某种方式告诉细胞核这件事，然后让它将所有东西发送回突触或其他什么。所以会有很多细胞变化。

或者假设你刚刚有很多可塑性，你是这个记忆的一部分。现在已经巩固到皮层或其他地方了。现在我们想把你重新用作一个可以再次学习的新记忆。会有大量的细胞变化，所以细胞中会发生大量的事情。但在算法上，它并没有真正添加超出这些算法之外的东西。

### (1:00:00 - 1:15:00) Part 5

那么，为什么不认为还有更多这样的事情呢？可能确实有。我认为我们可能正在接近某些东西的原因是，基于这些想法制造的 AI 正在以令人惊讶的方式运作良好。还有一些纯粹的经验性发现。卷积神经网络及其各种变体，我不确定最新进展如何，但与其他计算神经科学中关于视觉系统运作的模型相比，它们更具预测性。

你可以评分，即使是在猫图片等数据上预训练的 CNN，它们在某个任意图像上的表征相似性与通过不同方式测量的大脑激活相比如何？Jim DiCarlo 的实验室有这个大脑评分，AI 模型实际上……似乎确实有一些相关性。神经科学不一定有比这更好的东西。

所以是的，这只是在重申你说的，我们拥有的最好的计算神经科学理论似乎主要是作为 AI 模型的结果而被发明的，并找到了有效的东西。所以找到反向传播有效，然后说，"我们能用皮层回路近似反向传播吗？"或类似的东西。已经有这样的事情了。

现在，有些人完全不同意这个观点。György Buzsáki 是一位神经科学家，他写了一本名为《从内部看大脑》的书，他基本上说我们所有的心理学概念、AI 概念，所有这些都只是编造的东西。我们真正需要做的是弄清楚大脑实际使用的原语集是什么。

我们的词汇将不足以描述它。我们必须从大脑开始，创造新的词汇，而不是说反向传播，然后试图将其应用于大脑或类似的东西。他研究大脑中的许多振荡和类似的东西，而不是单个神经元及其功能。我不知道。我认为这是有道理的。

从研究计划设计的角度来看，我们应该尝试做的一件事就是模拟一只微小的虫子或一条微小的斑马鱼，几乎尽可能地采用生物物理或自下而上的方法。比如获取连接组、分子、活动，并将其作为一个物理动力系统来研究，观察它的行为。

但我不知道，感觉 AI 确实是计算神经科学的很好素材。那些实际上可能是相当不错的模型。我们应该研究这个。我既认为研究组合的一部分应该是完全自下而上的，不试图将我们从 AI 学到的词汇应用到这些系统上，也应该有另一大部分试图使用该词汇或该词汇的变体来逆向工程它。我们应该同时追求两者。

我的猜测是，逆向工程的方法实际上会或多或少地起作用。比如我们确实看到了像 TD 学习这样的东西，Sutton 也是单独发明的。

那一定是一种疯狂的感觉，就像——

是的，那很疯狂。我写下的这个方程式就像在大脑中一样。似乎多巴胺正在做一些这样的事情。

所以让我问你这个问题。你们正在资助不同的团队，试图弄清楚大脑中发生了什么。如果我们有一个完美的表示，无论你如何定义它，为什么认为它实际上会让我们找到这些问题的答案？

我们有神经网络，它们更容易解释，不仅仅是因为我们理解权重矩阵中的内容，而是因为存在权重矩阵。有这些装着数字的盒子。即便如此，我们也只能说出非常基本的东西。我们可以看到用于非常基本的模式匹配的电路，比如一个 token 跟随另一个。

我觉得我们并没有真正解释为什么 LLM 是智能的，仅仅因为它们是可解释的。

我认为我会在某种程度上反驳这一点。我们对 LLM 基本上在做什么有一些描述。它所做的是，我有一个架构，我有一个学习规则，我有超参数，我有初始化，我有训练数据。

但这些都是我们因为构建它们而学到的东西，而不是因为我们通过查看权重来解释它们。类似于连接组的东西就像看到权重。

我认为我们应该做的是，我们应该用架构、学习规则、初始化等语言来描述大脑，而不是试图找到金门大桥电路并准确地说这个神经元实际上如何……那将是一些令人难以置信的复杂的学习模式。

Konrad Kording 和 Tim Lillicrap 大约五年前有一篇论文，叫做"理解神经网络意味着什么？"

他们基本上说的是，你可以想象你训练一个神经网络来计算 π 的数字或其他东西。这就像一些疯狂的模式。你还训练那个东西来预测你能找到的最复杂的东西，预测股票价格，基本上预测真正复杂的系统、计算完备的系统。

我可以训练一个神经网络来做元胞自动机或任何疯狂的事情。我认为，我们永远无法通过可解释性完全捕捉到这一点。它只会在内部进行真正复杂的计算。

但我们仍然可以说，它变成这样的方式是它有一个架构，我们给了它这些训练数据，它有这个损失函数。所以我想以同样的方式描述大脑。

我认为我一直在阐述的这个框架是，我们需要理解皮层以及它如何体现学习算法。我不需要理解它如何计算"金门大桥"。

但如果你能看到所有的神经元，如果你有连接组，为什么这会教你学习算法是什么？

嗯，我想有几种不同的观点。所以这取决于这个组合的不同部分。

在完全自下而上、我们必须模拟一切的组合中，它基本上不会。你必须对斑马鱼大脑或其他东西进行模拟，然后你看到其中的涌现动力学是什么，你想出新的名称和新的概念以及所有这些。这是最极端的自下而上的神经科学观点。

但即使在那里，连接组对于进行生物物理或自下而上的模拟也非常重要。但另一方面，你可以说，"如果我们实际上可以应用 AI 的一些想法呢？"

我们基本上需要弄清楚，它是基于能量的模型还是摊销的 VAE 类型模型？它在做反向传播还是在做其他事情？学习规则是局部的还是全局的？

如果我们对此有一些可能的想法，只需将连接组视为大量额外的约束，这将有助于改进，最终获得一致的图景。

我也为 Steering Subsystem 的事情考虑这个，只是关于它的非常基本的事情。有多少不同类型的多巴胺信号或 Steering Subsystem 信号或思想评估器等等……有多少不同类型的广泛类别？

即使是这个非常基本的信息，下丘脑中的细胞类型比皮层中的更多，这也是关于在那里与其他地方构建了多少结构的新信息。有多少不同的多巴胺神经元？前额叶和听觉之间的连接与前额叶和视觉之间的连接是否相同？

最基本的事情，我们都不知道。问题是通过一系列定制实验学习即使是最基本的东西也需要非常长的时间。而通过获得连接组一次性学习所有这些只是更有效率。

### (1:15:00 - 1:30:00) Part 6

然后美国国家人类基因组研究所基本上正确地构建了资金流程。他们让一群公司竞争以降低成本。然后成本在10年内下降了百万倍，因为他们改变了范式，从宏观的化学技术转向了单个DNA分子。这些分子会在显微镜下形成小的DNA分子簇，你可以在相机的每个像素上只看到几个DNA分子。它会让你并行地看到DNA的不同片段。

所以你将整个过程并行化了百万倍。这就是成本降低百万倍的原因。通过从电子显微镜切换到光学连接组学，甚至未来可能出现的连接组学技术，我们认为应该会有类似的模式。这就是为什么E11，这个聚焦研究组织，从技术开发开始，而不是一开始就说我们要做人脑之类的事情，然后蛮力推进。我们说让我们用新技术降低成本。

但这仍然是个大工程。即使有了新的下一代技术，你仍然需要在数据收集上花费数亿美元。这会由慈善资金、政府还是投资者来资助？这非常待定，在某种意义上正在不断发展。我听到一些传言说可能会成立与连接组学相关的公司。到目前为止，E11一直是慈善资助的。

美国国家科学基金会刚刚发布了这个技术实验室的征集，这在某种程度上受到了FRO的启发或与之相关。你可以建立一个技术实验室，与我们一起实际绘制小鼠大脑图谱，这将是慈善加政府资助，仍在非营利、开源的框架内。但公司能加速这个过程吗？你能在公司背景下可信地将连接组学与AI联系起来并获得投资吗？这是可能的。

我是说，训练这些AI的成本正在大幅增加。如果你能讲出某种故事，不仅是我们要弄清楚某些安全问题，而且一旦我们做到了，我们还能告诉你AI是如何工作的......你应该去这些AI实验室，然后说："给我你们2030年预算的百分之一。"我在七八年前稍微试过一点，但没有太多兴趣。也许现在会有。

但我们一直在谈论的所有事情，谈论起来确实很有趣，但最终都是推测。例如，大脑能效高的真正原因是什么？它是在做真正的推理还是分摊推理或其他什么？这些都可以通过神经科学来回答。这会很困难，但实际上是可以回答的。

所以如果你只需要几十亿美元就能真正全面地解决这个问题，在万亿美元的GPU等大格局中，我觉得进行这项投资实际上是有意义的。另外，在过去一年中已经有许多实验室成立，它们以数十亿的估值融资，做的事情相当可信，但不是那种"我们下个季度的ARR将会是多少"。而是我们将发现材料之类的——

是的，登月计划创业公司或亿万富翁支持的创业公司。我认为登月计划创业公司与FRO是一个连续体。FRO是引导慈善支持的一种方式，确保它是开源的公益性质，以及给定FRO可能具有的各种其他属性。但是的，亿万富翁支持的创业公司，如果他们能瞄准正确的科学，确切的正确科学。

我认为有很多方法可以做登月计划神经科学公司，但永远不会让你获得连接组。就像"哦，我们要上传大脑"之类的，但永远不会真正获得小鼠连接组之类的东西。这些基本的东西是你需要获得的，以便为科学奠定基础。有很多方法可以让登月计划公司出错，而不做真正的科学。但也可能有方法让公司或大型企业实验室参与进来并正确地做这件事。

这让我想起了你五年前在一次演讲中提到的一个想法。你想解释一下行为克隆吗？实际上这很有趣，因为我第一次看到这个想法，我认为可能是在Gwern的博客文章中。

总有一篇Gwern的博客文章。

现在有一些学术研究工作和一些新兴的公司类型的努力试图做到这一点。

通常，比方说我正在训练一个图像分类器之类的东西。我向它展示猫和狗的图片，它们有"猫"或"狗"的标签。我有一个神经网络应该预测"猫"或"狗"的标签。每个标签输入的信息量是有限的。只是"猫"或"狗"。如果我还有"预测当我看到猫或狗以及所有其他东西时我的神经活动模式是什么"呢？

如果你把它作为辅助损失函数或辅助预测任务添加进去，这是否会塑造网络了解人类对猫和狗的了解，并以与大脑表示方式一致的方式表示它，以及大脑表示事物的那种表示维度或几何形状，而不是仅仅有这些标签？这是否能让它更好地泛化？这是否能让它有更丰富的标签？

当然这听起来真的很有挑战性。生成大量带标签的猫图片非常容易。Scale AI或其他什么都可以做到这一点。但生成大量与你想要训练AI做的事情相对应的大脑活动模式更困难。但同样，这只是神经科学的技术限制。如果每部iPhone也是大脑扫描仪，你就不会有这个问题，我们就会用大脑信号训练AI。只是技术发展的顺序是我们先有了GPU，然后才有便携式大脑扫描仪。

这里的机器学习类比是什么？因为当你蒸馏模型时，你仍然在看所有对数概率的最后一层——

如果你将一个模型蒸馏到另一个模型中，那是某种特定的事情。你只是试图将一个模型复制到另一个模型中。我认为我们还没有一个完美的提议来蒸馏大脑。要蒸馏大脑，你需要一个更复杂的大脑接口。

也许你也可以这样做。你可以制作替代模型。Andreas Tolias和这类人正在做一些大脑活动数据的神经网络替代模型。与其让你的视觉皮层进行计算，不如让替代模型来做。所以你在某种程度上将你的视觉皮层蒸馏成神经网络。这是一种蒸馏。这是在做一些稍微不同的事情。

这基本上只是说我正在添加一个辅助的......我把它想象成正则化，或者我把它想象成添加一个辅助损失函数，它平滑了预测任务，使其始终与大脑的表示方式一致。例如，它可能会帮助你处理对抗性示例。

但你到底在预测什么？你在预测大脑的内部状态吗？

是的。所以除了预测标签，一个标签向量，比如是猫，不是狗，是，不是船，独热向量或其他什么，是的，这是猫，而不是这无数其他类别，比如说在这个简单的例子中。你还在预测一个向量，它是所有这些大脑信号测量值。所以Gwern，无论如何，很久以前有这篇博客文章说，"哦，这是一个中间的东西。我们谈论全脑仿真，我们谈论AGI，我们谈论脑机接口。我们也应该谈论这种大脑数据增强的东西，它是在你所有的行为上训练的，但也在预测你的一些神经模式上训练。"

你是说学习系统已经通过指导系统在做这件事了？

是的，我们的大脑，我们的学习系统也必须预测指导子系统作为辅助任务。这有助于指导子系统。现在，指导子系统可以访问那个预测器并使用它构建一个很酷的奖励函数。

另外，你在Lean的董事会上，这是数学家用来证明定理等的正式数学语言。显然现在有很多关于AI自动化数学的讨论。你的看法是什么？

我认为数学的某些部分看起来已经很好地走上了自动化的轨道。首先，Lean在微软和其他地方开发了好几年。它已经成为融合聚焦研究组织之一，以推动更多的工程和关注。所以Lean是这种编程语言，你不是在纸笔上表达你的数学证明，而是用这种编程语言Lean来表达。

然后最后，如果你这样做，它是一种可验证的语言，所以你可以点击"验证"，Lean会告诉你你的证明的结论是否真的完全遵循你的证明的假设。所以它自动检查证明是否正确。就其本身而言，这对数学家合作等很有用。如果我是某个业余数学家，我想为证明添加内容，Terry Tao不会仅仅相信我的结果。但如果Lean说它是正确的，它就是正确的。

### (1:30:00 - 1:45:00) Part 7

规范问题究竟是什么？这些电网工程师制造了这个东西，但他们不一定知道如何从中提取形式化规范。而且想出你代码所需的规范并不一定容易。人们不习惯制定形式化规范，也没有太多工具可以帮助。所以你还面临这个用户界面加上AI的问题：我应该指定什么安全规范？这是我想要的规范吗？所以存在规范问题，而且一直以来都非常复杂和困难。

但就在最近很短的时间内，LLM才开始能够生成对数学家有用的可验证证明，开始能够在软件验证、硬件验证方面做一些工作。但我认为如果你推断未来几年的趋势，可能会完全扭转局面。形式化方法，整个形式化方法或形式化验证领域，可证明软件。这是编程语言理论部分中一个奇怪的、几乎是死水一潭的领域，通常带有很强的学术色彩。

虽然曾有DARPA项目制造了一个可证明安全的四旋翼直升机之类的东西。安全防范什么？确切证明的属性是什么？不是针对那个特定项目，而是一般来说。因为显然事物会因各种原因出故障。你可以说，内存这部分发生的事情，也就是用户应该可以访问的部分，不能以任何方式影响内存那部分发生的事情，诸如此类的事情。

所以有两个问题。一是这有多有用？二是作为数学家，这会让人多满意？如果能证明软件具有某些属性或硬件具有某些属性，如果这真的有效，显然会非常有用。但从纯粹的角度来看，我们会弄清楚数学吗？你是否感觉到，发现一个构造与另一个领域的构造相互映射，或发现"哦，这个引理，如果你重新定义这个术语，它仍然满足我对这个术语的定义。但之前能驳倒它的反例不再适用了。"这种在数学中发生的辩证过程。软件会取代这种过程吗？

是的。纯数学的价值有多少实际上来自于想出全新的方式来思考问题，将其映射到完全不同的表示？我们有例子吗？我不知道。我觉得这有点像当每个人都必须编写汇编代码的时候。创建的有趣酷炫创业公司数量就少得多。能做到的人更少，进展更加艰难、缓慢和孤独等等。

你有更多错误的失败，因为你没有掌握汇编代码的某些方面，而不是因为你的概念本质是否正确的问题。更难协作等等。所以我认为这会非常好。确实有些担心，如果不学习证明的机械部分，你就无法产生指导更概念性部分、创造性部分的直觉。

这和汇编一样。对。那么这在什么时候适用？通过氛围编程，人们是不是没有学习计算机科学，或者实际上他们在氛围编程的同时也在看LLM为他们解释这些抽象的计算机科学概念，一切都发生得更快？他们的反馈循环更快，他们学到了更多的抽象计算机科学和算法内容，因为他们在氛围编程。我不知道，这并不明显。这可能与用户界面和围绕它的人类基础设施有关。

但我猜有些人担心人们不学习机械部分，因此不建立基础直觉之类的。但我的预感是这超级积极。确切地说，这会有多有用，或者会发生多少整体数学突破，甚至是我们关心的数学突破？我不知道。我认为另一个很酷的事情是可访问性问题。好吧，这听起来有点老套。好吧，是的，更多人可以做数学，但谁在乎呢？但我认为有很多人可能会有有趣的想法。比如量子引力理论之类的。

是的，我们中的某个人会想出量子引力理论，而不是持证物理学家。就像Steve Byrnes在阅读神经科学文献，他并没有在神经科学实验室待过多久。但他能够综合神经科学文献并说："哦，学习子系统、控制子系统。这一切都有意义吗？"他在某种程度上是一个局外人神经科学家。你能有局外人弦论学家之类的吗，因为数学只是由计算机为他们完成？这会导致弦论有更多创新吗？也许会。

有趣。好的，所以如果这种方法有效，而你是对的，LLM不是最终范式，假设至少需要10年才能获得那个世界的最终范式。有一个有趣的科幻前提...Terence Tao今天发了一条推文，他说："这些模型就像自动化的聪明才智，而不是自动化的智能。"你可以对定义有异议。但如果你有自动化的聪明才智，并且你有某种过滤方式——如果你可以形式化和证明LLM所说的话，你就可以做到——那么你可能会遇到这种情况，数量本身就具有质量。

那么世界上哪些领域可以用这种可证明的符号表示？在AGI还很遥远的世界里，也许有意义的是字面上把LLM所做的一切，或几乎一切，都变成超级可证明的陈述。所以LLM实际上可以相互构建，因为它们所做的一切都是超级可证明的。也许这是必要的，因为你有数十亿个智能体在运行。即使它们超级智能，未来AGI文明相互协作的唯一方式可能是如果它们能够证明每一步。它们只是在暴力搅动...

这就是木星大脑在做的事情。这是一种通用语言，是可证明的。它也是从以下角度可证明的："你是在试图利用我，还是在发送一些试图有效入侵我大脑的信息？"你是在试图对我进行社会影响吗？你实际上只是发送给我需要的信息，不多不少吗？所以davidad，他现在是英国ARIA的项目主管，他有这整个ARPA风格项目的设计，一种非常依赖可证明安全属性的安全保护AI。你能将证明应用于...你能有一个世界模型吗？但那个世界模型实际上不是仅用神经元激活来指定的，而是用方程式指定的。这些可能是非常复杂的方程式，但如果你能在自动证明这些东西方面变得疯狂擅长，通过聪明才智，自动聪明才智...你能拥有明确可解释的世界模型，而不是神经网络世界模型，基本上回到符号方法，只是因为你可以拥有疯狂的证明能力吗？

### (1:45:00 - End) Part 8

在孵化和创立这些聚焦研究组织（Focused Research Organizations）的过程中——这些非营利的创业型登月计划，我们一直在说服慈善家和现在的政府机构来资助它们——我们与许多科学家进行了交流。有些科学家只是说："这是我的研究生接下来要做的事情。这是我感兴趣的。探索这些真正有趣的假设空间，就是我们一直在讨论的所有类型的事情。"

但有些科学家说："这里有个缺口。我需要这个基础设施。我实验室里的研究生无论怎么组合，或者我与其他实验室通过传统资助进行松散合作，都无法获得这个。我需要一个有组织的工程团队来建造相当于哈勃太空望远镜的微型版本。如果我能建造那个哈勃太空望远镜，那么我就能为我领域的所有其他研究人员扫清障碍，或者推进某条技术进步路径，就像哈勃太空望远镜提升了所有天文学家的研究能力一样。"

但它本身并不是天文学发现。只是你必须把这个巨大的镜子和CCD相机送入太空，并组织所有的人员和工程等等来完成这件事。所以我们与科学家讨论的一些事情看起来就是这样的。Gap Map就是列出了很多这样的事情，我们称之为Gap Map。我认为它实际上更像是一个基础能力地图。所有这些东西是什么，比如迷你哈勃太空望远镜？然后我们把它组织成缺口，帮助人们理解或搜索它。

你发现的最令人惊讶的事情是什么？我想我以前谈过这个，但一件事就是它的整体规模或形态之类的。它是几百个基础能力。所以如果每一个都是深度科技创业规模的项目，那只需要几十亿美元左右。如果每一个都是A轮融资，那只是……填补这些缺口不需要一万亿美元。比那要少。所以这是一件事。也许我们假设了这一点，这就是我们得到的。它并不是真正全面的。它真的只是总结我们与科学家进行的许多对话的一种方式。

我确实认为在整个过程中，像Lean这样的东西实际上是令人惊讶的，因为我确实是从神经科学和生物学开始的，很明显有这些-组学。我们需要基因组学，但我们也需要连接组学。我们可以改造大肠杆菌，但我们也需要改造其他细胞。生物基础设施有一些明显的部分。我没有意识到数学证明基础设施是一个东西，这是从尝试做这件事中出现的。

所以我期待看到其他事情，其中解决它实际上不是这个困难的智力问题。它可能略微相当于AI研究人员只需要GPU或类似的东西，以及专注和真正好的PyTorch代码来开始做这件事。哪些领域需要或不需要这些？那些已经有数十亿美元投资的领域，它们仍然需要其中一些吗？它们仍然有一些这样的缺口，还是只有被忽视的领域？

我们甚至在实际天文学、实际望远镜中发现了一些有趣的尚未被探索的东西。也许是因为如果你的项目规模超过了临界质量，那么你必须有一个真正大的项目，而这在联邦机构那里是一个更加官僚的过程。我想现在在科学的每个领域都需要规模。是的，我认为在许多科学领域都需要规模。

这并不意味着低规模的工作不重要。这并不意味着创造力、偶然性等等，以及你在大学里看到的每个学生追求完全不同的方向或论文不是关键。但我认为在基本上每个科学领域都缺少一定量的可扩展基础设施，甚至包括数学，这很疯狂。因为我以为数学家只需要白板，但他们实际上需要Lean。他们实际上需要可验证的编程语言和东西。我不知道这一点。

Adam，这非常有趣。感谢你来参加。非常感谢。很荣幸。人们在哪里可以找到你的东西？很荣幸。现在最简单的方式……我的adammarblestone.org网站目前好像挂了。但convergentresearch.org可以链接到我们一直在做的很多事情。然后你有一个很棒的博客，Longitudinal Science。Longitudinal Science，是的，在WordPress上。好的。非常感谢。很荣幸。

---

*生成时间: 2025-12-30 18:53:44*
*由 YouTube Monitor & Translator (Claude CLI) 生成*