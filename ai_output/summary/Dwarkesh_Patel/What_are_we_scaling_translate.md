我很困惑，为什么有些人既预测超短时间线，同时又看好在 LLM 之上扩展强化学习。如果我们真的接近类人学习者，那么这种基于可验证结果训练的整个方法就注定要失败。

目前，各个实验室正试图通过中期训练将大量技能烘焙到这些模型中。有整个供应链的公司正在构建强化学习环境，教授模型如何浏览网页或使用 Excel 构建财务模型。

这些模型要么很快就能以自主方式在工作中学习，这将使所有这些预烘焙变得毫无意义；要么它们不能，这意味着 AGI 并非迫在眉睫。人类不需要经历特殊的训练阶段，在那里他们需要预演工作中可能需要使用的每一个软件。

Baron Millig 在最近的一篇博客文章中对此提出了一个有趣的观点。他写道："当我们看到前沿模型在各种基准测试上不断改进时，我们不应该只考虑规模的增加和巧妙的机器学习研究想法，还应该考虑支付给博士、医学博士和其他专家数十亿美元来编写问题、提供示例答案和推理，专门针对这些精确能力的成本。"

在机器人技术中，这种紧张关系最为明显。从某种根本意义上说，机器人技术是一个算法问题，而不是硬件或数据问题。经过很少的训练，人类就能学会如何指挥或操作当前的硬件来完成有用的工作。所以如果你真的有一个类人学习者，机器人技术在很大程度上就是一个已解决的问题。

但事实是我们没有这样的学习者，这使得有必要去一千个不同的家庭，练习一百万次如何捡盘子或叠衣服。

我听到那些认为我们将在未来 5 年内起飞的人提出的一个反驳论点是，我们必须做所有这些粗糙的强化学习来构建一个超人类 AI 研究员。然后这个自动化 Ilya 的百万个副本可以去弄清楚如何解决从经验中鲁棒高效学习的问题。

这让我想起那个老笑话：我们在每笔销售上都在亏钱，但我们会在销量上弥补回来。不知何故，这个自动化研究员要弄清楚 AGI 的算法，这是人类花了半个世纪绞尽脑汁都没解决的问题，而它甚至没有儿童所具有的基本学习能力。我觉得这极其不可信。

此外，即使你相信这一点，它也没有描述实验室如何处理来自可验证奖励的强化学习。你不需要预先烘焙制作 PowerPoint 幻灯片的顾问技能来自动化 Ilya。显然，实验室的行动暗示了一种世界观，即这些模型在泛化和在职学习方面将继续表现糟糕，因此有必要事先将我们希望在经济上有用的技能构建到这些模型中。

你可以提出的另一个反驳论点是，即使模型可以在工作中学习这些技能，在训练期间一次性构建这些技能比为每个用户和每个公司重新学习要高效得多。

看，将常用工具（如浏览器和终端）的流利度烘焙进去是很有意义的。事实上，AGI 的关键优势之一就是这种在副本之间分享知识的更强能力。但人们真的低估了完成大多数工作所需的公司和上下文特定技能的重要性。目前还没有一种稳健高效的方式让 AI 掌握这些技能。

我最近与一位 AI 研究员和一位生物学家共进晚餐。生物学家的时间线很长，所以我们问她为什么有这些长时间线。她说，最近在实验室工作的一部分涉及查看幻灯片，决定幻灯片中的点是否真的是巨噬细胞，还是只是看起来像巨噬细胞。

正如你可能预料的那样，AI 研究员回应说：看，图像分类是一个教科书式的深度学习问题。这正是我们可以训练这些模型去做的那类事情的核心。我觉得这是一个非常有趣的交流，因为它说明了我和那些预期未来几年内会有变革性经济影响的人之间的关键分歧。

人类工作者之所以有价值，正是因为我们不需要为他们工作的每一个小部分构建精细的训练循环。为特定实验室准备幻灯片的具体方式构建识别巨噬细胞的定制训练管道，然后为下一个实验室特定的微任务构建另一个训练循环等等，这在净生产力上是不值得的。

你真正需要的是一个能从语义反馈或自主经验中学习，然后像人类一样泛化的 AI。每天你必须做一百件需要判断、情境意识以及在工作中学到的技能和上下文的事情。这些任务不仅在不同的人之间有所不同，甚至对同一个人来说每天都不同。

仅仅通过烘焙预定义的技能集合来自动化一个工作是不可能的，更别说所有工作了。事实上，我认为人们真的低估了真正的 AI 将会产生多大的影响，因为他们只是想象更多的当前体制。他们没有想到服务器上数十亿个类人智能，它们可以复制和合并所有学习成果。

明确地说，我期待这一点，也就是说我期待在未来一二十年内出现真正的类脑智能，这是相当疯狂的。

有时人们会说，AI 现在没有在公司中更广泛部署并在编程之外提供大量价值的原因是技术需要很长时间才能扩散。我认为这是自欺欺人。我认为人们用这个借口来掩盖一个事实，即这些模型缺乏广泛经济价值所必需的能力。

如果这些模型真的像服务器上的人类，它们会扩散得非常快。事实上，它们比普通人类员工更容易整合和入职。它们可以在几分钟内阅读你的整个 Slack 和云盘。它们可以立即提炼出你其他 AI 员工拥有的所有技能。

此外，人力招聘市场很像一个柠檬市场，很难事先知道谁是好人才。雇佣一个结果糟糕的人显然成本很高。如果你只是启动另一个经过验证的高质量模型实例，这根本不是你必须面对或担心的动态。

因此，我预计将 AI 劳动力扩散到公司中会比雇佣人类容易得多。公司一直在雇佣人。如果能力真的达到了 AGI 水平，人们愿意每年花费数万亿美元购买这些模型产生的代币。全世界的知识工作者每年累计赚取数十万亿美元的工资。实验室现在距离这个数字相差几个数量级的原因是，模型的能力远不如人类知识工作者。

现在你可能会说，看，标准怎么突然变成了实验室必须每年赚取数十万亿美元的收入，对吧？就像直到最近人们还在说这些模型能推理吗，这些模型有常识吗，它们只是在做模式识别吗？显然，AI 乐观派批评 AI 悲观派反复移动这些门柱是对的，这通常是公平的。很容易低估 AI 在过去十年中取得的进步。

但如果你在 2020 年向我展示 Gemini 3，我会确信它可以自动化一半的知识工作。因此我们不断解决我们认为是 AGI 的充分瓶颈的问题。我们有具有一般理解的模型，它们有少样本学习，它们有推理。然而我们仍然没有 AGI。

那么观察到这一点的理性回应是什么？我认为看待这一点并说"哦，实际上智能和劳动比我之前意识到的要复杂得多"是完全合理的。虽然我们真的很接近，并且在许多方面已经超越了我之前定义的 AGI，但模型公司没有赚取 AGI 所暗示的数万亿美元收入这一事实清楚地表明，我之前对 AGI 的定义太狭隘了。

我期待这种情况会在未来继续发生。我预计到 2030 年，实验室将在我关心的持续学习方面取得重大进展，模型每年将赚取数千亿美元的收入，但它们不会自动化所有知识工作。我会说，看，我们取得了很大进展，但我们还没有达到 AGI。我们还需要这些其他能力。我们需要模型中的 X、Y 和 Z 能力。

模型继续以短时间线人群预测的速度变得更加令人印象深刻，但以长时间线人群预测的速度变得更加有用。

值得问的是，我们通过预训练在扩展什么？我们在计算方面有这种极其干净和通用的改进趋势，跨越多个数量级。尽管这是在幂律上，而幂律和指数增长的强度一样弱。

但人们试图洗白预训练扩展所具有的威望，这几乎和宇宙物理定律一样可预测，以此来证明对可验证奖励强化学习的乐观预测是合理的，而我们对此没有已知的公共趋势。

当勇敢的研究人员确实试图从稀少的公开数据点中拼凑含义时，他们得到了相当悲观的结果。例如，Toby Board 有一篇很棒的文章，他巧妙地连接了不同 O 系列基准测试之间的点，这向他表明"我们需要大约一百万倍的总强化学习计算扩展才能获得类似于单个 GPT 级别的提升。"

因此人们花了大量时间谈论软件奇点的可能性，其中 AI 模型将编写生成更智能后继系统的代码，或软件加硬件奇点，其中 AI 还改进其后继者的计算硬件。然而，所有这些场景都忽略了我认为将成为顶级 AGI 进一步改进的主要驱动因素：持续学习。

再次想想人类如何变得比其他任何东西都更有能力。主要是通过在相关领域的经验。在对话中，Baron Miller 提出了一个有趣的建议，即未来可能看起来像持续学习代理，它们都出去做不同的工作并创造价值，然后将所有学习成果带回蜂巢思维模型，该模型对所有这些代理进行某种批处理蒸馏。

代理本身可能相当专业化，包含 Karpathy 所说的认知核心，加上与它们被部署去做的工作相关的知识和技能。解决持续学习不会是一个单一的一次性成就。相反，它会感觉像解决上下文学习。

GPT-3 在 2020 年已经证明了上下文学习可能非常强大。它的上下文学习能力如此出色，GPT-3 论文的标题是"语言模型是少样本学习者"。但当然，当 GPT-3 出现时我们并没有解决上下文学习。实际上，从理解到上下文长度，仍有大量进展要取得。

我期待持续学习会有类似的进展。实验室可能会在明年发布一些他们称为持续学习的东西，这实际上算作朝向持续学习的进展。但人类水平的在职学习可能需要另外 5 到 10 年才能解决。

这就是为什么我不期待从第一个破解持续学习并被越来越广泛部署和变得更有能力的模型中获得某种失控收益。如果你完全解决了持续学习并凭空出现，那么确实，这可能就是定局，正如 Sam 在播客中当我问他关于这种可能性时所说的。但这可能不是将要发生的情况。

相反，某个实验室将弄清楚如何在这个问题上获得一些初始牵引力，然后使用这个功能将使其实现方式变得清晰，然后其他实验室很快就会复制这一突破并稍微改进它。

此外，我只是有一些先验信念，即所有这些模型公司之间的竞争将保持相当激烈。这是基于观察到所有这些之前假设的飞轮，无论是聊天中的用户参与度还是合成数据或其他什么，都几乎没有减少模型公司之间越来越激烈的竞争。

每隔一个月左右，三大模型公司就会在讲台上轮换，其他竞争者也没有落后太远。似乎有某种力量——这可能是人才挖角，可能是旧金山的传言工厂，或者只是正常的逆向工程——到目前为止中和了单个实验室可能拥有的任何失控优势。

这是我最初在 dwarkash.com 博客上发布的一篇文章的旁白。我将发布更多文章。我发现这在访谈前整理我的思路方面实际上很有帮助。如果你想及时了解这些内容，你可以在 dwarkash.com 订阅。

否则，我们下次播客见。干杯。