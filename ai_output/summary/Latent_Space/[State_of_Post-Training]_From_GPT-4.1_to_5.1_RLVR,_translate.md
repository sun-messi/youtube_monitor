# [State of Post-Training] From GPT-4.1 to 5.1: RLVR, Agent & Token Efficiency — Josh McGrath, OpenAI

## 📹 视频信息

- **频道**: Latent Space
- **发布日期**: 2025-12-31
- **时长**: 27:32
- **原始链接**: [https://www.youtube.com/watch?v=botHQ7u6-Jk](https://www.youtube.com/watch?v=botHQ7u6-Jk)

---

> 本文内容整理自 OpenAI 后训练研究员乔什·麦格拉思（Josh McGrath）在 Latent Space 频道的技术访谈。

## TL;DR

OpenAI 后训练研究员深度解析从 GPT-4.1 到 5.1 的技术演进：RLVR 优化、Agent 能力提升、Token 效率突破、购物模型创新，以及 AI 研究与系统工程并重的未来发展趋势。

## 📑 章节导航表

| 时间戳 | 章节标题 | 一句话概括 |
|--------|----------|-----------|
| 00:00-01:30 | 职业背景与后训练转型 | 从预训练数据策展转向后训练的动机与挑战 |
| 01:30-03:34 | 后训练工程复杂性 | RL 训练的多组件架构与调试难度 |
| 03:34-06:08 | 购物模型与交互创新 | 新模型的中断功能与深度研究范式 |
| 06:08-08:09 | 模型个性化与用户选择 | Anton vs Clippy 的用户偏好分化 |
| 08:09-11:48 | RLVR vs RLHF 技术对比 | 数据质量光谱与验证信号的信任度 |
| 11:48-14:20 | Token 效率与长期任务 | 5.1 模型的 Token 使用优化突破 |
| 14:20-17:26 | 路由器架构与接口演进 | 显式与隐式路由的合并趋势 |
| 17:26-21:00 | 长上下文与扩展性 | 图遍历评估与百万级 Token 的可能性 |
| 21:00-24:38 | 人才需求与技能融合 | ML 研究与系统工程双重技能的稀缺性 |
| 24:38-27:32 | 预训练未死与技术迷雾 | 历史类比中的技术革命不确定性 |

## 📊 核心论点

#### 后训练已成为行为改变的主要驱动力

- **核心内容**：相比预训练的 3% 计算效率提升，后训练能够实现 40% 的行为改变。RL 训练的复杂性体现在多任务评分系统、更多基础设施依赖，以及更高的调试难度。每个任务可能有不同的评分设置，这使得深夜调试时需要理解更多代码组件。
- **关键概念**：行为改变幅度、多组件 RL 架构、任务特定评分、基础设施依赖性、调试复杂度
- **实际意义**：后训练成为 AI 能力提升的核心战场，需要更强的工程和数据科学结合能力；企业 AI 应用的差异化主要体现在后训练质量上。

#### Token 效率是长期任务能力的关键瓶颈

- **核心内容**：从 GPT-5 到 5.1，虽然整体评估分数提升有限，但在二维图表中，达到相同性能所需的 Token 数量大幅下降。这直接影响 Agent 能够执行的工具调用次数和任务复杂度。Josh 更倾向于用 Token 数量而非时间来衡量长期任务，因为 Token 效率是可以直接优化的指标。
- **关键概念**：Token 效率、工具调用预算、任务复杂度、性能-成本权衡、Agent 能力边界
- **实际意义**：决定了 AI Agent 在实际应用中的经济可行性；影响企业部署自主 AI 系统的成本结构；推动模型架构向更高效的推理方向演进。

#### RLVR 与 RLHF 的核心差异在于数据质量光谱

- **核心内容**：两者本质上都是策略梯度方法，关键区别在于输入数据的质量。RLHF 使用人类偏好数据，而 RLVR 使用可验证的信号（如数学题的正确答案）。有趣的悖论是 RLHF 被称为"不可验证"，但其实已经训练模型来预测人类反馈。真正的问题是信号质量光谱：从完全可信的数学验证到主观的人类偏好。
- **关键概念**：策略梯度方法、数据质量光谱、信号可信度、优化目标、验证机制
- **实际意义**：为不同类型任务选择合适的训练方法提供指导；推动行业关注数据质量而非单纯的优化技巧；影响 AI 安全性和可靠性的根本保证。

#### 模型个性化需求推动用户控制权的回归

- **核心内容**：用户对 AI 个性的偏好呈现明显分化：开发者偏好"Anton"式的工具型交互（直接、高效、无情感色彩），而其他用户可能喜欢"Clippy"式的友好交互。OpenAI 通过个性化切换功能和自定义指令来满足不同需求。Josh 个人使用自定义指令将模型设置为纯工具，专注于工作场景的效率。
- **关键概念**：用户个性化偏好、工具型 vs 友好型交互、自定义指令、用户控制权、工作场景适配
- **实际意义**：AI 产品设计需要考虑用户场景的多样性；企业 AI 部署可能需要针对不同角色定制交互风格；推动 AI 助手从标准化向个性化演进。

#### 购物模型的中断功能代表新的交互范式

- **核心内容**：购物模型展示了可中断的思维链，用户可以在模型搜索产品过程中按 ESC 键并提供新指令（如"我实际想要 USB-C 接口"）。这种实时交互模式类似于 Cursor 编辑器中的体验，代表了从单轮对话向连续协作的转变。虽然技术上可以在同一模型中实现，但为了快速实验新功能，选择了独立模型的方式。
- **关键概念**：可中断思维链、实时交互、连续协作模式、思维链可视化、用户引导能力
- **实际意义**：改变了人机交互的基本模式，从"提问-回答"变为"协作-调整"；为复杂任务提供了更好的用户体验；可能成为未来 AI 助手的标准交互模式。

#### 显式与隐式路由器的合并是技术发展必然

- **核心内容**：当前 GPT-5 中存在两套路由机制：显式的任务路由器和隐式的思考强度路由。这种重叠会导致奇怪的冲突情况——顶层路由器可能做出错误决策，而直接交给 GPT-5 反而能正确处理。未来趋势是合并这些机制，最终实现 AGI 级别的统一工具，自动决定思考深度而无需用户操作多个控制旋钮。
- **关键概念**：显式路由、隐式路由、思考强度控制、AGI 统一接口、用户体验简化
- **实际意义**：简化用户的模型选择复杂性；提高 AI 系统的自主决策能力；推动通用人工智能接口的标准化。

#### 长上下文能力的评估需要全局复杂变换

- **核心内容**：传统的上下文利用率测试（如"大海捞针"）过于简单，只需从单点采样信息。而图遍历评估要求在整个上下文窗口中进行多次复杂变换，更能反映真实的长上下文处理能力。这类评估分数持续攀升，表明上下文腐蚀是可解决的技术问题。对于 10 亿 Token 级的用例（如 8 亿 Token 的企业文档库），Agent 方法可能比纯粹扩大上下文窗口更有效。
- **关键概念**：图遍历评估、全局变换能力、上下文腐蚀、多模态上下文、Agent vs 长上下文权衡
- **实际意义**：为企业级 AI 应用提供更可靠的长文档处理能力；影响 RAG 系统与长上下文模型的技术选择；推动模型架构向更高效的信息处理方向发展。

#### AI 人才培养的最大缺口是 ML+系统双重技能

- **核心内容**：推动 AI 前沿需要既懂分布式系统又精通机器学习的复合型人才，因为瓶颈可能随时在两个领域间切换，甚至在单个项目内多次变化。当前教育系统优化程度不足，通常只专注其中一个领域。Josh 的数学背景加上导师指导的工程训练是个例，而非常规路径。理论上 LLM 对两个领域的帮助相当，但实际上 ML 研究更容易黑盒化。
- **关键概念**：复合型技能、瓶颈迁移、教育系统优化、分布式系统、机器学习研究
- **实际意义**：指导 AI 专业人才的培养方向；影响高校课程设计和企业招聘策略；推动跨学科教育模式的创新。

#### 预训练与后训练投入比例的历史性转变

- **核心内容**：Grok 团队的数据显示，他们在预训练和后训练上投入了大致相等的计算资源，这打破了后训练成本低几个数量级的传统认知。这种投入比例的变化反映了技术重心的转移，类似历史上工厂从蒸汽动力的线性布局向电力驱动的灵活布局的转变。当前我们处于技术革命的"迷雾"中，无法预测最终形态。
- **关键概念**：计算投入比例、技术重心迁移、历史类比、技术革命迷雾、投资策略转变
- **实际意义**：重塑 AI 研发的资源配置策略；影响投资人对 AI 公司的评估框架；推动整个行业重新思考技术发展路径。

#### Codex 等工具正在改变研究工作流程

- **核心内容**：Codex 能在 15 分钟内完成原本需要几小时的设计文档工作，但也带来了新的时间管理挑战——如何利用节省出的时间，以及如何适应 40 分钟工作块与 15 分钟高效期的新节奏。这种工具在代码库理解和调试方面特别有效，正在重塑研究人员的日常工作流程。
- **关键概念**：工作流程变革、时间管理优化、代码理解加速、效率倍增器、工作节奏适配
- **实际意义**：提高 AI 研发效率，缩短产品迭代周期；要求研究人员重新设计工作方式以适应新工具；可能加速整个行业的技术进步节奏。

## 🏢 提及的公司/产品

| 公司名 | 讨论语境 | 重要性 |
|--------|----------|--------|
| OpenAI | 主要讨论对象，Josh 的雇主，GPT 系列模型开发者 | ⭐⭐⭐ |
| Anthropic / DeepMind | 同行竞争对手，后训练技术交流伙伴 | ⭐⭐ |
| DeepSeek | GRPO 优化方法的发明者，数学模型创新 | ⭐⭐ |
| Cognition | AI 科学家自动化领域的参与者 | ⭐ |
| Cursor/Codex | 代码辅助工具，影响工作流程 | ⭐⭐ |

## 💬 经典金句（3-5 句）

> "Do I want to make compute efficiency wins of like 3% or do I want to change the behavior by 40%?"
> — Josh McGrath

> "I personally want my model to be a tool, so I don't necessarily want the warmth or anything. I just want some answers because I'm mostly using it at work."
> — Josh McGrath

> "We're all living through something that I read about in history books, and this one's live as it's happening."
> — Josh McGrath

> "It's really about this spectrum of how high quality a signal is... how much do I trust it and what's going to happen when I do a lot of optimization against it."
> — Josh McGrath

## 👤 主要人物

#### Josh McGrath（乔什·麦格拉思）

**身份**：OpenAI 后训练研究员，专注思考模型和搜索相关功能开发
**背景**：数学专业出身，之前从事预训练数据策展工作，在导师指导下掌握了软件工程技能。参与了 GPT-4.1 的长上下文功能开发，目前负责购物模型等新型交互范式的研究。
**核心观点**：强调后训练相比预训练能带来更大的行为改变幅度（40% vs 3%），认为 Token 效率是长期任务的关键瓶颈。主张 AI 人才培养需要 ML 和系统工程双重技能，预测显式与隐式路由器将最终合并为统一的 AGI 接口。对技术发展持开放态度，认为当前处于类似历史上电力革命的"迷雾"阶段。

## 📺 视频类型判断

**访谈对话**：技术深度访谈，主持人与 OpenAI 研究员的专业对话

---

## 📝 完整翻译

### (0:00 - 15:00) Part 1

我们今天请到了来自OpenAI的Josh。欢迎！请介绍一下自己。

Josh： 我在OpenAI从事思维模型的研究工作。最近主要专注于搜索相关的项目，我是OpenAI的博士后研究员。

你之前和我们一起参与了GPT-4o的访谈，当时Michelle还在，现在她在休产假。现在我们迎来了o1时代，真是跨越了整整一代。

Josh： 确实很疯狂。4o是一个非思维模型，而从那时起我们就转向了思维模型的开发。

那是你最后参与的项目吗？

Josh： 不是，我们仍然在发布非思维模型。但4o是我们专门针对API开发的非思维模型，所以关注重点确实有所转移。

你是怎么进入后训练领域的？

Josh： 在加入OpenAI之前，我从事预训练数据管理工作。从新闻和论文中我发现，预训练并没有死，但后训练领域将会有很多有趣的发展。我真的想在那里做出一些贡献。

问题不在于预训练已死，而是它确实在发生变化。我要选择3%的计算效率提升，还是40%的行为改变？说实话，后训练看起来更令人兴奋。经历了很多个深夜后，这确实是事实。这是一种完全不同的数据和工程学科，特别是强化学习的规模化，工作方式非常奇特。

强化学习运行中的活动部件数量要高得多。

Josh： 我不敢说是数量级的差异，但如果你想想预训练的过程——你把token传输到多台机器上，然后基本上从它们那里得到一个标量，然后进行反向传播。

而强化学习的问题在于，你要处理各种任务，每个任务可能有不同的评分设置，每一种不同的评分设置都需要更多的基础设施。所以当我深夜熬夜试图弄清楚运行中出了什么问题时，可能出现问题的地方比预训练运行要多得多。

你是否拥有任务的代码有关系吗？还是外包给第三方？我的印象是你们与很多外部合作伙伴合作，当然也有一些内部工作，哪种方式更好？

Josh： 说实话，我不会过多评论有多少外部合作伙伴。确实有一些，也有一些内部合作。

但从技术权衡的角度来说，当涉及到"我不拥有这段代码"时，实际上当我在照看一个运行或其他什么时候，不管是内部的、外部的还是其他什么，都没有太大关系。关键是我是否理解底层运行的系统。我认为你最终必须跳入大量你并不了解其功能的代码中。

我会监控运行状况，处理我负责的部分。同时还有其他人在处理其他部分，我需要理解他们的代码在做什么。这样当凌晨12:30我觉得有什么不对劲，查看代码时，我能否足够快地获得上下文来理解问题？

把问题丢给Cursor吧。

Josh： 我经常使用Cursor，它真的改变了我的工作方式。某种程度上，我有时会感到被Cursor束缚，因为如果我花30-40分钟写一些像设计文档的东西，Cursor能在15分钟内完成我几小时才能完成的工作。但问题是在那15分钟之后我该做什么？

这确实改变了我一天的工作流程，因为我现在必须管理这些40分钟的工作时段和15分钟的空闲时间。在这15分钟里我可以做点什么，但效果远不如这种新的工作流程。说实话，我仍在适应这种变化。

对于遇到不熟悉代码时的代码库理解来说，这确实很有趣。

Josh： 绝对如此。在我们开始之前，你简单谈到了购物模型，这是最新最热门的功能。显然我们在黑色星期五、网络星期一之后录制这期节目，在LGBTQ期间发布购物功能有什么有趣的发现吗？

好吧，首先我想说的是，我不知道为什么我会在8月的会议上说"嘿，黑色星期五就要到了，也许我们可以在那之前发布"。事后想想，我为什么会说这样的话？

他们说"好的"，现在你负责了。

Josh： 没错。我觉得最有趣的是新的中断功能和使用它的定性体验。Cursor也是如此，对吧？你写一个提示，然后可以按Escape键说"哦，我搞错了什么。"

我们在购物模型中也实现了同样的功能。它会显示其思维链，展示它正在查看的产品。你可以给它写新消息，比如"哦，我实际上想要这个。"

比如"我想要这个设备有USB-C接口"之类的。我认为这是一个真正有趣的新交互范式，我们在几个不同的服务中都有，我很期待看到人们如何使用它，是否喜欢它。

为什么必须是一个独立的模型，而不是一个新工具？

Josh： 请持续关注。我认为最终我们没有理由不能在同一个模型中实现，但我认为如果我们想尝试新东西，有时创建一个新模型是有意义的。这次我们想说，我们能否做一个深度研究风格的模型，但用于购物，它会在整个互联网上努力寻找不同的东西。

如果你看看原版深度研究和今天GPT-5在高推理能力上的思维模式，我认为你会看到最终所有模型在能力上都会趋于统一。

这是否也是我在社区中掀起的一个有点辣手的讨论？仍然有大约30%的社区在使用深度研究，很多人已经转向使用o1-thinking作为深度研究。这算是精神上的成功吗？还是它们是直接的替代品？如果我们这样做，原始深度研究模型中是否会失去一些东西？

Josh： 如果你看看我们发布的评估，它们基本上不相上下，甚至更好。所以我个人就是这样做的。我使用thinking的高模式，而不是使用深度研究模型。但正如我们在过去几个月中了解到的，有时人们更喜欢某个模型的特点，所以如果人们喜欢深度研究模型，那就随他们去吧。

在后训练中，人们是否真的对个性有特殊反应？这是人们真正关心的差异化因素吗？关心个性是你工作的一部分吗？

Josh： 是的，人们确实很关心个性。我认为在过去几个月中，我们一直在努力为用户提供更多个性选择。

对，就是那些开关功能。

Josh： 是的，现在我们有了那些开关。

你最喜欢的开关是什么？

Josh： 说实话是自定义指令。我个人希望我的模型像个工具，所以我不一定想要温暖或其他什么。我只想要答案，因为我主要在工作中使用它。

所以，我称这为Anton versus Clippy的分歧。Anton是HBO剧集《硅谷》中的角色。

Josh： 好的。

它是一台机器，它的主人让它工作。它不试图友善或友好或其他什么。它试图提供帮助，但不试图显得愉快。而Clippy试图显得愉快，我就像"别对我笑了，我遇到了问题。"

听起来你也站在使用Anton这一边？

Josh： 是的。我认为很多开发者想要Anton，它安静地工作，完成后就闭嘴。

我们正在努力为人们提供Anton和Clippy两种选择，我希望他们都喜欢。

### (15:00 - End) Part 2

某种程度上你确实需要将它们合并，否则就会出现奇怪的问题，有时顶层路由器做出错误决策，实际上如果你直接交给o1模型，它本来能够处理好。

我认为我们会逐渐找到正确的抽象方法。

主持人：合并仍然是计划吗？因为论文中是这样说的。

是的，我认为最终我们会实现AGI，那时你就不需要过多担心如何思考的问题。我们会有一个通用工具，你总是可以求助于它，它知道需要思考多长时间等等。我认为我们今天驱动这些模型的抽象方式会发生改变。从没有思考模型到可以在两者之间选择，现在我们可以进行路由并决定思考的深度，我们添加了很多控制选项，最终这些可能会简化。

主持人：另一个非常有趣的功能是上下文压缩或记忆压缩。这方面有什么进展？

目前没有可分享的内容。

主持人：让我来分享吧。这显然是一个重要功能，显然也受到了代码使用案例的启发。但从工程师的角度来看，感觉我过去需要在工具中处理这些，现在模型在为我做这件事，我不知道该如何思考这个问题。我习惯有更多控制权，现在我的控制权变少了。

有具体的反馈吗？

主持人：具体的问题是，这是否是一个我们需要接受的趋势，基本上从现在开始这将是永久性的现实？

我不知道。我之前专注于长上下文工作，这是我在4.1版本的工作重点，我们将上下文窗口的有效性提升了10倍。总会有某种平衡，如果我们想尽可能发挥能力，我们不仅应该增加上下文窗口的长度，还应该制定策略让上下文窗口尽可能长时间可用。我猜测两件事都会发生，因为我们想为模型注入尽可能多的能力。

我认为我们仍处于一个阶段，所有人都应该预期所有模型提供给我们的接口会发生变化。这样我们可以改进模型，因为如果我们锁定接口，从我的角度来看很遗憾的是，如果我们发现关于模型的新东西，我们可能会将这种改进困在需要改变的接口下。

主持人：说到长上下文，有一些关于上下文衰退或上下文利用率的讨论。即使你给我们百万token的上下文，我们可能也不会全部使用。这方面有什么建议？发展方向是什么？明年我们会有完美的上下文吗？这是不可能的梦想吗？

这不是不可能的梦想。我想为我们在4.1版本中做的一些评估点赞，叫做图遍历。

主持人：我喜欢图遍历，我们在播客中讨论过这个。

如果你观察一段时间，所有这些评估都在不断攀升。我认为有趣的一点是，你必须在整个上下文窗口中进行复杂的转换。这就是那些热图问题的关键所在。

主持人：我需要一点...但问题是如果你只需要从上下文窗口的一个点采样，那相对容易。而在图遍历问题中，你必须在整个上下文窗口中进行多次转换。

所以我认为要持续关注这些。我认为它们一直在攀升，会继续攀升。我会说这绝对是一个临时问题，我们会随时间逐步解决。

主持人：那么1000万token现实吗？1亿token呢？有自然的终点吗？还是没有终点，我们会走到能看到的极限？

天哪，我不知道。你觉得呢？

主持人：我觉得有些用例需要数十亿token，有些用例需要很多很多十亿，可能是万亿。

主持人：出于好奇，什么情况需要数十亿token？

我们刚讨论了一个上下文工程案例，关于一家公司支持问题的RAG代码库，包含10万份文档，总计约80亿token。你现在无法将这些放入上下文窗口。

这很有道理。我想我仍然会说我不知道，但我真的很惊讶。这让我想起我做信息检索工作的时候，BM25和这些简单的n-gram索引真的很难被击败。

我认为具有GPT的agent对我来说感觉非常相似，就像不合理的有效。所以即使你给了我1000万token的上下文窗口，我也可能不会使用。

主持人：也许吧，但如果我们使用上下文窗口来服务某个更大的目标，只是有很多子搜索调用呢？这就是为什么我说我真的不知道，我认为这正是让人兴奋的地方。

我还要说，其他模态如视频会消耗大量空间，显然硬科学有蛋白质等等，大量信息都编码在物理学中。所以我对此有复杂的感受，因为我觉得这永远不会扩展。不是在完全注意力机制下，我们可能需要投资系统，这意味着我们对现有的就满意了。

我是说，把你的图遍历搞好，但我不知道我们是否需要10倍100倍的提升，实际上也许我们需要找到1000倍、100万倍的方法。

这些只是不同的斜率。我当然很高兴你对目前的上下文窗口满意。我的梦想是推动它看看会发生什么，但我认为工程师的激励总是说，系统比模型更重要，而研究者的激励是说，去你的系统，我们就是要推进模型。

主持人：不，是这样的。我认为这是OpenAI后训练最美丽的事情之一，每个人都是共同设计。

是的，都是共同设计。我花很多时间做系统工作，也做很多像制作图遍历这样的学习方面的事情，我认为有一个让人们在两者之间无缝切换的地方是很棒的文化。

主持人：你们在招聘什么？想必你们在招人，你们在招聘什么是难招的？什么技能集是我们真的需要但找不到，请大家去学习的？

以我个人观点，我认为我们仍然很难，不是在OpenAI，而是整个行业，培养很多既想做系统工作又想做机器学习工作的人。我认为如果你想推动前沿，你不知道哪个地方当前是前沿的瓶颈，而且这一直在变化。即使在一个项目内，当前瓶颈可能会变化多次，但我认为我们现在的教育系统并没有为此优化。

就像我个人学习数学，然后非常幸运地在毕业后有一些很好的导师教我成为一名好的软件工程师。但似乎如果我们要在这个地方待一段时间，我认为我们会的，我们应该培养更多既擅长分布式系统和核心工程，又擅长统计学等机器学习研究所需技能的学生。

主持人：如果我们把Codex用在这上面，显然我们不能把Codex用在所有事情上。比如说哪个会进步得更快？哪个更容易被LLM解决？

这是个辣手的问题。

主持人：你不能说它们同样难。

我不知道，也许它们确实如此。我是说，它们的难度不同。一个比另一个更可攀登，哪一个呢？因为那样我们就可以去做了。

我认为ML研究的某些方面稍微简单一些，或者说ML研究也是分布式系统，但传统上被称为ML研究的一些东西可以更多地被视为黑盒，而构建训练环境、构建这些不同系统实际上就像一个复杂的数据工程问题。

理论上，我会说它们可能大致相等，但我觉得让环境适用于研究需要一些努力。

主持人：但它们本身也需要GPU。

是的，我猜它们都需要，但这是我的猜测。但我对此没有很高的信心。

主持人：所以很多人在构建AI科学家，对吧？自动化研究。你们有自己的TAP基准，那是我们在Cognition决定不做的一个领域，因为太难了。

好的，还有后训练团队的其他人你想点名，他们今年做了有趣的工作？他们应该得到更多关注但没有得到认可的？

当然，我刚刚合作的购物团队的每个人。Andrew Hoyel、Manuka Castrada、John Hullman，都是很棒的人。显然还有Issa Fulford，她是经理。

主持人：她是最初的深度研究人员。

是的，有三个人。

绝对是团队的那部分人，但每个人都很棒。我认为很难列出一个清单。现在后训练团队真的很有趣。每天都很激动人心。感觉我们都在深夜在办公室一起享受健怡可乐。

主持人：我确实想在结束前挤入这个话题。实际上没有人真正认为预训练已死，这只是一个梗。预训练还有很多工作在进行。实际上，我的很多研究朋友说太多钱流向了后训练。这也很有争议性。

我记忆中今年的一个图表是Grok 4图表。基本上是说，我们将预训练扩展到这里，大约同样水平的计算量，现在我们也在后训练上花费同样水平的计算量。我认为这很有争议性，因为我们都习惯了后训练需要少几个数量级的数据、计算等等。显然我们现在正在扩展这些。我们会到达它们相等的点吗？我不知道。但我认为这是一个值得讨论的话题。我们在这方面投资多少，而不是你之前做过的更多不同的自由交易？

首先，这两个都没有死。我认为能够亲历一些我所有其他历史或技术革命都是我在历史书中读到的东西，而这个正在实时发生，真的很有趣。

主持人：我们还不知道结局。

是的，所以有这种战争迷雾，我想"人们是否认为我们得到了蒸汽机，他们会有工厂，我不知道你是否知道这个，但工厂过去是线性的，因为你必须在整个房间驱动一个马达。当电力发展起来时，他们只是试图做同样的事情。他们想，这并不那么有用。花了几十年时间他们才意识到...最符合人体工程学的东西。然后制造业被电力改变了。"我认为这真的让我对说"哦这个东西已死"没有信心。

主持人：是的，我们的时间线很短，但最近好想法被实验、资助和传播的方式实际上仍然是人类时间线，不是AI时间线。

是的，所以我认为事情可能会处于休眠状态，但会是尖峰式的。突然会有...然后我们都会感觉不同。这就像那个梗，"完蛋了，我们回来了"。

这会发生很多次。我认为对此有一些情感稳定性对每个人的理智可能都有好处。

主持人：更多理智。非常感谢你的加入。感谢今年所有出色的后训练工作。

谢谢你。是的，请继续给反馈。我很喜欢听到你的想法。

主持人：太棒了。

---

*生成时间: 2026-01-02 05:14:40*
*由 YouTube Monitor & Translator (Claude CLI) 生成*