# [State of AI Papers 2025] Fixing Research with Social Signals, OCR & Implementation — Team AlphaXiv

## 📹 视频信息

- **频道**: Latent Space
- **发布日期**: 2025-12-31
- **时长**: 34:42
- **原始链接**: [https://www.youtube.com/watch?v=T0mZJjl_dsA](https://www.youtube.com/watch?v=T0mZJjl_dsA)

---

本文内容整理自 AlphaXiv 联合创始人 Raj、Rahan 和 Sebastian 在 Latent Space 频道的技术访谈。

---

## TL;DR

AlphaXiv 从简单的论文评论系统发展为 AI 研究工具平台：通过社交信号优化论文发现、OCR 技术解析、Docker 容器化实现，正在重新定义学术论文生态系统的价值链。

---

## 📑 章节导航表

| 时间戳 | 章节标题 | 一句话概括 |
|--------|----------|-----------|
| 00:00-03:06 | AlphaXiv 创立故事 | 三位 Stanford 室友从操作系统课堂的论文评论想法开始创业 |
| 03:06-06:10 | 产品发展与竞争优势 | 从评论功能到智能论文推荐，通过精准用户体验胜过 Hugging Face |
| 06:10-10:15 | 公司转型与愿景 | 从边缘项目到正式公司，目标成为研究工具而非社交网络 |
| 10:15-15:20 | 2025 年度论文讨论 | 小参数递归模型、进化算法替代梯度下降等创新研究 |
| 15:20-18:23 | AI for Science 评析 | 从自动化科学流程到虚拟实验室的现实与局限性 |
| 18:23-21:58 | 智能体与 RL 发展 | Agent R1 及基于 Qwen 2.5 的企业级 RL 应用趋势 |
| 21:58-27:32 | 学术生态系统危机 | 论文质量下降、AI 生成内容泛滥、同行评议体系失效 |
| 27:32-34:42 | 未来愿景与挑战 | 从论文到实现的转变，Docker 容器化和实用主义排序 |

---

## 📊 核心论点

#### 社交信号驱动的学术论文发现机制

- **核心内容**：传统的学术论文发现依赖时间顺序排列或关键词搜索，但在每月 30,000 篇论文的信息洪流中效果极差。AlphaXiv 通过整合社交信号（浏览量、评论数、分享数）与语义搜索，实现智能论文推荐。相比纯语义搜索在 300 万篇论文中的噪音问题，社交信号能够有效识别真正有价值的研究工作。
- **关键概念**：社交信号、语义搜索、论文排序、信息过滤、长尾分布
- **实际意义**：为应用研究人员和工业界从业者提供高质量论文发现工具，显著提升研究效率；改变学术声誉机制，让实用性成为论文评价的重要指标。

#### OCR 技术在学术文献解析中的突破

- **核心内容**：随着多模态大模型的发展，PDF 论文解析从传统文本提取转向视觉理解。DeepSeek 在成本效益方面表现最佳，特别是在自托管 A100s 上批处理时。OCR 模型发布呈现"一日效应"：当某个团队发布新模型后，其他团队会在 2-3 天内快速跟进发布类似工作，反映了学术界的激烈竞争。
- **关键概念**：多模态大模型、PDF 解析、视觉语言模型、成本效益、学术竞争
- **实际意义**：降低了学术文献数字化门槛，为自动化文献分析奠定基础；推动了开源模型在学术工具中的广泛应用。

#### 小参数递归模型的计算效率突破

- **核心内容**：TRM（Tiny Recursive Models）用 700 万参数的 Transformer 通过递归自传递实现了在特定任务上的惊人性能。在 Sudoku 和 ARC-AGI 任务上达到 45-50% 准确率，与 DeepSeek R1 或 Gemini 2.5 等大模型相当。这证明了在有限计算资源下，巧妙的架构设计可以获得与大规模模型相媲美的效果。
- **关键概念**：递归计算、参数效率、架构创新、任务特化、计算资源优化
- **实际意义**：为资源受限的研究团队提供了与大厂竞争的新路径；推动了模型架构创新而非单纯的规模扩张。

#### 进化策略在大规模优化中的复兴

- **核心内容**：研究者在百万参数规模上使用进化策略替代梯度下降，通过低秩扰动实现了与传统梯度方法相当的性能。这挑战了深度学习中梯度下降的绝对地位，证明了在特定场景下，进化算法仍有其独特价值。虽然可扩展性尚未验证，但为优化算法多样化提供了新思路。
- **关键概念**：进化策略、低秩扰动、梯度下降替代、优化算法、参数空间搜索
- **实际意义**：拓展了深度学习的优化工具箱；为处理非可微或梯度信息不稳定的场景提供了新选择。

#### AI for Science 的虚拟实验室定位

- **核心内容**：Agent Laboratory 等项目提出用 AI 自动化科学研究流程（文献调研→实验设计→结果分析→论文撰写），但完全自动化仍面临巨大挑战。更现实的定位是"虚拟实验室"：AI 作为工具降低实验成本和探索门槛，研究者仍是 PI（主要负责人）。BiOmni 等工具在制药公司的实际应用证明了这种渐进式方法的可行性。
- **关键概念**：科学自动化、虚拟实验室、人机协作、工具增强、渐进创新
- **实际意义**：为科研人员提供强大的辅助工具，特别是在文献调研和实验设计阶段；推动科学研究的民主化，降低高质量研究的门槛。

#### 基于 Qwen 2.5 的企业级 RL 应用生态

- **核心内容**：Qwen 2.5 在设计时特别考虑了强化学习微调的样本效率，成为众多 RL 服务公司的首选基座模型。Agent R1 等研究展示了在多跳问答等复杂推理任务上的优异表现。这种技术路线在 Cursor 等商业产品中得到验证，形成了从学术研究到产业应用的完整链条。
- **关键概念**：强化学习微调、样本效率、商业应用、开源生态、技术转化
- **实际意义**：为企业构建定制化 AI 智能体提供了成熟技术路径；证明了开源模型在特定领域可以与闭源模型竞争。

#### 学术论文生态系统的质量危机

- **核心内容**：学术会议面临投稿量指数级增长但评审质量下降的困境。ICLR 出现姓名泄露丑闻，20% 评审由 AI 完成。AI 生成论文的泛滥导致内容同质化和质量下降。传统同行评议制度已无法应对每月 30,000 篇论文的处理需求，急需新的质量控制机制。
- **关键概念**：同行评议、AI 生成内容、学术诚信、质量控制、评审负荷
- **实际意义**：学术声誉体系面临重构；需要开发新的论文质量评估工具和激励机制。

#### 从论文到实现的学术价值链重构

- **核心内容**：应用研究人员不关心论文的理论贡献，而关心实现的易用性和可复现性。论文作为 PDF 的传统形式越来越无法满足快速迭代的需求，GitHub 代码库、Docker 容器、在线演示等实现工件的重要性超越论文本身。AlphaXiv 计划通过实现难易度对论文进行排序，激励作者提供高质量的代码实现。
- **关键概念**：实现易用性、可复现性、代码质量、激励机制、价值重构
- **实际意义**：推动学术研究从"发表导向"向"应用导向"转变；提升研究成果的实际转化效率。

#### 基于社交信号的研究助手个性化

- **核心内容**：传统的语义搜索在海量论文中容易被关键词填充和低质量内容干扰。AlphaXiv 结合社交信号（浏览量、讨论热度）与语义相关性，实现更精准的个性化推荐。这种方法特别适合为产业界研究人员筛选出真正有应用价值的研究工作，而非仅仅是理论上新颖的成果。
- **关键概念**：个性化推荐、社交信号、语义搜索、质量过滤、应用导向
- **实际意义**：显著提升研究文献发现效率；为不同用户群体（学术界 vs 产业界）提供差异化服务。

#### Docker 容器化学术代码的自动化部署

- **核心内容**：AlphaXiv 正在开发能够自动为论文代码库创建 Docker 容器的 AI 智能体，解决代码复现中的环境配置难题。这种自动化部署能力将使研究人员能够在浏览器中直接运行和验证论文实现，大大降低了从论文到实际应用的技术门槛。对于无法自动化的复杂代码库，将通过实现难易度排序来激励作者改进代码质量。
- **关键概念**：容器化部署、自动化配置、代码复现、技术门槛、质量激励
- **实际意义**：彻底改变学术代码的分享和使用方式；推动研究社区向更高的代码质量标准发展。

---

## 🏢 提及的公司/产品

| 公司名 | 讨论语境 | 重要性 |
|--------|----------|--------|
| AlphaXiv | 论文评论和研究工具平台的核心主角 | ⭐⭐⭐ |
| Hugging Face | 早期论文讨论平台的主要竞争对手 | ⭐⭐ |
| DeepSeek | OCR 技术和开源模型的重要提供者 | ⭐⭐⭐ |
| Qwen/阿里 | 企业级 RL 应用的首选基座模型 | ⭐⭐⭐ |
| Stanford | 三位创始人的学术背景和项目孵化地 | ⭐⭐ |
| Cursor | 基于 Qwen 2.5 的商业化 AI 编程工具 | ⭐⭐ |
| NVIDIA | GPU 计算基础设施和 Launchables 平台 | ⭐⭐ |
| Papers with Code | 被 AlphaXiv 功能替代的传统平台 | ⭐⭐ |
| Emergent Minds | YouTube 作为论文信号来源的合作伙伴 | ⭐ |
| Replicate | Docker 容器化的早期尝试者（后转型） | ⭐ |

---

## 💬 经典金句（3-5 句）

> "论文本质上只是对实现的宣传册。"
> — Raj

> "在未来 5-10 年，论文作为一种工件将变得越来越无用。"
> — Sebastian

> "我们帮助人们用 AI 理解论文，而不是用 AI 写论文。"
> — Rahan

> "如果你只是尝试构建语义助手，事情会很快变得嘈杂。"
> — Raj

> "研究将远离论文形式，PDF 是一种过时的信息分享方式。"
> — Sebastian

---

## 👤 主要人物

#### Raj

**身份**：AlphaXiv 联合创始人兼 CEO
**背景**：Stanford 计算机科学专业，曾在 Dorsa 实验室从事机器人与 NLP 交叉研究，与 Percy Liang 合作过项目。与 Rahan 是 5 年室友关系。
**核心观点**：学术论文生态系统需要从传统的 PDF 形式转向更实用的实现导向模式。强调 AlphaXiv 的价值在于帮助用户理解研究而非生产研究，通过社交信号优化论文发现机制。

#### Rahan

**身份**：AlphaXiv 联合创始人兼 CTO
**背景**：Stanford 本科，主要从事机器人学和强化学习研究，在 GPT 时代之前就开始相关工作。最初的论文评论想法来自于他在 Web 开发课程中的期末项目。
**核心观点**：认为应该为学术论文建立类似 Stack Overflow 的问答社区，解决本科生在理解复杂论文时遇到的困难。支持通过技术手段降低学术研究的门槛。

#### Sebastian

**身份**：AlphaXiv 联合创始人
**背景**：Stanford 研究背景，曾从事稀疏深度学习相关研究。作为团队的导师和顾问，参与了公司从边缘项目到正式企业的转型过程。
**核心观点**：坚信未来研究工作的核心将是实现而非论文，PDF 作为信息载体已经过时。强调需要为应用研究人员构建更好的工具来缩小从研究到应用的差距。

---

## 📺 视频类型判断

**访谈对话**：多人讨论、问答形式、播客

---

## 📝 完整翻译

### (0:00 - 3:06) AlphaXiv 创立故事

主持人：大家好，欢迎来到 Latent Space。感谢你们的到来。你们是 AlphaXiv 的创始人，我确认这是官方发音。你们每个人是如何走到一起并创办这家公司的？

Raj：我是 Raj。我们之前都在 Stanford。我实际上和 Rayhon 是室友，过去 5 年一直是，现在也还是。我们开始时都像其他很多人一样在 Stanford 做 AI 研究。我在 Dorsa 的实验室，也和 Percy 合作过一些项目，主要研究机器人学和自然语言处理的交叉领域。

真正的创立故事是这样的：有一天 Rayhon 和我在上操作系统课，当时已经很晚了，大概凌晨 1 点。Rayhon 说："嘿，你想看看我的 Web 开发课期末项目吗？"我说："你为什么觉得我现在想看这个？我们正在赶作业想回家睡觉呢。"他说："不，你应该看看，挺酷的。"我说："好吧，给我看看。"

那个项目基本上就是在 arXiv 论文的每个段落旁边加了一个很粗糙的查看评论按钮。想法就是"嘿，你可以在论文上评论"。我当时想："这确实很有意思，我们应该继续做下去。考虑到有多少人在阅读 AI 论文，而且这个数量还在指数级增长，arXiv 论文上没有评论功能确实很奇怪。"

所以我们就开始为了好玩而开发它。我们把它展示给实验室的人看，他们说这很不错，如果它能成功的话他们会使用。但我觉得这件事真正变得严肃是因为它突然火了 —— 我们的一个朋友当时在 FAIR 工作，他在 LinkedIn 上发了这个项目，结果就火了。从那时候开始，我们开始和我们的导师 Sebastian 合作，一直发展到现在，非常不错。

Rayhon：我是 Rayhon。在做 AlphaXiv 之前，我作为本科生在做机器人学和强化学习的研究，那时候还是 GPT 之前的时代。作为一个普通的本科生，你的博士导师会给你论文，而你很难理解它们。所以我想应该有一个类似于 Stack Overflow 的东西来解决 arXiv 论文的问题，肯定有其他本科生也有同样的疑问。显然从那以后它经历了很多变化，但那就是最初的想法。

我和 Raj、Rayhon 一样，在本科阶段也做过研究，在 Stanford 小组做稀疏深度学习研究。我觉得我们都有这种共同的本科研究经历，就是一个看起来很简单的想法 —— 为 arXiv 论文加评论区的简单前提。这就是一个我们每周花 20、30 小时业余时间做的项目，显然它就是从那里起步的。

### (3:06 - 6:10) 产品发展与竞争优势

这是一个非常令人兴奋的旅程。我想另一个原因是，当我第一次看到 AlphaXiv 时，我并不一定认为它是新颖的，因为我知道 Hugging Face 也推出了论文讨论功能。既然 Hugging Face 这么大，为什么你们似乎胜出了或者说突破了？

我认为有几个原因。即使我们只是做评论功能时，我觉得核心在于我们就是我们产品的理想客户画像。我们知道 Hugging Face 的论文页面存在，但我们觉得有些问题没有得到解决。比如能够直接在论文上评论这样简单的事情，还有用户界面。我认为当我们开始时，我们非常刻意地去找到像 LoRA DPO 的 Laura 这样的作者，并且真正进行有用的、酷炫的交流，然后这些交流会被分享。

你们是主动联系他们说"嘿，请在这里讨论"吗？

是的，我们会利用现有的关系，比如我们从研究中认识的人。

那很艰难。

是的。但从那里开始，它会增长得非常非常快。我认为从评论功能开始，我们采取了一个非常自然的发展路径，这是其他论文平台没有做到的。当评论功能起飞时，我们想："好吧，我们很好地了解了人们在读什么论文，对吧？"所以如果你想发现论文，一个极端是 arXiv 按时间排序，每天有一千篇论文按新旧排序，另一个极端是 Twitter。所以我们觉得这是一个很好的机会，基于互动来整合一个更高信号的论文推荐流。评论功能变成了论文推荐流，然后从那里我们发现，人们问的很多问题可能都可以用 AI 来回答。Gemini 推出了 100 万 token 上下文的功能，我们想："好吧，让我们把它加进来。"所以我们不断发展，构建了更加一体化的体验，同时增长我们的用户基础，不断深挖这个方向。

关于 Gemini，你们是把 PDF 解析成文本然后输入上下文，还是直接输入图像？

这取决于模型，我们支持很多不同的模型。有些模型只是基于文本的。对于像 Claude 这样的模型，我们也会尝试传入相关的图表。

最好的 PDF 解析模型是什么？

这是个好问题。在过去一个月里，出现了大量不同的 OCR 模型。从成本和准确性来说，DeepSeek 相当不错。如果你在自己的 A100s 上托管它，并且正确地批量处理，DeepSeek 可能是性价比最高的。还有像 Mistral 这样的服务提供 API，那些可能在 OCR 方面也不错，如果你使用他们的 API 服务可能会更贵一些，但我认为 DeepSeek 非常非常好。

OCR 的例子真的很有趣，这是我们在 AlphaXiv 上看到的很酷的现象之一。第一天，有人发布一个 OCR 模型，然后接下来的两三天里，可能一直在研究这个问题几个月的其他四个人会发布他们自己的 OCR 模型。

是的，看到 AlphaXiv 在那里带来的价值很酷。

很棒。那么公司的进展如何？你们原本决定这是一个业余项目，什么时候决定把它提升到下一个层次，现在你们处于什么阶段？

### (6:10 - 10:15) 公司转型与愿景

Ran：当然可以。我想在最初一两年里，这确实只是一个业余项目。真正推动我们转型的是，我们看到了Papers with Code、Weights and Biases、Hugging Face这些平台，然后我们意识到我们有一个真正热爱我们所做事情的用户群体。显然研究远不止论文，我们想要处理研究的其他产物。我们即将开展的一项工作是让人们能够非常容易地在网站上直接试用论文的实现。

主持人：你们是否已经完全替代了Papers with Code？

Ran：我可以这么说。是的，因为我们有基准测试和很多最先进的页面。

主持人：我知道很多人都知道Papers with Code已经下线了。所以你们添加了信息流、基准测试等等。但我认为驱动我们成立公司的原因是，研究的产物远不止论文，从那里出发是很自然的选择。我不知道其他人是否想补充什么。

团队成员：我想用一个类比，就像arXiv已经存在，我们进来在arXiv之上构建了一个智能层，提供更好的界面和工具来快速理解论文的核心思想，就像评论功能一样。如果我们能对基准测试做同样的事情呢？你提到Papers with Code曾经很好用，但它仍然很依赖社区驱动，人们会上传自己的基准测试或实现等等。现在有了LLM，这变得非常容易，我们可以使用OCR从图表和表格中解析出哪些是领先的模型和论文在基准测试上的想法，然后把它们全部汇集到一个地方。

一种思考方式就是帮助人们理解AI研究的信息洪流，而这不仅仅是论文，还有基准测试、模型和实现。

主持人：我真正想要的功能，现在很容易实现，就是设置一个监控，当某个话题出现时通知我。

Ran：就像自定义信息流。这也是我们想要在助手功能上投入大量工作的地方，打造最好的研究助手，了解你的兴趣，为你提供最相关和最新的研究。这实际上是一个个性化和排名系统，一个论文推荐系统。

还有什么被低估的吗？你们把自己看作社交网络还是类似Goodreads的平台？

Ran：我们经历了多次迭代，我认为我们提供最多价值的地方具体来说不是社交网络，而是一种研究工具，也许从中有一些社交信号，但具体来说，人们把这当作理解研究的工具。我认为一个被低估的事实是，论文只是研究的冰山一角，我们处于很好的位置来帮助人们超越仅仅阅读论文的工作流程。你可以想象一件我们非常感兴趣的事情，虽然还没有公开发布，但我们想要开始为论文维护Docker镜像，让人们能够非常容易地直接从浏览器启动实现。很多时候当人们阅读论文时，他们为什么要读论文？我们的受众很多是应用研究者。所以他们在找出什么研究对他们相关。要获得这些信息，你需要的不仅仅是论文能告诉你的。归根结底，论文很好，但它们更像是实现的宣传片。要更接近研究的真正信号，意味着你需要让人们能够试用实现。所以我认为一个被低估的事实是，在为研究者制作工具这个领域，除了论文之外还有多大的潜力。

团队成员：即使在网站的当前状态下，我认为如果你想对AI研究的状态、对AI整体状态有一个鸟瞰视图，AlphaXiv是最好的地方。如果你看Twitter，那里有很多内容，但非常嘈杂。如果你看Hugging Face，当然有模型和数据集，有一些片段，但它不是一个连贯的整体体验。我认为我们所做的是，显然我们从评论区开始，但我们创建了一个平台，从ML研究者到只想了解AI最新动态的VC，任何人都可以使用，我认为AlphaXiv已经成为那个地方。显然如Ran所暗示的，我们想要走得更深。

### (10:15 - 15:20) 2025 年度论文讨论

我们不希望AlphaXiv仅仅是一个让你浏览和查看内容的地方。我们最终希望它成为一个你可以进行自己实验的地方，你能真正使用大量论文实现。我认为我们只是触及了这里可能性的表面。

既然我们在欧洲，而你在这里待得最久，我想请你们谈谈年度论文，谈谈新兴论文，以及你最喜欢的、让你欲罢不能的论文。

显然，在AlphaXiv工作，你必须热爱论文。

好的，我来谈一类论文。首先我要提到我们在Twitter上看到Ilya的那句话，"规模化时代已经结束，现在是智能化时代"。我觉得我们在AlphaXiv上看到了这种体现，因为发布开源研究的人可能并不总是拥有数千个GPU，所以你被迫想出非常有创意的解决方案来解决计算资源有限的问题。这些方案是否能转化为实际应用可能是另一回事，但我总是发现这类论文非常有趣。

有一篇论文我这个月来一直在谈论，就是《微型递归模型》（TRM）。它是HRM的简化版本，去掉了所有生物学灵感，说"让我们用一个700万参数的Transformer模型，让它递归地传递自己的潜在向量和输出"。用这个700万参数的模型在一些非常具体但具有挑战性的谜题任务上取得了相对非常好的结果。比如数独、ArcGI，我相信他在ArcGI上达到了45-50%的成绩，虽然不是最先进的，但相比Deep Seek R1或Gemini 2.5来说已经相当不错了。

我认为这些类型的创意解决方案非常有趣。它们在AlphaXiv上总是受到好评，每当这类论文出现时。所以作为一个论文迷，我发现这非常酷。另一篇最近的论文，我相信是在过去一两周内发布的，关于超大规模的进化策略。基本上是要摒弃梯度下降，使用低秩扰动在百万参数规模上获得非常好的结果。

所以是使用搜索而不是梯度下降？

是的，一些随机扰动。你不能一次在百万个参数上这样做，那没有意义，但你可以进行低秩扰动，一套低秩扰动，然后应用它，这是进化式的，与GRPL相比在某些任务上获得了相当好的结果。我觉得这很有趣，它在AlphaXiv上成为热门，我想"这样的东西真的有效"。同样，它是否能扩展到其他应用我不知道，但看到这种工作很酷。

很棒！Rex，我们继续吧。

我认为另一个非常令人兴奋的领域，特别是在我们的用户群体中，在这里的欧洲也是如此，就是科学AI。我们正在启动一个专门的科学AI播客，这是我的第二个播客。

太棒了，非常令人兴奋！我们有一个很大的社区。实际上我们周六要举办一个活动。

我会带我的新主持人过去。

太好了，这将很令人兴奋。我们有Laya的联合创始人之一，斯坦福的James Zo，还有Jeff Clune。我最初真正兴奋的是看到今年早些时候的一篇论文，叫做《代理实验室》，来自DeepMind的Sam Schmidgo。这个想法是，如果我们基本上自动化科学过程本身会怎样？基本上它会有不同的LM代理负责科学方法的不同部分，比如一个负责文献综述，一个负责运行实验，一个负责分析结果和撰写论文。这相当令人印象深刻。我认为仍然需要一些时间，人类参与循环仍然会产生很大影响，但他们能够展示，对于某些主题，只需几美元就能从想法到最终报告，这很有趣。我们也看到很多公司在这个领域形成，比如最近的Axiom。

我对此有个问题，也许其他人有，也许没有，就是把所有东西都归类为科学。

这确实很宽泛，有数学，然后有更像生命科学的东西，感觉要难一些。它们没有共同点。自动化机器学习研究似乎要容易一些，这是我的直觉，比如构建机器学习AI研究。我们能否同意机器学习AI研究不算作科学AI？

我认为这是个合理的观点。你可以为机器学习研究做个论证。

### (15:20 - 18:23) AI for Science 评析

这更像是一门艺术。

好的，那么总的来说，关于AI for Science，你们在过去几天里有没有什么特定的论文或讨论让你印象深刻？

我想是那篇Asian Laboratory的论文。

哦对，Asian Lab。是的，我对此的看法是，每个季度都会有人说"哦是的，我们已经做出了AI科学家。"

然后我不知道这是否会有什么进展，我不知道这是否只是概念验证。到底是怎么回事？

这取决于具体例子。回到生命科学AI这个话题，我来做个区分。我们有一位演讲者，他写了一篇叫做bio-only caching的论文，一开始只是一篇论文，但现在他获得了很大关注，并且在持续开发。我认为这是第一次真正概念化了这个想法，人们正在将其作为工具使用。显然，事情需要时间发展。

也许为了获得关注，你会称其为"我们正在自动化整个科学"，但在他的Biomni案例中，似乎确实有制药公司或生物组织的人在将其作为工具使用。至于使用到什么程度，我不是生命科学专家，但我认为从作为工具到自动化许多事情，中间还有很多步骤。

我对整个流程的自动化持怀疑态度。我更喜欢将其视为虚拟实验室的想法。James把这些AI科学家定位为虚拟实验室，就像，好的，实验和探索成本很低。

没错。人是主要研究员，我认为这个愿景很有道理。我不知道"我们将完全构建一个科学家"这种说法有多少是宣传，有多少是科学。在我看来，随着发展，会有更多研究人员，也许会有更多工具来帮助他们，但实际的研究过程，人类的工作，将是人类工作的最后前沿之一 - 能够直觉、构思和想出下一步该做什么。所以我将这些都视为工具。

我认为，延续Rayon所说的，也许对于宣传或我们在新闻中看到的内容，人们会说"哦，我们正在构建AI科学家"或"AI材料科学家"，但你实际上不需要做整个端到端的工作流程就能提供价值。就像Rayon提到的Biomni，我知道他们通过工具提供了很大价值，比如"我们会为你梳理文献，找出相关内容，然后帮你制定实验方案"。你并没有自动化整个工作流程，但这为研究人员或生物技术应用人员节省了大量时间。

我也认同你们的观点，对自动化整个端到端工作流程持怀疑态度，但我认为中间部分是有价值的。

对于这是否真正付诸实践，而不仅仅是为了论文或营销目的，我也持怀疑态度。

但我们可以转向其他论文。我想最后说一点，很多科学研究并不性感，有很多消融实验，很多非常像路面工程的手工工作。显然这些不需要独创性或人类的才华，但我认为智能体非常有能力完成科学过程中所需的许多工作。所以我认为这里有巨大价值。

### (18:23 - 21:58) 智能体与 RL 发展

是的。这并不完全是你们谈论的那种AI科学家，但我认为这里确实有一些价值。

你的论文。

哦，是的。我认为对我来说，在过去一年左右的时间里出现的一件事是用强化学习构建智能体，用于长期的复杂路径。我觉得有一篇具体论文很有趣，就是Agent R1。他们基本上构建了一个端到端的强化学习框架，用于在这些复杂推理任务上训练智能体。他们选择的具体推理任务是多跳问答。所以你必须训练一个智能体能够与工具环境交互，并回应复杂查询。当你将这个框架应用到像Qwen 2.5这样的基础模型之上时，你突然就有了一个在这些更复杂任务上表现非常出色的智能体。

我认为这对我来说很有趣的原因是，你会看到这篇论文与行业实际发生的事情有很多相似之处。比如Cursor的编程助手模型。网上有很多传言说这是基于Qwen 2.5构建的，人们看到了中文推理轨迹等等，但我们不知道他们到底是如何构建的。但你能看到这些技术。

是的，我的意思是，基于Qwen 2.5构建是一种非常流行的技术，但现在有一大批强化学习即服务、微调即服务这样的公司，帮助企业构建内部智能体。所以我们现在在企业行业中看到的很多东西，实际上反映了AI智能体和强化学习方面的大量研究。所以我认为这绝对是非常令人兴奋的。

还有一点要补充的是，除了Frontier实验室，还有这些初创公司，它们总共筹集了数亿美元。它们都在微调Qwen，特别是Qwen，因为如果你和这些公司的人交谈，你会发现Qwen是专门设计来在强化学习微调方面非常样本高效的。他们在构建模型时就是这样设计的，看到所有这些不同的初创公司都回到Qwen和开源生态系统真的很酷。然后你会看到像Agent R1这样的论文。

但那是DeepSeek，字面上是DC R1还是？

我不知道他们为什么在名字中加入R1，但他们微调的是Qwen模型。

我想知道为什么...

是的，我不知道。来自Qwen团队的Justin在这里，他在这里走动，我认为这很大程度上是Qwen的功劳。

事实上，相比之下，我认为DeepSeek在年初时确实处于超高水平，然后有点下滑了，这很有趣。我刚才和这里的一位同事谈论DeepSeek的存在感，就我们在ArXiv上看到的而言，当他们发布作品时人们仍然会倾听，他们仍然具有很大影响力。

出色的工作，这是出色的工作。比如OCR，他们发布了DeepSeek OCR，然后第二天就有OCR 2出来，一家叫Chandra的初创公司发布了一个OCR模型。

是的，但如果我没记错的话，他们的数字仍然比DeepSeek差。

是的，但我认为这仍然回到了当DeepSeek发布时其他人仍然非常关注这一点。所以无论他们...我不知道现在说这些是否足够还为时过早。

一天的差异并不意味着受到DeepSeek的激励，我不知道。

不对，但我认为他们感受到了压力。这就像研究和产品发布之间的平行关系，你在这里也能看到。

### (21:58 - 27:32) 学术生态系统危机

是的，我们确实看到了很多有趣的论文和报道。在 New York 我们刚刚报道了 DRL 的最佳论文。我想探讨的另一个问题是学术论文生态系统的健康状况，显然你们也很关心这个问题。从我与领域主席和项目主席的交谈中了解到，审稿流程跟不上节奏，因此会议的质量流程、投稿和质量都在下降。ICLR 最近发生了一个大丑闻，泄露了姓名，而且他们 20% 的审稿都是 AI 生成的。

你们对这一切有什么看法？

这确实是个问题，在多个层面都是如此。我们在 Arxiv 想做的一个有趣项目是——虽然我对这对我们是否有好处持怀疑态度——首先，我们一直对推出允许人们用 AI 写论文的工具持谨慎态度。我们帮助人们用 AI 理解论文，但让人们用 AI 写论文感觉不太对，虽然他们可能已经在这样做了。

我们想要推出的一个功能是识别哪些热门论文实际上是 AI 生成的，你可能会看到很大规模的这种情况。有很大的压力要快速产出大量工作，有很大的压力要快速写论文，这已经变成了一个 AI 输入、AI 输出的循环，所以这确实是有问题的。确实有发表压力，然后有帮助人们写论文的 AI 工具，论文本身的质量我感觉可能已经受到了影响。

我觉得这也很有趣。我知道有些人也在研究 AI 审稿人，这也很有意思。我虽然有一些担忧，但我认为如果做得对，对作者来说实际上可能是好事，比如如果作者能够使用这个功能，让他们在提交前先让 AI 审稿人审查他们的论文，他们就能看到比如论文中哪些地方可能不清楚，以及如何改进。

这样审稿人就不需要花太多时间去理解和解析论文，而可以真正专注于指出问题或进行文献综述和理解。

是的，这就像代码检查工具一样的质量检查。

对，如果做得不对，那么人们可能会找到方法来绕过 AI 审稿人。我知道 Andrew 最近推出了斯坦福的智能体审稿人，已经获得了一些关注。

哦，我不知道这个。你们在开发吗？

我们还没有过多考虑这个问题。我们想要集成的工具之一是某种类型的审稿人，在作者发表前为他们提供帮助，比如让我们告诉你有多少明显是 AI 生成的，哪些部分相似，并进行分解。我认为代码检查工具的类比很好。评估新颖性可能比较棘手，但作为第一步，我认为它可以筛选出低质量的工作，这可能是有前景的。

我特别想了解关于新颖性和文献综述方面，搜索有多重要？我想你们有索引，你们在索引上做 RAG，对吧？

模型在这方面表现如何？我想这取决于查询类型。在新颖性方面，Arxiv 从早期就有这个问题，人们会用它发布还未完全开发完成的预印本论文，然后就声称优先权。

在寻找相关文献方面表现还不错。我们的助手与众不同的地方在于我们也会使用社交信号，比如某些论文可能没有获得很多关注，我认为仅仅构建语义搜索并不是很有帮助。

比如 Twitter 或其他信号？

这是一个组合。我们会使用浏览量、语义信号等等。基本上，如果你只是试图构建语义助手，噪音会很快增加。我们有超过 300 万篇 Arxiv 论文的索引。如果你只是尝试使用语义搜索，给出像"做智能体推理的论文有哪些"这样的查询，你不会找到相关的工作。所以我们的做法是我们知道人们在阅读什么论文，这是我们提取相关结果时的一个权重因素。

### (27:32 - End) 未来愿景与挑战

是的，我觉得 YouTube 的功能非常有用。

现如今的研究不仅仅是论文，而是一个完整的包。越来越多的人开放他们的代码库，这很棒，我们希望继续看到这种趋势。所以除了论文，还有 GitHub，如果可用的话，人们会有推文串，有网站，如果是机器人学，还有视频演示，远远超过了论文本身。如果有一天我们能将所有这些内容索引到我们的助手中，尽可能地帮助找到所有相关的研究信息，你已经提到我们正在处理带代码的论文，还有基准测试，这将非常强大。

我只想说的是，很多人在 GitHub 方面在作弊，他们只放一个 README 文件，我们确保不会...

在接下来的五到十年里，论文作为一种产物将变得越来越没用。我认为研究将会转向，我们在这里感受到了，正如我之前说的，论文描述的是什么新的实现，数字是什么，但那只是一个实现，论文能告诉你多少？我认为拥有真正有组织的有用实现将是研究的未来。论文只是一个 PDF，是分享信息的一种过时方式，这就是我们存在的原因，让这一切更加顺畅。

这也完全符合我们今天在用户群中看到的情况。我们有很多用户不一定是训练有素的研究人员，他们不在学术界，而是在工业界，不在大实验室，我们称他们为应用 AI 研究人员或研究工程师。他们在各种公司，比如显然有大公司，但也有像 Spotify、Expedia、Nintendo 这样的公司，传统上你不会将它们与 AI 研究联系起来，但现在作为他们工作的一部分，他们需要跟上最新的研究，为他们正在构建的某个产品或功能。

坦白说，他们中的很多人并不真的关心论文，这只是工作的一部分。对他们来说，从"我应该读哪篇论文"开始，到快速理解核心思想是非常困难的，他们最终想知道的是这对我试图构建的东西是否有用。从论文到实现存在巨大的鸿沟，从你说的开始，人们在 GitHub 上作弊，实际上并没有用，或者即使有，很多时候用正确的依赖项设置代码库也是一个巨大的痛苦。所以我们正在考虑 Brhan 提到的为论文做 Docker 容器...

是的，这是 Replicate 的原始想法，我想他们转向了。

我现在会指向 Harbor，不知道是否来自 Terminal Bench 团队，这将是一个有趣的等价物，不是专注于论文，而是专注于环境。

你可以重用基础设施。回到整个论文讨论，你只需要看看过去十年 arXiv 提交的图表，它是指数级的，你基本上可以看到 CS，是的，完全正确，AI 类别每月 3 万篇。这很棒。

我的意思是，你可以有 AI 智能体来审查这些东西进行同行评议，但最终我认为真正的最终状态需要是我们不再那么关心论文。归根结底，所有研究人员想要的只是有用的想法。

只需开源代码库，开源权重，给我一个沙箱，让我能够快速验证你的想法或验证你所做的任何想法和贡献。你让这个循环变得越容易，而不是必须阅读论文，然后做很多无意义的工作来处理他们糟糕的代码库并尝试自己复制，你关闭这个循环的速度越快，你就会看到更少的垃圾提交之类的东西，我认为这对生态系统会更健康。

显然你们做你们认为最好的事情。如果我是公司的朋友和顾问，我会说你们可能承担了超出能力的任务。这是一个不可能的任务。

关于 Replicate 的一点，我刚想补充的是，与其将此视为复制或可重现性问题，比如我们需要尝试重新验证所有这些论文的结果并使其变得容易，我认为我们回到用户群是应用研究人员的观点。他们不关心哪些工作在论文中有最好的数字，但他们关心哪些工作最容易实现，所以有一些子集，我们能为这些人做简单吗？

如果有学者说我想要这个任意的东西实现它，就像我们不能做这个，利用这里存在某种幂律，就人们真正想要的已实现论文而言，让这种体验真的很容易。

例如，甚至想想我们前几天与其中一位 NeurIPS 研究人员谈论的，他说我实际上还没有玩过 LoRA，我说是什么阻止了你这样做？我们能否在真正流行的工作上让它变得非常简单，让人们很容易在此基础上直接迭代？

至于是否有一些数字很棒的晦涩工作，我们是否能够复制它并不在我们关心的事情范围内。

特别是如果你有任何涉及 GPU 的东西，我会称之为 NVIDIA 的 Launchables。他们通过收购 Brev 获得的，我曾经是投资者。

是的，有特定领域的方法来做这些事情，但它们没有得到广泛的社会化。

我想最后一点是 Ryan 简要提到的这个幂律，arXiv 有超过 240 万篇论文，但存在巨大的幂律，实际上最多浏览的论文是什么？它是非常长尾的。如果我们能够专注于对绝大多数人最有帮助的内容，让人们真正容易在此基础上构建，我认为这是一个好的起点。我们不需要为每篇论文都这样做。即使最初有一点脚手架，我认为如果你为这个指数增长的研究工程师群体节省时间...

最后一点是，我们正在研究的一件事是拥有一个能够根据代码库为论文自主设置 Docker 容器的智能体。假设在某些论文上它不起作用，需要手把手指导，未来我们想把这个责任推给作者，我们按实现容易程度对论文进行排名。

这就是应用研究人员关心的，对吧？如果智能体能够...通常需要激励...如果智能体已经...我们有作者来问我们如何在 Alphai feed 上排名更高，首先如果你没有 GitHub 代码库，你应该添加一个，这会对你有帮助。

但你可以想象，现在如果人们是我们的用户群或申请成为搜索者，所以他们只关心实现的容易程度。我们按实现容易程度排序，智能体是否能够解决设置论文的一些困难问题，这现在是作者的责任，我们的用户群首先对实现它们不会非常感兴趣。

太棒了，很好的事业。我很乐意宣传它，恭喜你们到目前为止的成功。我们拭目以待 2026 年会发生什么。

是的，我很感激。非常感谢邀请我们。

是的，谢谢你。

---

*生成时间: 2026-01-02 04:53:07*
*由 YouTube Monitor & Translator (Claude CLI) 生成*