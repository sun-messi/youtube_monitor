# Artificial Analysis: The Independent LLM Analysis House — with George Cameron and Micah Hill-Smith

## 📹 视频信息

- **频道**: Latent Space
- **发布日期**: 2026-01-09
- **时长**: 1:18:07
- **原始链接**: [https://www.youtube.com/watch?v=v5mBjeX4TJ8](https://www.youtube.com/watch?v=v5mBjeX4TJ8)

---

本文内容整理自Latent Space频道的George Cameron和Micah Hill-Smith关于AI分析独立机构Artificial Analysis的深度访谈。

## TL;DR

Artificial Analysis已从2年前的副业项目成长为AI评测领域的新标准，通过独立benchmarking帮助企业选择AI模型。他们不收费上榜，而是通过订阅服务和私有测试赚钱，并发现了一个核心洞察：尽管AI成本下降100-1000倍，但由于推理模型、智能体工作流等新范式，企业的AI支出反而激增。

---

## 📑 章节导航表

| 时间戳 | 章节标题 | 一句话概括 |
|--------|----------|-----------|
| 00:00-05:00 | 项目起源与商业模式 | 从副业到20人团队，通过企业订阅和私有测试盈利 |
| 05:00-15:00 | 技术架构与独立性 | 自建评测系统，坚持独立性，防止各种作弊手段 |
| 15:00-25:00 | 核心指标与演进 | 从V1到V3，不断提升难度以应对模型能力爆发 |
| 25:00-35:00 | 新指标：幻觉与知识 | 推出Omniscience Index测试模型"不知道时说不知道"的能力 |
| 35:00-45:00 | GDP-val与开放性指数 | 评测真实工作场景能力，量化模型开放程度 |
| 45:00-55:00 | Agent框架与工具生态 | 发布Stirrup框架，chatbot vs API性能对比 |
| 55:00-65:00 | 成本悖论与未来趋势 | 解释AI"微笑曲线"：成本降但支出增的原因 |
| 65:00-78:00 | 推理模型与效率革命 | Token效率差异超10倍，turn效率成为新关键指标 |

---

## 📊 核心论点

### 1. AI评测的独立性是生存之本

- **核心内容**：Artificial Analysis坚持不收费上榜，通过"神秘购物者"政策防止作弊。他们会注册匿名账户在各家API上运行测试，确保测试环境与真实用户一致。评测时统一prompt格式、控制温度参数、多次运行计算置信区间（95%置信度±1分），避免各种统计偏差。最重要的是，所有实验室都希望竞争对手也无法操纵结果，这创造了一个良性的制衡机制。
- **关键概念**：独立第三方评测、神秘购物者测试、统计置信度、prompt标准化、防作弊机制
- **实际意义**：为整个行业提供了可信的性能基准，帮助开发者在数百个模型中做出理性选择，推动了AI模型市场的透明化和标准化。

### 2. "微笑曲线"解释AI成本悖论

- **核心内容**：过去2年，GPT-4级别智能的成本下降了100-1000倍（如Amazon Nova），但企业AI支出反而激增。原因在于：(1)虽然小模型能达到GPT-4水平，但企业选择使用更大更强的前沿模型；(2)推理模型使用10倍以上token；(3)智能体工作流消耗海量输入输出token。一家创业公司每员工在coding agent上月花费达5000美元。这形成了一条"微笑曲线"：左侧成本急剧下降，右侧支出快速上升。
- **关键概念**：智能成本下降、推理模型token消耗、智能体工作流、微笑曲线、单位智能成本
- **实际意义**：企业需要重新思考AI预算策略，不能简单期待成本下降带来节省，而应关注如何最大化AI投入的价值回报。这也解释了为何Nvidia股价持续上涨。

### 3. 幻觉不再是bug而是可量化的feature

- **核心内容**：Omniscience Index采用-100到+100评分（答错扣分），首次系统量化模型"承认无知"的能力。测试发现：Claude系列幻觉率最低，但幻觉率与智能水平并不相关。Gemini 3 Pro知识量大增但幻觉率未改善。有趣的是，物理学研究者反而需要高温度下的"幻觉"来激发新想法。不同应用场景对幻觉的容忍度差异巨大：知识问答需要低幻觉，创意生成则相反。
- **关键概念**：Omniscience Index、负分机制、幻觉率、知识准确度、应用场景差异
- **实际意义**：帮助开发者根据具体应用选择合适的模型和参数设置，而非盲目追求"最智能"的模型。这标志着AI评测从单一维度向多维度、场景化方向演进。

### 4. 真实工作场景成为评测新标准

- **核心内容**：GDP-val评测44个真实白领工作任务，需处理zip文件、Excel、PDF等真实文档，甚至要求制作营销视频。测试发现：(1)API版本普遍优于同模型的chatbot版本；(2)最小化工具集（代码解释器+网页搜索+文件系统）效果最佳；(3)模型间性能差异巨大。Artificial Analysis发布的Stirrup框架证明，简单的agent架构反而更有效。
- **关键概念**：GDP-val、真实文档处理、multi-turn agents、ELO评分、Stirrup框架
- **实际意义**：推动评测从学术问题转向实际工作能力，帮助企业评估AI是否真正能替代或增强人类员工的工作。

### 5. 开放性成为新的竞争维度

- **核心内容**：Openness Index从6个维度（权重开放、数据透明度、训练代码等）量化模型开放程度，满分18分。AI2的32B模型以最高分领先，但图表显示开放性与智能水平负相关。Meta的Llama虽开放权重但限制7亿日活用户使用，引发许可证争议。Nvidia Nemotron系列虽非最智能但因完全开放而被广泛用于合成数据生成。
- **关键概念**：Openness Index、权重许可、数据透明度、训练代码开放、OSI标准许可
- **实际意义**：为企业选择模型提供了智能之外的重要决策维度，特别是对有合规要求或需要自主部署的企业至关重要。

### 6. 稀疏性达到物理极限但仍有想象空间

- **核心内容**：模型激活参数比例从25%降至3-5%（Qwen2.5的72B模型仅激活5%参数）。但测试发现，模型性能与总参数相关度极高，与激活参数比例几乎无关。这暗示当前的稀疏化可能还有很大空间。Gemini 3 Pro被推测可能达5-10万亿参数，远超开源模型的1万亿参数上限。
- **关键概念**：模型稀疏性、激活参数比例、总参数vs激活参数、MoE架构、参数效率
- **实际意义**：硬件和部署成本可能通过更激进的稀疏化继续大幅下降，为边缘部署和个人使用超大模型创造可能。

### 7. 多模态评测需要"创意总监"视角

- **核心内容**：Artificial Analysis的图像/视频竞技场采用预生成+投票模式，避免实时生成的安全和成本问题。他们扮演"创意总监"角色，主动设计专业创作者关心的测试类别。用户可提交新类别需求，通过测量推动模型改进。作者特别提到需要更多"工作马"用例（如信息图表生成）而非纯艺术创作。
- **关键概念**：预生成竞技场、创意方向把控、用户提交机制、工业用例vs艺术创作
- **实际意义**：将多模态AI的发展方向从技术驱动转向用户需求驱动，确保模型能力与实际应用需求对齐。

### 8. Token效率成为成本控制的关键

- **核心内容**：不同模型的token效率差异超过10倍，且"推理"标签不再等同于高成本。GPT-5.1展示了理想的token使用模式：简单问题用少token，复杂问题用多token。在客服场景（TAU-bench），GPT-5虽然每token更贵，但因为更少轮次解决问题反而总成本更低。未来需要同时优化token效率和turn效率。
- **关键概念**：Token效率、动态token分配、Turn效率、总成本优化、任务复杂度感知
- **实际意义**：企业在选择模型时不能只看标价，需要基于实际任务测试端到端成本，这可能完全改变模型选择决策。

### 9. 评测本身正在改变AI发展方向  

- **核心内容**：一旦某个指标被广泛关注，模型就会针对性优化（如数学竞赛能力的爆发式增长）。Artificial Analysis通过不断更新评测集和引入新维度来应对。他们鼓励用户提交被忽视的用例，通过"测量杠杆"推动AI朝着真正有用的方向发展。V4版本将整合幻觉率、物理推理、智能体能力等多维度指标。
- **关键概念**：评测驱动开发、指标游戏化、动态评测集、用户驱动改进、多维度整合
- **实际意义**：评测机构不再是被动的裁判，而是主动的生态塑造者，通过设计评测标准影响数千亿美元的AI研发投入方向。

### 10. 硬件进步将继续推动两端同时扩张

- **核心内容**：Blackwell一代相比Hopper在大型稀疏模型上可实现远超2-3倍的性能提升。这将使"微笑曲线"两端继续扩张：低端智能再便宜10倍，高端能力再强10倍。年度支出可能从每员工5000美元涨到50000美元，同时GPT-4级能力可能降到几乎免费。硬件效率提升+软件优化+模型创新三者叠加效应惊人。
- **关键概念**：Blackwell架构、硬件路线图、稀疏模型优化、成本与能力双向扩张
- **实际意义**：企业需要为AI支出的持续激增做好准备，同时也要准备好利用近乎免费的基础AI能力。这种两极分化将创造全新的商业模式和应用场景。

---

## 🏢 提及的公司/产品

| 公司名 | 讨论语境 | 重要性 |
|--------|----------|--------|
| Artificial Analysis | 独立AI评测机构，2年从副业成长到20人团队 | ⭐⭐⭐ |
| OpenAI (GPT系列) | 长期领先但优势正在缩小，推理模型先驱 | ⭐⭐⭐ |
| Anthropic (Claude) | 幻觉率最低，用户偏好度高 | ⭐⭐⭐ |
| Google (Gemini) | Gemini 3 Pro知识量最大，可能有5-10万亿参数 | ⭐⭐⭐ |
| DeepSeek | V3开创开源模型新高度，推动稀疏化架构 | ⭐⭐ |
| Meta (Llama) | 受限许可引发争议，最佳开源选择 | ⭐⭐ |
| Nvidia | Nemotron系列支撑合成数据，Blackwell推动硬件革命 | ⭐⭐ |
| AI2 | 开放性最高分，学术界标杆 | ⭐ |
| Amazon Nova | 成本最低，体现100倍成本下降 | ⭐ |
| Qwen | 2.5版本仅5%参数激活，稀疏化极限 | ⭐ |

---

## 💬 经典金句

> "Have you ever worked with or managed someone and wouldn't press the button to make them smarter?"
> — George Cameron（关于AI智能需求的永无止境）

> "The cost of GPT-4 level intelligence has dropped 100x, yet companies are spending more than ever on AI."
> — George Cameron（解释AI成本悖论）

> "Once things get measured, they can get targeted. You can make that work for you."
> — George Cameron（关于评测如何塑造AI发展）

> "Models have gotten smart enough that they perform better with a minimalist set of tools."
> — Micah Hill-Smith（关于Agent架构的反直觉发现）

> "I know many smart people who are confidently incorrect."
> — Micah Hill-Smith（解释为何智能与幻觉率不相关）

---

## 👤 主要人物

### George Cameron

**身份**：Artificial Analysis联合创始人
**背景**：澳大利亚人，后移居旧金山，2022-2023年开始关注AI领域
**核心观点**：坚信AI评测必须保持绝对独立性，通过"神秘购物者"等机制确保公正。认为AI智能需求将永无止境，即使成本下降1000倍，企业支出仍会因新应用模式而增长。

### Micah Hill-Smith

**身份**：Artificial Analysis联合创始人
**背景**：新西兰人，曾尝试构建法律AI助手，因优化需求开始做benchmarking
**核心观点**：强调真实工作场景的评测比学术指标更重要。发现模型"承认无知"的能力与智能水平无关，需要独立量化。倡导用户驱动的评测改进。

### Nat Friedman & Daniel Gross

**身份**：AI Grant创始人，Artificial Analysis的投资人和导师
**背景**：知名创业者和投资人
**核心贡献**：为Artificial Analysis提供战略指导，特别是在处理"没有明确答案的困难决策"方面给予帮助。

---

## 📺 视频类型判断

**访谈对话**：主持人与两位创始人的深度技术访谈，问答形式为主，穿插产品演示和数据讨论。

---

## 📝 完整翻译

### (0:00 - 5:00) 项目起源与商业模式
> 从副业到20人团队，通过企业订阅和私有测试盈利

这对我们来说是一个完整的循环时刻。因为人工分析第一次在播客上被提及就是你和 Alysia 在 Lyn Space 上。

太棒了。

那是 2024 年 1 月 24 日。

我甚至不记得做过那期节目，但对我来说确实很有影响力。我在看 2024 年 1 月 16 日或 17 日的 AI 新闻，我说这个模型和主机比较网站的瑰宝刚刚发布。然后我放了几张截图说，这是一个独立的第三方网站，清楚地概述了质量与吞吐量的权衡，并按模型和托管提供商进行了细分。我确实因为你们遗漏了 Fireworks 而给你们提了意见 —— 怎么能有一个模型基准测试网站却没有 Fireworks 呢？但你们有 Together，有 Perplexity，我想我们就是从那时开始聊起来的。

欢迎 George 和 Micah 来到 Lyn Space。我一直在关注你们的进展，恭喜你们度过了令人惊叹的一年。你们真正团结在一起，成为了 AI 领域的新权威机构。

那么，我该怎么付钱给你们呢？让我们直接谈论这个问题。你们是如何赚钱的？

我们很乐意谈论这个。过去几年对我们来说是一个巨大的旅程。人工分析网站即将在 2026 年 1 月迎来 2 周年，现在已经很近了。

我们最初显然是免费运营网站，并提供大量数据来帮助开发者和公司导航 AI 领域，在构建产品时对模型、提供商和 AI 技术栈的各种技术做出决策。我们非常致力于这样做，并打算继续这样做。

在此过程中，我们已经建立了一个相当可持续发展的业务。我们现在有 20 多人，主要有两个客户群体。我们希望成为企业在 AI 数据和洞察方面的首选。我们希望帮助他们在构建产品时对模型和技术做出决策。另一方面，我们为整个 AI 技术栈中构建 AI 产品的公司提供私人基准测试服务。

没有人为了出现在网站上而付费。我们从一开始就非常明确这一点，因为如果不是独立的 AI 基准测试，我们所做的就没有意义。但事实证明，我们的很多工作对构建 AI 产品的公司来说相当有用。

比如说我是一家财富 500 强公司，我需要客观分析方面的顾问，我打电话给你们，你们为我提供定制报告。你们会来我的办公室给我举办研讨会吗？这是什么样的合作模式？

我们有基准测试和洞察订阅服务，包含标准化报告，涵盖企业在理解 AI 并在所有技术中做出选择时面临的关键主题或关键挑战。例如，其中一份报告是模型部署报告，关于如何在无服务器推理、托管部署解决方案或租赁芯片并自己运行推理之间做出选择 —— 这是大型企业面临的一个例子决策，很难推理清楚，因为这些 AI 技术对每个人来说都是全新的。

### (5:00 - 15:00) 技术架构与独立性
> 自建评测系统，坚持独立性，防止各种作弊手段

我们试图通过报告和洞察订阅服务帮助公司应对这些挑战。我们还进行定制的私人基准测试，这与我们公开发布的公共基准测试非常不同，公共基准测试没有商业模式。对于私人基准测试，我们有时会创建基准测试，按照企业的规格运行基准测试，有时也为构建了产品的 AI 公司这样做，我们帮助他们通过私人基准测试了解他们构建的产品，主要通过我们在尝试为公众提供公共基准测试支持过程中开发的专业知识。

让我们谈谈背后的技术栈。但首先，我要回溯到你们开始这个项目的时候。你当时一直在悉尼。

对，我在澳大利亚悉尼。George 在旧金山，但他是澳大利亚人，已经搬到这里了。

我记得那次与你的 Zoom 通话。最初启动人工分析的动机是什么？你们从公共基准测试开始，让我们从那里说起，然后再谈私人业务。

我们甚至可以再往前回溯一点，谈谈为什么我们认为这是必要的。

故事始于 2022、2023 年左右，George 和我都对 AI 技术感兴趣很长时间了。2023 年具体来说，我试图构建一个法律 AI 研究助手。我觉得在那个时代它运行得相当好，但我发现越是深入使用 LLMs 构建产品，你所做的每一部分最终都变成了一个基准测试问题。

我有这个多阶段算法，试图找出每个部分的最小可行模型，试图优化每一部分。当你构建这个时，你需要考虑准确性、一系列其他指标、性能和成本。基本上没有人独立评估所有模型，当然也没有人关注速度和成本的权衡。

所以我们基本上决定构建一个开发者可以查看的工具，以独立测量所有模型和提供商之间这些因素的权衡。老实说，当我们最初开始时，这可能只是一个副项目。我们没有聚在一起说："嘿，我们要停止其他工作，这将成为我们的主要事业。"

当我第一次打电话给你时，我觉得你还没有决定创办一家公司。

这确实是真的。我甚至不认为 George 已经辞去了工作。我还没有停止我的法律 AI 项目。这确实只是一个副项目。

我们构建它是因为作为在这个领域构建产品的人，我们需要它，并且想："哦，其他人可能也会觉得有用。所以我们买个域名，链接到我们的 Vercel 部署，并在推特上谈论它。"但很快它就开始引起关注。谢谢 Swix 进行了最初的转发并关注了我们发布的这个项目，然后很快它对其他人很有用，但随着模型发布速度加快，它变得更有用。我们有了 Mixtral 8x7B，这是一个关键时刻。

那是个有趣的模型。

是的，这是一个真正改变了格局的开源模型，让人们关注其他无服务器推理提供商，开始思考速度和成本，所以它很快变得更有用。

我喜欢与像你们这样坐拥整个生态系统的人交谈，因为我对人们想要什么有理论，但你们有数据，这显然更相关。但我想再谈一下起源故事。当你们开始时，我认为当时的现状是每篇论文都会发布，他们会报告他们的数字与竞争对手数字的比较，基本就是这样。

我记得我做了这项工作。我想每个人都有某种版本的 Excel 表格或 Google 表格，你只是从每篇论文中复制粘贴数字并发布在那里，有时它们不匹配，因为它们是独立运行的，所以你的数字会看起来更好，或者你对其他人数字的重现会看起来更糟，因为你没有正确持有他们的模型或其他借口。

我想当时 Stanford Helm，Percy Lang 的项目也会有一些这些数字，我不知道是否有其他来源可以引用。如果我在你们同时启动人工分析，我会使用 Luther AI 的评估框架工具。

是的，那是一些很酷的东西。归根结底，运行这些评估，如果是简单的问答评估，你所做的就是询问一系列问题并检查答案是否正确，这不应该那么疯狂，但事实证明有大量的因素需要控制。

当我们开始网站时，我们意识到必须自己运行评估而不能只是采用实验室的结果的原因之一是，他们都会以不同的方式提示模型，当你在几个点上竞争时，你可以极端地将答案输入到模型中，就像 Google 为 Gemini 1.0 Ultra 做的疯狂案例，需要一个比 GPT-4 更好的数字，构建了我认为从未发布的思维链示例，在 MMLU 的每个主题中都有 32 个，有很多东西你可以...

他们从未发布 Ultra，对吧？

我确信它存在，但是的，所以我们非常确定需要自己运行它们，以同样的方式在所有模型上运行它们，我们从一开始就很确定你不能孤立地看待这些。你需要将它们与成本和性能内容一起看待。

### (15:00 - 30:00) Part 2

### (15:00 - 25:00) 核心指标与演进
> 从V1到V3，不断提升难度以应对模型能力爆发

但不一定会那样做。比如说，这些模型现在在回答竞赛数学问题方面表现卓越。这种推理类型、这种工作确实与我们可能如何使用现代编程 agent 等有一些相关性，但显然不是一对一的关系。我们必须意识到的是，一旦某个评估成为每个人都在关注的标准，它的分数可能会变好，但这并不意味着这些模型的整体通用智能真的在提升。这在过去几年里一直如此，在接下来的几年里也会如此。除了构建新的东西来保持相关性并测量对真实用户最重要的能力之外，没有银弹可以解决这个问题。

主持人：是的。我们也会介绍你们正在构建的一些新东西。这很酷。你们以前只是运行其他人的评估，但现在你们开始提出自己的评估。我想这显然是一旦你处于前沿时的必要路径。你已经用尽了所有现有的一对一评估。

我认为你们历史上的下一个节点是你们决定加入 AI Grant 并搬到这里。

被访者：这是什么样的体验？我想你们是第四批。

主持人：第四批，对。

被访者：那很棒。Nat 和 Daniel 显然很出色，我们在 AI Grant 中与一群非常酷的公司在一起。让 Nat 和 Daniel 加入真的很棒。显然，他们已经与很多领先公司在这个领域做了大量出色的工作，并且与我们试图做的使命极度一致。我们与他们投资的许多其他 AI 初创公司不太典型，但他们非常支持我们想要做的使命。

他们有没有说过什么建议真正影响了你，或者某个活动非常有影响力？

被访者：这是个有趣的问题。我记得 AI Grant 炉边谈话中来的一些演讲者。

主持人：那也是个疯狂的名单。

被访者：是的。完全是。与 Nat 和 Daniel 讨论创业过程中的挑战，以及如何处理那些没有明确答案的问题，如何有条理地处理这些问题，以及如何处理艰难的决策，他们一直是我们构建 Artificial Analysis 过程中的优秀导师。对我们来说另一个好处是，这一批中的其他公司以及 AI Grant 中的其他公司都在推动 AI 当前能力的极限。

与他们保持联系，确保 Artificial Analysis 对他们有用，这对支持我们弄清楚应该如何构建 Artificial Analysis 以继续对那些基于 AI 构建的人有用非常棒。

主持人：我对此有些矛盾的看法，因为在某种程度上，你的目标受众不是 AI Grant 中那些显然处于前沿的人。

被访者：在某种程度上是这样，但 AI Grant 公司很多正在做的事情是获取实验室产出的能力，并试图在构建出色应用程序的整个技术栈中推动它们能做什么的极限，这实际上使其中一些人成为 Artificial Analysis 的典型超级用户。他们是对我们做得好的地方、做得不好的地方以及他们希望我们接下来做什么持有最强烈意见的人。

因为当你现在构建任何类型的 AI 应用程序时，你很可能使用一大堆不同的模型，你可能会相当频繁地为应用程序的不同部分切换不同的模型，以优化你能在准确性水平上做的事情，并获得更好的速度和成本特性。所以对他们中的许多人来说，他们不是我们的商业客户。我们不对网站上的所有数据收费，但他们绝对是我们的一些超级用户。

主持人：那我们也来谈谈评估吧。你们从一般的 MMLU 和 GPQA 等开始。接下来是什么？你们如何构建整体指数？V1 版本是怎样的，你们又是如何演进的？

被访者：首先，背景是我们正在讨论 Artificial Analysis 智能指数，这是我们目前从 10 个不同的电子邮件数据集中综合得出的合成指标，以给出我们相当确信的查看模型智能程度的最佳单一数字。显然这不能说明全部情况。这就是为什么我们发布了包含所有图表的完整网站，可以深入了解每个部分并查看权衡。但这是最佳单一数字。

现在它包含了一堆对行业非常重要的问答类型数据集，就像你刚刚提到的几个。它还包含了几个 agentic 数据集。它包含了我们自己的长上下文推理数据集和其他一些用例专注的内容。

随着时间的推移，我们最感兴趣的、将对变得越来越重要的 AI 能力很重要的东西，开发者关心的东西，首先将围绕议程能力。不出所料，我们都喜欢我们的编程 agent 以及模型将如何执行类似的操作，然后为不同类型的工作做类似的事情对我们来说真的很重要。与经济上有价值的用例的联系对我们来说极其重要。然后我们有一些模型仍然难以处理的东西，比如在长上下文上工作得非常好，这些作为我们需要继续评估的特定能力和用例不会消失。

主持人：但我想我想要了解的一件事是 V1 与 V2 的对比，以及它随时间变化有多糟。

被访者：是的，我认为这很好地反映了行业的变化。这是讲述这个故事的好方法。V1 现在几乎每个发布的模型都会完全饱和，因为做像在 Human Eval 中编写 Python 函数这样的事情现在非常简单。实际上很容易忘记过去两年取得了多大进步。我们显然不断玩今天版本与上周版本以及前一周版本之间的游戏，以及当前前沿之间的所有小变化和谁拥有最好的小于 10B 模型的竞赛。这对很多开发者和人来说非常重要，特别是在旧金山这个特殊城市。

但当你放大几年前，字面上我们当时用来评估模型的大部分工作现在即使是相当小的模型也能 100% 解决。

### (25:00 - 35:00) 新指标：幻觉与知识
> 推出Omniscience Index测试模型"不知道时说不知道"的能力

顺便说一下，这一直是推动每个智能层级的智能成本下降的关键因素之一。我们可以稍后再详细讨论。所以 V1、V2、V3，我们让事情变得更难。我们覆盖了更广泛的用例，我们试图更接近开发者关心的东西，而不是像 MMLU 和 GPQA 所代表的那种问答类型的东西。

主持人：是的。我不知道你是否要补充什么。或者我们可以直接展示基准测试，点击浏览并提出相关问题。

被访者：是的，让我们这样做。这将是一个很好的方式来讨论我们最近推出的一些新东西。我们想要采取的方向以及我们想要推动基准测试的方向。

目前智能指数和评估重点主要关注原始智能，但我们想要多样化我们对智能的思考方式。我们已经构建了专注于幻觉等主题的新评估，我认为当前评估集没有涵盖但应该涵盖的许多主题。我们想要把这些带出来。

但在我们深入讨论之前，对听众来说，作为时间戳，现在排名第一的是 Gemini 3 Pro High，然后是 Claude Opus 70 分。5.1 高版本。你们还没有 5.2。以及 Kimmy K2 thinking。哇，仍然在那里坚持。所以这些是前四名。

主持人：这会很快让这个播客过时。

被访者：是的。我喜欢这样。明年这个时候回看会觉得多可爱。

快速浏览一下，好的。我喜欢这个图表。这是个最爱。在几乎每个会议中，我们总是首先展示这个来讨论我们在历史上这个时刻的定位。我认为这是我之前所说的关于放大并记住已经取得了多少进步的视觉版本。如果我们回到一年多前，在 01 之前，在 Claude Sonnet 3.5 之前，我们没有推理模型或编程 agent 作为一种东西，游戏非常非常不同。

如果我们回到更早一点，我们处于当你看这个图表时，OpenAI 在一年多的时间里是不可触及的时代。我是说你会很好地记住那个时期，有很多开放的问题，关于 AI 是否会有竞争力，关于 OpenAI 是否会一家独大，关于我们是否会有几个前沿实验室而其他人除了使用他们的 API 之外真的无法做任何事情。

我对我们最终所处的世界感到非常高兴，这是一个多模型的世界，在过去几年的每个季度都绝对且严格更具竞争性。是的，今年太疯狂了。你可以看到它。这个包含所有内容的图表目前很难阅读。上面有太多点，但我认为它有点反映了我们感受到的疯狂程度。

主持人：为什么默认是 14 个？这是手动选择吗？因为你那里有 ServiceNow，这些不太传统的名字。

被访者：是的，这些是我们在图表和智能指数中默认突出显示的模型。这就是你手动策划的列表。但实际上我认为不是每个 Artificial Analysis 用户都知道的是，你可以自定义我们的图表并选择什么模型。如果我们去掉几个名字，就会更容易阅读一些。但你可以看到 01 的跳跃。看那个，2024年9月，还有 DeepSeek 的跳跃，它接近了 OpenAI 的领导地位。他们非常接近。

### (30:00 - 45:00) Part 3

我们在幻觉率方面看到的一个有趣结果是，Anthropic 的 Claude 模型在左侧显示了我们评估的模型中最低的幻觉率。这是一个有趣的事实。我认为这可能与很多之前无法真正测量的、人们喜欢 Claude 模型的那种"感觉"因素相关。

主持人：数据集是公开的吗？有留出测试集吗？

被访者：这个有留出测试集。我们确实发布了一个公开测试集，但我们只发布了其中的 10%。原因是对于这个特定的评估来说，很容易出现数据污染，因为这就是事实性知识问题。我们会随时更新以防止这种情况，但我们保留了大部分数据，这样我们可以长期保持其可靠性。这让我们能做到很多非常酷的事情，包括按主题进行相当细致的分析，我们已经在网站上公开披露了其中一些内容，在我们分析非常具体主题的能力方面还有更多内容即将发布。

主持人：我对这个幻觉问题很感兴趣。让我们深入讨论一下。我注意到 Haiku 的幻觉比 Sonnet 少，Sonnet 比 Opus 少，而在正常的能力环境中会是相反的情况吗？你怎么看这个现象？

被访者：一个有趣的方面是，我们发现智能和幻觉率之间并没有很强的相关性。也就是说，模型在通用意义上越聪明，并不与它们在不知道某事时能说"我不知道"的能力相关。有趣的是，Gemini 3 Pro preview 相比 Gemini 2.5 Flash 和 2.5 Pro 有了很大的飞跃。

主持人：我打赌 Pro 版本真的很好。实际上不是，我指的是 GPT Pro。

被访者：哦对，因为传言 GPT Pro 我们不确定是否真的像八次运行然后上面有 LLM 判断器。

被访者：所以我们看到在准确性方面有很大的跳跃。这只是它们答对的百分比。Gemini 3 Pro 比其他模型知道更多。所以准确性有很大提升，但 Google Gemini 模型在版本之间的幻觉率相对没有变化。

主持人：和幻觉率。

被访者：正是如此。这很可能是由于 Claude 模型之间不同的后训练配方导致的。

主持人：你可以部分归咎于我们以及我们如何定义智能，到目前为止我们还没有将幻觉定义为我们思考智能方式中的负面因素。这正是我们正在改变的。我知道很多聪明人都是自信地错误的。

被访者：看，这确实很人性化，很真实。有时候确实需要这样。我认为我们的观点是，幻觉率在知识相关的情况下是有意义的，但在很多情况下，人们希望模型能够幻觉，能够尝试。在编程或者当你试图产生新想法时经常是这样。

被访者：我们在 Artificial Analysis 中添加的一个评估是 Critical Point，这些是真正困难的物理问题。

主持人：是类似人类评估的类型还是不同的，比如 Frontier Math 类型？

被访者：它与 Frontier Math 不太不同。这些是物理学界的学者能够回答但模型真的很难回答的研究问题。这里的最高得分是 9%。当创建这个评估的人们，比如 Minway 以及实际上是 Sweeten 背后的 Afia。

主持人：这是哪个组织，还是普林斯顿？

被访者：来自不同学术机构的一系列学者，都是非常聪明的人。他们谈到当他们试图探索物理学中的新想法时，如何将模型的温度调到尽可能高，作为思想伙伴，就是因为他们希望模型能够幻觉。

主持人：有时也许能得到一些新的东西。

### (35:00 - 45:00) GDP-val与开放性指数
> 评测真实工作场景能力，量化模型开放程度

被访者：所以不是在每种情况下都正确，但我认为在有意义的幻觉场景中测试是合理的。显而易见的问题是，这是许多评估中的一个，每个实验室都有显示某种幻觉数字的系统卡，而你选择不认可那些，而是制作了自己的。我认为这是一个选择。在某种意义上，Artificial Analysis 的其他部分都是其他人可以独立重新运行的公共基准。你在这里为我们提供了一项服务。你必须应对"我们凭什么这样做"的质疑，你的答案是我们有很多客户。但我想知道你如何让行业在一个实际上每个人都认同的数字上趋同，因为你有你的数字，他们有他们的数字，两者永远不会相遇。

被访者：我的意思是，我认为对于幻觉，有很多你可能合理关心并且会以完全不同方式测量的不同事物。我们称之为 Artificial Analysis 幻觉率，并不是试图宣布传统。

主持人：人类最后的幻觉。

被访者：你可以有一些有趣的命名约定。对此最大的回答，以及我实际上想提到的事情，正如 George 解释 Critical Point 一样，随着我们前进，我们正在内部构建评估。我们与学术界合作，与 AI 公司合作来构建优秀的评估。我们对 AI 技术栈的不同部分有相当强烈的观点，在各个方面都有一些没有被很好测量的东西，或者开发人员关心的应该被更多更好测量的东西，我们打算这样做。我们不一定痴迷于我们做的每件事都必须完全在我们自己的团队内完成。Critical Point 是一个很好的例子，我们是与学术界合作的发布伙伴。我们与几家领先公司即将建立一些合作伙伴关系。

被访者：显然我们在一些独立的事情上必须小心，但有了适当的披露，我们完全接受这样做。许多实验室过去发布了很好的数据集，我们用来独立创建成功，所以通过所有这些技术，我们将在未来发布更多内容。

主持人：很好。让我们来讨论最后几个问题，然后我想谈论你们的趋势分析。

被访者：在那之前，实际上我有一个小事实，如果你回到 Omniscience 的准确性上。这个准确性指标有一个有趣的地方，就是它比我们测量的任何其他东西都更密切地跟踪模型的总参数数量。

主持人：噢。

被访者：直觉上这很有道理，对吧？因为这是一个知识评估。这是纯知识指标。我们不是在看索引和我们认为更多关于模型如何训练的幻觉率。这只是他们回忆了什么事实，是的，它与参数数量极其密切相关。

主持人：Gemini 3 Pro 的传言大小是多少？

被访者：要明确的是，没有来自任何官方来源的确认，只是传言，但传言确实会传播。

主持人：我听到各种各样的数字。我不知道该相信什么。

被访者：如果你在 Artificial Analysis 的准确性与总参数之间画一条线，我们有所有的开放权重模型。你可以眯着眼睛看到，很可能现在领先的前沿模型比开放权重模型上限的一万亿参数要大得多。我们这里看到的模型有一个有趣的额外数据点，Elon Musk 最近透露了关于 xAI 的信息，Grok 3 有 1 万亿参数，Grok 4 有 6 万亿参数用于 Grok 5，但那还没有发布。把这些综合起来，看看，你可能合理地形成一个观点，即 Gemini 3 Pro 很有可能比这更大，可能在 5 到 10 万亿参数范围内。要明确的是，我完全不知道。但仅基于这个图表，如果你看一看，这就是你会得出的结论。

主持人：在某种程度上，我实际上有点不鼓励人们过多猜测，因为这真的重要吗？只要他们能以可持续的成本提供服务，就差不多了。

被访者：完全同意。与开放权重模型相比，他们也有不同的激励机制，开放权重模型考虑支持他人自部署，而对于大规模推理的实验室来说，我认为在许多情况下，与总参数相比，更多的是关于活跃参数的数量，所以有朝着更大更稀疏模型的激励。

主持人：同意。理解。

被访者：如果你是使用这些东西的开发者或公司，显然如你所说这并不重要。你应该看我们测量智能的所有不同方式。你应该看成本运行指数数字以及基于标价思考令牌效率和成本效率的不同方式，因为这就是重要的。

主持人：这对于内容创作者的传言工厂来说不太好，我可以说 GPT-4 是这个小圆圈，看 GPT-5 是这个大圆圈，这曾经是一段时间的事情。

被访者：但这本身实际上是非常有趣的，对吧？

主持人：是吗？好吧，不，只是纯粹地说，很可能过去几年没有看到这些模型总大小的戏剧性扩展，所以可能还有很大的上升空间，特别是随着即将到来的硬件世代，模型的总大小。

主持人：所以，脱下我的胡说八道发布阶段一分钟。是的。同时，我确实觉得，特别是从欧洲回来后，人们确实觉得 Ilya 可能是对的，这个范式没有太多数量级可以扩展，因此我们需要开始探索至少一条不同的道路。

被访者：GDP-Val 我认为大约只有一个月左右。当它首次发布时我也非常积极。我实际上与 Teddy 谈过，他是那个项目的首席研究员。

主持人：你有自己的版本。

被访者：这是一个很棒的数据集。

主持人：也许我会为仍然不了解的人回顾一下。这就像基于某种 GDP 门槛的 44 个任务，旨在代表广泛的白领工作，而不仅仅是编程。

被访者：每个任务都有一整套详细说明，其中很多都有一些输入文件。在 44 个任务中分为大概 220 到 225 个子任务，这些是我们通过代理运行的级别，它们真的很有趣。我会说它不一定捕获人们在工作中所做的所有事情。没有评估是完美的。总会有更多的事情要看，主要是因为为了让任务定义得足够好以便能够运行它们，它们需要只有少数文件和该任务的非常具体的说明。所以我认为考虑它们的最简单方法是，它们就像你在面试过程中可能做的相当困难的带回家考试任务。

主持人：对听众来说，这不再像一个长提示。它就像这里有一个带有电子表格或 PowerPoint 演示文稿或 PDF 的 zip 文件，随便折腾，回答这个问题。

被访者：OpenAI 发布了一个很好的数据集，他们发布了一篇很好的论文，查看了数据集上不同网络聊天机器人的性能。这是一篇很好的论文，鼓励人们阅读。我们所做的是拿那个数据集并将其转化为可以在任何模型上运行的评估。所以我们创建了一个可以在数据集上运行模型的参考代理工具，然后我们开发了一个评估器方法来比较输出，这是一种 AI 支持的方法。所以它使用 Gemini 3 Pro preview 来比较结果，我们进行了相当全面的测试以确保它与人类偏好一致。这里的一个数据点是，即使作为评估器，Gemini 3 Pro 有趣的是在 GDP-Val 中实际上表现并不那么好。

主持人：你必须注意 LLM 判断器的自我引用，模型通常更喜欢自己的输出，在这种情况下并不是这样。

被访者：完全同意。我认为我们现在考虑使用 LLM 判断器方法有意义的地方与几年前早期的 LLM 判断器内容相当不同，因为那时的一些内容，MTV 是一个很好的项目，是一段时间前这方面的好例子，是关于判断对话和很多风格类型的东西。在这里，评分模型正在做的任务与参加测试的任务完全不同。

### (45:00 - 1:00:00) Part 4

### (45:00 - 55:00) Agent框架与工具生态
> 发布Stirrup框架，chatbot vs API性能对比

被访者：是的。我也喜欢你在那里包含了 Llama for Maverick。这是不是就像最后一个...

主持人：不，不，不，不，不，不。它是 Meta 发布的最好的模型，所以它仍然进入了主页默认设置。另一个非常有趣的包含是我们还在最新版本的网络聊天机器人上运行了它。

被访者：哦，对的。哦，抱歉。是的，我完全错过了。好的。

主持人：完全没关系。那个有方格图案的。

被访者：所以那是他们的框架，不是你们的，是这个意思吧？

主持人：完全正确。真正有趣的是，如果你比较例如使用 Claude 网络聊天机器人的 Claude 4.5 Opus，它的表现比我们智能体框架中的模型要差。

被访者：在每种情况下，模型在我们的智能体框架中的表现都比它们创建的网络聊天机器人对应物要好。

主持人：我的倒推解释是，这是为消费者使用场景设计的。而在这里你推动它做某些事情。

被访者：约束条件不同，你能给模型的自由度也不同。另外，你有成本目标。我们基本上让模型想工作多长时间就工作多长时间。

主持人：你手动复制粘贴到聊天机器人中。

被访者：是的。

主持人：是的。

被访者：那就是我们获得聊天机器人参考的方式。我们不会像在网站上维护数百个模型那样保持相同规模的更新。

主持人：我不知道。和 browser base 谈谈。他们会为你自动化的，你知道。

被访者：确实。是的，我们应该。我想过我们应该把这些聊天机器人版本变成 API，因为它们本身就是合法的不同智能体。

主持人：是的。这在过去一年中增长了很多，对吧？可用的工具实际上在我看来在各大聊天机器人应用中分化得相当厉害，你可以连接到的数据源数量也增加了很多。这意味着你的体验和使用模型的方式比以往任何时候都更不同。当你说有趣的、值得注意的工作时，你想到什么工具和数据连接？

被访者：好的。我在这方面最喜欢的例子是，直到最近我都认为让 LLM 以任何有用的方式为我起草邮件基本上是不可能的，因为大多数时候你发送邮件，你不只是为了写作而写作。所需的上下文很可能是一堆历史邮件。可能是你做的笔记。可能是会议记录。可能是从你的任何工作存储地方提取的东西。对我来说像 Google Drive、OneDrive，如果我们需要对一些数据做分析或其他什么，最好是在我们的 Supabase 数据库中，模型可以插入所有这些东西并基于此做一些有用的工作。

我发现目前最令人印象深刻的，我有些惊讶在 2025 年末运行得非常好的是，我可以让模型使用 Supabase MCP 来查询，当然是只读的，运行一大堆 SQL 查询来做相当重要的数据分析并制作图表等等，还可以读取我的 Gmail 和我的 Notion。

主持人：好的，你实际使用那个，那很好，那很好。那是云端的东西吗？

被访者：在不同程度上同时支持 JBD 和 Claude。现在公平地说，这些东西目前几乎无法正常工作。

主持人：因为人们听到后实际上会尝试这个。

被访者：如果你收到 Mic 的邮件，很可能不是聊天机器人写的。

主持人：所以是的，我认为确实我从未真正发送过由聊天机器人起草的邮件给任何人。

被访者：但你能感受到它，对吧？明年这个时候我们会回来看看进展如何。

主持人：完全同意。Supabase 向另一位著名的新西兰人致敬。我不知道你是否与他就 AI 构建和 AI 基础设施的任何特定问题有过对话。

被访者：我们与他有过 Twitter 私信，因为我们是相当大的 Supabase 用户和高级用户，我们可能在 Supabase 中手动做了一些我们应该自动化的事情。

主持人：所以他就是支持热线，因为你们是...

被访者：有点是的，一直非常友好。

关于 GDP val AA 的一个额外要点是，基于模型相比聊天机器人的超出表现，我们意识到我们构建的参考框架实际上在通用智能体任务上运行得相当好。这在某种意义上证明了这一点。智能体框架非常简约。我认为它遵循了一些 Claude Code 中的想法。我们给它的只是上下文管理能力、网络搜索、网络浏览工具、代码执行环境，还有其他什么吗？

主持人：我是说我们可以为它配备更多工具，但默认情况下，是的，我们给它 GDPL 工具来查看图像，特别是因为模型可以使用终端以文本形式将内容拉入上下文，但要将视觉内容拉入上下文，我们必须给它们一个自定义工具。

被访者：事实证明我们创建了一个很好的通用智能体框架，所以我们昨天在 GitHub 上发布了它。它叫 Stirrup。如果人们想查看，它是一个很好的基础，你知道，构建通用智能体的基础。

主持人：对于更具体的任务，我认为使用它的最好方式是 git clone，然后让你最喜欢的编程智能体对它进行修改以做任何你想做的事情，因为它代码行数不多，编程智能体可以很好地与它配合工作。

被访者：这对社区探索、分享和破解很有帮助。我想也许在其他类似环境中，terminal bench 的人做了 start harbor，所以这是一个包，我们需要我们的最小框架，对他们来说是 terminus，我们还需要 RL 环境或 docker 部署来独立运行。我不知道你是否研究过硬件。那是人们想要采用的标准吗？

### (55:00 - 1:05:00) 成本悖论与未来趋势
> 解释AI"微笑曲线"：成本降但支出增的原因

主持人：是的，我们从评估角度研究过它，我们喜欢 terminal bench，并在 artificial analysis 上托管 terminal bench 的基准测试。我们从编程智能体角度研究过它，但可以看到它是任何类型智能体的绝佳基础。我认为我们正在达到的是这些模型已经变得足够聪明，它们在工具使用方面变得更好，当只给它们一套简约的工具并让它们运行时，它们可以表现得更好。让模型控制智能体工作流，而不是使用另一个更完善的框架来试图决定流程。

被访者：很棒。让我们讨论开放性指数，然后进入报告内容。那是我想的最后一个专有数字。我不知道你如何分类所有这些。

主持人：是的。或者叫它我们在过去几周谈论的三个新事物中的最后一个。因为我们做的是各种混合内容，我们使用开源的地方，我们开源什么以及我们做什么，以及我们并不总是开源的专有内容，比如去年我们开源的长上下文推理数据集，然后是网站上的所有性能基准测试工作。其中一些我们希望开源，但其中一些我们在不断迭代等等。我想说整个网站上开源和非开源内容有很大的混合。

被访者：那是 LCR，对人们来说。

主持人：是的。但让我们谈论开放语法。这是对模型有多开放的一种新思考方式。

我们长期以来一直跟踪模型在哪里是开放权重的以及它们的许可证是什么。这相当有用，告诉你你被允许用模型的权重做什么。但模型有多开放还有另一个非常重要的维度，我们直到现在还没有跟踪过。那就是关于它是如何制作的披露了多少。所以关于数据、预训练数据和后训练数据的透明度，以及你是否被允许使用该数据，以及关于方法论和训练代码的透明度。

被访者：嗯。

主持人：基本上这些就是组成部分。我们把它们结合起来为模型评分开放性指数，这样你就可以在一个地方获得模型有多开放的完整图片。

被访者：我觉得我看到过其他几个人试图这样做，但它们没有得到维护。我确实认为这很重要。除了最大数字是多少，我不知道这些数字意味着什么？这是满分 20 分吗？

主持人：目前是满分 18 分。我们有一个开放性指数页面，但本质上这些是分数。你在这些不同类别中越开放就能得到更多分数，你能达到的最高分是 18 分。所以 AI2 和他们极其开放的 32B think 模型在某种意义上是领先者，与 Hugging Face。

被访者：哦，与他们的较小模型。即将推出。我想我们需要在网站上运行智能基准测试。

主持人：我们不能有开放指数而不包括 Hugging Face。

被访者：我们喜欢 Hugging Face。我们很快就会有的。我是说精炼网和所有那些东西。太令人惊叹了。或者它叫 fine web？Fine web。

### (1:00:00 - 1:15:00) Part 5

所以每个等级你只需要看到线条下降得非常快，实际上对于过去几年中实现的每个新智能水平，下降速度都在加快。所以这种成本下降的速度实际上一直在上升。我们看到这种情况确实存在，但现在在AI推理上显然可以花费比几年前多得多的钱。NVIDIA股价在上涨。

主持人：确实在上涨。我刚从一个朋友的初创公司那里听说，他们刚进入种子轮。仅在编码代理上他们就花费每位员工5000美元。

被访者：这太离谱了。

主持人：这是个令人印象深刻的数字。我们需要提高我们的数字。我们还没有达到这个水平。

被访者：我想，这个数字如此之高，让我想问，你们是不是做错了什么？

主持人：是的，因为过程中确实存在一些效率问题，但是你可以通过很多我能想象到的方式，让AI推理在这个水平上发挥作用。我不认为这有那么疯狂。但基本上我们制作这张幻灯片来回答这个问题的原因，是为了说明疯狂的事情是，我们确实在左侧看到了GPT-4级别智能成本下降100倍到1000倍，但在右侧，由于乘数效应如此之大——即使小模型现在可以达到GPT-4的水平，我们仍然想要使用大模型，可能比以往任何时候都要更大的模型来实现前沿级别的智能。

我们有推理模型在使用token，然后我们将它们投入到这些代理工作流中，它们消耗大量的输入token，产生大量的输出token，工作很长时间。这两件事加在一起让我们回到了一个状态：我们今天可以花费的钱比几年前多得多。

被访者：是的，我认为这是对的。有很多驱动因素在起作用，我们在这里概述了大约六个关键因素。但你知道，情况很复杂，变化很快。所有这些在过去12个月中都发生了非常戏剧性的变化。让我们聊聊硬件效率，因为你也跟踪硬件相关的内容，我认为一般的断言或信息是，下一代NVIDIA芯片的效率实际上不是4倍，你这里有3倍，可能是2倍，更像是一个功耗的故事，而不是纯粹的计算token效率的故事。硬件方面到底发生了什么？

主持人：好的，不幸的是答案是"看情况"，这很大程度上取决于跨越不同类型工作负载和思考方式的许多因素。思考这个问题最简单的方法之一是选择单个相关模型，考虑以现实的速度为其提供服务——这些速度是你实际可能想要达到并能够负担得起的，然后考虑在这些速度下为模型提供服务时每个GPU能够实现的吞吐量。这很重要的原因之一是，你能实现的每GPU吞吐量和你能实现的每用户速度之间存在权衡。为用户快速提供服务的成本更高。当你针对特别是大型稀疏模型运行所有这些时，从Hopper到Blackwell一代的NVIDIA，你可以获得比2倍或3倍更好的性能提升。

我是，这不应该是一个太有争议的声明，但我很有信心Blackwell带来了相当巨大的收益，NVIDIA接下来几年的路线图将继续带来相当巨大的收益，这些收益实际上会作为运行模型的公司更低的每token总成本体现出来，并将允许更大的模型，将允许以更低的成本生成更多的token，这将继续推动这些发展。这些也会与所有正在进行的软件和模型改进相叠加。所以基本上，我对微笑图表的两侧都有预测——我们将看到左侧继续保持真实，可能再增长一个数量级，右侧也将继续真实，再增长一个数量级，这将使很多事情成为可能。

### (1:05:00 - 1:18:00) 推理模型与效率革命
> Token效率差异超10倍，turn效率成为新关键指标

被访者：好的。让我们回到小图表，我要对稀疏性提出异议。我们在稀疏性上已经走了很远。DeepSeek是细粒度专家的主要推动者。我心中有一个稀疏性的数字，以活跃参数与总参数的比例来说，这个数字从25%下降到了15%左右。你显然不能真正低于，我不知道，5%。

主持人：所以我想说稀疏性有一个下限。

被访者：我不认为这是显而易见的。

主持人：好吧。

被访者：某个地方必须有一个限制。

主持人：是的。但我们现在在实际应用中看到的数字比那要低得多。所以像GPT-4 OSS模型这样的大模型大约有5%的活跃参数。Kimmy K2大约有3%的活跃参数。

被访者：好的，我想我很确定我看过那些数字，我算过。我不记得了。是的。但我记得当时想这肯定就是极限了。你的5%正好在今天发布的开放权重模型的范围内。我认为一个有趣的现象让我在思考稀疏性不会进一步提高或活跃参数百分比不会降低时感到犹豫，就是我们在基准测试中看到性能与总参数数量的相关性远大于与活跃参数的相关性，而与模型的稀疏程度根本不相关。我们的准确性基准测试作为全知全能评估的一部分，与总参数高度相关，与活跃参数完全不相关，我认为这非常非常有趣。所以我认为这里还有相当大的发展空间。

主持人：太棒了。我们时间不多了，但我确实想留一些时间来讨论推理模型和非推理模型，以及token效率。

被访者：让我们来谈谈这个。在很高的层面上，人们必须将这个东西分类为推理与非推理的二元划分。内部人士对此有些不适，因为基本上你只是有思考标签或没有思考标签。你们是如何决定处理这个问题的？还有这在今年的过程中是如何展开的，我们有像GPT-5这样的模型路由器？

主持人：比如说GPT-5，消费者体验是一个模型路由器。当你访问API时，我们可以选择不同版本，你可以选择不同版本的推理强度，但这就是为什么现在这变成了如此复杂的事情。

今年早些时候，可能是你和George上次在AI工程师世界博览会上交谈时，我们有一张很棒的幻灯片，非常简单，显示在我们的智能指数中，平均推理模型每次查询使用的token数量是平均非推理模型的10倍。有那么一个时刻，这是一个相当清晰的区别，像这样看待它非常有用。现在绝对不再是这种情况了。特别是因为你可以考虑这些不同模型的推理强度，但特别是因为不同模型现在有截然不同的token效率，差异超过一个数量级。这意味着你可能需要思考任何应用程序成本的方式是使用我们的运行智能指数成本指标作为起点，来看看这些不同模型、这些不同推理强度和从非推理到推理的连续谱系会是什么样子。

这基本上就是我们现在的状态。我们仍然会显示推理和非推理，并将推理定义为当有那种分离的思维链时，你通常在API中的不同参数中得到它。但这不再意味着该模型实际上会比标记为非推理模型的模型在相同任务上有更长的端到端延迟或使用更多token。

被访者：这是真的。我认为是5.1，然后5. Codex有这些图表，非常漂亮，显示了底部10%的查询更快，但顶部10%的查询更长，这就是你想要看到的效率图表，对吧？

主持人：是的。这是一个额外的东西。让我们说这是一个非常重要的额外因素，对吧？你不仅有模型使用的平均token数量——我们现在很好地涵盖了这一点。但你在模型中想要的行为是当它需要更多token时使用更多token，当它不需要更多token时不使用更多token。

所以这就是OpenAI基本上声称5.1 CEX更擅长的事情。我们现在实际上没有发布任何关于这方面的内容，但在我们运行的所有模型的内部分析中，我们内部跟踪了很多，我们查看了问题的难度以及token使用量与难度之间的相关性，净净地，毫不奇怪，模型在今年过程中在这方面变得更好了。我认为进入明年，这将非常重要，特别是当你将其乘以模型在代理工作流中必须采取的步骤数量以获得答案时。我们将非常关心获得我们想要的东西的token效率和轮次效率。

被访者：你更愿意要token效率还是轮次效率？

主持人：嗯。

被访者：或者说哪个更重要需要努力？

主持人：这取决于应用程序，两者都将非常重要。

被访者：是的，零售电信基准。

主持人：是的。有趣的是，在T2基准电信运行中，你知道，按每token计算，更昂贵的模型如GPT-5与一些较小的开源模型相比，因为GPT-5实例更快地得到答案，因此能够更快地解决客户查询，轮次更少，也许每轮使用更多token，但每token的成本肯定更高，所以在那种情况下你总是更愿意使用5。我认为这就是我们要达到的地方。我认为轮次数将是我们要谈论更多的指标，我认为这将是人们真正开始思考很多的事情。

被访者：在基准测试方面存在权衡，大多数基准需要是单轮的才能自主、并行化等等，但现实生活中的很多用例需要是多轮的，特别是快速多轮，这样你可以对齐。

主持人：是的。我是说，我会说历史上基准测试一直是单轮的，但我不会说它们在未来需要如此。我们现在在指数中有几个代理基准测试，以及我们谈到的GPT val，我们让模型在我们的代理中做多达100轮来完成评估，我们将来会构建类似的东西。这确实很难，你会遇到各种基础设施问题来运行它，正如你所说的并行化，因为我们需要在数百个模型上运行它，当新模型出现时我们想要非常快地做到这一点，当实验室希望我们在他们的模型上运行它时，但你可以做到。我们正在投入工作来构建这些东西，这将是很棒的。

### (1:15:00 - End) Part 6

主持人：我们现在就结束吧？这个播客什么时候发布？

被访者：随时可以。好的，我们现在是V3版本。所以目前进入指数的是V3版本。V4是我们即将发布的下一个重大更新版本。不出所料，我们会添加今天讨论过的一些功能，这些都是我们在过去几周已经推出的。所以不会有太大惊喜，但最令人兴奋的是，添加GDP会让我们在智能指数中获得真正强大的通用代理性能。

添加关键点——我们谈到的物理学评估，类似于frontier math，会为我们提供全新视角和全新数据集，包含非常非常困难的研究问题。我们将使用omniscience和幻觉率。所有这些功能的具体整合方式...权重设置会比较困难，因为数字都不同。我们会确保不做任何可能导致奇怪扭曲或误导性的事情。

主持人：但每次你们更新版本时，都会有一次性的重置？

被访者：完全正确。我们就是这样考虑的。我们会确保在每个版本号内，所有分数都没有漂移，这样人们可以依赖和引用这些分数。你只需要注意版本号。一旦是v4.1版本，这些数字就不会与v4兼容。

主持人：当然，关于基准测试的准确性存在一些争议。我不知道你是否了解正在发生的情况。显然很多顶级测试都是不可能完成的。


---

*生成时间: 2026-01-09 02:12:38*
*由 YouTube Monitor & Translator (Claude CLI) 生成*