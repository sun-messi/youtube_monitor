# Building durable Agents with Workflow DevKit & AI SDK - Peter Wielander, Vercel

## 📹 视频信息

- **频道**: AI Engineer
- **发布日期**: 2026-01-06
- **时长**: 1:09:46
- **原始链接**: [https://www.youtube.com/watch?v=kmV-qg4uoNI](https://www.youtube.com/watch?v=kmV-qg4uoNI)

---

I'll analyze this AI Engineer conference talk about the Workflow DevKit and generate a structured summary.

## 视频开头信息

> 本文内容整理自 Vercel 工程师彼得·维兰德（Peter Wielander）在 AI Engineer 频道的技术演讲。

---

## TL;DR

Vercel 推出 Workflow DevKit，让 AI Agent 的生产化部署变得简单——通过将代码分离为可重试的步骤（steps）和持久化的编排层（orchestration），实现了开箱即用的可观测性、耐用性和人机协作功能。

---

## 📑 章节导航表

| 时间戳 | 章节标题 | 一句话概括 |
|--------|----------|-----------|
| 00:00-05:00 | 引言与项目介绍 | 介绍 Workflow DevKit 解决 AI Agent 生产化难题的背景 |
| 05:00-15:00 | 集成 Workflow 基础架构 | 演示如何在现有代码中添加 Workflow 支持 |
| 15:00-24:00 | 步骤标记与流式处理 | 展示如何标记工具调用为步骤并实现流式输出 |
| 24:00-32:00 | 可恢复流与生产部署 | 实现断线重连功能并部署到 Vercel |
| 32:00-40:00 | 睡眠与长时运行工作流 | 添加睡眠功能展示工作流可暂停数天 |
| 40:00-48:00 | Webhook 与人机协作 | 通过 Webhook 实现人工审批流程 |
| 48:00-69:46 | Q&A 深度探讨 | 讨论并发控制、版本管理、多平台支持等高级话题 |

---

## 📊 核心论点

### 1. 工作流模式：AI Agent 生产化的关键架构

- **核心内容**：传统 AI Agent 在本地运行良好，但部署到生产环境时需要处理队列、数据库、错误重试、状态持久化等复杂问题。Workflow DevKit 通过将代码分离为编排层（orchestration）和步骤（steps）两部分，让每个步骤在独立的 serverless 实例中运行，自动缓存输入输出，失败时可重试。这种架构模式让开发者只需添加几个指令（directives）就能获得生产级的可靠性。
- **关键概念**：编排层（orchestration layer）、步骤（steps）、确定性执行（deterministic execution）、状态持久化、自动重试
- **实际意义**：大幅降低 AI Agent 生产化门槛，让开发者专注于业务逻辑而非基础设施；支持运行数周甚至数年的长时工作流；为 AI 应用的规模化部署扫清技术障碍。

### 2. 可恢复流：解决长时 AI 任务的连接问题

- **核心内容**：通过创建独立于 API 处理器的流（stream），实现了断线重连功能。即使用户断开连接，工作流仍在后台运行，重新连接时可以从断点继续接收输出。每个工作流都有唯一 ID，客户端可以通过这个 ID 重新连接到正在运行的工作流。流可以存储在文件（本地开发）或 Redis（生产环境）中，支持多个并发流。
- **关键概念**：独立流（independent streams）、工作流 ID、断线重连、流持久化、多流支持
- **实际意义**：用户体验大幅提升，不再因网络问题丢失长时运行的任务结果；支持多设备接入同一任务；为构建可靠的 AI 助手和自动化工具奠定基础。

### 3. 零资源消耗的长时暂停机制

- **核心内容**：工作流可以通过 sleep 函数暂停任意时长（小时、天、周）而不消耗任何计算资源。暂停期间，工作流状态被完全序列化存储，到期后自动恢复执行。这种机制让构建定时任务变得极其简单——只需在 while 循环中调用 sleep 即可实现类似 cron 的功能。还可以通过 Promise.race 实现提前唤醒。
- **关键概念**：零资源暂停、状态序列化、定时任务、Promise.race 提前唤醒、长时工作流
- **实际意义**：大幅降低长时任务的运行成本；简化定时任务和周期性 Agent 的开发；支持构建"每天检查邮件并执行操作"等自动化场景。

### 4. Webhook 驱动的人机协作流程

- **核心内容**：通过简单的 await webhook() 调用，工作流可以暂停并生成一个唯一 URL，等待外部系统或人工触发后继续执行。这个 Webhook 是完整的 API 端点，可以验证请求体、返回响应、实现复杂的交互逻辑。在本地开发时生成 localhost URL，部署后自动切换为生产 URL。
- **关键概念**：人机协作（human-in-the-loop）、Webhook API、请求验证、动态 URL 生成、完整 HTTP 处理
- **实际意义**：轻松实现需要人工审批的 AI 工作流；支持与外部系统的异步集成；为构建合规性要求高的 AI 应用提供技术支持。

### 5. 编译时优化与确定性保证

- **核心内容**：使用 TypeScript 编译器插件，在编译时将工作流代码打包成独立 bundle，确保没有副作用的导入。编排层必须是确定性的（deterministic），这样可以安全地重放而不会产生重复的副作用。步骤的输入输出签名在编译时提取，用于版本兼容性检查和工作流升级。
- **关键概念**：编译器插件、确定性执行、无副作用、签名提取、版本兼容性
- **实际意义**：保证工作流的可重放性和可靠性；支持安全的版本升级和回滚；为大规模 AI 应用的维护和演进提供基础。

### 6. 内置可观测性与调试体验

- **核心内容**：提供本地 Web UI（npx workflow web）实时查看工作流执行状态、每个步骤的输入输出、执行时间和错误信息。生产环境可通过相同界面远程监控。所有步骤自动生成 span，可导出到 DataDog 等监控系统。支持取消运行中的工作流、从特定步骤重新执行等高级调试功能。
- **关键概念**：实时监控、步骤追踪、输入输出日志、远程调试、OpenTelemetry 集成
- **实际意义**：大幅降低 AI Agent 的调试难度；快速定位和解决生产问题；为 AI 应用的可维护性提供保障。

### 7. 多云部署与平台无关性

- **核心内容**：Workflow DevKit 设计为平台无关，可部署到 Vercel、AWS、Cloudflare Workers 等任何 TypeScript 运行环境。存储层支持 Postgres、Redis 或自定义实现。所有适配器都是开源的，可以根据需要扩展到任何后端。本地开发和生产环境使用相同的概念模型，确保开发体验的一致性。
- **关键概念**：平台无关、可插拔存储、开源适配器、统一开发体验、多云支持
- **实际意义**：避免供应商锁定；根据需求选择最合适的部署平台；为企业级 AI 应用提供灵活的基础设施选择。

### 8. 版本管理与在线升级

- **核心内容**：每次部署自动创建新版本，运行中的工作流继续在原版本执行。通过比对步骤签名检查新旧版本兼容性，支持在线升级运行中的工作流到新版本。不兼容时可选择取消并重启，或等待完成后再使用新版本。支持批量升级和选择性迁移。
- **关键概念**：自动版本控制、签名比对、在线升级、兼容性检查、批量迁移
- **实际意义**：支持 AI 应用的持续迭代而不中断服务；安全地演进长时运行的工作流；为大规模 AI 系统的维护提供关键能力。

### 9. 并发控制与资源管理

- **核心内容**：默认支持无限并发，每个工作流在独立的 serverless 实例中运行。即将推出的并发控制功能允许限制特定工作流或步骤的最大并发数，超出限制的请求会排队等待。这可用于实现分级服务（免费用户 10 并发，付费用户无限）、保护下游服务、控制成本等场景。
- **关键概念**：无限扩展、并发限制、请求排队、分级服务、资源保护
- **实际意义**：支持 AI 应用的弹性扩展；实现基于订阅的服务分级；保护系统免受突发流量冲击。

### 10. 步骤级错误处理与重试策略

- **核心内容**：每个步骤失败时自动重试，使用指数退避策略。开发者可以捕获特定错误类型，决定是否重试、切换到备用方案或通知人工介入。超时的步骤（如 serverless 函数的 15 分钟限制）可以拆分为多个小步骤。所有重试历史在可观测性界面中完整记录。
- **关键概念**：自动重试、指数退避、错误分类、超时处理、重试历史
- **实际意义**：提高 AI Agent 的可靠性；优雅处理外部服务的临时故障；为构建健壮的生产系统提供必要工具。

---

## 🏢 提及的公司/产品

| 公司名 | 讨论语境 | 重要性 |
|--------|----------|--------|
| Vercel | Workflow DevKit 的开发者，提供部署平台和 AI SDK | ⭐⭐⭐ |
| AWS Lambda | 作为 serverless 函数运行时的例子，讨论超时限制 | ⭐⭐ |
| Cloudflare Workers | 多云部署支持的平台之一 | ⭐⭐ |
| Redis | 生产环境中用于存储流数据的后端选项 | ⭐⭐ |
| Postgres | 支持的持久化层选项，有开源适配器 | ⭐⭐ |
| DataDog | 可集成的监控平台，通过 OpenTelemetry | ⭐ |
| Next.js | 演示应用使用的前端框架 | ⭐ |

---

## 💬 经典金句

> "I don't know about you, but for my AI agents, I like focusing on the capabilities and the features, and I like not thinking about all of the extra effort that goes into getting something that works locally into production."
> — Peter Wielander

> "A workflow could wait for a week and not consume any resources."
> — Peter Wielander

> "Everything you do in a workflow, you can resume at any point."
> — Peter Wielander

---

## 👤 主要人物

### Peter Wielander

**身份**：Vercel 工程师，Workflow DevKit 项目负责人
**背景**：专注于开发者工具和基础设施，在 TypeScript 生态系统有深厚经验
**核心观点**：AI Agent 的生产化不应该需要复杂的基础设施工作。通过正确的抽象（工作流模式），开发者可以专注于业务逻辑而获得生产级的可靠性、可观测性和可扩展性。他强调了确定性执行、状态持久化和平台无关性的重要性。

---

## 📺 视频类型判断

**教程示范**：技术教学、产品演示

---

## 📝 完整翻译

### (0:00 - 5:00) 引言与项目介绍
> 介绍 Workflow DevKit 解决 AI Agent 生产化难题的背景

感谢大家的到来。大家好。

好的，我不知道你们怎么样，但对于我的智能体代理，我喜欢专注于功能和特性，而不愿意去思考将本地运行的东西部署到生产环境中所需要的额外工作。对此非常有用的就是工作流模式。这就是我们为什么开发了工作流开发工具包，也就是我们今天要讨论的主题。如果你们在这里，想必也遇到过类似的问题。

今天我们将把一个编程智能体转换为支持工作流的编程智能体，贯穿整个会话过程。

我们有一个开源示例已经准备就绪。这个在 Vercel/examples 仓库中。你们可以克隆它并查看 VIP 编程平台应用的相关内容。我们今天的演示将使用这个应用。

完成后，我们将获得内置的一流可观测性，以及持久性和可靠性。我们还会得到许多额外功能，比如可恢复性，草案工具包使添加人机循环工作流和类似功能变得非常容易。

如果你们想想我们之前都见过的一般智能体循环，我们主要是在大语言模型和我们的工具调用以及后端代码之间进行往返调用，对吧？这包括 MCP 服务器、人工批准、任何异步任务。

通常的做法是连接一些队列和数据库，特别是如果你在做长时间运行的智能体，可能要运行几个小时，而且你想要扩展规模，并且在无服务器环境中运行，你需要某种可靠性布局，通常由队列来填补。然后你还需要添加大量错误和重试代码，需要存储用户发送的所有消息以及状态之间的消息，还可能需要添加某种可观测性层。

今天我们将使用单一库来完成所有这些事情，这就是工作流开发工具包。它是开源的，可以与任何 TypeScript 前端或后端配合使用，也可以在任何云平台上运行。我们今天将部署到巴西，但这同样可以在你们的任何云技术栈或自定义技术栈上运行。

好的，这里有多少人听说过工作流模式或使用过工作流库？举手示意。好的，不到一半的人。我将快速解释什么是工作流模式，以明确我们在做什么，然后大约2分钟后我们就进入代码环节。

所有帮助工作流开发运行在任何类型的云后端或自制后端上的适配器也都是开源的。所以你可以准确地看到正在发生什么，你可以将它连接到你自己的后端，只需查看该代码，我们很乐意帮助你。

**主持人：** 你能谈谈路线图吗？

**演讲者：** 好的，关于版本控制，我谈了一点关于跨版本升级运行的能力。版本控制将非常简单，我们为你创建的所有版本提供一个群组接口，对大多数人来说这将是一个部署。如果你部署你的 CI 将代码部署到预览环境或生产环境，每个部署将是一个版本。

你可以随时使用工作流 API 列出这些版本，运行将知道它在哪个版本上运行，你可以调用 run.upgrade 来查看它是否与新版本兼容，以将其升级到该版本。

**主持人：** 还有其他关于版本的内容吗？

**演讲者：** 每个部署都有自己的 URL，不仅在 basel 中，而且如果你使用 AWS Lambda 等，每个部署都有自己的 URL，所以 webhook 将应用到自己的 URL，这意味着除了在首次创建部署时标记版本外，你不需要担心版本控制。

然后你认为应该是主版本的任何内容都是通过你的公共 API 路由的。

**主持人：** 我想很多人不幸地会遇到隔离问题，但有时你想就地修复已经存在一段时间的事情。

**演讲者：** 是的，迁移几乎就像智能体迁移到新版本。这与升级是一样的，对吧？但如果你有一堆都在某个版本上的运行，你发布了新代码，你希望所有这些运行都升级到新版本或迁移。

在 UI 中，你可以选择你想要的任意数量的运行，或者对于 CLI，你可以获得一个列表，然后说对于这 20 个 ID，我想将运行升级到这个版本。它将进行内部检查，我能否从某个点恢复这些工作流？

就像我能就地迁移它们吗，因为步骤签名重叠，如果不行，它将为你提供取消所有现有运行并在新版本上使用相同输入重新运行它们的选项。如果你以兼容的方式编写代码，就地迁移将有不同的选项。

**主持人：** 它如何检测到这一点，只是通过代码部分没有改变？

**演讲者：** 因为我们本质上是一个编译器插件，我们可以获得完全的兼容性，我们正在将输入和输出签名保存到我们为版本上传的清单中。

所以对于每个版本，我们可以告诉每个步骤和工作流本身以及之间发生的所有其他事情的签名是什么。另一件事是工作流函数本身。所以是的，我们在执行期间播放了很多次。

当你想升级你的事件时，这是你在事件上得到的代码与之对比。当然，有很多变化，比如我做一个步骤，所有先前的步骤保持不变，或者你知道这个被改变了。

如果一切都自动完成，感觉好像我可以立即与我的所有智能体一起下降或上升。有两种版本控制方式，我认为重点是你为一个平台构建，你假设代码总是在同一个地方进化。

我们看到的是，当你开始发布工作负载的第一个版本时，但当你开始更新时，你开始新版本，你的代码现在有所有的东西在那里，你无法保证运行在实际代码上的版本。

默认假设是我的代码可能无论如何都在事件日志上运行，你最终开始很棒，然后你必须做模型。但这与杀死和维持已经存在很久的东西是一样的。

有一个自然的步骤说很酷，我们只是假设你推送工作流的新版本，你固定一切，所以你不必担心那种心理模型代码，而是时候按下按钮，我可以进入，甚至理论上选择确切地要获得多少那个按钮。

### (5:00 - 15:00) 集成 Workflow 基础架构
> 演示如何在现有代码中添加 Workflow 支持

工作流模式本质上是一种编排层，它将你的代码分离成可以独立运行、可以重试、数据可以持久化的步骤，还有一个我们称为工作流的编排层，不同平台有不同的名称。在我们这个案例中，工作流部分就是调用大语言模型、然后回到工具调用、再回到大语言模型调用的循环。而步骤就是我们实际的工具调用和大语言模型调用。

好的，看看今天的议程，我们将直接进入代码。我们将添加工作流开发工具包，这会很快完成，然后我们有很多时间讨论它添加的酷炫附加功能，比如开箱即用的可恢复流、如何在任何时点暂停和恢复、以及如何为人机循环流程添加网络钩子。最后会有充足的问答时间，但你们在这里参加工作坊而不是在线观看是有原因的——你们可以提问。请随时在任何时候提问，可以举手或直接说出问题。

如我所说，我们将基于基础示例仓库工作，使用 conf 分支。为什么是这个分支？我删除了示例中的一些多余代码，确保我们能专注于最重要的部分。这个工作坊的每个检查点都有自己的分支。所以如果你们不是直接跟着编码，也可以逐步查看这些步骤，检查差异，看看变化了什么。

我已经在这个平台上本地运行了 npm dev，只是向你们展示它的样子。我将运行一个简单查询。这是一个编程智能体，就像一个代码编辑器，但没有代码编辑功能，它可以接受提示，生成一些文件，最终会显示一个包含已部署完成应用的 iframe。

所以它主要是 UI，加上几个简单的工具调用，我们稍后会看到。文件系统和输出通过 Cell Sandbox 运行，但你也可以轻松地在本地运行。

查看代码，我将检查我们的实际分支。看代码，我们有一个接受聊天消息的端点，对吧？然后它进行一些常规的模型 ID 检查，看看模型是否受支持。最终它将简单地创建一个智能体。

分支是 conf。你们可以看到我们会转到这些 com/2- 等等。寻找数字，你们就能找到所有的检查点。

我们的主端点只是接受一些消息并调用 AI SDK 智能体，这本质上与流文本调用相同。我们会传递一些工具，内部它只是循环进行流文本到调用流文本的调用，然后将生成的所有块以客户端易于理解的格式流回客户端。这些都是 AI SDK 的常规代码，如果你想的话可以用不同的库替换。这主要是为了支持 UI。但同样，所有实际的智能体功能都非常简单，就在这里发生。

我们也看看我们拥有的工具。我们有四个工具：创建沙箱、获取沙箱URL。这些非常简单，只是包装了 Bell Sandbox 的创建和获取 URL，运行命令本质上包装了 sandbox.run 命令，生成文件将从简单提示生成文件。我们将以其中一个根调用为例。我们有一个看起来像 markdown 文件的提示，说明要做什么、不要做什么。

回到工具调用，我们还有一个输入模式，这是一个 Z 模式，用于 BI 应该传递的内容。这些都很标准。然后有一个执行运行，它用一些错误处理包装沙箱一个命令。

这基本上就是我们整个智能体代码设置，然后在前端我们只是从 AI SDK 调用 use chat 来使用流并在 UI 中显示内容。让我们开始为此添加工作流。在我开始之前有任何问题吗？

### (15:00 - 30:00) Part 2

你可以在上面做很多事情，因为你有。但好的是这是一个硬美国，你知道对我们来说构建做得好时希望非常。我不知道我们接近完成了。我认为我们接近完成了。

**主持人：** 我想另一部分是可观测性。我在周围查看，我没有看到太多仪表板。我期望你显然会构建一个，对吧？然后我也想将其导入到我的 data dog 中。

**演讲者：** 开放遥测范围，我们将能够发出。我们将默认向范围添加一些上下文。所以如果你只是通过 data dog 传输你的范围，它将已经有很多关于步骤和事件日志的信息。你也可以显然提交你自己的遥测。

**主持人：** 这是计划还是你有第一方？

**演讲者：** 计划是我们将第一方支持添加一些所有相关步骤和事件日志相关上下文。我们可能会导出一个帮助程序来向范围添加这些信息。然后你想在那里标记的所有信息都取决于你。

**主持人：** 我可以以某种方式将秘密附加到工作流，当我需要更新它们时它们像你知道的那样？

**演讲者：** 是的。首先，现在你可以检查所有输入和输出数据，显然对于你作为有权访问 API 的人，通过 Web API 消费工作流或启动工作流的人通常不会有。

工作流在与通常相同的部署中运行，并且可以访问进程环境，所以你可以像通常那样注入环境级别。只要你不记录它们，你无论如何大概不会这样做，这与 API 端点是一样的。

然后如果你希望你的数据是秘密的，现在我们在可观测性中暴露它，如果你有访问权限，但我们将来也将允许对任何数据存储进行端到端加密。

**主持人：** 好的，我们将结束这次会议，但我们会再待一会儿回答问题，如果你想查看的话。

### (15:00 - 24:00) 步骤标记与流式处理
> 展示如何标记工具调用为步骤并实现流式输出

是的。已经有志愿者帮助任何跟着学习并有调试问题的人。请随时联系。

我也在团队里。如果你们有人在跟着学习，请告诉我。

我也会在这里帮忙。

最后，这个 start 调用返回一个运行实例，它有一个流，我们最终会写入并返回给 UI。这样就完成了我们的工作流定义。现在我们还说需要将东西标记为步骤。

durable agent 类已经将 LLM 调用标记为步骤。但我们的工具现在还没有被标记为步骤。幸运的是，这很简单。在每个工具的执行函数中，你只需要写 use step，这将让编译器知道这是一个单独的代码块，要在单独的实例中执行。如果这被部署到生产环境，这将在单独的无服务器实例中运行，如果已经运行过，输入和输出会被缓存，如果失败则会重试。

所以我要去遍历其他工具调用，也给它们添加 use step。幸运的是我们只有四个工具。这应该就完成了我们的转换。

现在我们可以运行 npm dev，看看这是否按预期工作。我们要重新加载页面。看起来什么都没有改变。让我们实际运行一个查询。

我们可以看到它仍然按预期进行流式传输。所以对于我们在本地开发，我们所要做的就是提取一个函数，然后添加一些指令。但现在如果我将此部署到任何适配器，再次是 AWS 适配器或者也许你有自己的，这将以隔离的方式运行，具有持久性和所有这些好处。

对于本地开发来说，还有一个非常好的特性是，如果我进入同一个文件夹，运行 npx workflow web，这是一个 CLI 调用，用来启动一个本地 Web UI 来检查我们的运行。你可以看到我们的运行目前仍在运行。每个被标记为步骤的东西都会在这里有一个跨度，你可以检查输入、输出和任何相关事件。我们可以看到我们的工作流刚刚完成了，这是内置的。

澄清一下，每次你提示你的 vibe coder，那就是工作流的一个实例，运行到完成。所以每一个都是...

完全正确。你可以按任何你想要的方式建模。你也可以将整个用户会话建模为一个工作流，让工作流执行循环，等待下一个查询，然后再次运行。如果需要，我们本质上可以运行代码几周。我稍后会介绍一些相关工具。

现在我们已经设置好了，你可以看到在右侧我们没有得到任何有用的反馈。但如果我访问这个链接，看看我们的应用是否已经正确创建，或者因为某些错误而失败，无论如何，我们在右侧都没有得到任何输出。

发生这种情况的原因是我们正在将智能体输出流式传输到客户端，但我们的工具现在实际上没有进行任何流调用。

我们可以在工具调用中类似地获取 writable，这将获得与工作流本身相同的可写实例。在工作流中可以创建和消费无限数量的流。你也可以用特定名称标记它们，然后从那里获取。但这将获得默认实例。

一旦我们有了可写实例，我们就可以通过获取 writer 来实际连接到可写实例。现在我们可以将任何类型的信息写入到 iPhone 以供消费。我想我们需要类似 data create sandbox 的东西，我想这是我在 UI 中连接的，然后我们会调用 ID，我们想要沙箱 ID。这是我编写的一个数据包，我们的 UI 知道如何消费。

现在我做了这个，如果我重新加载应用并重新开始，我们会看到至少沙箱创建调用可能在开始时正确填充。

你说有可以创建的流，你是什么意思？

对的。流工作流，适配器，他们在本地开发中用于工作流，这只是一个文件，在生产中这可能是一个 Redis 实例，支持工作流调用它来创建新流，例如在 Redis 中，然后传回该流。所以每当你调用 get writable 时，它会创建一个流，例如再次在 Redis 中，带有该工作流的 ID，它会传回。所以任何步骤都可以附加到那个，任何客户端都可以附加到那个。

在本地主机中，这会被写入文件并从文件中读取。

对的。以前我们有一个 API 处理程序，它接受一些消息，调用智能体，然后从该 API 处理程序流回消息。现在我们有一个 API 处理程序，它调用启动工作流，它会传回这个工作流创建的流。这也让我们能够做到的是...我认为那个没有正常工作。我要重启服务器看看是否是这种情况。

到目前为止有其他人需要帮助设置的吗？

看起来不错。你提出的好观点，这让我们能够做到的是流不绑定到 API 处理程序。这意味着在任何时候我们都可以恢复这个流。如果你失去与 API 处理程序的连接，然后用户重新连接，这个流仍然存在，我们可以重新连接到流来恢复会话。这也是持久性方面的一部分，你在工作流中做的一切都可以在任何时候恢复。

我要重启这个查询，希望这次能工作。是的。现在我连接了这个数据包，你可以看到创建沙箱的特殊 UI 处理工作了。但即使在完成后，也没有显示它完成了。这是因为我们只写了初始加载状态包。所以我可以遍历我们所有的工具，添加更多数据包，让 UI 更丰富。

但我要切换到一个不同的分支，这是 conf-sleep 分支。下一步，已经有这些...实际上我会选择工作流分支。对不起，conf/2-workflow，已经填充了所有这些 writer 调用。除此之外没有区别。现在我们所有工具都有这些写入调用，流应该再次看起来和我们开始这个应用时一样。

### (24:00 - 32:00) 可恢复流与生产部署
> 实现断线重连功能并部署到 Vercel

好的。现在我们又让流工作了，一切都按预期工作，我们有了更多可观察性，可以用持久性部署这个。我之前谈到了可恢复的流。我们来看看是否能让这个流恢复，这样我们就有了持久的会话。

我们需要做的唯一事情是去我们的 API 端点，在我们获取运行实例的地方，我们还要返回工作流 ID 作为附加信息。例如，我可以返回 run.runID。这只是任何你这样做的方式都可以。我在这里将其添加为头部，因为我们已经在返回流。但无论如何你将 ID 传递给 UI，UI 然后可以用它来恢复流。

我们从这里做的是 UI 应该能够决定是否有运行 ID，是否应该恢复流。所以我们要创建一个新端点。让我们称它为 ID，类型是 slash existing ID。然后我们要创建一个文件夹 stream，添加一个路由处理程序。这只是 next.js 的配置，用于在 slash chat/ID/stream 添加 API 路由，我们要用 AI 自动完成。

我们本质上在做的是从参数中获取 ID，然后我们要做的就是在工作流 API 中调用 get run，这会获取运行实例，然后我们可以返回与其他端点相同的流，只是不调用实际的智能体，只做流。

我认为这应该不错。我们还从 AI 获取我们的开始索引，这非常有用。我们可以从特定起始点获取可读流。

我认为这就是为什么它是自动计算的。如果你试图在中途恢复流，你可以传递一个，你知道，当你最初离开时你在哪个块上。现在这完成了，我要注释掉这些我们目前不需要的东西。

我们需要 UI 支持这个条件，是恢复还是开始新聊天。所以我要去我们的聊天前端，为了简单起见，我要从不同分支拉一些代码，它在 four-streams 分支上，我要展示完成情况。

我们已经在 UI 中使用 use chat 调用来消费流，我们现在添加的是一个传输层，这是这里的大块，它为流提供一些中间件，说如果我试图启动这个调用，我首先要检查我们是否有现有的运行 ID，如果有，我将通过调用这个不同的 API 端点来进行重新连接。

我有点草率地处理这个，因为这是客户端处理传统流的。如果对此有更多问题，请随时提出。

好的。这给了我们可恢复的流。我还要演示如果我们想部署这个并在生产中看到它会怎样。我要调用这个，然后我们可以查看生产预览示例。

与此同时，我们接下来要做的是谈论事件和可恢复性。工作流的运行方式是每个步骤在生产中都在自己的无服务器实例上运行。实际的工作流编排层只会很简短地被调用来促进步骤运行。这让我们能够让工作流花费任何时间。工作流可以等待一周而不消耗任何资源。这内置在工作流开发工具包中，我们可以在工作流内部任何标记为 use workflow 的地方简单地调用 sleep 三天，这也会唤醒我们，这会暂停工作流三天，然后从我们离开的地方恢复。

### (30:00 - 45:00) Part 3

工作流函数在这个时间点的状态会被保存，所有状态调用的输出也都会被保存。当我们从这行特定代码重启工作流时，它会重新注入整个状态，然后从这里继续执行。

这样做是为了确保我们不必重复执行任何实际消耗资源的代码。

我们可以利用这个功能来创建一个本质上相当于 cron job 的智能体。我们还可以用它来制作在很长时间范围内运行数周或与任何信息交互的智能体。

在我讲话的时候，我们已经将当前应用部署到了 Vercel。我可以查看这个预览分支，你可以看到应用现在已经在线运行，工作状态和平时一样。它运行得很完美。

我也可以使用 UI 在任何时候检查这个。如果我调用 workflow inspect web 或者只是 workflow web，加上 dash backend for vercel 和 dash preview 参数，这会让系统知道我们的部署在哪里，然后启动相同的 UI。现在我们可以检查这个在生产环境中运行的任务，你可以看到我们获得了同样的信息。

这展示了本地运行和生产环境运行在概念上是完全相同的，这就是我们要追求的用户体验。

### (32:00 - 40:00) 睡眠与长时运行工作流
> 添加睡眠功能展示工作流可暂停数天

好的。我之前提到了 sleep 和 suspend。让我们来写一个 sleep 工具调用，这会非常简单。我要复制这个，然后从头开始写。

我们要写一个 sleep 工具调用，我把它叫做 sleep.ts。我们要把输入模式设置为类似超时毫秒数，实际的运行命令就是调用 sleep。因为 sleep 已经是我们从 workflow 库中导出的一个步骤，我们不需要将这个函数标记为 use step，但这现在应该是一个数字。

**观众问：**你能再解释一下为什么不需要 use step？

**演讲者：**因为这已经是我们从 workflow 导出的一个步骤。可观察性也会将其显示为一个步骤，我们马上就会看到。

假设提示是好的，这应该能工作。我们要修改提示，比如说"只有在用户指示你这样做时才使用这个工具"。

现在 sleep 调用设置好了，这应该是我们需要做的全部。我们叫它 run sleep command 和 sleep tool，并将其添加到我们的工具列表中。

我们还希望 UI 在休眠时能显示状态。我要添加另一个记录休眠的函数。我们这样做的原因是不能直接从工作流写入流，因为那样就不再具有确定性了，每次运行工作流都会再次写入流。

**观众：**我在尝试运行项目时必须为 AI 网关创建一个 Vercel API 密钥，但收到错误说请求缺少头部信息。你在项目设置中启用了 YC 选项吗？

**演讲者：**你在开始时跳过了这个，是的。因为这段代码使用了沙盒，你需要登录。我的错误，这应该在本地运行。如果你不使用这个沙盒，我们会在演讲后提供一个不使用沙盒的分支。

现在我只是在后面处理这个问题。在这里我要添加另一个对 writable 的调用，我们需要本地 ID。这会写入流，应该能让我们在 UI 中正确显示。

现在我有了这个，可以再次启动我们的应用。加载后，我们可以尝试第二个提示，"休眠 30 秒然后返回"，只是为了展示它会正确解释 sleep 调用然后休眠。

遗憾的是这里没有显示数据包，但我们可以进入 web UI 显示它正在进行 sleep 调用，这将在 30 秒后返回。

好的，这就是 sleep。还有一个最后的功能我想展示给你们，就是 webhooks 和从 webhooks 轻松恢复的能力。

实现 webhooks 通常相当困难或令人头疼，在我们的情况下，我要检出 conf/5-hooks 分支，展示我们可以用与 sleep 相同的方式添加一个新工具。

我会展示实际的工具调用在哪里，只是一个日志调用，然后我们创建一个 webhook，这是我们从工作流中导出的一个函数。我们可以将 webhook URL 记录到客户端或其他地方，然后等待 webhook，这会暂停直到有人点击这个 URL。

让我看看能否展示这个运行。重新加载，"等待人工批准再开始"并调用 Pokemon index。

我一直在切换分支，所以可能需要重启服务器。

这个工作原理是我们会创建一个 URL，然后让工作流休眠直到有调用进入那个端点。这带来了很多额外功能，比如我也可以用 respond with，这是一个完整的 API 请求处理器。我可以用请求对象响应，我可以将其视为 API 端点。我也可以检查 body 是否符合结果模式，然后只有匹配时才恢复。

这给了你完全的控制，但好处是它内部连接了 URL。你可以看到它暂停等待人工点击这个链接，如果你在本地主机运行，这就是一个本地主机链接，在生产环境运行时，这会是你的部署 URL。

### (40:00 - 48:00) Webhook 与人机协作
> 通过 Webhook 实现人工审批流程

**观众：**关于 sleep 和人工批准，工作流纯粹是步骤，步骤总是运行到完成，对吧？所以 sleep 是一个步骤，它不像是某种执行的暂停。

**演讲者：**不，它确实是这样。我们在可观察性和调用方式上将其建模为步骤，但这是一个完全暂停工作流的内部功能，sleep 期间没有任何东西在运行。你也可以 sleep 和另一个步骤，如果你想的话可以 promise 它们。

从这个意义上说，它作为一个步骤调用工作，它是一个需要一定时间的执行。你可以使用 promise await 语法来建模，但同样，它完全暂停，除非当时有其他东西在运行，webhook 也是如此。

**观众：**据我理解，如果你有一个智能体运行工作流，它会保持运行。你再次连接，比如通过另一个会话，你在这个会话中调用 sleep，之前的那个会做什么？

**演讲者：**比如说我们有一个编码会话，它已经构建了一个应用，然后它休眠一周，然后我们重新连接到流。

**观众：**如果我启动一个工作流，它在计算 pi 的数字，一直在计算，但我连接到同一个沙盒，然后调用 sleep，它会停止计算 pi 吗？

**演讲者：**沙盒是 Vercel 沙盒，可以想象成一个 EC2 实例。这只是帮助我们启动一个实例来运行这个编码智能体，比如运行代码以存储文件。如果你用不同方式实现这个，你不必使用沙盒。

sleep 调用不会作为 bash 调用发生。有两个不同的概念：你可以从终端在沙盒中作为终端命令调用的 sleep，以及从工作流调用的暂停工作流的 sleep。

我们有这些 webhooks 功能，你可以看到在我点击 URL 后它恢复了，然后为我编写了一个 Pokédex。

这就是我们在本次会议中要展示的所有功能，我想我们有充足的时间进行问答，至少 20 分钟。

**观众：**我如何启动一个 Claude Code 会话？

**演讲者：**Claude Code 会话是远程的还是？

**观众：**不，是作为智能体运行和启动它做某些事情，这可能吗？然后将其作为智能体进行编排？

**演讲者：**这是可能的。Claude Code 如果你说的是像音调应用那样的 Claude Code，它内部并不使用很多工作流功能，所以很难隔离或知道编排在哪里。

你可以编写自己版本的 Claude Code 或采用 Claude Code 源代码，为调用添加工作流和步骤，然后这将作为云端的工作流运行。没有办法说"好的，我有我的步骤，启动 Claude 工作代码并输入这个命令然后等待"，这将是一个 Vercel 工作流。

**观众：**如何实际启动 Claude Code？

**演讲者：**如果你在 VM 上调用 Claude Code，这本质上被视为 SSH 会话，但如果你在工作流中运行任何智能体或步骤，那些步骤将通过工作流模式变得可恢复和可观察。

**观众：**另一个问题，我如何控制我的智能体访问权限，比如访问互联网做事情？

### (45:00 - 1:00:00) Part 4

**演讲者：**这将是你已经为智能体做的任何事情，对吧？如果最终你要进行工具调用和流式调用到 LLM 提供商，那在你的代码中presumably已经存在了，你已经在使用的任何权限控制方式，比如你的工具调用，如果你的工具调用允许你删除 S3 中的资源，那么你作为调用者可以用通常的方式编写任何你想要的代码。

**观众：**实现这个是我的工作，但它没有一些包装器，最终都在沙箱中。

**演讲者：**工作流是用于持久执行的通用编排层，并不一定为运行代码或运行第三方代码或运行智能体代码或创建文件提供沙箱。这就是沙箱的用武之地，因为每个沙箱实例都是一个新的 VM，只在你的会话持续期间存在。

**观众：**如果我运行工作流并通过我的兄弟创建大量智能体工作流，这会在你们的系统中排队吗？如何运行？是否有速率限制或并发控制可以使用？

**演讲者：**是的。这涉及到所有这些将要支持的一些模式，大部分现在已经支持了。如果你部署到比如 Vercel，就像通常情况下如果你使用 Next.js，每次部署都是一个单独的实时 URL，如果你调用它就会启动一个无服务器实例，所以你的工作流绑定到部署上。

你在这里得到的一个非常好的特性是，如果你有一个智能体运行一周，但你在这一周内部署了五次，那些新部署将与原始工作流隔离，原始工作流将运行到完成，然后任何新工作流将在新部署上运行，我们还将允许在它们之间升级。

所以如果你有一个运行一年的工作流，比如每月给我某某的摘要，但你有新代码，你希望工作流采用当前状态并使用新代码。UI 中将有一个升级按钮，通过检查所有步骤签名和所有现有事件来检查旧工作流和新工作流之间的兼容性，然后你可以升级工作流。或者你可以取消并用新工作流重新运行。

**观众：**这些工作流步骤有超时吗？

**演讲者：**是的。如果你在使用无服务器，无论你在什么平台上，无论是 Lambda 还是其他，你的无服务器函数都会有超时。好处是每个步骤都在自己的无服务器函数中运行。所以超时只适用于步骤。

### (48:00 - 1:09:46) Q&A 深度探讨
> 讨论并发控制、版本管理、多平台支持等高级话题

如果你的某个单独步骤有运行超过 5 分钟或 15 分钟的风险（取决于平台），那么你可以分成两个步骤。或者如果它超时失败，它会重试，也许会更快，你会在 UI 中看到这个步骤在 15 分钟后被重试很多次，可能是因为它失败了，然后你可以将它分成两个步骤，升级工作流，它就会从那里继续。

另一点是关于排队工作流，比如我多次触发智能体。

**观众：**是的，它会排队吗？这个过程如何运作？

**演讲者：**你可以用不同方式建模这个。现在我们从 API 路由做这个，每次调用这个 API 路由都会创建一个新工作流。主要是，你唯一的可交互输出是一个流。所以它会做事情，会写入流。没人看流，我们不知道工作流在运行。你可以启动 10 个这样的流程，它们会在后台运行。

基本上对你可以创建多少个没有限制，因为它们都在无服务器函数中运行。所以你可以扩展到你提供商有多少计算资源，这是很多的排队。你也可以列出活动运行，这里有一个 API 用于与你的运行交互，查看所有正在运行的运行，查看它们在哪个版本，在哪个步骤，取消它们。

希望这回答了你的问题。关于并发，是的，现在是无限并发，但很快我们会添加每步骤或每工作流并发控制，你可以说这个工作流最多同时运行 10 次，任何额外的启动会排队，等待那 10 个减少然后进入。你也可以用这个在你的产品上实现免费层，比如免费层任何时候有 10 个实例运行，后来的人会等待队列，但你的专业层有无限并发。

**观众：**我可以回滚步骤吗？比如我有 10 个步骤，但在第七步我想回到第三步。是否可能重置工作流状态？

**演讲者：**技术上你可以这样做。我们目前不支持，但很容易实现，因为每个步骤的输入和输出都被缓存了，我们可以在任何点进入工作流并从那里播放。所以我们需要在 UI 中暴露这个功能，作为从某某步骤恢复的功能。但是，这是可能的。更可能的是你想要做的是因为你控制工作流。

所以你想在那里记录日志并使用这个 JavaScript，可能必须进入状态或做些什么，只是保持增长。

**观众：**我的第二个问题。当你经历步骤时你说，你传递输入和输出，这就是被缓存的东西。是否有办法附加元数据，还是总是必须在函数的输入输出中？

**演讲者：**你也可以附加元数据。我们很快会有一个标记 API，你可以在工作流运行的任何点向工作流添加任意标签，你也可以使用这些标签来决定是否提前退出或去重你的运行。

**观众：**关于部署，我们是否绑定到 Vercel 还是可以...

**演讲者：**就像我之前提到的，这有两个方面。有框架的前端部分，文档在 use workflow.dev 上。你可以看到前端部分，这也是 API 层可能使用的。我们目前支持所有这些平台，更多即将推出。

然后单独有部署目标，Next.js 你现在可以部署到任何地方，这可以与任何你可以部署 Next.js 的地方工作，比如任何这些其他框架，我们有 Postgres 的第一方实现，使用 Postgres 作为持久性层。

随着我们构建这个并且社区加入，我们将支持基本上任何后端，因为在 TypeScript 框架下面连接到任何存储或队列层，所以任何提供存储、数据库或队列的东西都可以用作后端。

**观众：**相关问题，对于可观察性，我们也喜欢提供商到 DataDog 的东西。

**演讲者：**我们有多种东西，我们有一个 API 你可以用来直接访问数据，我们也有开源 UI 组件你可以用来显示它，然后你可以导出这个到 DataDog 如果你想要的话。

**观众：**你谈到了流一点，谈到它本质上像作业。在工作流中是否有更多调度和定时控制？

**演讲者：**因为它只是 TypeScript，如果你在工作流中，你可以做比如我们调用 sleep，这只是在一天后恢复。但你也可以做的是这只是一个 promise 或者你可以把它当作 promise，所以你可以做 while true sleep 一天然后做你的代码，它会一天运行一次。

如果你想在凌晨 2 点一天运行一次，你可以说到明天凌晨 1 点还有多长时间，然后完成。你也可以每小时醒来检查是否真的想要运行代码的其余部分。如果不是就回去睡觉。任何你可以用定时器做的事情你都可以在这里做。

如果你想要并发控制或任何其他确定性控制，你在 TypeScript 中有控制流。你可以检查外部 API，你必须包装在一个步骤中，但你可以进行 fetch 调用如果你想实际检查数据然后从那里确定。

**观众：**所以如果你想要一个每天偶尔运行的智能体，你可以有一个调度包装器调度工作流来启动另一个智能体工作流。

**演讲者：**也可以。你可以从工作流启动工作流，或者你可以这样做，你睡一天然后调用你的智能体，然后根据流你想要的，这都在同一个流中，可能你不想要那个，也许你可以使用可写表允许你做命名空间，你可以在这里获得一个新的可写，然后每次运行时你可以有一个具有确定性名称的新流，你可以选择连接到哪个流。

**观众：**是否有取消逻辑？比如我有东西等待很长时间然后我决定不要那个。我如何停止现有的 sleep 唤醒？

**演讲者：**你可以从可观察性 UI 或从 API 或 CLI 取消你的工作流。所有这些途径都有你可以调用取消。

或者你也可以说我甚至不知道是否想要在变焦结束时睡觉，你可以做一个 await promise race，你可以做 sleep 一天，你可以做其他实际的人工批准，如果人类点击按钮可能会提前醒来。

**观众：**如果你有多个智能体运行，你建议的让它们相互通信的方式是什么？

**演讲者：**这取决于你寻找什么样的通信。

**观众：**触发事情并且它们在工作，但我不确定是否有...

**演讲者：**在步骤中你可以访问所有代码 API 或 Node.js API fetch 等。你可以有一个数据库，如果你想要自动化你自己的数据源，你可以有一个数据库。如果你想要有多个智能体，你可以使用一些相同的流来写入和共享流。

我猜最终取决于我们，在我们的步骤中它们是等幂的，如果它们中途失败时有副作用，那表现良好，那不在你的编排层，那取决于我们。

**演讲者：**对工作流层，我们保证没有副作用，因为如果你试图导入一些有副作用的代码，我认为它只会说无法编译，不要这样做。

**观众：**那对步骤来说是真的，但对于步骤...

**演讲者：**对于步骤，它可以有副作用。这就是重点。

**观众：**所以取决于我们，如果它失败，我们需要确保事务性和可重新运行...

**演讲者：**等幂。有一些错误控制你可以在这里添加，如果一个步骤失败，它通常会失败并带有一个错误，告诉工作流状态布局你可以重试它。你也可以捕获这个错误并说，如果它是这种错误，不要重试它。相反，向人类发信号做些什么或尝试其他途径。

**观众：**你有一个分支具有你刚才做的完整代码吗？

**演讲者：**是的。它们都建立在彼此之上。所以 complete 分支有人工批准工具调用的 sleep 工具调用，可恢复流和使用工作流。我会看看如何发布一般访问权限，只是发推特。

我们会这样做。工作流处于测试阶段。是的，我忘了提到这个重要的工作流开发，我相信我们有一个 GitHub，在生产中使用尤其是持久智能体的东西。在内部我们已经运行了超过 100 万个工作流。一天，主要只是让 API 稳定和一堆问题。但我喜欢的一件事是我们实际上有更多问题。

### (1:00:00 - End) Part 5

如果你需要任何功能或者你真正想看到的东西，我们在 GitHub 讨论中有一个 RFC 部分，用于即将推出的功能，我们将在 GA 或之后不久发布的东西。然后是开放问题，对吧？你可以在那里添加任何问题，我们很快就能解决，或者社区中的某个人会解决。


---

*生成时间: 2026-01-07 14:15:19*
*由 YouTube Monitor & Translator (Claude CLI) 生成*