# DSPy: The End of Prompt Engineering - Kevin Madura, AlixPartners

## 📹 视频信息

- **频道**: AI Engineer
- **发布日期**: 2026-01-08
- **时长**: 1:13:08
- **原始链接**: [https://www.youtube.com/watch?v=-cKUW6n8hBU](https://www.youtube.com/watch?v=-cKUW6n8hBU)

---

> 本文内容整理自 AlixPartners 管理顾问凯文·马杜拉（Kevin Madura）在 AI Engineer 频道的技术演讲。

## TL;DR

DSPy 将 LLM 调用当作函数，通过声明式编程让开发者专注于"要做什么"而非"怎么做"，同时支持优化器自动改进提示词性能，让模型迁移和性能优化变得简单高效。

## 📑 章节导航表

| 时间戳 | 章节标题 | 一句话概括 |
|--------|----------|-----------|
| 00:00-06:00 | 背景介绍与 DSPy 概览 | 介绍 DSPy 作为声明式框架的核心价值和设计理念 |
| 06:00-17:00 | 核心概念详解 | 深入讲解签名、模块、工具、适配器、优化器等六大核心组件 |
| 17:00-31:00 | 多模态与优化器原理 | 展示多模态支持和优化器如何通过迭代改进提示词来提升性能 |
| 31:00-48:00 | 代码演示：基础用法 | 通过情感分类、文档分析等实例展示 DSPy 的快速原型能力 |
| 48:00-01:00:00 | 高级应用：工具调用与异步处理 | 演示工具集成、React 模块和异步并行处理能力 |
| 01:00:00-01:13:00 | 优化实践与问答讨论 | 展示优化器效果并回答关于成本、延迟反馈等实际应用问题 |

## 📊 核心论点

### DSPy 不是优化器优先，而是编程抽象优先

- **核心内容**：Omar（DSPy 创始人）强调："DSPy 不是一个优化器，它是一套编程抽象"。开发者首先获得的价值是能够将 LLM 当作一等公民（first-class citizen）来构建程序，而不是不断调整提示词字符串。优化器只是这种设计带来的额外好处——当你用 DSPy 的方式构建程序后，恰好也能够对其进行优化。
- **关键概念**：声明式编程、LLM 作为函数、编程抽象、模块化设计、可组合性
- **实际意义**：改变了 LLM 应用开发范式，从"prompt engineering"转向"program engineering"，让开发者能够构建可维护、可测试、可优化的 AI 应用。

### 签名（Signatures）是表达意图的核心抽象

- **核心内容**：签名允许开发者通过简单的字符串（如 "text -> sentiment: int"）或 Pydantic 类来定义输入输出，而将具体实现细节留给 LLM。参数名称本身就是提示词的一部分，描述字段提供额外上下文。这种设计让开发者专注于"要什么"而非"怎么做"，极大加速了迭代速度。
- **关键概念**：声明式意图、类型化输入输出、参数名即提示词、Pydantic 集成、快速原型
- **实际意义**：将提示工程从字符串操作提升到类型安全的函数定义，减少了 90% 的样板代码，让非全职工程师也能快速构建复杂应用。

### 适配器（Adapters）实现提示格式的灵活切换

- **核心内容**：适配器在签名和 LLM 调用之间充当翻译器，将高级意图转换为具体的提示格式。研究表明，不同格式（JSON vs BAML vs XML）可以带来 5-10% 的性能差异。BAML 格式相比 JSON 更易读、更节省 token，在复杂场景下表现更好。适配器让开发者能够在不改变程序逻辑的情况下切换提示格式。
- **关键概念**：提示格式化、BAML vs JSON、性能优化、token 效率、格式无关性
- **实际意义**：让开发者能够针对不同模型选择最优提示格式，同时保持代码的整洁和可维护性，为未来的格式创新预留空间。

### 模块化设计支持复杂业务逻辑的优雅实现

- **核心内容**：模块基于 PyTorch 的设计理念，允许开发者将 LLM 调用与传统编程逻辑无缝结合。一个模块可以包含多个签名、硬编码逻辑、数据库操作等。内置模块如 ChainOfThought、React、ProgramOfThought 封装了成熟的提示技术，开发者也可以创建自定义模块来复用业务逻辑。
- **关键概念**：PyTorch 风格、forward 函数、内置提示技术、可组合性、业务逻辑封装
- **实际意义**：让 AI 应用开发从"提示词拼接"进化到"软件工程"，支持构建可测试、可复用、可维护的生产级系统。

### 优化器通过"寻找模型的缝隙"实现性能提升

- **核心内容**：Karpathy 提到 LLM-as-judge 的风险在于模型会找到对抗性样本来"欺骗"评判者。DSPy 优化器正是利用这一特性，通过迭代寻找模型的"缝隙和角落"来优化提示词。研究表明，DSPy 的 JIPA 优化器性能可匹敌甚至超越 GRPO 等微调方法，但成本更低、速度更快。
- **关键概念**：对抗性优化、in-context learning、提示词迭代、latent requirements、成本效益
- **实际意义**：使得从 GPT-4 迁移到更小模型（如 GPT-4-mini）成为可能，在保持 87% 性能的同时降低成本数个数量级。

### 多模态支持让复杂文档处理变得简单

- **核心内容**：通过 attachments 库的集成，DSPy 可以自动处理 PDF、图像、音频等多种格式，自动进行 OCR、格式转换等预处理。开发者只需将文件路径传入签名，无需关心底层细节。演示中展示了对 SEC Form 4 的自动解析和多交易金额计算。
- **关键概念**：attachments 库、自动 OCR、多模态原生支持、格式无关、简化集成
- **实际意义**：将原本需要数百行代码的文档处理流程简化为几行声明式代码，极大降低了多模态 AI 应用的开发门槛。

### React 模块实现优雅的工具调用

- **核心内容**：React 模块将 Python 函数自动暴露给 LLM 作为工具，支持最多 5 轮的工具调用循环。开发者只需定义普通 Python 函数，React 会处理所有的工具描述、参数传递和结果解析。trajectory 对象记录每次调用的完整轨迹，便于调试和审计。
- **关键概念**：工具自动暴露、轨迹记录、循环控制、Python 函数即工具、调试友好
- **实际意义**：让 LLM 能够与外部世界交互（搜索、API 调用、数据库查询等），同时保持代码的简洁性和可追踪性。

### 度量（Metrics）定义优化的成功标准

- **核心内容**：度量可以是严格的相等检查，也可以是基于 LLM 的主观评判。JIPA 优化器特别强大，因为它不仅告诉模型答案错误，还提供文本反馈解释原因。这种"教师反馈"机制让优化循环更紧密，收敛更快。多个度量可以组合使用，优化器会平衡不同目标。
- **关键概念**：objective vs subjective metrics、教师反馈、多目标优化、收敛速度、度量组合
- **实际意义**：让开发者能够精确定义"好"的标准，并自动优化到达这个标准，支持复杂的业务需求如"既要准确又要简洁"。

### 系统思维使模型迁移成为可能

- **核心内容**：DSPy 的设计理念是"系统思维"——程序的控制流和业务逻辑应该独立于底层模型。当新模型发布时，开发者可以保持程序结构不变，通过重新优化来适配新模型。这种可迁移性在模型能力快速迭代的当下尤为重要。
- **关键概念**：模型无关性、控制流保持、意图编码、快速适配、系统稳定性
- **实际意义**：企业可以在新模型发布时快速评估和迁移，避免被锁定在特定模型上，同时保护已有的开发投资。

### 实际应用：从合同分析到文档边界检测

- **核心内容**：演示展示了多个实际用例：(1) 自动检测 13 页合同中主文档与附表的边界；(2) 通过递归摘要处理任意长度文本；(3) 根据文件类型（SEC filing、合同、城市基础设施图片）自动路由到不同处理流程；(4) 时间条目标准化处理数十万条记录。所有这些只需要几十行代码。
- **关键概念**：文档结构理解、自动路由、递归处理、批量标准化、类型检测
- **实际意义**：展示了 DSPy 在真实商业场景中的威力，特别是在处理大量非结构化数据时的效率提升。

## 🏢 提及的公司/产品

| 公司名 | 讨论语境 | 重要性 |
|--------|----------|--------|
| AlixPartners | Kevin 所在的管理咨询公司，将 DSPy 应用于各类客户项目 | ⭐⭐⭐ |
| Anthropic (Claude) | 多模型示例中使用，展示模型切换能力 | ⭐⭐ |
| OpenAI (GPT-4) | 主要演示模型，展示从 GPT-4 到 4-mini 的迁移 | ⭐⭐⭐ |
| Google (Gemini) | 多模态处理的首选模型，特别是图像识别 | ⭐⭐ |
| LangChain | 对比中提到的框架，DSPy 提供更高抽象层级 | ⭐ |
| Pydantic | DSPy 底层使用的类型系统 | ⭐⭐ |
| Arize Phoenix | 用于可观测性和追踪的工具 | ⭐ |
| Nvidia | Form 4 文档分析示例的数据来源 | ⭐ |

## 💬 经典金句

> "It's not optimizers first. It is just a nice added benefit."
> — Kevin Madura

> "DSPy is not an optimizer. It's just a set of programming abstractions."
> — Omar Khattab (DSPy 创始人)

> "The optimizer is finding these nooks and crannies in the model to optimize performance."
> — Kevin Madura

> "You're building a program first. It just happens to also use LLMs."
> — Kevin Madura

## 👤 主要人物

### Kevin Madura

**身份**：AlixPartners 技术顾问
**背景**：非全职工程师，主要从事技术咨询工作，处理各种客户问题如法律调查、流程改进、AI 部署、合同条款识别等
**核心贡献**：通过实际案例展示 DSPy 如何加速 AI 应用开发，强调其在快速迭代和原型构建中的价值，分享了多个真实客户场景的解决方案

### Omar Khattab

**身份**：DSPy 创始人/原始开发者
**背景**：斯坦福大学研究者，专注于 AI 系统设计
**核心观点**：DSPy 的核心是编程抽象而非优化器，强调"系统思维"的重要性，认为程序设计应该独立于模型能力的快速迭代

## 📺 视频类型判断

**教程示范**：技术教学、产品演示

---

## 📝 完整翻译

### (0:00 - 6:00) 背景介绍与 DSPy 概览
> 介绍 DSPy 作为声明式框架的核心价值和设计理念

感谢大家参加今天的分享。我今天要和大家聊的是 DSPI。随时可以提问或者插话，这个演讲很轻松。我不打算用满整个一个半小时，知道这是今天的最后一场，所以保持轻松就好，随时可以提问。我先做一点背景介绍，不会讲太多幻灯片。我在技术上是个顾问，所以必须做些幻灯片，但后半部分我们会深入代码。有个 GitHub 仓库可以下载，大家可以跟着一起操作。

有多少人听说过 DSPI？

几乎所有人，太棒了。有多少人在日常生产环境中实际使用过？三个人，很好。希望今天能多说服一些人使用。

DSPI 的高级概念，这是直接从网站上摘的，它是一个声明式框架，用于构建模块化软件。对我这样的人来说最重要的是，我不是每天都在写代码的工程师。如前所述，我更像是技术顾问。我会遇到各种不同的问题，可能是为律师事务所做调查，可能是帮助公司理解如何改进流程、如何内部部署 AI，也许需要查看一万份合同来识别特定条款或段落。DSPI 对我个人和我的团队来说是一个很好的方式，能够快速迭代构建这些应用程序。

最重要的是构建程序。这不是在提示词上迭代和来回调整，而是构建一个真正的 Python 程序，DSP 是实现这一点的好方法。

之前提到的，如果你想现在下载仓库并设置好一切，这里有在线仓库。稍后我会把这个放到屏幕上。如果你想去这里下载一些代码，这是在过去几天里整理的，所以不会是完美的生产级代码，更多是一些工具和小功能，用来演示今天我们要讨论内容的实用性和要点。我们会走过所有这些不同的用例：情感分类器、处理 PDF、一些多模态工作、一个非常简单的网络研究 agent、检测 PDF 文档边界、如何总结任意长度的文本，然后进入用 Jeepo 的优化器。

但在此之前，先设定一下基调。对我个人来说，DSP 最大的特点是它是一个很好的方式，将你的逻辑分解为一个将 LLM 视为一等公民的程序。归根结底，你基本上就是在调用一个函数，这个函数底层恰好是 LLM，DSPI 为你提供了一个非常好的直观简单的方式来实现这一点，并对输入和输出类型提供一些保证。当然有结构化输出，当然还有其他方法来做这件事，Pyantic 和其他工具。但 DSPI 有一套原语，当你把它们组合在一起时，允许你构建一个连贯的模块化软件，然后你恰好能够优化它。

我这么推崇它的几个原因：它处在一个非常好的抽象层级上。我觉得它不像 LangChain 那样阻碍你的工作。这不是在贬低 LangChain，只是 DSPI 的结构化方式是不同的范式，让你专注于真正重要的事情。你不需要写 choices zero messages content，不需要做字符串解析，不需要在底层做一堆工作。你只是声明你的意图，声明你希望程序如何运作，你希望输入和输出是什么。

### (6:00 - 17:00) 核心概念详解
> 深入讲解签名、模块、工具、适配器、优化器等六大核心组件

正因为如此，它让你能创建计算机程序。如前所述，不只是调整字符串然后来回发送，你首先是在构建一个程序，只是恰好也使用了 LLM。这里最重要的一点是，Omar KB，这个框架的创始人或原始开发者，在 A16Z 的播客中说得很好，我想那期节目就在两三天前发布。他说这是用系统思维构建的，真正关于你如何编码或表达你想要做什么的意图，最重要的是以一种可转移的方式。我想你的系统或程序的设计不会像底层模型能力那样变化得那么快。当我们几乎每天都看到新发布、不同能力、更好的模型时，DSPI 允许你以一种保留控制流、保留系统和程序意图的方式来构建，同时允许你根据需要在不同模型之间切换。

便利性是免费的。不需要解析 JSON 之类的东西。它处在一个很好的抽象层级上，你仍然可以理解底层发生了什么。如果你想，可以深入调整，但它让你专注于你想要做的事情，同时保持我认为我们大多数人在构建程序时希望拥有的精确度。如前所述，它对模型和范式转变很鲁棒。你可以保持程序的逻辑，但让这些 LLM 基本上保持在线。话虽如此，绝对还有其他优秀的库。Pedantic AI、Langchain，还有很多其他的允许你做类似事情的库。Agno 是另一个。这只是一个角度，可能不适合你的用例。

对我来说，我花了一点时间才理解 DSPI 是如何工作的，你马上就会明白为什么。我建议保持开放的心态，玩弄一下，运行代码，调整代码，做任何你需要做的事情，看看它如何适用于你。这个演讲更多是关于我发现它有用的方式，这不是关于 DSPI 每个细节的论文，更多是，我自己遇到了这些问题，现在我自然而然地转向 DSPI 来解决它们。这就是为什么。希望你能将其中一些推广到自己的用例中。

我们会相当快地讲完所有内容，但 DSPI 的核心概念实际上归结为屏幕上看到的这五个或六个。我们会详细讨论每一个，但高级别的签名指定你希望函数调用做什么。这是你指定输入和输出的地方。输入和输出都可以是类型化的，你将其余的基本实现推迟给 LLM。

模块本身是逻辑结构化程序的方式。它们基于签名。一个模块可以在其中嵌入一个或多个签名，还有额外的逻辑。它基于 PyTorch，在结构化方法论方面。工具我们都熟悉工具 MCP 和其他的，从根本上说，DSPI 看待工具就是 Python 函数。这是一个非常简单的方式，让你能够非常容易地将 Python 函数暴露给 DSPI 生态系统中的 LLM。

适配器存在于你的签名和 LLM 调用本身之间。我们都知道，提示词最终只是发送给 LLM 的文本字符串。签名是你在更高层次表达意图的方式。适配器是位于这两者之间的东西，它是你将输入和输出翻译成格式的方式，基本上从你的初始签名爆炸出来，成为最终发送给 LLM 的提示词的格式。

有一些研究或辩论，某些模型在使用 XML 作为例子或 BAML 或 JSON 或其他格式时表现更好。适配器为你提供了一个很好的简单抽象，基本上可以随意混合和匹配这些。

优化器是 DSP 最有趣的，也不知为何是最有争议的部分。这是人们想到的第一件事，至少当他们听到 DSP 时，他们想到优化器。我们马上会看到一个引用。这不是优化器优先。这只是一个很好的额外好处和 DSPI 提供的一个很好的能力，除了用签名和模块等结构化程序的能力。指标与优化器结合使用，基本上定义了如何衡量 DSPI 程序中的成功。优化器使用指标来确定是否找到了正确的路径。

如前所述，签名是你表达意图的方式，你的声明性意图可以是超级简单的字符串，这对我来说最初是最奇怪的部分，但现在是最强大的部分之一，或者可以是更复杂的基于类的对象，如果你使用过 Pyantic，这基本上就是它在底层运行的东西。

这是基于类的签名的一个例子。它基本上就是一个 Pyantic 对象。超级有趣的是，字段名称本身几乎像小型提示词一样。它是提示词本身的一部分。你马上就会看到这如何发挥作用。但最终从这样的东西传递给模型的是，它会说好的，你的输入将是一个叫做 text 的参数，它基于这个类中特定参数的名称。所以这些东西实际上被传递了。所以以一种对模型来说直观易于理解的方式命名参数是非常重要的。你可以在描述字段中添加一些额外的上下文或其他内容。

大部分，如果不是全部，这是适当的类型化 Python 代码，但它也几乎像一个最终输入到模型中的提示词。这基本上通过适配器的使用来翻译。突出显示的这些，有点深色和粗体的，这些东西实际上是提示词的一部分，被发送进去，你会看到 DSPI 如何处理所有这些，并以一种方式格式化，让你只需要担心你想要什么。担心构造你的签名，而不是想办法在提示词中最好地措辞。

有人想提问吗？

我有一个非常好的提示词。

当然，那我不想要这个东西。

完全正确。

所以在线朋友们的问题是，如果我已经有一个很棒的提示词呢？我已经做了所有这些工作，我是一个出色的提示词工程师，我不想我的工作消失或其他什么。是的，你绝对可以从自定义提示词或你已经证明效果很好的东西开始。你完全正确，这可以在文档字符串本身中完成。还有一些其他方法让你基本上注入系统指令或在最终提示词的某些部分添加额外的东西，当然你也可以在最终字符串中注入它。我的意思是这只是由 DSPI 构造的字符串。所以绝对地，这不一定阻止你，不会阻止你添加你已经有的超级提示词。绝对可以。正如你所说，它可以作为一个很好的起点来构建系统的其余部分。

这里是同样内容的简写版本，对我来说第一次看到这个时非常困惑。但它就是这样工作的，你基本上再次将实现或逻辑或其他东西推迟给 DSPI 和模型，让它们基本上弄清楚你想要做什么。在这种情况下，如果我想要一个超级简单的文本情感分类器，这基本上就是你需要的全部。你只是在说，好的，我要给你文本作为输入，我想要情感作为整数作为输出。现在你可能想指定一些额外的指令来说好的你的情感，较低的数字意味着负面，较高的数字是更积极的情感等等。但它给你一个很好的简单方式来搭建这些东西，你不必担心从手工创建这整个提示词。就像好的我只想看看这如何工作，然后如果它工作了，我可以添加额外的指令，然后我可以从中创建一个模块或其他任何东西。这种简写使得实验和迭代变得非常快。

### (15:00 - 30:00) Part 2

当你使用这些不同的原语来解构你的业务逻辑或你想要实现的任何目标时，这一切都旨在协调配合并流畅运行。我们稍后会讲到优化器，但至少对我和我的团队的经验来说，能够逻辑地分离程序的不同组件，但基本上内联LLM调用对我们来说是非常强大的。这只是一个额外的好处，因为我们基本上处于DSPI范式中，最终我们也能够优化它。

它内置了一堆标准模块。我不太经常使用底部的一些模块，虽然它们非常有趣。顶部的基础模块就是DSpi.predict。这就是一个LM调用，就是一个普通的调用。思维链现在可能不太相关了，因为模型已经解决了这些问题，但它是一个很好的例子，展示了可以内置到这些模块中的提示技巧类型。它基本上只是添加一些文献中的字符串，比如说"让我们一步步思考"或其他类似的内容。

React和CodeAct也是如此。React基本上是你向模型暴露工具的方式。它在底层包装和处理一些事情，基本上是获取你的签名并注入你给它的Python函数作为工具，React就是你在DSP中进行工具调用的方式。

Program with Thought相当酷。它强制模型用代码思考，然后返回结果。你可以给它内置的Python解释器，但如果你想要的话，也可以给它一些自定义的解释器或某种类型的自定义工具。我没有太多使用这个，但它非常有趣。如果你有高度技术性的问题或工作流程，想要模型在管道的某些部分注入代码推理，这是一种非常简单的方法。其他一些模块基本上就是比较输出或并行运行的不同方法。

### (17:00 - 31:00) 多模态与优化器原理
> 展示多模态支持和优化器如何通过迭代改进提示词来提升性能

这是一个例子的样子。再次，它相当简单。归根结底它是一个Python类。你在顶部进行一些初始化。在这种情况下，你看到的是上面的简写签名。为了给你一些背景，这个模块是从存储库中的一个Python文件中摘录的，基本上是接收一堆时间条目并确保它们遵循某些标准，确保内容正确大写或句子末尾有句号等等。

这来自一个真实的客户用例，他们有数十万个时间条目，需要确保它们都遵循相同的格式。这是一种非常优雅的方法，至少在我看来是这样的。在顶部你可以定义签名。它添加了在其他地方定义的一些额外指令，然后说对于这个模块，change tense调用将只是一个普通的predict调用。当你实际调用模块时，你进入forward函数，你基本上可以穿插LLM调用（第一个）然后在下面做一些硬编码的业务逻辑。

如我之前提到的，工具就是普通的Python函数。这是DSP的工具接口。在底层，DSPI使用light LLM。因此需要两者之间的某种耦合，但从根本上说，你在其他地方使用的任何类型的工具，你也可以在DSPI中使用。这对你们大多数人来说可能很明显，但这里是一个例子。你有两个函数，get_weather和search_web。你将它们包含在签名中。在这种情况下，我说签名是我要给你一个问题，请给我一个答案。我甚至没有指定类型。它会推断出这意味着什么。我给它get_weather和search_web工具，我说，好的，做你的事情，但只进行五轮，这样它不会失控做一些疯狂的事情。这里的调用就是调用我上面创建的React代理，问题是"东京的天气如何？"我们会在代码会话中看到这个例子，但基本上这会给模型提示词、工具，让它做自己的事情。

适配器，在我稍微介绍之前，它们基本上是提示格式化器。文档中的描述可能说得最好。它获取你的签名、输入和其他属性，并将它们转换为你指定的或适配器指定的某种消息格式。作为例子，JSON适配器采用我们之前定义的pydantic对象，这是发送到LLM的实际提示。你可以看到输入字段，这会被定义为clinical note类型字符串，patient info作为patient details对象，这会在其他地方定义，然后这是patient info的定义。它基本上是该pydantic对象的JSON转储。

主持人：这个想法是有一个基础适配器默认值，对大多数情况都很好，这是如果你想调整它做一些更具体的事情。

正确。问题是是否有基础适配器，这是否是你想做一些具体事情的例子？答案是肯定的。

Pashant这个人很棒，我在演示末尾有他的Twitter。他做了一些测试，比较JSON适配器和BAML适配器。你可以直观地看到，即使对我们人类来说，这种格式方式更直观一些。考虑到这里杂乱的JSON与这里格式稍好的BAML，它可能在token效率上也更高。根据你的用例，实际上可以提高5到10%的性能。这是如何以不同方式格式化内容的一个好例子。程序的其余部分根本不会改变。你只需指定BAML适配器，它就完全改变了信息在底层向LLM呈现的方式。

多模态。这显然更多是在模型层面，但DSPI默认支持多种模态。图像、音频和其他一些。同样类型的东西，你只需将它们作为签名的一部分输入，然后可以获得非常好的清洁输出。这让你能够非常、非常、非常容易和快速地使用它们。

对于那些眼尖的参与者，你可以看到第一行是attachments。这可能是一个不太知名的库。Twitter上另一个很棒的人，我想是Maxim。他创建了这个库，基本上是一个处理不同类型文件并将其转换为与LLM超级容易使用格式的万能工具。他也是DSPI的大粉丝。所以他基本上制作了一个专门针对此的适配器。但这就是提取图像、PDF或任何内容所需的全部。你会看到一些例子，它至少让我的生活变得超级、超级容易。

这是同样内容的另一个例子。这是Form 4表格的PDF。你知道，来自英伟达的公开SEC表格。在顶部我只是给它链接。我说，好的，attachments，做你的事情。下载它，创建图像，你要做什么都行。我不需要担心它。我不在乎它。这是超级简单的RAG，但基本上，我想对这个文档做RAG。我要给你一个问题。我要给你文档，我想要答案。你可以看到这有多简单。就是直接输入文档。

卖出了多少股票？有趣的是，我不确定是否容易看到，但你这里实际上有两笔交易。所以它可能必须在底层做一些数学运算。你可以在这里看到思考过程和最终答案。

主持人：在RAG步骤中，它是创建某种向量存储还是创建嵌入并在其上搜索？后台是否有很多事情在进行？

这是简陋版的RAG。我应该澄清一下。这实际上就是提取文档图像，我认为attachments会在底层做一些基本的OCR。但除此之外它什么都不做。就是这样。我们在这里输入的所有内容，被输入的实际文档对象，实际上就是被OCR的文本。图像，模型做其余的工作。

优化器非常强大，是一个非常有趣的概念。有一些研究表明，在某些情况下，对于某些模型的某些情况，它的性能与微调一样好，如果不是更好的话。有所有关于上下文学习等的研究。所以无论你是否想进行微调并做所有那些，没有什么阻止你。但我建议至少先尝试这个，看看在不必设置大量基础设施的情况下你能走多远，看看优化器如何工作。

但从根本上说，它允许你做的是DSPI为你提供了测量和定量改进性能所需的原语和组织。我之前提到过可转移性。这种可转移性可以说是通过使用优化器实现的，因为如果你能得到好的分类任务，在4o上效果很好，但可能有点昂贵，因为我必须每天运行一百万次。我能在4o nano上尝试吗？好的，也许是70%的性能。但我在4o nano上运行优化器，我可以将性能提高回87%。也许这对我的用例来说是可以的，但我现在刚刚将我的成本降低了几个数量级。

是优化器让你能够做这种模型和用例的可转移性。但它在底层真正做的就是迭代地优化或调整底层的那个提示字符串。因为你使用不同的模块构建了程序，DSPI在底层为你处理所有这些。所以如果你用多个模块组成一个程序，并对所有这些进行优化，DSPI本身会优化各种组件以改善输入和输出性能。

我们从Omar本人那里了解到，DSPI不是一个优化器。我已经多次说过这一点。它只是一套编程抽象或编程方式。你只是碰巧能够优化它。再次，我和我的团队获得的价值主要来自编程抽象。这只是一个令人难以置信的额外好处，如果你选择的话，你也能够在之后优化它。

我前几天在听Dhruv和Karpathy的对话，这正好击中了要害。我在为这次演讲做准备时想到了优化器。比我聪明的人可以纠正我，但我认为这是有道理的，因为他基本上在谈论使用LLM作为评判者可能是一件坏事，因为被评判的模型可以找到对抗性例子并降低性能，或者基本上创造一种评判者没有正确评分的情况。因为他说模型会找到这些小裂缝。它会在巨大模型的角落和缝隙中找到这些小的虚假东西，并找到欺骗它的方法。基本上说LLM作为评判者只能走这么远，直到另一个模型找到那些对抗性例子。如果你颠倒过来，DSP优化器正是利用这种特性来优化，在模型中找到角落和缝隙，无论是更大的模型还是更小的模型，来改善你数据集上的性能。所以这就是优化器在做的事情，找到模型中的这些角落和缝隙来优化和改善性能。

典型的流程，我不会在这上面花太多时间，但相当合乎逻辑。构造程序，将你的逻辑分解为模块。你使用你的指标来定义程序工作方式的基本轮廓，然后你通过优化所有这些来获得最终结果。

Chris Potts几天前刚有的另一个演讲，他提出了这个观点，这就是我之前提到的，Deepa（你可能看到了前几天的一些演讲）的优化器与GRPO（另一种微调方法）的性能相当或超越。所以相当令人印象深刻。我认为这是一个活跃的研究领域。比我聪明得多的人，如Omar和Chris等人正在引领这个方向。但重点是，我认为提示优化是一个相当令人兴奋的领域，如果没有别的，也值得探索。

最后，指标再次是这些构建块，让你定义优化器成功的样子。这就是它使用的，你可以有很多这些，我们会看到这样的例子。在高层次上，你的程序处理输入和输出，优化器将使用指标来理解，我在提示中的最后一次调整是否改善了性能，是否降低了性能，你定义指标的方式为优化器提供了直接反馈。

这是另一个例子，一个来自我之前提到的时间条目例子的超级简单的例子。指标可以是相当严格的，比如这等于1或某种相等性检查，或者更主观一些，使用LLM作为评判者来说生成的字符串是否遵循这些各种标准。但这本身可以是一个指标。

所有这些都是说，这是一种冗长的方式来说，在我看来，这可能是你构建任意复杂的工作流程、数据处理管道、业务逻辑或任何可能的东西所需要的大部分或全部。与LLM工作的不同方式。如果没有其他，DSPI为你提供了构建这些模块化、可组合系统所需的原语。

### (30:00 - 45:00) Part 3

如果没有其他，DSPI为你提供了构建这些模块化、可组合系统所需的原语。

如果你对一些在线人员感兴趣，这里还有很多很多。还有一个Discord社区。但通常这些人都掌握着最新最棒的技术，所以推荐关注他们。你不需要关注我，我不怎么发表内容，但其他那些人真的非常不错。

好的，现在到了有趣的部分，我们将实际接触一些代码。如果你还没有机会，现在是获取代码仓库的最后机会。

### (31:00 - 48:00) 代码演示：基础用法
> 通过情感分类、文档分析等实例展示 DSPy 的快速原型能力

我会介绍我们刚才讨论的几个不同示例。

好的，我会设置Phoenix，这是来自Arise的一个可观察性平台。我今天刚配置的，所以不知道是否会正常工作，但我们来试试看。基本上它允许你对所有后台调用进行观察和跟踪。我们看看这是否有效，再给它5秒钟时间。

它应该会自动为我处理所有这些事情。好的，我们看看。好的，有些问题。很好。

我将浏览这个笔记本，这是一系列不同用例的集合，基本上是将我们刚刚看到的内容付诸实践。请随时提出任何问题。我们从这个笔记本开始，之后还有几个更正式的Python程序要介绍。但真正的目的是快速回顾DSPI对我和其他人有用的不同方式。

加载环境文件。通常我会有这样的配置对象，这样我可以很容易地在后面使用它们。比如我要进行模型混合，如果我有一个超级复杂的问题或某个工作负载需要推理模型的强大功能，比如GPT-5或其他类似的模型，我会定义多个LM。一个是4.1，一个是5，也许我会用4.1 nano、Gemini 2.5 flash等等。然后我可以根据我的判断或对工作负载的合理预期来混合或穿插使用它们。

你会看到这在分类和其他方面的应用。我会引入其他几个。我使用Open Router来做这个，所以如果你有Open Router API密钥，建议你接入。现在我有三个不同的LLM可以使用：Claude、Gemini和4.1 mini。然后我会基本上问每个模型：Google、Anthropic、OpenAI哪个最好。它们都有些模糊，说是主观的、未定义的。好吧，这不是很有帮助。

但因为DSPI基于Pydantic工作，我可以将答案定义为字面量。我基本上强制它只给我这三个选项，然后我可以遍历每个选项。你可以看到每个模型当然都选择了自己的组织。

这些响应返回如此之快的原因是DSP在底层自动进行了缓存。只要你的签名定义或基本上任何东西都没有改变，这对测试非常有用，它会直接从缓存加载。我之前运行过这个，所以它们返回得如此迅速。这是另一个非常有用的功能。

确保我们正在运行。如果我把这个改成带空格的hello，你可以看到我们正在进行实时调用。很好，我们还在运行。

超级简单的类情感分类器。显然这可以构建成任意复杂的东西。让我把它放大一点。我基本上给它文本和你之前看到的情感，并添加额外的规范，说较低的值更消极，较高的值更积极。

我将把这定义为我的签名，传递给一个超级简单的预测对象。然后我说，"这家酒店很糟糕"。好的，这可能相当消极。现在如果我改成"我感觉很开心"。

好在我现在不在酒店。你可以看到"我感觉很开心"得到了8分。这可能看起来不那么令人印象深刻，确实不是，但重要的是它展示了简写签名的使用。我有字符串，有整数，传入自定义指令，如果使用基于类的方法，这些指令会在文档字符串中。

DSPI另一个有趣或有用的部分是它内置了大量使用信息。因为它被缓存了，所以会是一个空对象。但当我改变它时，你可以看到我现在使用的是Azure，但对于每次调用，你都会得到这样的详细分解。

我觉得这来自Late LLM，但它让你很容易跟踪你的使用情况、token使用等，用于可观察性和优化。这些都是其中的小贴士。

我们在幻灯片中看到过之前的例子，但我要在线获取那个Form 4。我将使用附件创建这个文档对象。你可以看到它在底层做的一些事情。它提取了PDF plumber，从中创建了markdown，提取了图像等等。同样，我不必担心所有这些，附件让这变得超级简单。

我要展示我们正在处理的内容。在这种情况下，我们有Form 4。然后我要做我之前提到的穷人版RAG。很好，总共卖了多少股票？它会经历整个思考链并返回响应。

这很好，但在我看来DSPI的强大之处在于你可以拥有这些任意复杂的数据结构。这很明显，因为它使用Pydantic和其他一切，但你可以在这方面有点创意。在这种情况下，我要说，好的，一种不同类型的文档分析器签名。我只给它文档，然后我让模型定义它认为文档中最重要内容的结构。

在这种情况下，我定义了一个字典对象，所以它希望能以结构化的方式返回描述文档重要信息的一系列键值对。你可以在这里看到，这可能是缓存的，但我传入了 - 在这种情况下我在一行中完成了所有操作 - 但我说我想使用文档分析器签名进行思维链，我要传入输入字段，这里就是文档。

我要传入之前得到的文档。你可以看到这里它以超级结构化的方式提取了大量很棒的信息。我不必真正思考它，我只是将所有这些延迟给模型和DSPI来处理。

当然，你可以反过来说，好的，我有一个非常具体的业务用例。在格式或我想从文档中获取的内容方面，我有特定的东西。我将其定义为典型的付费类。在这种情况下，如果有多个交易，我想提取架构本身的重要信息，比如提交日期。

我要定义文档分析器架构签名。再次超级简单的输入字段，就是文档本身，由附件解析给我文本和图像，然后我传入文档架构参数，它有上面定义的文档架构类型，这基本上是你传递给结构化输出的内容，但只是用DSPI的方式做，它会给你特定格式的输出。

你可以看到它很好地提取了信息：提交日期、表单日期、表单类型、交易本身，然后最终答案。这很好，因为它以一种你可以使用点符号的方式暴露它。所以你可以很快地访问结果对象。

查看适配器，我会使用DSPI的另一个小功能，即检查历史。对于那些想知道底层发生了什么的人，检查历史会给你实际发生的原始转储。你可以在这里看到在底层构造的系统消息是所有这些。你可以看到输入字段是文档输出字段，或推理和架构。它会传递这些。

然后你可以在这里看到被提取并放入文本和提示的实际文档内容，带有一些元数据。这全部由附件生成。然后你得到遵循这种特定格式的响应。

你可以看到这里的不同字段。这是一种相对任意的响应格式，用于名称，然后由pie解析并作为用户传回给你。我可以执行response.document架构并获得实际结果。

为了展示BAML适配器的样子，我们基本上可以进行两个不同的调用。这是我在线朋友Pashant的一个例子。我们在这里做的是定义Pydantic模型超级简单的一个：患者地址，然后患者详细信息。患者详细信息在其中包含患者地址对象。

然后我们要说我们要创建一个超级简单的DSPI签名，采用临床笔记，这是一个字符串。患者信息是输出类型。我将以两种不同的方式运行这个。第一次使用我之前提到的智能LLM，只使用内置适配器。我在那里没有指定任何东西。

第二个将使用定义在那里的BAML适配器。这里有几件事在进行。一个是使用Python上下文的能力，即以with width开始的行，它允许你基本上跳出全局LLM定义并仅为该调用使用特定的LLM。

你可以在这种情况下看到我使用相同的LM，但如果我想将其更改为lm anthropic或其他什么，我认为那应该有效。但基本上它所做的只是将该调用卸载到你为该特定调用定义的其他任何LLM。

我们有两个独立的调用。一个是对智能LLM的，我认为是4.1。另一个是对Anthropic的。其他一切都完全相同。笔记完全相同等等。我们得到了完全相同的输出。这很好。

但我想在这里展示的是适配器本身。在这种情况下，我做检查历史等于2。我将获得最后两个调用。我们将看到提示会如何不同。你可以在这里看到第一个，这是内置的JSON架构，这个疯狂长的JSON字符串。LLM足够好来处理这个，但对于超级复杂的可能就不行了。然后你在这里看到第二个，它使用BAML记号，正如我们在幻灯片中看到的，更容易理解。在超级复杂的用例中实际上可以有可测量的改进。

### (45:00 - 1:00:00) Part 4

这可以是任何类型的任意业务逻辑或控制流程，或任何数据库操作等等。当这个图像分析器类被调用时，这个函数就会运行，然后当你实际调用它时，这就是它实际运行核心逻辑的时候。你可以看到我正在传入参数，我实例化了分析器AIE123，然后我会调用它。

很好。它调用了那个，你可以看到计数器在我每次实际进行调用时递增。这是一个非常简单的例子。我们没有太多时间，但我会向你展示一些其他模块以及它们是如何工作的。

在工具调用方面相当直接。我要定义两个不同的函数：perplexity搜索和获取URL内容，创建一个bioagent模块。这将定义Gemini 25作为这个特定模块的LLM。它将创建一个答案生成器对象，这是一个react调用。所以我基本上会在调用时进行工具调用，然后forward函数字面上就是用提供给它的参数调用那个答案生成器。然后我也创建了该函数的异步版本。

所以我可以在这里这样做。我要说好，识别特定人员在他们公司工作超过10年的实例。它需要进行工具调用来获取最新信息。所以它基本上在循环中进行，它将调用那个bio agent，它在后台使用工具调用，并将根据我的标准确定他们的背景是否适用。在这种情况下，Satia是真的，Brian应该是假的。但这里有趣的是，在运行时，类似于你从思维链中得到的推理对象，你可以从像react这样的东西中得到轨迹回馈。

### (48:00 - 1:00:00) 高级应用：工具调用与异步处理
> 演示工具集成、React 模块和异步并行处理能力

所以你可以看到它调用什么工具，传入的参数，以及每个调用的观察结果，这对于调试和其他明显的其他用途很有用。我想讲到其他内容，所以我要加快完成剩下的部分。这基本上是同一件事的异步版本。所以你会并行运行它们两个，同样的想法。

我要跳过JEPA示例一下。我可以向你展示输出是什么样的，但基本上它在做的是创建一个数据集。它向你展示数据集中有什么。它正在创建各种签名。在这种情况下，它将创建一个系统，对数据集中不同的帮助消息进行分类和归类。

比如"我的同步坏了"或"我的灯坏了"之类的。它们想要分类这是积极的、中性的还是消极的，以及实际消息的紧急程度。它要对其进行分类，然后将所有这些东西、所有这些不同的模块打包到单个支持分析器模块中。然后从那里，它要做的是定义一堆基于数据集本身的指标。所以它会说，好的，我们如何评分紧急程度？这是一个非常简单的，它要么匹配要么不匹配。还有其他一些可能更主观的，然后你可以运行它。这需要太长时间，可能需要20分钟左右。

但它基本上会评估基础模型的性能，然后应用这些指标，并迭代地想出新的提示来创建那个。现在我想在这里暂停一下，因为有不同类型的指标，特别是对于JEPA，它使用来自教师模型的反馈。所以它可以与相同级别的模型一起工作，但特别是当你试图使用较小的模型时，它实际上可以提供文本反馈。所以它不仅说你分类错了，还会给你一些额外的信息或反馈，如你在这里看到的，为什么它错了或答案应该是什么。

这使得它，你可以读论文，但它基本上使它能够迭代地找到应该如何调整提示以基于该反馈优化它的帕累托前沿。它基本上只是收紧了迭代循环。你可以看到这里有很多。然后你可以运行它并看看它如何工作。但只是给你一个具体的例子，说明它们如何结合在一起。

所以我们从之前拿了一堆那些例子。我们基本上要做一些分类。所以我有合同、图像、一个DSPI程序可以理解和进行某种处理的不同东西。

所以这是我们在客户情况下经常遇到的事情，他们有一大堆文件。他们不知道里面有什么。他们想找到一些东西，也许想找到SEC文件并以某种方式处理它们。他们想找到合同并以某种方式处理这些。也许那里有一些图像，他们想以某种方式处理这些。这是你如何做到这一点的例子，如果我从底部开始，这是一个常规的Python文件。它使用DSPI来做我刚才提到的所有那些事情。

所以我们正在拉取配置，设置常规LM，我们用于图像的小型LM。例如，Gemini模型可能在图像识别方面比其他模型更好。

所以我可能想要推迟或为特定工作负载使用特定模型。所以如果我检测到图像，我会将请求路由到Gemini。如果我检测到其他东西，我会路由到4.1或其他任何东西。所以我要处理单个文件。它所做的是使用我们便捷的附件库将其放入我们可以使用的格式中。然后我要对其进行分类。这里不是很明显，但我从这个分类文件函数调用中获得文件类型。然后我根据文件类型做一些不同类型的逻辑。

所以如果是SEC文件，我做某些事情。如果是某种类型的SEC文件，我做别的事情。如果是合同，也许我会总结它。如果它看起来像城市基础设施，在这种情况下，我们之前看到的图像，我可能会对其进行更多的视觉解释。

如果我快速深入分类文件，它正在运行文档分类器。所有这些基本上都是对文件中的图像进行预测，并确保它返回一个类型。这返回一个文档类型，所以你可以在这里看到，最终它是一个相当简单的签名，我们基本上所做的是在这种情况下获取PDF文件，从中获取所有图像，获取第一个图像或前几个图像，在这种情况下是图像列表作为输入字段，我说好，只需给我类型，这是什么，我给它这些文档类型的选项。

显然这是一个相当简单的用例，但它基本上是说，给定这三个图像，文档的前三页，它是SEC文件吗？是专利文件吗？是合同城市基础设施吗？这些是相当不同的东西，所以模型在任何这些方面都不应该有问题。

然后我们有一个其他的通用桶，然后如我之前提到的，根据你得到的文件类型，你可以不同地处理它们。所以我使用小模型来做我们之前看到的相同类型的form4提取，然后在这种情况下基本上断言它是我们认为的那样。对于合同，在这种情况下我们说，我有大约10分钟时间，所以我们可以继续，我们将在这个文件之后停止，但对于特定合同，我们将创建这个总结器对象。

所以我们会遍历尽可能多的页面。我们会使用单独的DSPI函数对其进行一些基本的递归总结，然后我们也会检测该文档的某种边界。所以我们会说我想要总结，我想要文档的边界，然后我们会打印出这些东西。

所以让我看看我是否可以运行这个。它要分类，应该作为合同。

**主持人：** 所以你只是依靠模型本身来意识到这是城市基础设施？

**演讲者：** 是的。问题是我只是依靠模型来确定它是否是城市基础设施。是的。我是说这更像是一个研讨会的快速简陋例子。这只是因为有一张街道标志的图片。如果我们查看数据文件夹，我有一个合同、一些不相关的图像、SEC文件的表单，然后是停车。它们非常不同。在我给它的那些类别中，模型应该没有问题正确地对其进行分类。

在某种生产用例中，你会想要更严格的或者甚至多次分类，也许使用不同的模型来做到这一点。但是的，给定这些选项，至少在我运行的许多次中，都没有问题。所以在这种情况下，我给它其中一个合同文档，它在后台运行了一些额外的总结逻辑。如果我快速查看，你可以在代码中找到所有这些，但基本上它做的是使用三个独立的签名来基本分解合同的内容，然后总结它们。所以它基本上只是迭代地处理文档的每个块，创建你在底部看到的总结。

### (1:00:00 - End) Part 5

### (1:00:00 - 1:13:00) 优化实践与问答讨论
> 展示优化器效果并回答关于成本、延迟反馈等实际应用问题

**问题参与者：** 那么在底层，DSP的美妙之处在于它对模型强制执行了某种结构化输出。

**演讲者：** 我觉得这可能过于简化了它的全部潜力，但总体来说是正确的。是的，你可以使用结构化输出，但基本上你必须做一堆繁琐的工作来协调，比如将所有这些输入到程序的其余部分。也许你想以不同的方式调用模型，或者在这里使用XML，或者使用不同类型的模型等等来实现这一点。所以绝对是的，我不是说这是创建这些应用程序的唯一方式，或者你不应该使用Pydantic或不应该使用结构化输出。你绝对应该用。这只是一种方式，一旦你掌握了DSPI提供的基本元素，你就可以开始非常快速地构建这些类型的...我是说，这些现在还像是原型，但如果你想将其提升到生产规模的下一个级别，你面前就有了所有能够做到这一点的组件。

还有其他问题吗？我大概还有五分钟时间。请说。你能谈谈你使用优化的经验吗？

是的。我会拉起一个...我在这之前刚运行了一个。这使用了一个叫做mypro的不同算法，但基本上优化器，只要你有结构良好的数据...对于房间里的机器学习专家，这里大概每个人都是，显然你的数据质量非常重要。你不一定需要成千上万的例子，但只要你有足够的，也许10到100个输入和输出。如果你以一种相对直观的方式构建你的指标，并且准确描述了你试图实现的目标，改进可能会相当显著。

那个我之前提到的时间条目纠正器，你可以在这里看到输出。它在迭代通过，测量每一个的输出指标。然后你可以看到在底部，一旦它完成了所有的优化工作，你可以看到基础模型与优化模型的实际性能对比。在这种情况下，从86提升到89。有趣的是，这个还在开发中，但你可以按指标分解。所以你可以看到模型在某些指标上优化得更好，性能更好。这对于你是否需要调整指标、也许需要分解指标、或者在数据集或程序结构的其他区域可以改进的地方，非常有说明意义。这是一种真正了解底层发生什么的好方法。如果你不关心其中一些，优化器在这些方面做得不好，也许你也可以抛弃它们。所以这是一个非常灵活的系统，处理所有这些的灵活方式。

**问题参与者：** 优化的输出是什么？你从中得到什么，然后如何使用那个对象，无论它是什么？

**演讲者：** 优化器的输出基本上就是另一个...这几乎像一个编译对象。DSPI允许你保存和加载程序。所以优化器的输出基本上就是一个模块，然后你可以序列化并保存在某个地方，或者你可以稍后调用它，就像你调用任何其他模块一样。

**问题参与者：** 它只是在操作提示的措辞吗？比如它实际的解决空间是什么样的？

**演讲者：** 在底层，它实际上就是在迭代实际的提示本身。也许它在添加额外的指令。它在说："好吧，我在这个特定的事情上一直失败，比如没有正确地将名字首字母大写。我需要在提示的前期标准中添加一个指令给模型，说你必须正确地将名字首字母大写。"

我之前提到的Chris有一个很好的表达方式，我现在要搞砸了，但优化器基本上是在寻找你最初可能没有预先指定的潜在需求，但基于数据，它有点像穷人的深度学习，但它在从数据中学习。它在学习什么做得好，什么做得不好，它在动态构建一个基于你的指标改善性能的提示。

**问题参与者：** 这是LLM引导的吗？比如关于大写化？

**演讲者：** 问题是这全部都是LLM引导的吗？是的。特别是对于JEPA，它使用LLM来改善LLM的性能。所以它使用LLM来动态构建新的提示，然后这些被输入到系统中进行测量，然后它会迭代。所以它在使用AI来构建AI。

**问题参与者：** 为什么解决方案对象不只是优化的提示？

**演讲者：** 为什么解决方案对象不是什么？

**问题参与者：** 不只是优化的提示。为什么你要使用...

**演讲者：** 哦，绝对是的。你可以在底层得到它。问题是为什么你不只是得到优化的提示？你绝对可以。除了提示之外还有什么？DSPI对象本身。所以模块...如果我们有时间，我们大概可以看一个。如果我能看到一个优化状态的转储，那会很有趣。

是的，当然。让我看看能否快速找到一个。但从根本上说，是的，你会得到一个优化的提示，一个你可以在任何地方转储的字符串。

**问题参与者：** 签名有很多组成部分，对吧？比如你如何在文档中描述你的字段。

**演讲者：** 这是一个完美的过渡，我会在这之后结束。我在玩一个叫DSPIHub的东西，我创建它来创建优化程序的存储库。基本上，如果你是某个领域的专家，你针对这个数据集优化了一个LLM，或者有一个很棒的城市基础设施图像分类器，就像Hugging Face一样，你可以下载一些已经预优化的东西。我这里的是实际加载的程序，这将是优化过程的输出，然后我可以像调用任何其他东西一样调用它。

你可以在这里看到，这是输出，我使用了从这个hub下载的优化程序。如果我们检查加载的程序，你可以在底层看到，这是一个带有时间和推理字符串签名的预测对象。这里是优化的提示。最终，这是优化过程的输出，这个长字符串。然后是输入和输出的各种规范和定义。

**问题参与者：** 你发现了它们的具体用途吗？比如对于他的问题，它是什么？你能用它做什么？

**演讲者：** 这取决于你的用例。所以如果我有一个...文档分类器可能是一个好例子。如果在我的业务中，我遇到某种类型的文档，我可能会针对这些优化一个分类器，然后我可以在其他地方，在不同的项目或类似的地方使用它。所以在100,000个文档中，我想只找到有发票的页面，作为一个例子。当然，100%你可以使用典型的ML分类器来做到这一点。这很棒。这只是一个例子。我们理论上也可以训练或优化一个模型来做这种类型的分类或某种类型的文本生成等等，然后你有了优化状态，它存在于你的数据处理管道中，你可以将其用于其他类型的目的或给其他团队等等。所以这取决于你的特定用例。像这样的hub，也许它不有用，因为每个人的用例都如此超级特定，我真的不知道，但你可以用它做任何你想要的事情。

最后一个问题。

**问题参与者：** 通常你知道，使用DSPI的人们是否只是做重放来优化他们的提示，还是有办法在实时情况下做到这一点，考虑到延迟？我的意思是，ChatGPT给你答案，你可以点赞或点踩。那个点赞会在10分钟后、30分钟后、一天后出现，对吧？

**演讲者：** 所以问题更多的是关于持续学习，比如你如何在这里做到这一点？

**问题参与者：** 你来判断吧。

**演讲者：** 你如何将延迟的指标反馈来优化它？为什么需要延迟？因为你知道通常反馈来自用户，对吧？比如延迟。

那么，它基本上会被添加到数据集中，然后你会使用最新的优化，并继续基于那个真实数据集进行优化。

**问题参与者：** 对的。你会收集优化的输出并将其反馈，循环继续。

**演讲者：** 但为什么你要尝试做离线优化，对吧？

**问题参与者：** 是的。

**演讲者：** 但我在问，你能否在线进行，通过指标反馈？

如果你是一个足够好的工程师，你可能可以做到。但我不推荐为特定用例用优化的DSPI程序替换ML模型。也许分类是一个糟糕的例子，我认识到这一点。但对于其他...理论上是的，你知道，你可以做类似的事情。

但对于特定的LLM任务，我相信我们都有有趣的任务。如果你有相对明确定义的东西，你有已知的输入和输出，它可能是值得优化的候选。如果不是为了其他，就是为了将其转移到一个更小的模型，以更低的成本保持性能水平。这确实是我看到的最大好处之一。

好的，最后一个问题。我听说DSPI可能会很昂贵，因为你在做所有这些LM调用。我很好奇你在这方面的经验，也许相关地，如果你有任何关于大上下文优化数据集的经验，缩小这些的方法。

**演讲者：** 问题是DSPI是否会很昂贵，然后对于大上下文，你是如何看到的？你是如何管理的？昂贵的部分完全取决于你。如果你异步调用一个函数一百万次，你会产生大量成本。我不认为DSPI必然...也许它使调用事情变得更容易，但它本质上并不昂贵。它可能，正如你所说的，向提示添加更多内容。比如，当然，签名是一个字符串，但发送给模型的实际文本比那长得多。这完全正确。我不会说这是一个大的成本驱动因素。我的意思是，它最终更多的是一个编程范式。所以如果你愿意，你可以编写你的压缩适配器，减少发送给模型的数量。

在大上下文方面，我觉得这在某种程度上是同样的答案。如果你担心这一点，也许你在程序本身或适配器或模块的一部分中有一些额外的逻辑来跟踪这一点。也许你做一些上下文压缩或类似的事情。在过去几天有一些关于这方面的很好的讲座。显然，我有一种感觉，这在某个时候会消失，要么上下文窗口变得更大，要么上下文管理以某种方式被抽象化。我真的没有答案，这更多的是一种直觉。但DSP再次给你工具，你选择的原语来做到这一点。并随时间跟踪状态、跟踪管理。

我想就是这些了。我们很快就要被赶出去了。非常感谢你们的时间。真的很感激。


---

*生成时间: 2026-01-09 02:55:15*
*由 YouTube Monitor & Translator (Claude CLI) 生成*