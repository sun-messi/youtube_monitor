# OpenAI + @Temporalio : Building Durable, Production Ready Agents - Cornelia Davis, Temporal

## 📹 视频信息

- **频道**: AI Engineer
- **发布日期**: 2026-01-12
- **时长**: 1:18:14
- **原始链接**: [https://www.youtube.com/watch?v=k8cnVCMYmNc](https://www.youtube.com/watch?v=k8cnVCMYmNc)

---

> 本文内容整理自 Temporal 开发者倡导者科妮莉亚·戴维斯（Cornelia Davis）在 AI Engineer 频道的技术演示与教程。

## TL;DR（一句话核心洞察）

> OpenAI 与 Temporal 合作开发了一种革命性的 AI Agent 架构方案：通过将 OpenAI Agents SDK 与 Temporal 的分布式系统持久化技术深度集成，让原本脆弱的 AI Agent 变得具备企业级的容错能力——即使系统崩溃或网络中断，Agent 也能从中断点完美恢复，无需重新消耗 token，彻底解决了生产环境中 AI Agent 的可靠性难题。

## 📑 章节导航表

| 时间戳 | 章节标题 | 一句话概括 |
|--------|----------|-----------|
| 00:00-05:00 | 开场介绍与技术背景 | 介绍演讲者背景和分布式系统经验，了解听众对 OpenAI Agents SDK 和 Temporal 的熟悉程度 |
| 05:00-07:30 | OpenAI Agents SDK 基础 | 快速介绍 OpenAI Agents SDK 的核心概念：代理循环、工具调用和编排方式 |
| 07:30-19:00 | Temporal 平台深度剖析 | 详细讲解 Temporal 作为"分布式系统即服务"的核心价值：自动重试、状态管理和崩溃恢复 |
| 19:00-42:00 | 纯 Temporal 实现 Agent Demo | 展示如何用 Temporal 的活动和工作流构建持久化的 AI Agent，包括崩溃恢复演示 |
| 42:00-59:00 | OpenAI SDK + Temporal 集成 | 展示两者深度集成后的效果：保持 SDK 简洁性同时获得企业级持久化能力 |
| 59:00-1:04:00 | Agent 编排模式 | 讲解微代理（Micro-agent）架构、并行执行、人机协作等高级编排模式 |
| 1:04:00-1:10:00 | 总结与资源分享 | 总结集成优势，分享开源资源、文档和社区信息 |
| 1:10:00-1:18:14 | Q&A 互动环节 | 回答关于状态存储、流数据处理、语音代理、监控告警等实际应用问题 |

## 📊 核心论点

### 1. 分布式系统即服务：Temporal 的革命性理念

- **核心内容**：Temporal 将复杂的分布式系统能力封装成一个后端服务，就像 Redis 提供缓存服务、Kafka 提供消息队列服务一样。开发者只需编写业务逻辑（happy path），所有的故障处理、重试机制、状态管理都由 Temporal 自动处理。在 AI Agent 场景中，当你的 Agent 在第 1,350 次 LLM 调用时崩溃，Temporal 已经记录了所有之前的调用和返回，重启后无需重新消耗任何 token，直接从中断点继续执行。
- **关键概念**：分布式系统持久化、事件溯源（Event Sourcing）、活动（Activities）、工作流（Workflows）、透明重试机制
- **实际意义**：彻底改变了构建生产级 AI 应用的方式——将开发者从 75% 的基础设施工作中解放出来，专注于 AI 业务逻辑；大幅降低了 AI 应用的运营成本（避免 token 重复消耗）；使得长时间运行的 AI Agent（小时/天/月级别）成为现实。

### 2. Agent 持久化的关键突破：抽象 Runner 类

- **核心内容**：OpenAI 专门为 Temporal 集成将 Agents SDK 的 Runner 类抽象化，允许 Temporal 实现自己的 Runner。这使得每个 LLM 调用、工具执行都被透明地包装在 Temporal 的持久化层中。通过活动装饰器（@activity）和工作流装饰器（@workflow），开发者用极简的代码就能获得企业级的可靠性。演示中展示了 Agent 在执行过程中被强制终止，重启后完美恢复并继续执行的场景。
- **关键概念**：抽象 Runner 类、活动装饰器、工作流装饰器、动态活动（Dynamic Activities）、事件历史回放
- **实际意义**：首次实现了 AI Agent 的真正生产化——不再是玩具级的概念验证；为金融、医疗等对可靠性要求极高的行业开启了 AI Agent 应用的大门；显著提升了 AI 应用的投资回报率（ROI）。

### 3. 微代理架构：AI 时代的微服务

- **核心内容**：正如微服务革命使软件能够每天部署多次，"微代理"（Micro-agent）架构正在 AI 领域掀起类似变革。每个代理专注做好一件事，通过 Temporal 的编排能力组合成复杂系统。演示展示了天气查询代理如何自动调用 IP 定位、地理位置转换、天气 API 三个独立工具，所有决策由 LLM 自主完成，而持久化和容错由 Temporal 透明处理。
- **关键概念**：微代理、工具即活动、代理编排、并行执行、条件分支、长时间等待
- **实际意义**：实现了 AI 应用的模块化和可复用性；降低了复杂 AI 系统的开发和维护成本；使得 AI 系统可以像传统软件一样进行版本管理和灰度发布。

### 4. 进程抽象的范式转变

- **核心内容**：传统开发中，程序员需要时刻考虑物理进程的生命周期、崩溃恢复、进程间通信等问题。Temporal 让开发者只需关注逻辑进程——编写代码时假设进程永不崩溃，Temporal 负责将逻辑进程映射到实际的物理进程。这在人机协作场景中尤其强大：Agent 可以"等待"人类响应数小时甚至数天，期间不占用任何计算资源，人类响应后立即恢复执行状态。
- **关键概念**：逻辑进程 vs 物理进程、状态缓存机制、内存重构、实体工作流（Entity Workflows）、数字孪生模式
- **实际意义**：极大简化了长时间运行 AI 应用的开发；使得复杂的人机协作流程变得可行；为 AI Agent 的大规模部署扫清了技术障碍。

### 5. 生产环境的关键能力矩阵

- **核心内容**：Temporal 为 AI Agent 提供了完整的生产级能力：(1) 自动重试与指数退避策略；(2) 完整的执行历史和审计日志；(3) 多区域部署和故障转移；(4) 细粒度的监控和可观测性；(5) 版本管理和灰度发布支持。案例显示，Snapchat 每条消息、Airbnb 每个订单、OpenAI 的 Codex 和图像生成都运行在 Temporal 上。
- **关键概念**：重试策略配置、执行历史可视化、多区域命名空间、工作流版本控制、性能调优
- **实际意义**：将 AI Agent 从实验室带入真实生产环境；满足企业级的合规和审计要求；支持 AI 应用的规模化运营。

### 6. 集成架构的优雅实现

- **核心内容**：通过 activity_as_tool() 函数，任何 Temporal 活动都能自动转换为 OpenAI Agent 可调用的工具，包括自动生成 JSON Schema 描述。工具的注册和调用完全动态化，新增工具无需修改 Agent 核心代码。集成保留了两个框架的最佳特性：OpenAI SDK 的简洁性和 Temporal 的可靠性。
- **关键概念**：activity_as_tool、JSON Schema 自动生成、插件架构、动态工具注册、框架互操作性
- **实际意义**：大幅降低了 AI 应用的开发门槛；提高了代码的可维护性和可扩展性；为 AI 工具生态系统的繁荣奠定基础。

### 7. 可观测性与调试能力

- **核心内容**：Temporal UI 提供了 AI Agent 执行的完整可视化：每个 LLM 调用、工具执行、重试尝试都清晰可见。结合 OpenAI SDK 的 tracing 功能，开发者能够深入了解 Agent 的决策过程。失败的活动会显示详细的错误信息和重试历史，极大简化了复杂 AI 系统的调试。
- **关键概念**：Temporal UI、执行时间线、活动追踪、错误诊断、性能分析
- **实际意义**：将 AI 的"黑盒"变成"白盒"；加速了 AI 应用的开发迭代；提供了生产环境问题诊断的有力工具。

### 8. 成本优化的多重维度

- **核心内容**：(1) Token 成本：通过持久化避免重复调用，崩溃恢复不消耗额外 token；(2) 开发成本：从 25% 业务逻辑 + 75% 基础设施变为 75% 业务逻辑 + 25% 基础设施；(3) 运维成本：使用 Temporal Cloud 免去 Kafka、Redis 等中间件运维；(4) 扩展成本：通过工作者（Worker）池自动扩展，无需修改代码。
- **关键概念**：Token 经济学、开发效率提升、运维自动化、弹性扩展、成本归因
- **实际意义**：使 AI 项目的 ROI 计算变得可预测；降低了 AI 创业公司的技术门槛；为大规模 AI 应用部署提供了经济可行性。

### 9. 编排模式的多样性

- **核心内容**：支持多种 Agent 编排模式：(1) 顺序执行：通过 handoff 机制切换 Agent 上下文；(2) 并行执行：多个 Agent 同时工作后汇总结果；(3) 条件分支：基于 LLM 决策动态选择执行路径；(4) 循环迭代：支持复杂的迭代优化流程；(5) 人机协作：Agent 可等待人类输入数天而不占用资源。
- **关键概念**：Agent handoff、并行模式、条件路由、异步等待、信号与查询
- **实际意义**：支持构建任意复杂度的 AI 系统；适应不同业务场景的需求；为 AI 工作流标准化铺平道路。

### 10. 生态系统的蓬勃发展

- **核心内容**：继 OpenAI 之后，Pydantic 等主流 AI 框架纷纷集成 Temporal。社区贡献了大量模式和最佳实践，包括 MCP 工具集成、流数据处理方案、语音 Agent 实验等。Temporal 正在开发原生的流支持和大负载存储功能，进一步提升 AI 场景的适用性。年度 Replay 大会汇聚了 Nvidia、Replit 等行业领袖分享实践。
- **关键概念**：开源生态、框架集成、社区驱动、技术路线图、行业标准化
- **实际意义**：预示着 AI 基础设施的标准化趋势；降低了技术选型的风险；加速了 AI 应用的产业化进程。

## 🏢 提及的公司/产品

| 公司名 | 讨论语境 | 重要性 |
|--------|----------|--------|
| Temporal | 分布式系统持久化平台，本次集成的核心技术提供方 | ⭐⭐⭐ |
| OpenAI | Agents SDK 的开发者，Codex 和图像生成服务使用 Temporal | ⭐⭐⭐ |
| Snapchat | 每条消息都通过 Temporal 处理，展示大规模应用案例 | ⭐⭐ |
| Airbnb | 每个订单都使用 Temporal，验证其在交易系统中的可靠性 | ⭐⭐ |
| Uber | Temporal 的前身 Cadence 的创造者和最大用户 | ⭐⭐ |
| Pydantic | 主动集成 Temporal 到其 Agent 框架中 | ⭐⭐ |
| Pizza Hut/Taco Bell | 订单系统使用 Temporal，展示在传统行业的应用 | ⭐ |
| VMware | Cloud Foundry 的孵化地，演讲者的前雇主 | ⭐ |
| Nvidia/Replit | Replay 大会的参与者，AI 生态系统的重要玩家 | ⭐ |

## 💬 经典金句

> "With Temporal, you get to program the happy path. You get to program your business logic. And the business logic that we're going to program today are AI agents."
> — Cornelia Davis

> "When you're on the 1,350th turn to the LLM and your application crashes, no sweat. We have kept track of every single LLM call and return and you will not be reburning those tokens."
> — Cornelia Davis

> "I love the term micro-agent... Microservices have proven themselves to be very valuable. I think we're going to see a very similar paradigm, very similar success when it comes to building AI agents."
> — Cornelia Davis

> "Temporal lets you write your program thinking about a process as a logical entity and just let Temporal map it down to the actual physical processes that are there."
> — Cornelia Davis

## 👤 主要人物

### Cornelia Davis

**身份**：Temporal 开发者倡导者（Developer Advocate）
**背景**：拥有超过 30 年软件开发经验的资深工程师，曾在 Pivotal 参与 Cloud Foundry 早期开发，是《Cloud Native Patterns》一书的作者。在微服务架构和分布式系统领域有深厚造诣，曾在 Amazon Alexa 团队工作。
**核心观点或贡献**：展示了如何将 OpenAI Agents SDK 与 Temporal 深度集成，创造性地解决了 AI Agent 在生产环境中的持久化难题。强调了"微代理"架构的重要性，认为这将像微服务一样革命性地改变 AI 应用的构建方式。

### Johan

**身份**：Temporal AI 工程负责人（Head of AI Engineering）
**背景**：领导了 OpenAI Agents SDK 与 Temporal 的集成工程工作，负责 Temporal 的 AI 相关技术方向。
**核心观点或贡献**：补充了关于流数据处理的现状和未来规划，确认了多个 AI 框架正在进行 Temporal 集成，强调团队正在招聘以加速 AI 功能的开发。

## 📺 视频类型判断

**教程示范**：技术教学、产品演示

---

## 📝 完整翻译

### (0:00 - 8:00) Part 1

**(0:00 - 1:20)**

我先简单介绍一下自己，不过我想先了解一下大家。你们可以看到屏幕上有两个品牌，一个是 OpenAI Agents SDK，另一个是 Temporal。我在 Temporal 工作，稍后会详细介绍自己。我想知道，今天有多少人在使用 OpenAI Agents SDK？

好的，大约四分之一的人。那其他的智能体框架呢？大概是同样的人数。看起来还有相当多的人还没有使用智能体框架。没关系，我会教大家一些相关知识。下一个问题，有多少人在使用 Temporal？

**(1:20 - 2:30)**

人数不多。很好，我有很多东西可以教大家。今天我们要讲这两项技术，我会分别独立介绍它们，但会花大量时间讲解它们的结合使用。剧透一下，Temporal 和 OpenAI 其实一起开发了两个产品的集成功能，效果非常不错。

让我简单介绍一下自己。我叫 Cornelia Davis，是 Temporal 的开发者布道师。我职业生涯的大部分时间都在分布式系统领域。我很幸运能在 Pivotal 工作，从 2010 年代初就参与 Cloud Foundry 项目。那时正值向微服务架构和分布式系统转变的时期。在座有 Cloud Foundry 的用户吗？只有几个人。

**(2:30 - 3:45)**

对于不了解 Cloud Foundry 的人，它是市场上早期的容器技术，作为开源项目在 VMware 孵化。它使用容器镜像、Linux 容器、容器编排、最终一致性等技术，甚至比 Docker 出现得还早，远早于 Kubernetes。我很幸运在那个转向支持更敏捷分布式系统的平台运动的开端就参与其中。由于我在微服务领域花了很多时间，我还写了这本书。

今天我们要讲的内容包括：OpenAI Agents SDK 介绍，然后是 Temporal 概览，会有很多演示，我还会展示代码库。如果你们想跟着学习，可以去获取这些代码库。我的两个演示今天早上刚刚修改过，所以它们在分支里而不是主分支，我会明确指出这一点。

**(3:45 - 5:00)**

我们会先做很多演示，然后转到 OpenAI Agents SDK 和 Temporal 结合使用的部分，还会有更多演示。最后我会从一般意义上讲一讲智能体编排。

这里有一个笔记本，我今天不会用到。我本周早些时候刚举办过这个工作坊，但我觉得对 AI 工程师这个群体来说太基础了。不过如果你们感兴趣，可以去看看。它用 Jupyter notebooks 设置，可以在 GitHub 的 codespaces 中运行，你们可以运行第一个 OpenAI Agents SDK 智能体，然后运行第一个 Temporal 101 应用（不是智能体，而是 Temporal 应用），然后按照议程一路学下去。但内容相当基础，我决定为这个群体做一些更高级的内容。

**(5:00 - 6:15)**

我今天早上刚制作了一些演示。好了，话不多说，这将是演示中最短的部分，我要给大家介绍 OpenAI Agents SDK。这是在大约五月份推出的。我不会逐字念幻灯片，顺便说一下，我会使用一些幻灯片，因为我觉得图片很有帮助。这里有很多图表，但我们也会花大量时间浏览代码。

我觉得不需要定义什么是智能体。我个人对生成式 AI 应用和智能体的区别是：当我们给 LLM 赋予自主权，当 LLM 决定应用程序的流程时，这对我来说就是智能体。像 OpenAI Agents SDK 这样的框架旨在让你们更容易上手。事实上，我们会在今天的两个主要演示中看到对比。

**(6:15 - 7:30)**

它支持 Python 和 TypeScript。这里是最基本的应用程序。你们看到我们定义了一个智能体，给它一个名字和指令，其他部分采用默认设置。其他默认的内容包括模型本身，我不知道现在的默认模型是什么。然后你只需要运行它。每当你看到 runner.run 时，它对应的就是一个智能体循环。我们在整个演示中会多次谈到智能体循环。每次你看到 runner.run，它就是独立的智能体循环。当我们稍后讲到编排内容时，你们会明白我为什么要做这个区分。

正如我说的，这里很简单，但它还有很多其他选项可以放入智能体配置中来驱动智能体循环的工作方式。你可以设置交接，我稍后会详细说明。你可以设置护栏，可以添加工具。

**(7:30 - 8:00)**

我的两个示例都大量使用 LLM 自主性，让它决定使用哪些工具，所以我会展示工具功能。这里还有很多其他功能，我会在过程中展示例子。这张图就是我所说的，每一个 runner.run 基本上都有一个不断回到 LLM 的循环。在 LLM 调用之后，它决定要做什么。比如，如果 LLM 说"我要你调用一些工具"，它就会调用那些工具，然后将工具的输出结果路由回 LLM 并继续运行。LLM 根据系统指令决定什么时候完成，我们会看到这个过程。

这就是基本的智能体框架概览，市面上有很多智能体框架。由于你们中很少人了解 Temporal，我要放慢速度，详细介绍一下 Temporal。

### (8:00 - 16:00) Part 2

**(8:00 - 9:15)**

事实证明，Temporal 非常适合这类 AI 用例。当然，它也被广泛用于非 AI 用例。比如，每个 Snapchat 都通过 Temporal 运行。每个 Airbnb 预订都通过 Temporal。Pizza Hut、Taco Bell 的订单都通过 Temporal。还有很多其他的例子我记不全了。OpenAI 的 Codex 运行在 Temporal 上。现在我们开始进入 AI 用例。Codex 运行在 Temporal 上，OpenAI 的图像生成也运行在 Temporal 上。这是我能告诉你们的两个公开案例。我们还有很多其他案例，Lovable 也运行在 Temporal 上。所以我们确实在 AI 领域取得了很大进展，有大量的应用案例。

**(9:15 - 10:30)**

我告诉了你们谁在使用它，现在让我告诉你们它是什么。Temporal 是分布式系统即服务。我想大家都熟悉 Redis 即服务、Kafka 即服务或数据库即服务的概念。我有正在运行的应用程序，我使用这些后端服务来为我的应用程序的一部分提供服务。Temporal 就是一个后端服务。它提供的是分布式系统的持久性。随着演示的进行，我会让这一点变得更清晰。这意味着作为开发者，你可以专注于编程快乐路径。你可以专注于编程你的业务逻辑。我们今天要编程的业务逻辑就是 AI 智能体。

**(10:30 - 11:45)**

所以你可以说，你知道吗，我想做的是调用一个 LLM。然后我想获取 LLM 的输出，可能想调用一些其他 API，然后再循环回到 LLM。你不必在其中构建处理 LLM 被速率限制时该怎么办的逻辑。当我的下游 API 暂时宕机时该怎么办？当我的应用程序崩溃时该怎么办？你不必编程任何这些逻辑。我们为你处理这些。稍后我会展示一些图片说明这是如何工作的。

有一个 Temporal 服务作为后端服务。你通过 SDK 连接到后端服务。SDK 与你的业务逻辑并存。所以你可以编程你的业务逻辑。编写业务逻辑的方式是，你在某些函数周围放置包装器。

**(11:45 - 13:00)**

这样 SDK 就能说："等等，你在进行下游 API 调用。我要介入并为你提供一些服务。我会为你提供重试机制。如果那个下游服务成功了，我会为你记录下来。我会记录答案，这样在出现问题需要再次执行流程时，我可以直接获取你之前调用的结果。"这意味着，比如说，如果你使用 Temporal 为你的智能体提供持久性，当你在第 1350 秒轮次调用 LLM 时应用程序崩溃了，没问题。我们已经跟踪了每一次 LLM 调用和返回，你不会重复消耗那些 token。这就是持久性在这个领域的含义。

**(13:00 - 14:15)**

我们正式支持七种不同的编程语言，但 Apple 几周前也发布了 Swift SDK。所以几乎任何语言都有支持。还有一些实验性的东西，比如 Clojure 等类型。我说过这是一个开源项目。绝大部分是 MIT 许可的。Java SDK 中还剩一点 Apache 2 许可。所以许可证非常宽松。对于不了解历史的人，Temporal 是从 Uber 创建的一个叫 Cadence 的项目分叉出来的。有人知道 Cadence 吗？好的，有几个人知道 Cadence。Cadence 几乎支撑着 Uber 运行的每个应用程序，因为他们可以编程快乐路径，所有的持久性都会为你处理。

**(14:15 - 15:30)**

这就是 Temporal 的概述。我要讲两个基础抽象概念。还有其他一些，但作为开发者你需要知道的两个基础抽象是：你需要了解 Activity（活动）。Activity 就是一块工作。这是要进行外部调用的工作，所以是可能失败的工作。或者如果你在做大量工作，不想在出错时重新做，你可能也想把它放在一个 Activity 中。比如从账户中提取资金、向账户中存入资金。我们马上会讲到 AI 用例。这些就是你要包装的 Activity。

**(15:30 - 16:00)**

哦，我没有提到，但 SDK 不仅仅是位于 REST API 之上的轻薄包装器。正如你所能想象的，在分布式系统中提供持久性意味着所有那些你以为必须实现的算法，比如担心并发性、仲裁等等，这些都在 Temporal 中实现了，所以我们的 SDK 包含了很多这样的逻辑。服务主要是为此提供持久化。所以 SDK 中有很多智能。

这些 Activity，如果你说，看，这是我的工作，这是一个重型工作或要对外部进行操作的东西，让我们在上面放一个 Activity 装饰器。然后 SDK 会说，好的，我要给你一些特殊行为。然后你将这些 Activity 编排到你的业务逻辑中。我们称这些编排为工作流（Workflows）。

### (16:00 - 24:00) Part 3

**(16:00 - 17:15)**

这是通过队列促成的，所以看起来像一个单体应用的东西实际上已经变成了一个分布式系统。你可以去部署一大堆这样的实例，基本上通过部署更多实例就能扩展。你不需要管理 Kafka 队列或任何那样的东西，这些都内置了。我本周在 AI Engineers 大会上和一个人聊过，他是我们的开源用户，实际上也是我们的客户。我问他，这是一个相对较小的创业公司，我说你为什么选择 Temporal？他说因为我们试图用 Kafka 队列构建所有这些，结果我们把所有时间都花在了 Kafka 的运维上，只有 25% 的时间花在业务逻辑上。当我们切换到 Temporal 后，我们把 75% 的时间都花在业务逻辑上，而且他们使用的是 Temporal Cloud。

**(17:15 - 18:30)**

我没有提到我们的商业模式是我们提供那个服务作为 SaaS。所以他们使用 Temporal Cloud。他们基本上从 25/75 的比例转变为 75/25。不再需要管理 Kafka 队列或 Redis 或任何那样的东西。说到 Redis，你可以看到右上角显示的状态管理。我们做的事情之一是跟踪你在应用程序执行中的位置。我们通过记录状态来做到这一点。每次你调用 Activity 并返回时，我们都会记录下来。这基本上就是事件溯源。这就是我们在做的。这不仅仅是事件驱动架构，而是作为服务的事件溯源。

**(18:30 - 19:45)**

我们存储所有这些状态，这样如果出现问题，我将会演示这一点，我们会看到出错的情况，它会从中断的地方继续，因为我们会运行整个事件历史并从中断的地方继续。我之前展示的那些覆盖在逻辑图上的小图标，我马上回答你的问题。实际上，所有这些服务都存在于这里的服务中。所以它们都是持久的。它们不是存在于进程中，而是存在于这里的服务中。你有问题吗？

**主持人：** 不确定是否相关。我的很多 Agent 都处理流数据。所以我想看看这能否帮助解决这个问题。

**(19:45 - 21:00)**

**Marc：** 很好的问题。问题是我正在构建的很多 Agent 都在做流处理。你们支持流处理吗？答案现在是简单的不支持。但这是我们正在研究的事情之一。我在后面的同事 Johan 是 AI 工程负责人。和他聊聊，或者和我们任何一个人聊聊。这是我们目前正在研究的两个最优先事项之一。另一个是大型载荷存储。如果我在这次工作坊期间没有机会讨论它，来找我们任何一个人。我们可以告诉你相关信息。你可以想象大型载荷存储是什么。你在使用 LLM 时会传递大量数据。不通过值传递，而是通过引用传递。这就是大型载荷存储。那是 Johan。

**Johan：** 我要提一下有很多人在使用变通方法。

**Marc：** 对的。

**Johan：** 今天在生产环境中大规模进行流处理。很乐意讨论这个，但会有更集成的解决方案。

**(21:00 - 22:15)**

**Marc：** 我重复一下 Johan 说的，以防你们听不清。我们确实有客户在 Temporal 之上构建了流支持，但我们正在做的是原生地构建它。所以你今天可以做到。只是需要多一点工作。这不是最佳路径。

好的，那么我想给你们做个演示。这将是我的第一个演示，我移动到这里。让我看看能否恢复我的屏幕。好的，如果你想跟着做，我要做的第一件事是来到这里，让我增大字体大小。我要给你们指向两个代码仓库。这实际上是第二个仓库，但我现在屏幕上显示的是如果你想开始使用 Temporal，非常简单，你不必使用 Temporal Cloud。你可以直接运行一个 Temporal 服务。

**(22:15 - 23:30)**

后端服务，你可以在你的机器上本地运行。你可以通过 curl 这个来做，也可以用 homebrew 安装。然后要运行那个本地服务器，你可以说 `temporal server start dev`。现在你就有了一个本地运行的 Temporal 服务。我这里所有的应用程序都只是连接到我的 localhost。我们马上会看到 UI。我会马上回到这个仓库。

我要为你们演示的仓库是这个。抱歉我不知道如何增大字体大小，但你可以看到这里的组织和仓库是 temporal io 组织。那也是你会找到所有 Temporal 开源代码的地方。然后我们有一个叫做 AI cookbook 的东西，这是其中一个例子。我今天早上实际上扩展了这个例子，你会发现我们今天要演示的分支叫做 agentic loop 分支。如果你想稍后自己回头看看，那就是我们要查看的内容。

**(23:30 - 24:00)**

好的，让我转到我正确的终端。这是我要运行它的地方，但我想先给你们看代码。我在正确的地方吗？OpenAI。不对，这是错误的。我的另一个光标。好了。这就是 agentic loop。我今天要做两个演示。

你在左侧看到的，让我把它调大一点，记住我讲过 Activity 和 Workflow。这是我要做的第一件事，我要给你们展示 Activity。记住我们有取款和存款之类的操作。当然，这里我们做的是 agentic loop。所以我的 Activity 将是调用 OpenAI API，还不是 agents SDK，只是 OpenAI API 和调用一些工具。这就是我的两个 Activity。

### (24:00 - 32:00) Part 4

**(24:00 - 25:15)**

所以，我很快就会回到这个工具调用器，因为这里发生了一些有趣的事情。现在如果我们看看工作流，工作流也非常简单直接。你可以看到我这里有工作流定义。你可以看到它是一个类。它是一个类的原因是，当你创建工作流时，你创建了应用程序主体，我称之为应用程序主体，这就是有 workflow.run 的部分。

但这个工作流，我今天不会涵盖这些抽象，但我们有一些其他的抽象，比如信号。所以对于一个运行中的工作流，你可以向其中发送信号，我们还有一个叫做更新的抽象。这是一种特殊的信号。我们还有类似的查询。

**(25:15 - 26:30)**

所以这些东西被添加到这个工作流类中，作为用信号、更新或查询注解的函数。这就是为什么我们为工作流使用类的原因。如果我们看看这里的逻辑是什么，你可以看到我有一个 while true。所以这个简单的应用程序就是我之前给你们展示的同一张图片，我说 LLM 是 - 我们只是在 LLM 上循环。如果 LLM 做出这样的决定，我们就会调用工具。这就是整个应用程序。

但你会看到我在这里用 temporal 做了一些有趣的事情。所以为了调用 LLM，我执行那个活动。所以你可以看到我传入我的模型。这里的指令，我不会给你看，但你可以在仓库中看到所有内容。有用的智能体系统指令基本上只是说你是一个有用的智能体。如果用户说了什么，你认为应该使用工具，让我知道。你知道，选择一个工具。否则，用俳句回应。你很快就会看到。俳句就像 AI 世界的 foo bar，对吧？我们都要写智能体。这是智能体领域的 hello world。所以我们要用俳句回应。就这样。

**(26:30 - 27:45)**

所以我们在 while true 中这样做。我有几个打印语句。你很快就会看到这是如何运行的。

这里有个简化假设。我假设它一次只调用一个工具。所以我抓取那个输出。然后我只是看看它，问是否是函数调用？如果它是函数调用，那么我将处理那个函数调用。我稍后会给你展示那段代码。然后我将从那个函数调用获取输出，并将其添加到对话历史中。所以我这里没有做任何花哨的上下文工程。什么都没有。我基本上只是附加到对话历史的末尾。

现在，处理函数调用也非常简单。所以我做的第一件事是添加来自 LLM 的响应。所以当我们完成这个函数调用时，我们将向对话历史添加两个东西。我们将添加来自 LLM 的响应，它说请进行函数调用，然后我们将进行函数调用，然后我们将添加结果。我刚刚给你展示了我们在哪里添加函数调用的结果。

**(27:45 - 29:00)**

所以这里，这只是我添加到... 这是一些奇怪的东西。我让这个应用程序也运行在 Gemini API 上。所有这些东西中最痛苦的是格式不同。所以我必须重写，因为对话历史的 JSON 格式在不同模型之间是不同的。是的，我知道有 Light LLM，但我不喜欢最小公分母。而且我喜欢了解这些格式是什么样的。

但你可以看到这里我只是在做一些丑陋的解析，然后我在执行 - 记住我在这里处理工具调用。我用那个工具调用执行活动。所以我从 LLM 的响应中提取了工具调用，然后我将调用那个活动，也就是执行活动，项目名称就是工具。

**(29:00 - 30:15)**

现在我这里真正专注的一件事是，我不想构建一个做一套工具的智能体循环应用程序，然后当我有不同的工具集时必须重建另一个完全不同的应用程序。智能体本身，我不记得是谁谈到了这个，但本周有人在台上谈到了这个，他们说看，智能体模式是相当标准的，我们现在正在做的是将东西插入到这个标准化的智能体循环中，这正是这些 AI 框架在做的，这些智能体框架，我想在这里的 temporal 代码中也这样做。

酷的是 temporal 有一个叫做动态活动的东西。动态活动允许你按名称调用活动，但那个活动是在运行时动态找到的。所以这里的活动处理器，我很快会给你展示代码，基本上会接受那个名称并说，哦，好的，我... 记住这是事件驱动的。

**(30:15 - 31:30)**

所以我们有一个活动在队列上等待东西。所以你可以配置一个活动。你可以配置我们的一个工作器说："嘿，这是一个基本上会从活动队列中拾取任何东西的工作器。名称是什么并不重要。"所以你不必紧密绑定到特定的主题名称，例如。

**观众：** 我需要提前映射哪些工具对基于活动的智能体可用。

**讲者：** 那是分离的，我将给你展示那个模块。这里有一个模块叫做工具。如果你看到工具目录，我在这里运行的方式，它在我加载应用程序时加载那些东西。所以，我没有做任何动态加载，但我可以换入换出那个工具模块，智能体代码完全不会改变。所以，我没有一直到实现注册表和动态调用那些东西的程度。你可以那样做，但这个简单的例子基本上只是把所有东西都放入一个独立的模块。你会看到那个模块如何被换入换出，因为我在运行时开始时加载它。

**(31:30 - 32:00)**

所以，简化了，但是的，你可以那样做。好的。所以，我只是要调用一个活动。那么，让我们看看那个活动是什么样的。这是这个工具调用器。你可以看到这里它有我之前给你展示的活动装饰器，但现在它说 dynamic equals true。所以这意味着这个活动处理器会拾取任何出现在队列中还没有被其他活动拾取的东西。所以它会拾取天气获取。它会拾取随机数获取。它会拾取任何出现在那里的东西。你必须注册...不，你不必注册所有那些。那些东西可以动态完成。你不必将它们注册到工作器中。

### (32:00 - 40:00) Part 5

**(32:00 - 33:15)**

这是一个 get tools 函数，顺便让我回到那里。在 OpenAI 响应中... 不，抱歉，是在工作流程的下方，当我调用 LLM 时。注意这里我做了一个 get tools 调用。我马上会向你展示这个 get tools 调用。它完全在工作流程和活动的范围之外。它在自己的模块中。我马上会向你展示这个函数。

回到工具调用器。它现在基本上是获取名称，然后执行一个 get handler。所以这里某个地方有一个 get handler 调用。这是处理器。

**讲者：** 你刚刚跳过了它。

**讲者：** 我刚刚跳过了。抱歉。

**讲者：** 第17行。

**讲者：** 第17行。谢谢，我很感激。所以这是 get handler，我马上会向你展示这个函数。关于这些东西绑定有多紧密的问题很棒。让我现在向你展示绑定在哪里。

**(33:15 - 34:30)**

我这里有一个工具模块，在初始化中定义了这两个函数。我有 get tools，get tools 基本上就是获取函数列表，我会向你展示这些函数。我们在这里传递的是作为工具描述传递给 LLM 的 JSON 数据块。这些就是工具描述。例如，让我向你展示 get weather 这个。如果我们到这里看 get weather，你可以看到 JSON 数据块就在这里。

有趣的是，OpenAI 在 completions API 中，他们有一个公共 API，允许你获取任何带有文档字符串的函数并为 completions API 的工具生成 JSON。但 responses API 没有这样的公共 API。所以这里有一个警告，说我使用的这个 API 在这个工具助手中。让我向你展示工具助手。我的工具助手在哪里？在 helpers 里。

**(34:30 - 35:45)**

这里。我想我可以把它放在工具中。里面有个东西说警告：目前没有公共 API 为 responses API 生成工具的 JSON 数据块。所以我在使用内部 API。这上面有一个开放的问题。所以里面只是有个警告，说我在使用内部 API。

如果我们回到那里，我使用了内部 API 来处理我的 get weather alerts 请求，这是一个 Pydantic 模型，里面有函数和一些额外的元数据，它生成 JSON 数据块。再次，这就是我们进入代理时看到的，get tools 给你的就是每个工具的 JSON 数据块数组。

然后如我所说，get handler 基本上是一个我实现为一组 if 语句的字典。它接受工具名称，然后选择实际的函数，完全独立。

**(35:45 - 37:00)**

这个特定示例有一套工具，我马上会为你演示。你可以切换这些东西。目前你确实需要重启 Python 进程，因为我实现的方式。好的，基本明白了吧。让我向你展示实际操作。

我这里运行的是 worker。我不会花太多时间讲 worker，但你记得我说过这都是事件驱动的。有东西从事件队列中提取工作，然后基于从事件队列中提取的内容执行正确的工作流程和活动。在 Temporal 中做这件事的东西叫做 worker。Worker 是你运行的一个进程。在这个 worker 中，你注册该 worker 负责的活动和工作流程。所以它会在队列中寻找要提取的东西。Worker 本身是多线程的。所以不是一个 worker 一个进程。一般来说，这取决于你可以做 worker 调优，但一般人们运行几百个线程。所以你运行一个 worker，它已经是一个并发的多线程架构。

**(37:00 - 38:15)**

Temporal 真是太棒了。它真正是分布式系统设计。我在这里运行 worker，这实际上是你会看到活动和工作流程输出的地方。我要运行一个工作流程。

让我们说，加利福尼亚有什么天气警报吗？那是我来的地方。我想你们很多人也来自那里，希望今晚我能回到那里。我们要开始了。你可以看到这个应用程序编写的方式，基本上是我说是否在调用工具。你可以看到这里说，哦，我调用了 get weather alerts。这就是正在发生的事情。有一个工具调用正在进行。我碰巧知道，一旦加利福尼亚下了几滴雨，到处都是警报。

看，这里是加利福尼亚的一大堆天气警报。你会明白我为什么指出这一点。挺有趣的。现在让我向你展示这在 Temporal UI 中是什么样子的。

**(38:15 - 39:30)**

这里我有 Temporal UI，你可以看到今天早上我运行了一堆工作流程。让我刷新这个。这是我刚刚运行的那个。我们在这里看到的是，是的，有所有那些浓雾警报。这大概是我们在加利福尼亚能得到的最极端的情况了。一点雾，一点风，大浪，海滩危险。但这里是发生的事情。

在 Temporal UI 中，你可以看到我调用的每个活动。你可以看到我调用了 LLM。那是你在底部看到的创建线。我们从底部到顶部工作。然后你可以看到我做了一个动态活动，但我做的特定动态活动，它不说通用动态活动。它说我做了一个 get weather alerts。然后就像我们在代理循环中做的那样，我们获取工具的输出并将其发送回 LLM，我们得到了这个。

**(39:30 - 40:00)**

现在我想向你展示一些东西。我要展示一个不同的例子。我要问，我所在的地方有什么天气警报吗？它知道我在哪里吗？我要开始这个，很快过来这里，我们会看到这个正在运行。你可以看到... 看起来我会太慢，但我会回来重新演示。但你可以看到它是如何引入这些东西的。

我现在注册了三个工具。我有一个接受州名的工具。我有一个接受 IP 地址并返回州名的工具。我有一个给我当前运行计算机 IP 地址的工具。我没有连接这些，LLM 仅基于工具做出了这些决定。我所做的只是提供这些工具。但你可以在 Temporal 中获得这种可见性。你可以看到我们从 get IP address 开始，然后从那个 IP 地址获取位置信息，然后获取天气警报。

### (40:00 - 48:00) Part 6

**(40:00 - 41:15)**

从那个 IP 地址获取了位置信息，然后获取了天气警报。有趣的是，纽约没有任何天气警报。我觉得纽约应该是一个天气变化更多的地方，但也许今天很平静。你们有雾，但没有雾霾警告。所以，你们比我们加州人要坚韧得多。

现在我想再展示一个功能。我要回到这边重新运行一遍，我会尽量快一点。我点击确定，然后来到这里按 Control+C。没有 worker 在运行。我的 agent 没有在运行，完全没有运行。

**(41:15 - 42:30)**

如果我们回到这里查看 Temporal 中的情况，这会让你更清楚地理解我所说的持久性和持久代理的含义。我的这个 agent 在运行，你可以看到它进行了第一次 LLM 调用，然后调用了 IP 地址工具，现在它卡住了。它开始调用 LLM，但等等，出了什么问题。agent 本身没有在运行。

顺便说一下，我还可以做其他演示。虽然今天没有时间做所有演示，但我可以演示网络中断的情况。我可以切断网络，然后你会在这个小红条中看到：创建尝试一、创建尝试二、创建尝试三。我可以恢复网络，然后它就会继续执行。但为了简洁起见，因为我还有更多内容要讲，我只展示其中一种故障场景。有很多种故障场景都被覆盖了。

**(42:30 - 43:45)**

我要回到这里重启 worker。我们应该能看到它继续运行。果然，它继续了。所以它从中断的地方继续执行。当我说从中断处继续时，当然，我杀掉了进程，内存中什么都没有运行了。所以当我重启 worker 时，它必须重建应用程序的状态。它通过事件溯源来实现这一点。

这就是 Temporal 的基本工作原理。对此有什么问题吗？

**观众：** 我们可以将一个 agent 委托给另一个 agent 吗？

**讲者：** 可以将一个 agent 委托给另一个 agent 吗？当然可以。我们还没有对特定协议的原生 Agent-to-Agent 支持。但你确实可以让一个 agent 作为工具使用。有几种不同的方式来实现。你可以让一个活动调用另一个 agent，或者使用其他机制。我们有子工作流等功能。我不会涵盖这个更高级的用例，但绝对是可以的。

**(43:45 - 45:00)**

**观众：** 有几个问题。第一，你编码的方式看起来函数都很简单，基本上只有一行。如何确保开发人员创建的函数具有幂等性，避免重试造成问题？第二个问题是框架增加的延迟问题。

**讲者：** 第一个问题关于幂等性。你已经意识到活动本身应该是幂等的。我们不要求这一点，也不检查，因为我们真的不深入活动的内部工作。我们把这留给开发人员。但指导原则是，如果它们不是幂等的——记住当我们代表你重试时，我们不知道为什么第一次调用没有收到响应。所以我们会继续重试，直到得到响应。

当然，可能是请求从未到达活动，也可能是到达了并调用了下游函数，可能在很多地方出错。那么如何确保你的开发人员创建幂等的活动呢？教育。我们在这方面没有万能解决方案。

**(45:00 - 46:15)**

第二个问题是关于延迟，因为我确实在每次活动调用时都要访问服务器。当我们考虑 agent 时——Johan，我不记得确切的数字，你记得活动访问服务器的延迟数字吗？我是说很小。

**Johan：** 这取决于服务器在哪里，但大约是几十毫秒。

**讲者：** 几十毫秒，非常小。我听说有几个客户在相当实时的应用中使用这个。但对于 agent 来说，特别是长期运行的 agent，运行几分钟、几小时、几天，或者有用户交互的 agent，几十毫秒是可以容忍的。可能存在因延迟而不适用的用例，但延迟很小，适用于大多数情况。

**(46:15 - 47:30)**

好的。这就是 Temporal 的概览。现在我想切换回 agents SDK，展示它们的差异和相似之处。让我回到这里，我会再演示几张图片。

OpenAI agents SDK——这两个东西的组合在高层次上是这样的。基础层我们有 OpenAI 模型和 OpenAI API，不是 SDK 而是 OpenAI API。你可能已经注意到我一直在使用 OpenAI API，现在我们要开始使用 agents SDK。然后我们还有 Temporal 作为基础元素。agents SDK 就是在这些基础之上构建的。这是两个基础组件。

我们不是让 Temporal 放在一边或让 OpenAI 模型放在一边，我们实际上整合了这些东西。当我们看到代码时，我会评论我们如何做这种整合，我也完全邀请 Johan 补充，因为他领导了这里的整合工程。

**(47:30 - 48:00)**

现在你有了 agents SDK，你将使用它来构建你的 agent，添加防护栏。我会展示一些追踪功能。我展示了 Temporal UI，但 agents SDK 也有一些很棒的追踪功能。你会看到我们将这些东西整合在一起。当然还有工具。

我一直在谈论这些 Temporal 活动，我们已经看到了这一点。我们要用相同的例子。我们有三个工具：一个是天气 API，另外两个是位置 API。我们要做什么呢？我们要在它们周围放置活动装饰器。我马上会在另一个代码库中展示这个样子。

### (48:00 - 56:00) Part 7

**(48:00 - 49:20)**

那个 JSON blob 是集成的一部分。所以你可以拿一个活动，我们为你提供了一个叫做 activity as tool 的函数，它会接收活动函数本身。所以你不必担心自己序列化它。没有内部 API，这是一个公共 API，它是集成的一部分。你要调用 activity as tool，它会生成 JSON blob，然后你也可以设置超时。

还有一个非常重要的部分，就是你必须配置集成。agents SDK 本身不使用 Temporal，如果你想使用 Temporal，你需要确保包含一个插件，我马上会展示相关代码。然后当然我们会运行它，使用基本相同的方式来运行。

**(49:20 - 50:45)**

好的，让我们演示一下。我们要花更多时间在代码和演示上。让我回到 Cursor。我有四个文件想展示给你们。我先从活动开始。这是 get weather 活动，你会看到它实际上变得更简单了。它只是在 get weather alerts 上有活动装饰器，然后这里是实际调用国家气象局 API 的函数。之前有一些代码在做格式化，进行 API 调用来生成 JSON blob，现在这些都不需要了，因为我们有一个支持的函数来做这件事。

位置活动同样简单。这实际上就是整个文件。我有这两个带活动装饰器的函数和我的文档字符串。文档字符串描述参数等信息。

**(50:45 - 52:10)**

现在 agent 本身呢？记住活动只是 agent 使用的工具。我之前展示的是用 Python 编写的代理循环，用来协调 LLM 调用和工具调用。

现在如果我转到工作流，我的工作流是什么样的？就是这样。让我增加字体大小，因为我有足够的空间。注意我使用的是 agents SDK。我在第 18 行定义了一个 agent，给它起名叫"your helpful agent"，并给它一组工具。这些工具被实现为活动。

你可以看到我调用了 activity as tool 函数来生成 JSON blob。就是这样，这就是我实现它的方式。

**(52:10 - 53:25)**

注意我仍然在工作流中这样做，因为记住我之前说过我们有活动，我们有工作流。当你把它们结合在一起时，魔法就发生了。将这个 agent 放在工作流中，就是这样添加了所有这些持久性能力。

我不会演示这个的非持久版本，因为今天时间有限。但如果我只用 agents SDK（这只是一个 Python 库）来实现，我会有一个单一进程。如果我杀掉那个进程，一切都会随之消失。我没办法扩展那个进程。记住，我这里有一个 runner.run，对吧？每个运行器都只是一个整体的 agent，只是一个 Python 进程。通过这种方式，你可以看到如果我运行多个 worker，我可以通过运行多个从队列中获取任务的 worker 来扩展规模。

**(53:25 - 54:40)**

提问者：agent 之间的切换能工作吗？

回答：agent 之间的切换能工作吗？是的，可以。我会在最后一节回到这个话题，我们会讨论编排。是的，绝对可以。

好的，现在让我转到... 我需要找到我的 worker。我的 worker 在哪里？在这里。因为正是在 worker 中... 插件在哪里？Johan，帮帮我。

哦，OpenAI agents 插件在这里。好的，它在 worker 中。记住 worker 是所有执行发生的地方。把它想象成一个逻辑上的隐喻容器。通常你会在容器中运行 worker。这里是你需要放置的配置。注意它在做诸如配置 LLM 周围的重试行为等事情。

**(54:40 - 56:00)**

你会注意到，我没有给你一个调用 LLM 的活动——那是作为 agent 的一部分完成的，但我们仍然希望它是持久的。这是我们实现中做的事情之一。所以你为 LLM 设置了一些重试策略，基本上是在说"嘿，OpenAI agents SDK，使用 Temporal 的这些部分"。

让我告诉你我们作为集成的一部分做了什么。如果你回顾 OpenAI agents SDK 的提交历史，你会发现一个提交说"让 runner 类变成抽象的"。他们为我们做了这个，因为这就是我们实现持久性的方式。这就是我们能够让 LLM 调用以及你刚才看到的所有工具都具有持久性的方式。我们有自己的抽象 runner 类实现。这就是它工作的方式。

我们看了活动，看了工作流，然后运行了工具工作流。让我们转到演示窗口。在顶部窗口，我再次运行我的 worker。你之前看过这个。在下面的窗口，我启动工作流，在这里与 agent 交互。我问"加利福尼亚有天气警报吗？"记住代码——代码就是那个 agent。我们仍然实现了活动，但代码就是那个 agent。你可以看到正在滚动的内容——对 LLM 的 API 调用和对国家气象局的 API 调用。如果我们回到 Temporal UI，它叫做 tools workflow，你可以看到它看起来完全一样。这就是为什么我想花时间用 Temporal 展示给你们，因为如果你在构建这些 Temporal 原生应用，你会得到所有这些持久性和可见性。它看起来完全一样，但你使用 agents SDK 来实现你的 agent，我觉得这太酷了。

### (56:00 - 1:04:00) Part 8

**(56:00 - 57:15)**

UI 界面，它有所不同，叫做工具工作流。在这里你可以看到它看起来完全一样，对吧？这就是为什么我想花时间用 Temporal 向你们展示，因为如果你在构建这些 Temporal 原生应用程序，你会得到所有这些持久性。你会得到这种可见性。它看起来完全一样，但你使用的是 agents SDK 来实现你的 agents，我觉得这太酷了。

让我们运行第二个例子。我马上会向你展示代码库。我们要运行第二个例子，"我所在的地方有任何天气警报吗？"我们来到这里，观察它的进度。

**(57:15 - 58:30)**

所以这里它正在运行，运行方式完全相同。当它回来时我会再运行一次。它说"不，你在纽约很安全。"让我再运行一次，让它开始，运行到一半时，用 Control C 退出。然后我们回到这里，看到和之前一样的情况，对吧？agents SDK 持久化，这太棒了。抱歉，我总是这样，但我仍然对此感到非常兴奋。

我想和你们分享一种直观思考这个问题的方式。我写软件已经超过 30 年了。是的，我有白发为证，对吧？我写过这样的软件，当我在写软件时，我会考虑它运行的进程。我会考虑这样的事实，我在这里有一个进程，如果这个进程出了什么问题怎么办？或者当我扩展系统时，东西可能不会在同一个进程中运行，我总是在考虑进程。

**(58:30 - 59:45)**

有了 Temporal，你可以做的是将程序编写为一个逻辑实体的进程，然后让 Temporal 将其映射到实际的物理进程。这在人工干预循环这样的场景中尤其酷。本周早些时候我做了另一个关于 agents 人工干预循环的演讲，人工干预循环的一个大痛点是，当你考虑构建这些系统时，你在考虑进程，你说好吧，我需要运行一段时间，现在我要等待人工干预，可能需要一秒钟，可能需要一分钟，很可能需要几个小时或几天才能等到人回来。在此期间，我该如何处理那个等待响应的进程？作为开发者，你必须搞清楚这一点。

**(59:45 - 1:01:00)**

有了 Temporal，你不用担心这个。你只需要编写代码，就好像那个进程一直在那里一样。顺便说一下，worker 架构的工作方式是，如果它在等待人工输入之类的东西，它会在内存中保留一段时间，几秒钟，然后将其从活动内存中取出，但它仍然在缓存中。再过一段时间，它会从缓存中出来，就像你刚刚杀死了那个进程一样。所以当它几天或几周后真的回来，当用户回来给你输入时，它只是重新构建等待用户时的内存状态，然后继续。

记住我说过这可能是崩溃或其他事情，操作方面的事情，所有这些类型的事情。一旦你真正进入 Temporal 的世界，就会感到非常自由。意识到我不必再考虑物理进程了，这是如此自由。对我来说，进程只是逻辑的，Temporal 为我处理其余部分。超级酷的东西。

**(1:01:00 - 1:02:15)**

好的，我们还有大约 20 分钟。我要再过几张幻灯片来回答关于交接的问题，只是再向你展示一些内容，然后我们在最后大概 10 到 15 分钟有时间，我很乐意接受更多问题，Johan 也肯定很乐意参与。

关于 OpenAI agents SDK，我在这里谈论的内容在某种程度上是特定于 agents SDK 的，但这确实可以推广到一般的 agents，也就是说，在 OpenAI agents SDK 中，他们使用的范式是构建很多具有自己独立 agent 循环的小型 agents，然后将它们协调在一起。在 agents SDK 中，你可以用两种方式将它们协调在一起，我马上会向你展示这两种方式。

**(1:02:15 - 1:03:30)**

我们在屏幕上看到的是几个图表，我有一个分流 agent，我有一个澄清 agent，然后我有一个人工干预环节，那不是 agent，尽管你可能认为人是这个应用程序中的 agent，对吧？然后我有一个指令 agent 来制作一些东西，然后我有一个规划 agent。然后你可以看到我们在并行执行。我没有谈到这个，但 Temporal 有所有这些抽象。你可以做任何你能在常规编程语言中写的事情，你想要多线程，有一堆不同的线程，并行做事情，然后等待它们回来聚合，你可以做到。你想要某种 await，说当它们开始进来时，我就开始处理它们，没问题，你可以做到。任何你能在代码中做的事情，你都可以用 Temporal 做，因为你只是在编码。

**(1:03:30 - 1:04:00)**

这就是它与 agent SDK 一起工作的有效方式。我稍后也会再次向你展示这些东西。所以你可以并行执行，你可以有长时间等待，你可以有循环。我已经向你展示了我不必在 Python 中编写逻辑的事实。逻辑，LLM 决定了流程在该应用程序中如何发生，对吧？所以我只是有一个循环，循环本身是固定的，但循环中发生的事情完全由 LLM 决定。这些都是你可以做的事情。

有了 agents SDK，你可以用两种方式来协调这些微型 agents。顺便说一下，我必须说我喜欢微型 agent 这个术语。正如我早期提到的，我在微服务世界花了很多时间，我们从中获得了很多价值，对吧？这就是我们每天能多次部署软件的原因。这就是我们能够按现在这种方式扩展的原因。微服务已经证明自己非常有价值。我认为当涉及到构建 AI agents、MCP 工具和所有这类东西时，我们将看到非常相似的范式和非常相似的成功。

### (1:04:00 - 1:12:00) Part 9

**(1:04:00 - 1:05:15)**

OpenAI 有第二种编排方式叫做 handoffs。你在我的 agent 定义中可以看到，我可以定义 handoffs。这些 handoffs 就是其他 agents，它们已经被定义了。我应该把它放在幻灯片上，但我有一个 weather agent，它的定义非常相似。它使用的 agent 有名称、有指令，可能有工具。

所以这两个都是 agents。这一切都与 Temporal 的集成配合使用，但有趣的是，当它将任务交接给 agent 时，这些微型 agents 并不会运行独立的 agentic 循环。实际上，这是我试图描述这里发生的事情的奇怪尝试：当你进行 handoff 时，你实际上只是在改变 agentic 循环的上下文。

**(1:05:15 - 1:06:30)**

有一个单一的 agentic 循环，比如你有一个分类 agent，它决定要进入哪个服务。我在 Alexa 工作过一段时间，所以你是问"Costco 几点关门"还是问"现在的温度是多少"，对吧？这是两个不同的 agents：天气 agent 和本地信息 agent。你实际上在做的就是让那个 agentic 循环承担不同的角色。你只是在切换上下文。这周我们听了很多关于上下文工程的演讲，因为 LLM 的健忘特性是美妙的，你可以完全控制你想要什么，可以控制输入给它们的上下文是什么。

**(1:06:30 - 1:07:45)**

所以这完全有效。Temporal 完全支持 handoff。我没有这个功能的现场演示。就是这样。好的，现在我们还有几分钟的问题时间。我想留给你们一些资源。你在左侧看到的是 Temporal Python SDK 的二维码。你会在我们的 Python SDK 中找到很多有用信息，但你也会找到一个 contrib 目录，那里有所有与 OpenAI agents SDK 集成的代码。你会在那里找到很多示例。

**(1:07:45 - 1:09:00)**

在右侧，我没有为它准备二维码，因为我的营销团队周六早上不工作，这对他们来说很好。你会看到一个 URL。如果你访问我们的文档 docs.temporal.io，在顶部横幅中，你会找到 AI cookbook。我们有一个 AI cookbook，实现了一堆模式。我今天向你展示的 Agentic Loop 目前在一个分支中。它已经准备好合并了，已经被审核过，但我的审核者实际上没有给出批准审核。他们只是审核了并说"看起来不错，但我需要批准"，所以我今天早上不能合并它。

**(1:09:00 - 1:10:15)**

但是那个方案会出现在那里。还有其他一些。那里有一个 OpenAI agents SDK 的方案，你也会在那里找到它。总结一下，我不会过度阐述。我想我们也讨论过了。我想留给你们的另外两个资源是，左侧你会找到我们的博客，我们在那里描述了 OpenAI agents SDK 与 Temporal 的集成。右侧的博客是 Pydantic 的。将持久性引入这些原本非持久的 agent 框架的想法非常受欢迎。

**(1:10:15 - 1:11:30)**

在我们完成 OpenAI agents SDK 之后，Pydantic 他们自己将 Temporal 集成到了他们的 agent 框架中。Johan，我不知道我们可以谈论哪些项目。我们还有一大堆其他正在进行的项目。我们只能说这些吗，还是你想具体谈论其中的任何一个？

Johan： 今天就说这些，但还有更多即将到来。

我想我们现在正在进行两三个或四个项目，它们要么从我们这里要么从其他一些 agentic 框架中涌现出来。所以，将持久性引入原本只是概念验证工具的想法正变得相当强大。

**(1:11:30 - 1:12:00)**

最后，如果你愿意，这里有一个二维码和 URL。如果你想给我们一些关于这个工作坊的反馈，我们将非常感激。在反馈中包含你希望看到更多什么内容。比如"嘿，这很酷，但还不够深入"或者"你提到了这个，我真的很想了解更多关于 Human in the Loop 的内容"。顺便说一下，如果你访问我们的 YouTube 频道，你会找到很多不同的演示。关于 human in the loop，我三周前做了一个网络研讨会。我们做了一些 MCP 模块的内容，甚至是高级的。

### (1:12:00 - End) Part 10

**(1:12:00 - 1:13:15)**

主持人：当我启动和停止实例时，你是指 agent 吗？我是说如果用户想要停止它，我们该如何停止工作流？

约翰：有几种不同的方式可以启动工作流。你可以启动一个同步的工作流，它会自然结束，你需要某种终止机制。但更常见的是，你会以异步模式启动它，然后获得一个句柄，可以通过该句柄来停止工作流。

不过通常最常见的情况是，你会在逻辑中定义什么叫做完成了那个 agentic 体验或以某种方式完成了工作流。所以你会决定"我现在完成了"，然后直接返回。实际上就是简单地从中执行 return。

**(1:13:15 - 1:14:30)**

这是个很好的问题，因为我们在谈论这些异步的东西。我在这次会议中没有讲到，但其中一个非常强大的功能是，这些工作流可以运行数小时、数分钟、数天、数周、数月、甚至数年，而且超级高效。

我们很多用户使用的一个模式是，他们将工作流用作其他东西的数字孪生。我们也称之为实体工作流。例如，你可能有一个对应忠诚客户的工作流，每当那个忠诚客户在收银台扫描二维码时，它会向工作流发送信号，工作流在其他时候不会消耗任何资源，它只会弹出、接收信号、处理所需内容，然后再次消失。

**(1:14:30 - 1:15:45)**

这是一个非常常见的模式——将数字工作流作为其他处理器或实体的数字孪生概念。超级强大，很多人都在使用。

观众：如果工作流宕机了，而你让它处于阻塞状态等待，你们有没有与事件管理系统的集成，可以触发警报让工程师介入？

约翰：据我所知，我们没有这些集成，但我们的客户会构建这些集成。是的，他们绝对会在上面构建。我们的云服务中是否有这些功能我不确定，但我们没有原生的 Slack 连接器或类似的东西。

**(1:15:45 - 1:17:00)**

当然，其中一些不一定是 Temporal 的问题。比如如果你在 Kubernetes 上运行 worker，你可能已经设置了 Kubernetes 配置，这样当容器宕机时，你会收到警报，或者当你在 Kubernetes 仪表板中看到自动扩缩器的问题时。你可以让这些 worker 运行在带有自动扩缩器的 Kubernetes 上。所以很多这类编排工作可能会通过你的运营环境来实现。

这实际上是个很好的观点——我们托管服务器，但不为你托管工作负载。你需要自己托管工作负载。大多数人喜欢这样，因为他们想要完全控制。我们正在考虑在某些情况下未来可能托管 worker，但这目前不在路线图上。

**(1:17:00 - 1:18:15)**

观众：有人用 Temporal 构建语音代理的例子吗？

约翰：用 Temporal 构建语音代理的例子？我不知道有什么现成的。我不知道有任何已部署的。人们正在实验，我们也在实验语音代理。这绝对是有意义的，这是我们预期代理未来发展的方向之一。

观众：关于 Claude 的示例，我没有在食谱中看到。你有 Claude 的示例吗？

约翰：我目前还没有 Claude 的示例。Gemini 快完成了。我们也想将 Claude 添加到食谱中。我们也很乐意接受 PR。如果你想将这个示例映射到 Claude，我们很欢迎 PR。

**(1:18:15 - 1:19:30)**

食谱是完全开源的，在我们的主仓库中都是 MIT 许可证。

观众：有从 Excel、PDF 中提取信息的示例代理吗？

约翰：从 Excel 或 PDF 提取信息的示例代理？我个人没有。我要提到的另一件事是，我们有一个代码交换平台，我们有食谱——那是我们的，我们非常小心地确保它展示最佳实践，我们对这些进行严格审查，因为我们不想误导任何人。

我们还有一个代码交换平台，里面有大概 20、30 或 40 个示例。那里可能有相关内容，说实话我不确定。

观众：它像 GitHub 吗？

**(1:19:30 - 1:20:45)**

约翰：是的。你可以在我们网站上找到代码交换平台，我相信代码交换中的所有条目都有 GitHub URL。我们不拥有大部分内容，因为它们来自社区，但它们在其他人的仓库中。

好的，这就是... 哦，还有其他问题吗？不，我只是想说，我们提到了几次即将到来或真正酷的功能，我的团队正在招聘专注于 Temporal 的 AI 应用的人员。

既然他这么说了，我是开发者倡导团队的。我们也在招聘开发者倡导者。如果你符合工程师档案，和约翰聊聊。如果你符合开发者倡导者档案，来找我聊聊。

**(1:20:45 - 1:21:00)**

好的，非常感谢大家。

---

*生成时间: 2026-01-13 00:05:53*
*由 YouTube Monitor & Translator (Claude CLI) 生成*