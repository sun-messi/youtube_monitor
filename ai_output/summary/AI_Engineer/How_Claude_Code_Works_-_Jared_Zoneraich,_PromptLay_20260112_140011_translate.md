# How Claude Code Works - Jared Zoneraich, PromptLayer

## 📹 视频信息

- **频道**: AI Engineer
- **发布日期**: 2025-12-26
- **时长**: 1:05:43
- **原始链接**: [https://www.youtube.com/watch?v=RFKCzGlAU6Q](https://www.youtube.com/watch?v=RFKCzGlAU6Q)

---

## 视频开头信息

> 本文内容整理自 PromptLayer 创始人兼 CEO 贾里德·佐内赖希（Jared Zoneraich）在 AI Engineer 频道的技术演讲。

---

## TL;DR（一句话核心洞察）

> Claude Code 之所以能在编程助手领域取得突破性成功，是因为它采用了"给工具，让开路"的极简架构设计理念：通过一个简单的主循环 + 工具调用，避免过度工程化，充分信任模型的探索能力，而非试图通过复杂的 DAG 和分类器来规避模型缺陷。

---

## 📑 章节导航表

| 时间戳 | 章节标题 | 一句话概括 |
|--------|----------|-----------|
| 00:00-05:19 | 开场与背景介绍 | 讲者介绍自己和公司 PromptLayer，解释为什么研究编程助手的内部机制 |
| 05:19-10:00 | 编程助手的演进历史 | 从复制粘贴到 Cursor 再到 Claude Code，探讨是什么让编程助手终于变好 |
| 10:00-22:18 | Claude Code 的核心架构 | 详解简单架构的威力：主循环 + 工具调用，避免过度工程化 |
| 22:18-30:31 | 工具系统与子代理 | 深入分析各种工具（bash、grep、read等）的设计哲学和子代理的上下文管理 |
| 30:31-38:46 | 系统提示词与技能系统 | 探讨系统提示词的设计、技能（Skills）系统的扩展性以及未来发展方向 |
| 38:46-48:34 | 其他编程助手对比分析 | 分析 Codeex、Cursor Agent、AMP 等竞品的不同设计理念和优势 |
| 48:34-57:18 | 评估与测试策略 | 讨论如何评估编程助手的效果，包括端到端测试、工具测试等方法 |
| 57:18-65:43 | 问答环节与总结 | 回答观众关于 DAG vs 循环、规范驱动开发等问题，总结核心观点 |

---

## 📊 核心论点

### 1. 简单架构胜过复杂系统：编程助手的设计革命

- **核心内容**：Claude Code 成功的关键在于其极简的架构设计 - 仅使用一个主循环（while loop）配合工具调用，摒弃了早期编程助手中常见的复杂 DAG（有向无环图）、分类器、RAG（检索增强生成）等组件。这种设计理念是"给它工具，然后让开路"（give it tools and get out of the way）。模型在主循环中不断调用工具，获取结果，继续调用，直到完成任务。这种简单性让系统更容易维护、调试和改进。
- **关键概念**：主循环架构、工具调用（tool calls）、简单性原则、Python 之禅、扁平优于嵌套
- **实际意义**：开发者在构建自己的 AI 代理时应避免过度工程化，不要试图通过复杂的控制流来弥补模型的不足。随着模型能力的提升，简单架构能够更好地利用模型的改进，而复杂系统反而会成为瓶颈。

### 2. Bash 是万能工具：为什么选择最通用的接口

- **核心内容**：在所有工具中，Bash 是最重要的。Claude Code 可以通过 Bash 执行任意操作，包括创建 Python 文件、运行测试、删除临时文件等。这种设计的天才之处在于：(1) Bash 是人类开发者最常用的工具，有海量训练数据；(2) 它是通用的，可以调用任何其他工具；(3) 它让模型能够尝试和探索，而不是被限制在预定义的操作集中。甚至可以说，理论上只需要 Bash 一个工具就足够了。
- **关键概念**：通用接口、训练数据优势、人类任务模拟、探索性执行、沙箱环境
- **实际意义**：构建 AI 代理时应该优先考虑通用性强、训练数据丰富的工具接口。不要创造全新的、模型不熟悉的工具抽象，而应该模拟人类开发者的工作方式。

### 3. 上下文管理是核心挑战：如何让模型保持智能

- **核心内容**：上下文长度是编程助手面临的"头号敌人"。随着上下文增长，模型会变得"更笨"。Claude Code 通过多种策略管理上下文：(1) 使用子代理（sub-agents）处理特定任务，只返回结果而不污染主上下文；(2) 使用异步缓冲区（H2A）智能压缩和总结历史信息；(3) 将长期记忆保存为文件而非保持在上下文中；(4) 使用 diff 而非重写整个文件来减少 token 使用。当上下文达到 92% 容量时，系统会自动进行压缩。
- **关键概念**：上下文窗口、子代理隔离、异步缓冲、上下文压缩、长期记忆存储
- **实际意义**：开发高效的 AI 代理必须将上下文管理作为首要考虑。使用分层架构、任务隔离和智能压缩策略可以显著提升代理的性能和可靠性。

### 4. 待办事项列表的威力：结构化但不强制执行

- **核心内容**：Claude Code 的待办事项（to-do）系统看似简单，却极大提升了用户体验和模型表现。有趣的是，这个系统完全基于提示词，没有任何代码层面的强制执行。模型被指示一次只处理一个任务、标记完成状态、遇到错误时保持任务为进行中等。这种设计依赖于现代模型优秀的指令遵循能力，在一两年前是不可能实现的。它强制模型进行计划、提供进度可见性、支持崩溃后恢复，并提高了可操控性。
- **关键概念**：结构化规划、纯提示词实现、指令遵循、用户体验、进度追踪
- **实际意义**：现代 LLM 的指令遵循能力已经足够强大，很多原本需要硬编码的功能现在可以通过精心设计的提示词实现。这种方法更灵活、更容易迭代。

### 5. 不同哲学共存：为什么不会有"最佳"编程助手

- **核心内容**：作者提出"AI 治疗师问题"类比 - 就像纽约每个街区都有 6 个治疗师，每个都有不同方法（冥想、CBT、死藤水等），编程助手也没有全局最优解。Claude Code 擅长用户友好性和 Git 操作；Codeex 在处理复杂问题时更强大；Cursor 的 Composer 速度最快；AMP 注重代理友好环境；Factory 专注于专门化的子代理。这种多样性是健康的，因为不同任务需要不同方法。
- **关键概念**：多样化生态、专业化优势、用户偏好、任务适配、防御性护城河
- **实际意义**：企业在选择或构建编程助手时，应该根据具体使用场景选择合适的工具或设计理念，而不是寻找"万能"解决方案。差异化和专业化是构建竞争优势的关键。

### 6. 技能系统：可扩展的系统提示词

- **核心内容**：技能（Skills）系统本质上是一个可扩展的系统提示词机制。它解决了 Claude.md 文件过长（超过 40k 字符会警告）的问题，允许按需加载特定领域的知识和指令。例如，文档更新技能包含写作风格指南，设计技能包含设计原则，深度研究技能包含研究方法论。虽然目前模型在自动调用正确技能方面还不完美（通常需要手动指定），但这个架构方向是正确的 - 它平衡了上下文限制和功能丰富性。
- **关键概念**：模块化知识、按需加载、领域特定指令、上下文优化、可扩展架构
- **实际意义**：构建复杂 AI 系统时，模块化和按需加载是管理复杂性的有效方法。这种设计模式可以让系统在保持简单核心的同时，支持无限的功能扩展。

### 7. 从 DAG 到循环：信任模型的探索能力

- **核心内容**：传统 AI 代理使用复杂的 DAG 来控制执行流程，试图预防每一个可能的错误。但这种方法创造了难以维护的"工程疯狂之网"。现代模型已经足够智能，可以通过探索和自我纠正来完成任务。作者举例说，他试图为网站按钮添加标签来帮助浏览器代理导航，结果反而让代理表现更差 - 因为过多的指令限制了模型的探索能力。关键是要"依靠模型"（rely on the model）而不是试图控制每个细节。
- **关键概念**：探索式学习、自我纠正、灵活性优于刚性、模型信任、简化控制流
- **实际意义**：AI 工程的范式正在转变 - 从"防御性编程"（预防模型出错）转向"赋能性设计"（让模型自由探索和纠错）。这需要开发者改变思维模式。

### 8. 评估策略：如何测试不确定性系统

- **核心内容**：评估编程助手面临独特挑战，因为简单的 while 循环架构使系统行为更加灵活和不确定。作者提出三种评估方法：(1) 端到端测试 - 给定任务，检查是否完成；(2) 时间点快照 - 在特定上下文中验证工具调用；(3) 回测 - 使用历史数据重现执行。还引入了"代理异味"（agent smell）概念 - 通过工具调用次数、重试次数、执行时间等表面指标进行快速健全性检查。对于需要确定性输出的部分，可以将其封装为可严格测试的工具。
- **关键概念**：端到端测试、时间点验证、历史回测、代理异味、工具隔离测试
- **实际意义**：测试 AI 系统需要新的方法论。混合使用不同粒度的测试，在关键功能上保持确定性，在探索性任务上接受灵活性，是实用的平衡策略。

### 9. 模型选择与适应性预算

- **核心内容**：未来的编程助手将更智能地选择和切换模型。AMP 的"快速/智能/神谕"三级模型，Cursor 同时显示三个模型的执行，Claude Code 的"思考/深思/超级思考"触发机制，都指向同一趋势：根据任务难度动态调整计算资源。这类似于把推理模型作为工具调用 - 大部分时间使用快速便宜的模型，遇到难题时调用强大但昂贵的模型。推理预算成为模型可以自主调整的另一个参数。
- **关键概念**：自适应计算、模型分级、推理预算、动态资源分配、成本优化
- **实际意义**：未来的 AI 系统将更像人类 - 对简单任务使用"系统 1"快速思考，对复杂问题启用"系统 2"深度推理。这种自适应架构将大幅提升效率和降低成本。

### 10. 统一差异格式：为什么 Diff 是关键创新

- **核心内容**：使用统一差异（Unified Diff）格式而非重写整个文件是一个看似简单但影响深远的设计决策。这不仅减少了 token 使用量，提高了速度，更重要的是降低了错误率。作者类比：让你修改文章时，在纸上划掉修改比重新抄写整篇文章容易得多。Diff 是一种自然的防错机制。一些编程助手甚至开发了自己的 diff 标准变体，因为标准 unified diff 中的行号有时是不必要的。这个简单的选择体现了"针对模型优化"的设计思维。
- **关键概念**：增量修改、错误预防、token 效率、认知负载、格式标准化
- **实际意义**：在设计 AI 系统的接口时，应该选择最符合任务认知模型的格式。对于代码修改任务，差异格式比完整重写更自然、更安全、更高效。

---

## 🏢 提及的公司/产品

| 公司名 | 讨论语境 | 重要性 |
|--------|----------|--------|
| Anthropic | Claude Code 的开发商，推动模型和工具调用能力的进步 | ⭐⭐⭐ |
| PromptLayer | 讲者的公司，AI 工程工作台，提供提示词管理和评估平台 | ⭐⭐⭐ |
| Cursor | 领先的 AI 代码编辑器，以速度快和 Composer 功能著称 | ⭐⭐⭐ |
| Sourcegraph | Codeex 编程助手的开发商，专注于代码理解和搜索 | ⭐⭐ |
| OpenAI | GPT 系列模型提供商，编程助手生态的重要参与者 | ⭐⭐ |
| Factory | Droid 编程助手开发商，专注于专门化子代理 | ⭐⭐ |
| Cognition | Devon 自主编程助手的开发商 | ⭐ |

---

## 💬 经典金句

> "Give it tools and then get out of the way."（给它工具，然后让开路）
> — Jared Zoneraich

> "The longer the context, the stupider our agent is."（上下文越长，代理越笨）
> — Jared Zoneraich

> "Simple is better than complex, complex is better than complicated, flat is better than nested."（简单优于复杂，复杂优于繁复，扁平优于嵌套）
> — Python 之禅（引用）

> "Switch weapons, it's faster than reloading."（切换武器，比换弹匣快）
> — Jared Zoneraich（类比 AMP 的 handoff 功能）

> "When in doubt, rely on the model."（有疑问时，相信模型）
> — Jared Zoneraich

---

## 👤 主要人物

### Jared Zoneraich（贾里德·佐内赖希）

**身份**：PromptLayer 创始人兼 CEO
**背景**：AI 工程领域的创业者，公司位于纽约。PromptLayer 创立于 3 年前（AI 领域算是老牌，其他领域算新），专注于为 AI 工程提供严格的提示词工程和代理开发工具。每天处理数百万 LLM 请求。作为创始人，他花大量时间使用自己的产品来构建代理（dog fooding）。
**核心观点**：他的团队完全围绕 Claude Code 重建了工程组织，制定规则：如果任务能在一小时内用 Claude Code 完成，就直接做，不要排期。他认为编程助手成功的关键是简单架构和对模型能力的信任，而不是试图通过复杂系统来弥补模型缺陷。强调不同编程助手会有不同优势，不存在"最佳"方案，就像治疗师有不同流派一样。

---

## 📺 视频类型判断

**演讲独白**：单人技术演讲，包含大量技术细节分析和代码示例展示

---

## 📝 完整翻译

### (0:00 - 8:00) Part 1

**(0:00 - 1:15)**

欢迎来到最后一个工作坊。你们成功了，恭喜！从大约 800 人中脱颖而出，你们是最后坚持下来的非常专业的工程师们。这一场有点特别，我因为这个标题还被 Anthropic 找了麻烦。显然是因为标题的缘故。实际上我也把标题给了他，问他要不要修改，他说不用，就这样用吧，挺有趣的。这并非 Anthropic 官方认可的内容，但我们是黑客，对吧？Jared 非常专业。另外我很喜欢的一点是介绍纽约本地的 AI 人才，所以不要以为这是 Jared 唯一在做的事情。他有自己的完整创业公司，你们绝对应该向他了解。我很兴奋能为本地人才提供更多内容展示机会。好的，Jared，开始吧。

**(1:15 - 2:30)**

非常感谢，非常感谢。这真是一个了不起的会议。虽然很遗憾要结束了，但希望这会是一个精彩的收尾。我是 Jared，这场演讲将讲述 Claude Code 是如何工作的。再次声明，与 Anthropic 无关。他们不付我钱，虽然我愿意收，但他们就是不给。我们还会谈论其他几个编程代理。我个人的核心目标是，作为所有编程代理的重度用户，就像在座的各位一样，这些工具最近爆发式增长，作为开发者我很好奇发生了什么变化，是什么让编程代理终于变得好用了。

**(2:30 - 3:45)**

让我们开始吧。先介绍一下我自己。我是 Jared，你们可以在 Twitter 或 X 上找到我，用户名是 Jared Z。我正在构建 AI 工程的工作台。我的公司叫 PromptLayer，总部在纽约。你们可以看到我们的办公室，是一栋小楼，被其他几栋楼遮挡了，所以我们是个小团队。三年前我们推出了这个产品，对 AI 来说算是很久了，但对其他领域来说还很年轻。我们的核心理念是相信严谨的提示工程、严谨的代理开发，我们认为产品团队应该参与进来，工程团队也应该参与进来。如果你在构建 AI 律师，那么律师和工程师都应该参与其中。

**(3:45 - 5:00)**

这就是我们在做的事情，每天处理数百万次大语言模型请求。这次演讲中的很多见解来自我们与客户关于如何构建编程代理等话题的对话。整个演讲过程中请随意提问，我们可以让气氛轻松一些。如果我说的任何内容有疑问，请随时提出来。我花了很多时间来体验我们自己的产品，这是创始人现在工作的奇怪之处，一半时间在启动代理，另一半时间在使用自己的产品来构建代理，感觉很奇怪但挺有趣的。

**(5:00 - 6:15)**

最后要补充的是，我是个狂热爱好者。我们真的围绕 Claude Code 重构了整个工程组织。构建平台的难点在于你必须处理所有这些边缘案例，比如我们在这里上传数据集但不工作，你可能会被千刀万剐而死。所以我们为工程组织制定了一个规则：如果你能用 Claude Code 在一小时内完成某件事，那就直接去做，不要排优先级。我们故意保持小团队规模，但这确实帮助了我们很多，我觉得真的让我们提升到了下一个水平。所以我是个忠实粉丝，让我们深入了解这些工具是如何工作的。

**(6:15 - 7:30)**

正如我所说的，这就是这次演讲的目标。首先，为什么这些工具会爆发式增长？是什么创新、什么发明让编程代理终于开始工作了？如果你在这个领域待过一段时间，你就知道很多自主编程代理在开始时都很糟糕，我们都试图使用它们。但现在简直是天壤之别。我们会深入内部机制，最后，这次演讲的一切内容都围绕着如何构建你自己的代理以及如何使用它们来为自己做 AI 工程。

**(7:30 - 8:00)**

让我们谈谈历史，我们是如何走到今天的。大家都知道是从复制粘贴 ChatGPT 代码的工作流程开始的，那很棒，在当时是革命性的。第二步，当 Cursor 出现时，如果我们都记得的话，开始时软件并不那么好。它只是 VS Code 的一个分支，带有 Command K 功能，我们都很喜欢。但现在我们不再使用 Command K 了。然后我们有了 Cursor 助手，那个小型来回对话代理，接着是 Claude Code。

### (8:00 - 16:00) Part 2

**(8:00 - 9:15)**

今天的很多缺陷都会得到改善，所以你不应该浪费时间去修复它们。这就是我对 Claude Code 的理解哲学：忽略嵌入向量，忽略分类器，忽略部分匹配。我们之前有整个 RAG 系统，实际上 Cursor 又带回了一点 RAG 功能，他们在混合搭配使用。但我认为 Claude Code 的天才之处在于，他们抛弃了这一切，说我们不需要这些花哨的范式来解决模型的缺陷。让我们直接做一个更好的模型，然后让它发挥作用，只依赖这些工具调用，并简化工具调用，这是非常重要的一部分。

**(9:15 - 10:30)**

不再使用主提示可以分成三个不同分支，然后再分成四个不同分支的工作流程，而是真正只有几个简单的工具调用，包括使用 Grep 而不是 RAG，这就是它们训练的内容。所以这些都是非常优化的工具调用模型。这就是 Python 之禅，如果你们熟悉的话，在 Python 中输入 import this 就能看到。我喜欢这个构建系统的哲学，我认为它非常适合 Claude Code 的构建方式。简单胜过复杂，复杂胜过繁琐，扁平胜过嵌套。

**(10:30 - 11:45)**

这就是你需要知道的一切，这就是整个演讲的内容。这就是你需要了解的关于 Claude Code 如何工作以及为什么有效的全部知识，特别是我们回归到工程原则，即简单的设计就是更好的设计。我认为无论你是在构建数据库架构还是构建这些自主编程代理，这都是正确的。现在让我来分解这个编程代理的所有具体部分，以及为什么我认为它们很有趣。

**(11:45 - 13:00)**

首先是规范文件。我们很多人都认为理所当然，尽管他们一个月或两个月前，或者三四个月前才开始这样做。这就是 CLAUDE.md 代码库，其他人使用 agents.md。我想大多数人都知道这是什么，就是你为你的库放置指令的地方。有趣的是，这基本上是团队在说，我们不需要过度工程化一个系统，让模型首先研究代码库，比如 Cursor 1.0 在本地创建向量数据库来理解代码库并进行所有这些研究。他们只是说："啊，只需放一个 markdown 文件。让用户在需要时更改内容，让代理在需要时更改内容，非常简单。"

**(13:00 - 14:15)**

这又回到了提示工程，我可能有点偏向于此，因为 PromptLayer 是一个提示工程平台，但最终一切都是提示工程或上下文工程。一切都是关于如何为你的使用调整这些通用模型？我认为这里最简单的答案就是最好的答案。这就是系统的核心，只是一个简单的主循环。考虑到我们过去构建代理的方式，这实际上是革命性的。Claude Code 和今天所有的编程代理，包括 Codebase、新的 Cursor 和 AMP 等，都只是一个带有工具调用的 while 循环，运行主 while 循环，调用工具，然后回到主 while 循环。

**(14:15 - 15:30)**

这基本上就是四行代码。我认为他们内部称之为 N0，至少根据我的研究是这样的。只要有工具调用，就运行工具，将工具结果给模型，然后再次执行，直到没有工具调用，然后询问用户该做什么。第一次使用工具调用时，我非常震惊，模型竟然如此擅长知道何时继续调用工具，何时修复错误。我认为这是 LLM 最有趣的地方之一，它们真的很擅长修复错误和保持灵活性。回到前面的观点，你越是依赖模型去探索和解决问题，当模型变得更好时，你的系统就会变得更好、更稳健。

**(15:30 - 16:00)**

这些是我们今天在 Claude Code 中拥有的核心工具。说实话，这些每天都在变化。你知道，他们每隔几天就会发布新版本，但这些是我发现最有趣的核心工具。明天可能有 15 个工具，也可能减少到 5 个工具，但这就是我觉得有趣的地方。首先是 Read 工具。是的，他们可以直接用 cat 命令，但有趣的是 Read 工具考虑到了我们有 token 限制。如果你经常使用 Claude Code，你会看到有时它会说这个文件太大或类似的话。这就是为什么值得构建这个 Read 工具的原因。还有 Grep 和 Glob 工具。

### (16:00 - 24:00) Part 3

**(16:00 - 17:15)**

之所以如此稳健。但同样重要的第二点是，有大量的训练数据支持，因为这就是我们使用的语言。这就是为什么模型在 Rust 或其他不常见编程语言上表现不佳的原因，仅仅是因为使用这些语言的人较少。

所以它真的是通用适配器。你有数千种工具，可以做任何事情。这是我刚才给出的 Python 示例。我总是觉得当它执行 Python 脚本或创建测试时非常酷，不过我总是要告诉它不要这样做。但所有这些 shell 工具都在其中。我发现自己经常使用 Claude Code 来启动本地环境，通常我会在某个文件中写下五个命令，然后这些命令就过时了。它真的很擅长搞清楚这些东西并运行你想要做的事情。

**(17:15 - 18:30)**

它特别允许模型尝试各种操作。这里的其他建议和工具使用，我认为系统提示中有一些内容告诉它使用哪些工具以及何时使用哪种工具，这会经常变化，但这些都是你发现模型陷入困境的边缘情况和角落。比如编辑前先读取，他们实际上强制你使用 Grep 工具而不是 bash。如果你看这里的工具列表，有一个特殊的 Grep 工具。这可能有很多原因，我认为安全是一个重要因素，还有沙盒，但也包括 token 限制，以及并行运行独立操作。所以在某种程度上推动模型更多地这样做。还有像引用包含空格的路径这样的琐碎事情，就是常见的问题。我确信他们在 Anthropic 内部大量使用，发现问题后就说："好吧，我们把它加入系统提示中。"

**(18:30 - 19:45)**

好，现在让我们谈谈待办事项列表。同样，这是一个非常常见的功能，但在以前并不常见。这实际上是我为这个幻灯片进行研究时的待办事项列表。但待办事项列表真正有趣的地方在于它们是结构化的，但不是结构性强制的。

规则如下：一次执行一个任务，标记为已完成，这是你期望的那种东西。如果有阻塞或错误，继续处理进行中的任务，并将任务分解为不同的指令。但对我来说最有趣的是，这不是确定性强制执行的。它纯粹基于提示，纯粹在系统提示中，纯粹因为我们的模型现在很擅长遵循指令。这在一年前是不可能的，两年前也不可能。

**(19:45 - 21:00)**

系统提示顶部有工具描述，我们将待办事项注入系统提示中。但它不是在实际代码中强制执行的。也许有其他智能体采取相反的路径。我只是觉得这很有趣，至少作为用户，这会产生很大的差异，甚至看起来实现起来非常简单，几乎就像某人周末做的项目，而且似乎有效。我可能对此判断错误，但是，它就是一个函数调用。

当你第一次询问某事时，推理会导出这个待办事项块，我将在下一张幻灯片中展示结构是什么样的。里面有 ID，有某种结构化模式和确定性，但它只是被注入到那里。

**(21:00 - 22:15)**

这是一个示例，展示它可能的样子。你得到一个版本，你的 ID，待办事项的标题，然后它实际上可以注入证据。这是看似任意的数据块，它可以使用。ID 是哈希值，然后它可以引用标题，一些人类可读的内容，但这只是结构化数据的另一种方式。就像你工作时会整理桌子一样，这就是我们试图组织模型的方式。

我认为我们得到了四个好处：我们强制它进行规划，我们可以在崩溃后恢复，Claude Code 会失败。我认为用户体验是其中很大一部分。作为用户，你知道它的进展情况，它不是只在那里循环运行 40 分钟而没有给你任何信号。所以用户体验不容忽视。

**(22:15 - 23:30)**

即使用户体验可能不会让它成为更好的编码智能体，但它可能让我们所有人更好地使用它，还有可操控性。这里还有两个隐藏的部分：异步缓冲区，他们称之为 H2A。这是一种 IO 过程，以及如何将其与推理解耦，以及如何以一种不只是将你在终端中看到的所有内容都塞回模型的方式管理上下文，因为上下文是我们这里最大的敌人。它会让模型变笨。

所以我们需要在压缩和总结方面聪明一点。所以你在这里看到，当它达到容量时，它会丢弃中间部分，总结头部和尾部。然后我们有上下文压缩器。限制是什么？似乎是 92% 之类的。它如何保存长期存储？这实际上是 bash 和拥有沙盒的另一个优势。

**(23:30 - 24:00)**

我甚至会在这里做一个预测，你所有的 ChatGPT 窗口，所有的 Claude 窗口在不久的将来都会配备沙盒。这会好得多，因为你可以存储长期记忆。我一直这样做，我有用于深度研究等的 Claude Code 技能，我总是指示它保存 Markdown 文件，因为上下文越短，速度越快，也越智能。

这就是我最兴奋的地方。我们不需要像这样的 DAG（有向无环图）。我给你一个真实的例子。PromptLayer 的一些用户，不同的智能体，比如客户支持智能体，基本上每个人在过去两年半里都在构建这样的 DAG。这很疯狂，数百个节点：如果这个用户想要退款，就把他们路由到这个提示；如果他们想要那个，就路由到另一个提示，还有很多分类提示。

### (24:00 - 32:00) Part 4

**(24:00 - 24:50)**

也许我可以再运行一次，也许我在这个测试中做错了什么，但它让智能体在 PromptLayer 上的导航变得更糟，因为它分心了，因为我告诉它你必须点击这个按钮，然后你必须点击那个按钮，然后它不知道该做什么。所以，最好依靠探索。你有问题吗？

**(24:50 - 25:20)**

我会稍微反驳一下。我承认我们今天创建的任何脚手架来解决特殊性或局限性都会在3到6个月内过时，即使如此，它们今天还是有点帮助。你如何平衡这种浪费的工程来解决我们只会遇到三个月的问题？

**(25:20 - 26:10)**

这是个很好的问题。重复一下，问题基本上是解决我们今天实际遇到的问题和依赖一个现在还做不到但三个月后就能做到的模型之间的权衡是什么？这要具体情况具体分析，取决于你在构建什么。如果你在为银行构建聊天机器人，你可能确实想要更谨慎一些。对我来说，快乐的中间地带是使用这种智能体范式，即主循环和工具调用，但让你的工具调用非常严格。

**(26:10 - 27:00)**

所以我认为有一个看起来像这样或看起来像这一半的工具调用是可以的，就像 Claude Code 使用 read 作为工具调用或使用 GP 作为工具调用一样。所以对于边缘情况，把它放在一个结构化工具中，然后你可以对它进行版本评估等等。我稍后会更多地谈论这个，但把它放在那个结构化工具中。但对于其他一切，对于探索阶段，交给模型或添加一些系统提示。所以这是一个权衡，非常依赖于具体用例，但我认为这是个好问题。谢谢。

**(27:00 - 27:50)**

回到 Claude Code。我们要摆脱所有这些东西。我们说我们不想要基于 ML 的意图检测。我们不想要 ReAct。我们不想要——我是说它确实使用了一点 ReAct，但我们不想把 ReAct 烘培进去。我们不想要分类器。很长一段时间我们实际上为 PromptLayer 构建了一个产品。我们从未发布它，因为那只是一个原型，在你的提示管道中使用基于 ML 的非 LLM 分类器而不是 LLM。

**(27:50 - 28:40)**

很多人在这方面取得了很大成功，但感觉越来越像它不会那么有用，除非成本对你来说是一个巨大的担忧。即使如此，较小模型的成本也在下降，因为所有这些公司之间的金融工程为我们的 Token 买单。Claude 也在触发阶段做了这个聪明的事情。你知道，你有思考、努力思考、更努力思考，而超级思考是我的最爱。这让我们可以使用推理预算，推理 Token 预算作为模型可以调整的另一个参数。

**(28:40 - 29:30)**

这实际上是模型可以调整的，但这是我们强制它调整的方式。而不是你可以为硬规划做一个工具调用。实际上，有一些编码智能体会这样做。或者你可以让用户指定它，然后在运行中改变它。这是这里最大的话题之一。沙盒和权限。老实说，这对我来说是最无聊的部分，因为我有一半时间都在 YOLO 模式下运行它。

**(29:30 - 30:20)**

我们团队的一些人实际上删除了他们所有的本地数据库。所以你确实必须小心。当然，我们不会对我们的企业客户使用 YOLO 模式，但我认为这个东西感觉像是会被解决的，但我们确实需要了解它是如何工作的。所以来自互联网的提示注入有一个大问题。如果你连接这个具有 shell 访问权限的智能体，并且你在进行 web fetch，那是一个相当大的攻击向量。所以有一些容器化。有阻止 URL。你可以看到 Claude Code 对"我可以从这个 URL 获取吗？我可以做这个吗？"非常烦人，它把它放进一个子智能体中。

**(30:20 - 31:10)**

是的，这里最复杂的代码大部分都在这个沙盒和权限集中。我认为有整个管道来管控 bash 命令。根据前缀，它如何通过沙盒环境，很多其他模型在这里工作方式不同。但这是 Claude Code 的做法。我稍后会在最后解释其他的。这里相关的下一个话题是子智能体。这回到了上下文管理和这个我们一直回到的问题：上下文越长，我们的智能体就越愚蠢。这是对它的一个答案。

**(31:10 - 32:00)**

所以为特定任务使用子智能体，子智能体的关键是它有自己的上下文，它只反馈结果，这就是你如何不让它混乱。所以我们有研究员，这只是四个例子：研究员、文档阅读器、测试运行器、代码审查员。在我之前谈到的那个例子中，当我在我们的网站上添加所有标签来让智能体做得更好时。显然我使用了一个编码智能体来做这件事，我说先阅读我们的文档然后做，它会在一个子智能体中做这件事。它会反馈信息，这里的关键是智能体的分叉以及我们如何将它聚合回我们的主上下文。

### (32:00 - 40:00) Part 5

**(32:00 - 33:15)**

我们可以回到系统提示词。Claude Code 的系统提示词有一些泄露版本，我就是基于这些来分析的。你可以在网上找到。我从中注意到了一些要点：简洁输出，显然不要给出过长的回答；不要说"这是什么"或"我将要做什么"，而是直接执行用户想要的任务；推动它更多地使用工具而不是文本解释。显然，我认为当我们都构建过编码智能体时，它通常会说"嘿，我想运行这个SQL"，不，要推动它使用工具；匹配现有代码，不添加注释。这一点对我来说不太有效，但广泛地并行运行命令，以及待办事项之类的。有很多你可以通过系统提示词来引导它做的事情。

**(33:15 - 34:30)**

但正如你所看到的，我认为这里有一个很有趣的观点，回到你之前关于DAG和循环之间权衡的问题。很多这些东西你可以看到，感觉就像是有人在使用Claude Code时说："哦，要是它少做一点这个，或者多做一点那个就好了。"这就是提示词发挥作用的地方，因为迭代起来很容易，这不是硬性要求，但只要它稍微多说一点就行。有时候说一点是可以的。

**(34:30 - 35:45)**

好，技能（Skills）。技能很棒，它是一个相对较新的功能。说实话，我最近才被说服。我用技能构建了这些幻灯片。在这次关于架构的讲话背景下，基本上可以把它看作是可扩展的系统提示词。就像我们不想让上下文变得混乱一样，有很多不同类型的任务你需要完成，而你希望获得更多的上下文。这就是我们给Claude Code提供的几个选项，让它能够利用更多信息。这里有一些例子。我用这个功能有一个文档更新技能，告诉它我的写作风格和我的产品。所以，如果我想做文档更新，我就说使用那个技能，加载那个技能。

**(35:45 - 36:50)**

编辑Microsoft Office，Microsoft Word和Excel。我不使用这个，但我见过很多人在使用它。它有点像反编译功能，真的很酷。它让Claude Code做设计风格指南，这是一个常见的功能。深度研究，前几天我输入了一篇文章或GitHub仓库关于深度研究如何工作的内容，我说把它重建为Claude Code技能，效果非常好，太棒了。

**(36:50 - 37:40)**

统一差异比较（Unified Diffing），我认为这值得单独一张幻灯片。这很明显，可能不需要过多讨论，但它让一切变得好多了，让token限制更短，更快，更不容易出错，就像我之前给出的那个例子，当你重写一篇文章与用红线标记它的区别。它就是更好。我强烈建议在你做的任何智能体中使用差异比较。统一差异比较是一个标准。当我研究很多这些编码智能体时，有些实际上构建了它们自己的标准，对统一差异比较有轻微的变化，因为你并不总是需要行号，但统一差异比较确实有效。

**(37:40 - 38:45)**

你有一个问题。

"回到技能。我不知道有没有人见过，Claude Code会用黄色文本警告你，如果你的Claude实际上超过4万个字符。所以我想好吧，让我把这个分解成技能。所以我花了一些时间，然后Claude忽略了我所有的技能。所以我把它们放到某个地方。所以我怎么了？我不知道。技能感觉全球性地被误解了，或者我遗漏了什么。帮我理解一下。"

是的。所以问题是关于，好的，所以Claude Code系统Claude MD，它告诉你当它太长时。所以你把它移到技能中，然后它不识别技能，在需要时不选择它。

是的。

我会说把这个问题提给Anthropic团队。但这也是一个很好的例子，也许是系统提示词的问题。

**(38:45 - 40:00)**

"这就是意图，比如技能你需要调用它们，智能体本身不应该一直调用它们。"

对吧？它确实给模型提供每个技能的描述，或者应该告诉它"好的，这里是每个技能的一行描述"。所以理论上在一个完美的世界里，它会一直选择所有技能。但你是对的，我通常必须手动调用技能。我认为这是一个很好的回归到什么时候提示词是正确的解决方案，或者什么时候DAG是正确的解决方案，或者也许这是一个模型训练问题的联系。也许他们需要在后训练中做更多工作，让模型调用技能，这几乎就像调用工具调用。你必须知道什么时候调用它。所以也许这只是一个功能，还不是很好，但我认为这个范式很有趣，但正如我们学到的，它并不完美。

### (40:00 - 48:00) Part 6

**(40:00 - 41:15)**

就像在纽约市，如果我需要看心理治疗师，每个街区都有六个。没有全球通用的最佳治疗师答案。有不同的策略。有的治疗师做冥想或认知行为疗法，也许有的会给你死藤水。这些只是针对同一目标的不同策略，就像你在构建AI治疗师时一样，没有全局最大值。这有点像我的反AGI观点，但这也说明了当你构建这些应用时，品味很重要，设计架构也很重要。

**(41:15 - 42:30)**

你可以有五个不同的编码智能体，都很棒。没人知道今天哪个最好。说实话，我不认为Anthropic知道。我不认为OpenAI知道。我不认为Source Graph知道。没人知道谁的最好，但有些在某些方面更好。我个人喜欢Claude Code用来运行本地环境、使用git或这些需要来回交互的人类操作，但我会用Codeium解决难题，或者用Cursor的Composer因为它更快。

**(42:30 - 43:45)**

基本上，所有这些都说明在这里拥有不同理念是有价值的。我不认为会有一个赢家。我认为不同用例会有不同的赢家。顺便说一句，这不仅仅是编码智能体。这是所有AI产品。这就是为什么我们整个公司专注于领域专家，引入产品经理和主题专家，因为这就是你建立护城河的方式。

**(43:45 - 44:30)**

这里是我的观点。我认为这不是编码智能体的完整列表，但这些是我认为最有趣的。Claude Code我认为在用户友好性和简洁性方面获胜。就像我说的，如果我在做需要大量应用的事情，git就是最好的例子。如果我想创建PR，我会用Claude Code。

**(44:30 - 45:45)**

Codeium在上下文管理方面真的很好。感觉很强大。我有证据证明它更强大吗？可能没有。但对我来说感觉是这样，市场也这么认为。这里有另一个对话要说市场最了解，人们谈论的最了解，但我不知道他们是否也知道。Cursor IDE是那种模型无关的视角。它更快。Factory制作了Droid，很棒的团队。他们也在这里。他们有多个，他们真正专门化了这些Droid子智能体。所以这是他们的优势，这也许也是DAG对话或者也许是模型训练。

**(45:45 - 47:00)**

Cognition的Devon，这种端到端的自主性、自我反思。AMP我一会儿会更多谈论。他们有很多有趣的观点，实际上我发现他们这些天很令人兴奋。Free it是模型无关的，对用户有很多UX糖衣，实际上我喜欢他们的设计，他们在这次会议上的演讲，他们有非常独特的观点。

**(47:00 - 48:00)**

让我们从Codeium开始，因为它很受欢迎。它与Claude Code非常相似，同样的主while循环，大多数都这样做，因为这就是获胜的架构。有趣的是Rust核心。酷的是它是开源的，所以你实际上可以用Codeium来理解Codeium是如何工作的，这就是我所做的。它更多是事件驱动的，在并发线程这里投入了更多工作，提交队列、事件输出，就是我在Claude Code中谈到的IO缓冲区的东西。我认为他们做得有点不同。沙箱化非常不同。他们的更多是基于内核的，然后状态，这些都在线程和权限下，我会说这是主要的不同点。然后真正的区别说实话是模型。

### (48:00 - 56:00) Part 7

**(48:00 - 49:15)**

我要说同样的情况也适用于OpenAI的CodeX模型。它们虽然不够快，但它们针对这些编程agent进行了优化，并且经过了蒸馏。我可以预见OpenAI会推出一个非常快的模型，因为他们也拥有数据。

这是他们博客上的一张图片。我认为你可以从中看出他们对编程agent的看法，仅仅基于他们展示的三个运行模型。他们提供Composer，但让你使用最先进的模型，因为他们知道也许GPT-5.1在规划方面更优秀，这里显示的是5，但现在我们有了5.1。

所以这就引出了一个重要问题：我们应该使用哪一个？哪种架构最好？我们应该怎么做？

**(49:15 - 50:30)**

我的观点是基准测试相当无用。基准测试已经成为许多模型提供商的营销手段。每个模型都声称击败了基准测试。我不知道这是怎么发生的，但我认为评估确实很重要。

问题是你能评估什么。问题是这整个简单的while循环架构——我一直在基于我的理解推广它——实际上让评估变得更加困难，因为如果我们更多地依赖模型的灵活性，你如何测试它？你可以运行集成测试，这种端到端测试，然后问："它解决问题了吗？"这是一种方法。你也可以分解它。你可以做时间点快照，说："嘿，我要给我的聊天机器人一个来自半完成对话的上下文，我知道它应该运行特定的工具调用。"我可以运行这些测试。或者我可以运行回测，问："它多久改变一次工具？"

**(50:30 - 51:45)**

我认为还有另一个概念正在被开发，叫做"agent气味"，至少我是这么称呼它的。运行一个agent，看看它调用工具多少次？重试多少次？花费多长时间？这些都是表面指标，但对于健全性检查非常有用。这些东西很难评估，涉及很多因素。我来展示一个我做的例子来深入探讨。

但在这个话题上，我再说一点。我的思维模型是你可以做端到端测试、时间点测试，或者我最常推荐的就是做回测。从回测开始，开始捕获历史数据，然后重新运行。

**(51:45 - 53:00)**

让我给你举个例子。这是Prompt Layer的截图。这是我们的评估产品，也是一个批处理运行器。你可以通过prompt运行一堆列，但在这种情况下，我通过的不是prompt，而是Claude Code。我有一个无头的Claude Code，我取所有这些提供商，我的无头Claude Code说——我想下一张幻灯片有——搜索网络查找模型提供商。它在文件变量中给出，找到最近发布的最大模型，然后返回名称。

我不知道它在做什么。它在做网络搜索。我甚至不关心这个。这是一个端到端测试。这是我们尝试Claude Code的方式。我实际上认为将Claude Code放入你的工作流程和那些类型的无头SDK有很大价值。

**(53:00 - 54:15)**

主要收获是你可以开始做端到端测试。你可以从高层次查看，做模型气味检测，然后查看每行的统计数据，看看它调用了多少次工具。

回到我们在这次演讲中讨论的很多内容：严格的工具。工具可以被严格测试。你可以这样将确定性卸载到模型的不同部分。你测试工具。你测试工具的输出。把它们看作函数——输入和输出。如果你的工具是运行的子agent，那么我们就陷入了递归，因为你必须回去测试端到端的东西。

但对于你的工具，我给你举个例子。在我的编程agent或一般的自主agent中，如果有非常特定的输出要求。比如，如果我有非常特定类型的邮件格式或博客文章类型，我真的想要准确表达我的声音，我不想依赖模型探索。我想实际构建一个可以严格测试的工具。

**(54:15 - 55:30)**

在这种情况下，这也是一个Prompt Layer截图，但这是我构建的工作流程。它有一个LLM断言，说检查邮件是否符合我的标准。如果好，它会修订。如果不好，它会添加缺失的部分，比如它错过的标题，并用同样的步骤修订。这显然是一个非常简单的例子，但我们有另一个版本用于我们的SEO博客文章，有大约20个不同的节点，从深度研究写大纲，然后修正结论并添加链接。

对于你有非常特定愿景的东西，测试就变得容易得多，因为你可以看到，测试这种工作流程显然有更少的步骤和更少的灵活性。这是我制作的评估。我从一堆样本邮件开始，我运行了这个agent工作流程，我只是添加了一堆启发式方法。这是一个非常简单的LLM判断器——它是否包含三个部分。这就是我测试的内容，比如"Hi Jared"、邮件正文和签名。你可以做得更复杂。你可以做代码执行。LLM判断器通常是最简单的。

**(55:30 - 56:00)**

显然你可以看到我可以持续运行直到在所有情况下都正确，并且随时间查看我的评估。这只是来自这个例子，我达到了100分。很有趣。

我想添加另一个面向未来的东西。关注无头Claude Code SDK。我知道今天早上有关于它的演讲。我有一个GitHub action，每天更新我的文档，读取我们推送到其他仓库的所有提交。我们有很多提交，它就运行Claude Code。Claude Code拉取所有仓库，检查更新内容，读取我们的Claude MD看是否应该更新文档，然后创建PR。

我认为这解锁了很多可能性，我们可能会开始在更高抽象层构建agent，只是依赖Claude Code和这些其他agent来做大量的工具和编排工作。

### (56:00 - 1:04:00) Part 8

**(56:00 - 57:15)**

agents。我觉得工程师大脑并不总是像应该的那样理解这一点，特别是在...我也是工程师，所以我也在说我自己，但不同的视角很重要，因为有不同的方式来解决问题，其中一种并不比另一种更好，你可能想要一个混合专家agent。我很想让我的运行Claude Code和codeex以及其他工具，给我输出结果，并将其视为一个团队，也许让他们在基于Slack的消息频道中相互对话。我在等待有人构建这样的系统。那会很棒。

**(57:15 - 58:30)**

但这些是我的收获。我要展示的额外内容是我如何使用Claude Code构建这个幻灯片演示。我构建了一个slide dev技能。我基本上告诉Claude Code研究slide dev是如何工作的，以及它如何...那只是我用来制作这个的一个库。我构建了一个深度研究技能来研究所有这些agent以及它们如何工作。我构建了一个设计技能，因为我知道什么东西看起来糟糕或好看，但我不是一个好的设计师来搞清楚它。所以，甚至这些盒子，我就是说，"哦，让盒子更好看一点。给它一个强调色。"所以，这就是我如何构建它的。

**(58:30 - 59:00)**

再次感谢大家的聆听。很高兴回答任何问题。我是Jared，Prompt Layer的创始人。可以在那里找到我。

[掌声]

**(59:00 - 59:45)**

观众：是的。谢谢。很棒的演讲。你提到关于DAG基本上就是让我们摆脱它们，对吧？但DAG某种程度上强制执行这种顺序执行，对吧？比如我不知道客户服务agent询问姓名、邮箱，以某种序列。你是说只需要将其写出来，现在这应该作为一个计划让agent执行，并且相信模型会按顺序调用这些工具，比如我们如何强制执行顺序？

**(59:45 - 1:01:00)**

Jared：对。所以问题是为什么我一直在谈论摆脱DAG？你还应该如何强制执行解决问题的特定顺序？我认为有不同类型的问题。构建一个我们都可以用来完成工作的通用编码agent，甚至非技术人员也可以使用，解决这个问题没有特定步骤，这就是为什么更好地依赖模型。如果你的问题是构建一个旅行行程，这更多的是一个特定步骤，因为你有一个总是相同的可交付成果。所以DAG可能更重要一些，但在旅行的研究步骤中，你可能不想要DAG，因为每个城市都会不同。所以这真的取决于你要解决的问题。

**(1:01:00 - 1:02:15)**

如果我想为旅行行程制作一个agent，我可能会让我的工具调用之一是一个创建输出文件的DAG，因为我希望输出看起来相同，或者创建计划。然后在系统问题中，我可以说总是以输出结束，例如。但你需要混合搭配。每个用例都是不同的，但如果你想做一些通用的东西，我的观点是更多地依赖模型上的简单循环，而不是DAG。

观众：酷。还有其他问题吗？是的。

**(1:02:15 - 1:03:00)**

观众：是的。基于那一点，你认为我们正朝着一个世界发展，在那里你实际上不会通过代码调用API，大多数LM调用都是通过触发Claude Code并只是编写文件来实现的吗？

Jared：所以问题是我们是否会摆脱直接调用模型，而只是调用像无头Claude Code这样的东西，对吧？

观众：是的。比如如果我有一个pipeline，每个文档进行一次LM调用，在最后总结它。你可以制作一个while循环的Claude Code，每次保存一个文件。除了在while循环中使用Claude Code，你永远不会调用API。

**(1:03:00 - 1:04:00)**

Jared：可能。我会给你利弊分析。优点是开发更容易，我们可以依赖前沿技术。如果你想想，推理模型就是这样。推理模型并不总是存在。我们只有普通的LM模型，然后现在我们有了01和推理模型。那就是...我的意思是，这比这更复杂一些，但它基本上就是OpenAI服务器上的一个while循环，不断运行上下文，然后最终给你输出。就像Claude Code SDK是一个带有更多东西的while循环一样。所以我完全可以看到很多构建者只接触这些agentic端点。也许甚至看到模型提供商将模型作为agentic端点发布。但对于很多任务，你会想要更多的控制。而且他们可能你仍然想尽可能接近底层。话虽如此，有很多人仍然想要completions模型，但那从未发生，现在没有人真正谈论那个了。所以，很可能一切都变成这个SDK，但我没有水晶球，但这些是我会考虑的方式。

### (1:04:00 - End) Part 9

**(1:04:00 - 1:05:30)**

答案似乎是肯定的。还有其他问题吗？

观众：有。

Jared：这是最后一个问题吗？

观众：可以是。

观众：你能谈谈 PromptLayer，以及大家如何帮助你们吗？

Jared：好问题，我差点忘了这个。谢谢提醒。

**(1:05:30 - 1:07:00)**

我们在招人。如果你在寻找编程工作，想加入纽约一个非常有趣、快节奏的团队，可以在 X 上联系我，或者发邮件到 jared@prompter.com。

我们总部在纽约。我们是一个构建和测试 AI 产品的平台，专注于提示词管理、可审核性、治理等有趣的功能，还有日志记录和评估。我刚才展示的那些截图就来自 PromptLayer。

**(1:07:00 - 1:08:30)**

如果你在构建 AI 应用程序，特别是团队协作开发，你应该试试 PromptLayer。它会让你的生活更轻松。团队越大，越想协作，越想与产品经理和非技术用户协作，或者即使只是技术用户之间的协作，这都是一个很棒的工具。它会让你的生活更美好。强烈推荐。

**(1:08:30 - 1:09:00)**

访问 promptlayer.com，操作很简单。我的演讲就到这里。

感谢大家的聆听。

[掌声]

[音乐]

---

*生成时间: 2026-01-12 14:00:11*
*由 YouTube Monitor & Translator (Claude CLI) 生成*