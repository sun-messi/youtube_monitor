# How METR measures Long Tasks and Experienced Open Source Dev Productivity - Joel Becker, METR

## 📹 视频信息

- **频道**: AI Engineer
- **发布日期**: 2026-01-19
- **时长**: 1:15:36
- **原始链接**: [https://www.youtube.com/watch?v=k1t2xyWMUdY](https://www.youtube.com/watch?v=k1t2xyWMUdY)

---

I'll analyze this video content and provide a structured summary following the specified format.

> 本文内容整理自METR研究员Joel Becker在AI Engineer频道的技术演讲。

---

## TL;DR（一句话核心洞察）

METR通过严格的随机对照实验发现，即使是经验丰富的开源开发者使用AI编程工具（如Cursor）时，实际开发效率并无明显提升，甚至略有下降，这与业界普遍认知形成鲜明对比，揭示了当前AI在复杂软件工程任务中的局限性。

---

## 📑 章节导航表

| 时间戳 | 章节标题 | 一句话概括 |
|--------|----------|-----------|
| 00:00-15:00 | AI能力增长与计算资源关系 | 计算资源增长放缓可能导致AI能力提升延迟，时间跨度能力与计算资源呈因果比例关系 |
| 15:00-30:00 | 开发者生产力研究方法论 | 介绍16位经验丰富开源开发者的随机对照实验设计和结果分析 |
| 30:00-45:00 | J曲线假说与熟悉度影响 | 探讨开发者对AI工具熟悉度是否影响生产力，以及企业级数据分析的挑战 |
| 45:00-60:00 | AI村庄实验与真实世界任务 | AI在完成模糊目标和真实世界任务时表现不佳，类似"神经多样性个体"面临的挑战 |
| 60:00-75:00 | 未来研究方向与硬件限制 | 探讨机器人技术、芯片制造自动化的挑战，以及软件奇点的可能性 |

---

## 📊 核心论点

### 计算资源与AI能力的因果关系

- **核心内容**：Joel Becker提出了一个关键假设：如果计算资源的增长速度减半，AI能力提升的速度也会相应减半。这种因果比例关系基于标准经济学假设，在"软件奇点"（software-only singularity）不可能的前提下尤其成立。他展示的图表显示，从2028年开始，如果计算增长曲线开始弯曲，那么原本一个月就能达到的AI里程碑可能会延迟数年。
- **关键概念**：计算资源约束、时间跨度（time horizon）、对数线性增长、软件奇点、能力外推
- **实际意义**：这意味着AI发展可能不会无限加速，物理约束（如电力限制）和经济约束（大型科技公司的投资上限）将成为关键瓶颈。这为AI安全研究提供了更多时间窗口。

### AI编程工具的真实效率悖论

- **核心内容**：METR进行了一项严格的随机对照试验，涉及16名平均拥有11年编程经验的开源开发者。实验结果显示，使用Cursor等AI编程工具的开发者完成任务的时间反而比不使用的略长（效应值为负）。这与开发者自己的时间估计（认为会快41%）形成鲜明对比。即使控制了开发者对工具的熟悉度（50小时以上使用经验），结果依然没有显著改善。
- **关键概念**：随机对照试验（RCT）、效应值、时间感知偏差、专家级任务、代码质量标准
- **实际意义**：这挑战了科技公司关于AI工具能大幅提升生产力的宣传。对于成熟的开源项目和高质量代码要求，AI工具可能增加了验证和修正的时间成本，抵消了初始编码的速度提升。

### J曲线假说的证据不足

- **核心内容**：Meta公司的内部研究显示，开发者使用AI工具存在J曲线效应——初期生产力下降，3-6个月后才显著提升。但METR的研究未发现明显的J曲线证据。即使将开发者按Cursor使用时长分组（0-10小时到50+小时），生产力提升依然不明显。最有经验的一组开发者中，有人已将Cursor作为2024年的主要IDE，累计使用超过140小时。
- **关键概念**：J曲线、学习曲线、工具熟悉度、时间估计偏差、样本量限制
- **实际意义**：这表明AI工具的价值可能被高估，特别是在处理复杂、成熟的代码库时。企业在采用AI开发工具时应谨慎评估实际ROI。

### AI在真实世界任务中的"神经多样性"特征

- **核心内容**：AI Village实验让多个AI模型在虚拟环境中完成模糊目标（如组织公园活动、运营商店），结果显示AI普遍失败。Joel将此比作神经多样性个体面临的挑战——虽然在特定领域表现出色（如在GPQA上击败专家），但在应对为人类设计的复杂世界时却困难重重。世界的各种系统都是基于人类能力设计的，从税务表格到军事装备尺寸。
- **关键概念**：任务泛化能力、模糊目标处理、人机交互界面、分布内/外任务、实际部署挑战
- **实际意义**：这解释了为什么尽管AI在基准测试上表现优异，但在实际应用中仍需大量人类辅助。未来要么AI需要变得更"类人"，要么世界需要重新设计以适应AI。

### 数据科学领域的AI应用困境

- **核心内容**：在企业数据分析场景中，AI面临独特挑战。以LinkedIn为例，系统中有5000个名为"impressions"的数据表，数据字段命名不一致且随时间变化（如date_started字段在不同时期存储不同格式的数据）。数据科学家需要了解大量未文档化的业务逻辑和数据演变历史。虽然AI擅长生成SQL，但理解复杂的企业数据生态系统远超其能力范围。
- **关键概念**：数据血缘、企业知识、上下文理解、数据质量问题、隐性知识
- **实际意义**：这揭示了AI在企业应用中的重大障碍。相比软件工程，数据科学可能更难被AI自动化，因为它需要大量特定组织的隐性知识。

### 硬件瓶颈与机器人经济的远景

- **核心内容**：关于"软件奇点"能否在不自动化芯片设计和生产的情况下实现，存在重大疑问。机器人技术的计算投入比语言模型低两个数量级，这可能解释了能力差距。制造业的迭代周期极其缓慢且成本高昂（建造晶圆厂需10亿美元），与软件开发形成鲜明对比。即使是自动驾驶这样"接近完成"的技术，最后10%的完善也极其困难。
- **关键概念**：软件奇点、硬件约束、制造业迭代、机器人计算投入、反馈循环
- **实际意义**：完全自动化的"机器人经济"可能需要比预期更长的时间实现。物理世界的自动化面临的挑战远超纯软件领域，这为人类适应AI时代提供了缓冲期。

### 开源项目的特殊性与AI工具局限

- **核心内容**：成熟的开源项目有极高的代码质量要求。以Haskell编译器为例，项目创始人可能会为一个PR争论数小时，远超开发者编写代码的时间。研究中PR的中位数修改时间为0分钟——即大多数PR第一次就完美无缺。开源维护者的激励机制倾向于拒绝增加维护负担的代码，这与商业环境"完成任务优先"的文化截然不同。
- **关键概念**：代码质量标准、维护者激励、开源文化、PR审查流程、技术债务
- **实际意义**：AI生成的代码可能在开源项目中面临更高的拒绝率，因为它可能不符合项目的隐性规范和长期可维护性要求。这限制了AI在高质量软件开发中的应用。

### 监控下的AI能力衰减

- **核心内容**：Joel提出了一个有趣的思想实验：如果AI在被严密监控时（如其他AI审查其输出），其有效任务完成时间可能从40小时降至2小时。这类似于在没有安全控制的情况下测试AI能力。主要AI公司可能已经在进行此类对比测试，以了解安全措施对能力的影响程度。
- **关键概念**：能力监控、安全-能力权衡、任务时长限制、欺骗检测、递归监督
- **实际意义**：这为AI安全研究提供了新思路——通过监控系统可能显著限制AI的危险能力，同时保留其有用功能。但这也可能激励绕过安全措施的研究。

### 绿地vs棕地项目的微弱差异

- **核心内容**：METR还进行了一项大型黑客松实验，随机分配团队是否可以使用AI工具进行全新项目开发（绿地项目）。令人惊讶的是，使用AI的团队仅比不使用的高4个百分位点，且结果高度重叠。这表明即使在最有利于AI的场景下（无需理解现有代码库），AI工具的优势仍然有限。
- **关键概念**：绿地项目、棕地项目、黑客松实验、评委评分、项目质量
- **实际意义**：这进一步质疑了AI工具的普遍价值。即使在创新项目中，人类的概念理解和架构设计能力仍然是关键，AI的辅助作用有限。

### 未来研究方向：真实世界的AI轨迹

- **核心内容**：Joel提出分析"野外"AI使用痕迹的研究方法——通过Cursor、Claude Code等工具留下的实际使用记录，了解AI在真实工作场景中的表现。这些数据虽然缺乏实验控制，但反映了真实的使用模式和挑战。另一个方向是改进AI Village类实验，使用纯文本界面和更合适的工具，观察AI在完成模糊目标时的失败模式。
- **关键概念**：野外数据分析、使用轨迹、真实场景评估、失败模式分析、工具适配
- **实际意义**：这种研究方法可能揭示实验室条件下无法发现的AI局限性，为改进AI系统和调整部署策略提供关键洞察。

---

## 🏢 提及的公司/产品

| 公司名 | 讨论语境 | 重要性 |
|--------|----------|--------|
| METR | 主要研究机构，专注于AI能力和安全性评估，进行开发者生产力研究 | ⭐⭐⭐ |
| Meta | 内部开发者体验研究，发现AI工具的J曲线效应，拥有最佳量化测量基础设施 | ⭐⭐ |
| Cursor | AI编程IDE，作为实验中的主要测试工具，开发者使用体验核心 | ⭐⭐⭐ |
| LinkedIn | 数据分析复杂性案例，5000个同名数据表展示企业数据挑战 | ⭐⭐ |
| OpenAI (GPT系列) | AI发展里程碑参照，GPT-2到GPT-5的能力演进时间线 | ⭐⭐ |
| Claude Code | AI编程工具之一，与Cursor并列作为实际使用痕迹来源 | ⭐ |
| AI Village | 进行AI真实世界任务测试的实验平台，展示AI在模糊目标上的失败 | ⭐⭐ |
| Capital One | 企业部署流程复杂性案例，展示数据分析的实际挑战 | ⭐ |

---

## 💬 经典金句

> "If compute growth were to halve, then time horizon growth would halve."
> — Joel Becker

> "They are effectively neurodivergent individuals, and our world was not built for that."
> — 观众评论（关于AI系统）

> "The median PR in the study has zero minutes spent working on the code post review."
> — Joel Becker（关于开源项目的高标准）

> "Today is the 200th day my car didn't rocket off the Earth at escape velocity."
> — 观众评论（关于AI Village实验的类比）

> "Developers will tell you they were faster when they weren't."
> — 观众评论（关于感知偏差）

---

## 👤 主要人物

### Joel Becker

**身份**：METR（Model Evaluation and Threat Research）研究员
**背景**：专注于AI能力评估和安全性研究，设计并执行了开发者生产力随机对照实验
**核心观点**：当前AI编程工具对经验丰富的开发者帮助有限，甚至可能降低效率。AI能力增长与计算资源投入存在因果关系，物理和经济约束将限制AI发展速度。他认为AI系统在处理真实世界的模糊任务时表现不佳，需要谨慎评估AI自动化研发的可能性时间线。

### Simon Marlow（被提及）

**身份**：Haskell编译器维护者
**背景**：以对代码质量的极高要求著称
**核心观点**：会为PR的细节争论数小时，体现了开源项目对代码质量的严格把控

---

## 📺 视频类型判断

**访谈对话**：技术演讲后的深度讨论，包含演讲者展示研究成果和与观众的互动问答

---

## 📝 完整翻译

### (0:00 - 8:00) Part 1

**(0:00 - 1:15)**

让我来阐述一个非常简单的论点。如果你观察计算量随时间变化的子概念，这可能包括研发支出中的计算部分、实验性计算，或者是某个特定实验室正在使用的训练计算量等等，图表看起来就是这样，毫不意外。

如果你有另一个关于对数时间范围的图表，比如说这个度量是从这个图形得出的——你们很多人可能在Twitter上见过——随时间变化的情况看起来就像这样。

**(1:15 - 2:30)**

假设这不仅仅是巧合，而是这两者存在因果比例关系，即如果计算量增长减半，那么时间范围增长也会减半。那么为了论证起见，假设从大约2028年开始，计算量曲线开始像这样弯曲，这里代表零增长，这里代表原始增长——比如说减半的情况。

如果它们确实存在因果关系，特别是存在因果比例关系，那么你会期望这条线也这样变化。对于你关心的某个里程碑——比如这里我们有一年的工作周期，一个月——那么AI能力发展的延迟可能会是巨大的。

**(2:30 - 4:00)**

很多人都认为计算量增长可能会出现某种放缓，我不是这些预测领域的专家，但我认为先验原因对我来说确实显得相当有说服力。一个是我们可能遇到的物理约束，比如你提到的电力约束，或者EPO报告中考虑的各种其他约束，所有这些约束似乎在2030年之前都不会产生影响，但可能在2030年之后的某个时候会产生影响。

我认为更可能的情况就是资金约束，大型科技公司在某个节点只能花费这么多，大型民族国家也只能花费这么多——你不能无限制地投入。当然，有一些场景可以让你继续前进，但这似乎自然地暗示了这种放缓趋势。

**(4:00 - 5:20)**

这篇论文试图提出的额外观点是，在一个非常有争议但在经济学中标准的假设下，你实际上应该期望这两者存在因果比例关系。我认为特别是，在软件奇点不可能的程度或期间内，你应该期望它们存在因果比例关系——这是另一个我们可以讨论的话题。

但至少在这种某种程度上的常规情况下，或者说直到该情况不再适用之前，我认为这可能是一个合理的模型，并且确实暗示着在不久的将来AI能力的某种整理。我对这次会议没有任何计划。

主持人：这也告诉我们，我们没有戏剧性改善能力的技术进步，比如不可预测的技术突破，对吧？

**(5:20 - 6:40)**

演讲者：是的，所有的预测都假设没有不可预测的情况。我认为在AI领域，对数线性图上的直线一直是一个被严重低估的预测工具。它们在现在许多数量级上都表现得极其出色。

我认为合理的默认期望是对数线性趋势会继续持续大约相同数量级的时间，除非输入端出现某种重大突破。当然，在上行方面可能会有相当戏剧性的变化。软件奇点是我首先想到的，但另一个Transformer风格的时刻似乎也是另一个自然的候选。

**(6:40 - 8:00)**

当然，测试这个理论的问题之一是，我认为你能够测试的大多数任务在某个时间点会超过评估集中这些任务可能花费的最大时间。

主持人：是的，我认为有一些方法可以解决这个问题，我们正在研究中。我很乐意讨论这个话题，但它们都感觉还很早期。但是你说得对，如果时间范围在翻倍，最终翻倍时间会变得如此之长，以至于你不可能在相关范围内制作足够长的任务。

也有可能我们实际上会达到这样一个点，时间范围不再是一个有用的度量，因为实际上你现在想要的是总时间的减少——你想要的是在更短时间内获得相同结果。

### (8:00 - 16:00) Part 2

**(8:00 - 9:15)**

这是你第一次体验工具。但如果你这样做是为了获得一些投资收益，你知道以后可能会更熟练地使用工具，或者在 AI 的情况下，也许你只是期望模型会变得更好，所以即使你没有变得更熟练，这也是你想要做的事情。这些解释在广义上对我来说是合理的。我可以给你一些我有这些分数的原因。

我想说的一件事是，作为背景，你知道，我们正在继续这项工作，我们会观察结果。另一件要说的事是，从量化角度来看，这两者之间的差异非常大。

**(9:15 - 10:30)**

我想知道雅各布解释了多少？我认为它解释得并不多。让我解释一下，因为我们在软件工程研究中一再看到这种情况：在调查中你不能问人们的一个问题就是一项任务花费了多长时间。你可以问人们感觉效率提高了多少，他们会给你一个与定量反馈相关的准确回应。但如果问任何人某件事花费的时间，他们几乎总是错误的。

**(10:30 - 11:45)**

所以当我与同事分享这个时，我想好吧，这一点都不让我惊讶，但有趣的是减速方面有多少，这就是关键所在。

是的，这个观点很有道理，我确实同意。所以我认为尽管如此，我们对时间估计感兴趣，因为你知道，我们有兴趣提供...

我的意思是感知层面，我确实认为这也是相关的，因为感知方面也有炒作因素。

对的，就像开发人员会告诉你他们更快了，而实际上并不是，我认为这是值得了解的。

**(11:45 - 13:00)**

你知道，在我们有兴趣测量能力爆发或 AI 被自动化的可能性和时机性质的程度上，一个常见提议的措施就是问开发人员或研究人员他们被加速了多少，出于你们指出的确切原因，我对这些估计并没有太大信心。所以很高兴看到这样的结果。

还有一些关于雅各布的事情。所以那些不预测完成时间的预测者，他们只是在预测这种效果大小，即非开发人员，专家预测者被告知这些开发人员的经验程度，一些预测者在思考这个群体可能与其他群体的不同之处时，指出了关于研究的各种事实，比如他们更有经验，我期望有经验的人获得更少的加速，或者你知道，代码库更大。我认为 AI 在大型代码库上的工作能力较弱，我期望更少的加速。

**(13:00 - 14:15)**

他们从来没有提到对工具的熟悉程度。我的感觉是，他们分享了我事先的感觉，那就是大部分作用在于理解 AI 擅长或不擅长的事情类型。所有这些开发人员都有使用 LLM 的经验以及他们核心开发工作流程的经验。只是他们对 Cursor 完全不熟悉，这是他们中的三个在研究开始时完全不熟悉的。所以我看不到太多的边际效应。

我认为这确实是一个开放的问题。我们观看了这些开发人员工作的许多小时的屏幕录像，我就是看不到...我认为他们的提示非常合理，有些情况下比我和我的同事差，有些情况下更好。我没有看到他们没有访问的那些高级工作流程。

**(14:15 - 15:30)**

是的。我的经验与此相距不远，有时我被大幅减速，有时我被加速。

是的。

随着我对工具熟悉程度的增加，我确实改进了很多，因为我随着时间学习到什么可以告诉它做，什么不能告诉它做。

是的。

除了它在理解方面变得更好，比如理解好吧现在我需要计划等等。但这就是为什么在你做出高层架构决定之前，你知道十轮对话后会在你面前爆炸，你真的要努力思考它。

是的，完全正确。也要将其范围缩小到更小的问题。我起初会尝试太大的问题，而它无法处理。

**(15:30 - 16:00)**

但只是说，我的意思是对于未来，如果你们再做的话，我认为显然用16个人的样本量很困难。但这很好，因为在未来，我认为有一个截止点，试图找出是否存在熟悉程度的截止点，在那里数字会发生变化，看看这个元结果是否在其他地方推广，这将很有趣。

我们正在努力。我认为在这个期间 AI 一直在变得更好，这显然会加剧很多正在发生的事情，但是是的。

### (16:00 - 24:00) Part 3

**(16:00 - 17:15)**

我的意思是，我认为除了主要图表之外的所有其他图表，所有这些子集的东西，你都不应该太过相信。我完全同意这一点。然后很多人都在讨论这个图表，这也是我们将其归类为"不明确证据"的原因，因为事情指向了不同的方向。很多人认为这个图表暗示了某种J型曲线，特别是在最后，一旦人们有了更多经验，他们确实会体验到一些加速。但这里有一些问题。

首先，其他图表并没有显示这种趋势，我认为这很重要。其次，这些使用小时数的编码非常保守。例如，在30到50小时这个区间的某个人，在2024年将Cursor作为他们的主要IDE，他们在时间追踪软件上记录自己使用Cursor共140小时，但他们保守估计只用了50小时。所以他们最终被归入我们的30到50小时区间。这是一个去年主要IDE就是Cursor的人。

**(17:15 - 18:30)**

人们一直在评论这件事，说他们使用Cursor还不到一周。我认为这不是一个很公平的评估。如果你要将那个开发者从倒数第二个柱状图移动到最后一个——再次强调，由于统计问题你不应该相信这个——但如果你将那个开发者从倒数第二个效应大小估计移到最后一个，那么你会看到一些平衡，最后一个区间基本回到零。所以像传递性的雅各布解释仍然是很有可能的。

主持人：但50小时组同样有可能低估了他们使用Cursor的时间，如果你有一个更长的时间尺度，你仍然会看到一定程度的（提升），这难道不太可能吗？

这是一个有趣的观点，这对我来说似乎是合理的。然后我想说，我不确定这是低估，因为我们使用的是非常保守的（估计）。

**(18:30 - 19:45)**

我认为这对我来说似乎是合理的。然后，为了让这个不成为强有力的证据，我会退回到我认为你真的不应该相信其中任何一个。

主持人：我认为最大的问题是样本量很小，而且数据集中也有很多偏见，对吧？这是一种特定类型的数据集，都是开源的。

你是指开发者的类型吗？

主持人：是的，开源开发者，而且还在从事相当成熟的开源项目。

是的，如果你与开源开发者合作处理相当成熟的项目，这可能是相当有指示性的，但样本量确实很小，除此之外就变得有点困难了。

**(19:45 - 21:00)**

我认为这个群体真的很奇怪，也很有趣，它有趣的原因和奇怪的原因是一样的。我们有兴趣研究AI对研发加速或自动化的可能影响。如果任何类型的开发者都没有被大幅加速，这意味着整个事情都没有被加速。所以看到即使是特定的奇怪群体也很有趣。你可能会想象在大型生产推理代码库中，可能比草率的实验脚本更多地具有这种形状。

主持人：我认为这非常有趣，只是很难泛化。我们就是不知道。

是的，我们正在进行这项大型研究，我认为不幸的是，即使在包括更多绿地项目的大型研究之后，由于不太相似的原因，仍然很难（得出结论）。

**(21:00 - 22:15)**

主持人：虽然我不觉得你们的结果与任何实际进行的独立研究特别矛盾。我看到的唯一与你们结果矛盾的研究，是由模型公司或智能体公司资助的研究。

我能对此说些什么呢？我确实认为发布的大部分研究都与大型科技公司有关，我认为这些研究也存在其他方法论上的担忧。

主持人：我对此也有方法论上的担忧。我知道在这些地方工作的人对输出的工作也有方法论上的担忧。

我认为也存在这些担忧。

主持人：当然。但我实际上觉得，当有人把你的论文发给我，当我看到标题时，我想"不可能"。

我也是这么想的。

**(22:15 - 23:30)**

主持人：我想那听起来像胡说八道。然后我读了论文，我想"哦，这一点都不糟糕"。至少你的高层结论既符合直觉——对于一个读过很多软件工程研究的人来说——也是有充分理由的。我认为人们一直在与我争论16个开发者的问题，但我不认为在那种特定情况下这实际上很重要，因为我认为他们实际上是一个相当好的控制组，对于一个实验来说，因为他们通过成为专家消除了很多有效性担忧。

所以是的，确实他们不代表开发者的某些广泛方面，但他们也消除了你对人群预期的很多差异，他们让你能够有一种认识论功能，就像嘿，让我们隔离那个因素，然后看看会发生什么，我喜欢这一点。然后他们认为研究进行的方式完全足以得出他们得出的高层结论。

**(23:30 - 24:00)**

非常感谢。这里有一个有趣的发现。我们进行了但由于组织原因没有发布——我不会深入细节——我们确实进行了这项研究。人们会提出各种解释来解释这里发生的事情，其中许多都很有道理，有些我比较怀疑。一个自然的解释是棕地项目versus绿地项目。所以我们举办了这种大型黑客马拉松，我们随机让一半的团队使用AI，另一半不使用，这是最大程度的绿地项目。然后我们让一群评委给他们评分，每个项目有很多评委分数来试图平衡噪音，看看是否底部50%都是不允许AI的组，顶部都是允许AI的组。

### (24:00 - 32:00) Part 4

**(24:00 - 25:15)**

我对更具概念性的工作非常感兴趣。你知道，我会很兴奋与数学博士生或非常不同类型的软件开发者合作，或者在大型AI公司或大型科技公司内部进行这类研究。我们对那些虽然不是完全直接但与大型航空公司案例有某种类似性的研究非常感兴趣。所以如果某个研究偏离那种模式太多，我们可能就不太感兴趣了。

有趣。所以听起来你对测量数学研究和其他一些研究的能力很感兴趣。

对，我想说我感兴趣的是AI到底发生了什么，以及我如何才能最大程度地了解AI到底发生了什么。我认为一些更具概念性的东西，一些目前较少人类在研究的东西，这样它在训练数据中出现得较少，这将帮助我更好地三角定位AI发生的真相，即使我并不特别关心数学研究，它仍然会得出有用的定性经验，这就是我的感觉。

**(25:15 - 26:30)**

如果我要选择我认为AI最成功的领域，或者我期望它更成功但我认为它表现不够成功的领域，我可能会选择数据科学作为一个有趣的例子，比如数据科学如何，一群数据科学家今天如何被AI帮助。

说说你为什么期望它表现不够成功。

让我给你一个实际例子。Google LinkedIn，在LinkedIn有5000个名字叫"impressions"的表，对吧？所以如果一个分析师想了解某个页面发生了多少次展示，他们到底该去哪里找？人类都无法弄清楚这个。

**(26:30 - 27:45)**

是的。就像今天，我们没有任何现有的AI系统可以接入像那样的企业环境并处理——我是说那些表中有数万亿行数据。所以数据科学家需要做的是分析大量数据并得出结论，对吧？我听到很多关于构建系统的想法。人们谈论ML转SQL。模型写SQL比以前好多了。但我相信底层数据的状态如此糟糕，以至于实际的数据科学家从AI中获得的价值将远远少于软件工程师混合使用所获得的。

这很有趣。这非常令人好奇。所以一些对AI未来更悲观的人有这样的观点：有太多经典知识，有太多嵌入在公司内部的知识，你无法从那些强化学习训练环境的初创公司或其他东西中获取。

**(27:45 - 29:00)**

也许自然状态并不需要很多专业化的AI，过去几年的教训是一个大的通用AI似乎性能更好。但在未来某个时候，当数据被锁在公司内部时，我们将看到更多专业模型的扩散，比如我有专门在LinkedIn数据上微调的GPT-N。

我有一种类似的反应，是的我不知道。我确实有一种不信的反应，就像啊科学你知道。但也有矛盾的事实，这些问题之一是所有这些数据集都包含矛盾的前缀，比如字段的名称可能是"date started"或"time started"，然后它只包含日期，除了它只包含到去年11月的日期，然后之后它只包含月份，但之后它可能包含任务完成的秒数。为了成功查询数据集，数据分析师或数据科学家必须知道这些截止日期是什么，而这些信息没有写在任何地方。

**(29:00 - 30:15)**

虽然理论上你可以做的是导入其他分析师编写的大量SQL来试图弄清楚他们如何三角定位这些东西，并从那些报告中反推。但今天，比如今天——抱歉我只是没有在大公司工作过——人们不修复这个源头。

哦不。所以我一遍又一遍学到的教训是数据规范真的很重要。不，我也一直在数据分析和研究开发者研究方面工作。

是的，所以问题是他们的工作是为这个高管制作这个报告，而不是去建立基础设施来为这个高管制作这个报告。

但我想如果我，好的，我同意你，我每天都过着那个梦想。是的，你最终不得不做的是你必须为此构建基础设施，这必须是工作描述的一部分。另一部分是你必须在源头修复问题。

**(30:15 - 31:30)**

我仍然记得有一次对话，有人说在源头修复太困难了，因为依赖源头的所有系统都太复杂了。我说等一下，你是在说在源头解决太复杂了，但在下游某个地方解决一个对整个组织来说都太大的问题却更容易？在那里解决更容易。拜托，这没有任何意义。

我只是认为这里有如此大的潜力，我没有看到很多关于在数据空间工作的人如何体验AI的研究。令人着迷的是，真正的ML主要是数据工作，就像ML，特别是在LLM之外，大多数ML工程师把大部分时间花在特征策划上，而不是实际的直接模型训练，以及试图清理用于特征策划的坏数据。

**(31:30 - 32:00)**

所以理论上，通过让ML成为更好的数据科学家来改进ML的潜力是巨大的，我怀疑如果你进入这个领域，你会发现它很擅长告诉我如何编写SQL或如何编写pandas、polars或任何你使用的东西。它在做非常琐碎的事情方面还可以，但在所有复杂任务上都完全失败。我甚至不知道，我甚至没有为此设定基准。

你能给我一个复杂任务的例子吗？

当然。复杂任务是确定时间间隔，给我Capital One所有部署之间时间间隔的P90。

### (32:00 - 40:00) Part 5

**(32:00 - 33:15)**

我必须去 GitHub 调用 GitHub API，而目前任何 LLM 或 agent 能搞清楚这些的可能性微乎其微。

相对于我的同事们，我对 AI 进展还是比较悲观的。我仍然有种反应是，难道你不能花一天时间把这些写进 cursor 规则文件里吗？就是那种存在层次结构的地方。

**主持人：** 我觉得这就是为什么我认为这很有趣，值得研究。我还没有看到任何关于数据科学家体验的真正全面研究。如果你在大型科技公司有任何内部关系可以帮我们进行这种研究，那我完全愿意参与。

**(33:15 - 34:30)**

**研究员：** 唯一的是，OpenAI 有个人我聊过，他是演讲者之一，负责内部评估，他提到过和数据科学家做了一些工作。所以他可能知道一些有这种数据的人，但这些都是他与 Anthropic 之类的公司之间的内部合作。

我也很好奇律师这个群体，还有那些更传统的、更资深的职业，比如律师、医生，我觉得数学家也很有趣。

**主持人：** 就是因为律师和医生都被历史遗留问题严重束缚，包括他们的工作方式和周围的限制条件。

**研究员：** 是的，法律问题我觉得仍然是一个重大障碍。

**(34:30 - 35:45)**

**主持人：** 他们很保守...我也很感兴趣的是，保守主义...我觉得保守主义作为经济现象的长期解释我不太买账。法律限制确实会长期存在，但保守主义不同，我可以开一家不那么保守的新律所，然后干掉之前那些律所。

**研究员：** 我同意。我不认为它是持久性的，只是我觉得看看这种保守主义是否会影响他们今天的思维模式很有趣，比如他们被如何谈论 AI，或者他们对 AI 的信任程度如何影响他们的使用方式。

对我来说，了解这个会很有趣...我不知道这是否是有价值的研究，更像是我闲时会思考的事情。

**(35:45 - 37:00)**

理想情况下，你找一个刚从大学毕业的律师，花了大量时间使用 ChatGPT；然后找一个从业 50 年的律师，他有一个巨大的文件夹，里面装满了几十年来所有初级助理为他写的法律摘要的 Word 文档。他只需要打开那些摘要，改几个词，然后发给法官。他认识那些法官 30、40 年了，完全知道他们想要什么。

那么他能从中获得任何价值吗？或者他应该获得什么价值？有什么方式能让 AI 帮助到他吗？我当然知道法律证据发现 (discovery) 是一个巨大的问题，我知道有 Harvey 这样的公司，虽然我不了解他们的成功情况，但很多人在这个领域工作，这是一个持续进行的事情。总是有相关技术，但采用技术是完全不同的事情。

**(37:00 - 38:15)**

**主持人：** 这就是关键，对吧？因为我有一些法律背景，当 GPT-3 出来时我想到的第一件事就是，"哦，这完全可以改变证据发现。"

这可能会改变一切，因为证据发现是最痛苦、最困难、最昂贵的过程。通过降低证据发现的成本，你可以产生严重的社会后果。这是诉讼中最昂贵的部分。

如果你能让证据发现变得便宜、即时和可靠，你实际上可以对社会产生重大影响。

**研究员：** 是的。

**主持人：** 我有个问题。

**(38:15 - 39:30)**

**听众：** 散点图，对吧？第一个是 50 小时。

**研究员：** 是的，那一个。所以你说的是人们开发...cursor 没有区别。我们谈论的是 VI 编码的 IDE，他们使用了 50 小时。我对此很感兴趣，因为每个人都在谈论 VI 编码以及 cursor 的重要作用。你是怎么得出 50 小时的？只是好奇。

**主持人：** 50 小时包括开发者在实验中花费的时间加上他们过往的经验。所以对于参与实验中某些问题的一些开发者，其中一些人的 cursor 经验已经超过 50 小时，这些都被编码在最后那个分组里。

**听众：** 每个组的任务是相同的吗？

**(39:30 - 40:00)**

**主持人：** 不是。这些是 GitHub 仓库中出现的自然任务，正如我提到的...我不想说它们很奇怪，因为这暗示它们不寻常，我想说的是它们非常有趣，而且有趣的原因正是因为它们很特殊。

这些是仓库，在这些项目中，他们需要建立大量的心理语境，而 AI 可能没有这些语境。他们已经在这些项目上工作了很多年，可以...我不确定这总是如此，但我想象他们基本上在真正开始尝试之前就知道如何执行特定任务，因为他们在这个项目上是专家。

### (40:00 - 48:00) Part 6

**(40:00 - 41:15)**

我们如何获得这些信息呢？我们会做类似这样的事情：用 AI 不被允许的时间除以允许 AI 的时间。你知道，如果这个比值是 1.1 倍，比如说，比允许的时间长 1.1 倍，那么我们就能得到大约 1.1 倍的速度提升。就是这样的情况。

事实上，我们确实发现了这种减速。

**主持人：** 我刚读到一篇非常有趣的文章，虽然记不起公司名字了，基本上是说一位记者被允许使用五种编程语言做 Pull Request，也就是说有一个功能需求，AI 被用来协助构建需求，据文章描述，她实际上只是做了一些小调整，然后就签字同意了。

这真是太有趣了。那就是整个实时编程的事情。

**(41:15 - 42:30)**

**研究员：** 是的，实时编程就是整个重点。就像你没有任何软件开发背景一样。这就是我好奇的地方。你有试图对此做过研究吗？

所以我确实有分享，但你知道，如果你对正在发生的事情一无所知，那么可能会有一些显著的速度提升。我要说的第一点是，这并不明显。事实上，我们举办了一个黑客马拉松，有非常有经验的人和经验较少的人，我们试图看看会发生什么。我们发现，评判分数极其嘈杂，我认为你不应该相信它，但当允许使用 AI 与不允许使用时，评判分数并没有高出很多，人们实际上并没有取得更多进展。

**(42:30 - 43:45)**

另一件事是，我认为在座的人在这方面会比我有更多专业知识。据我与这些开源开发者相处一段时间后的理解，而我自己并不是一个非常有能力的开发者，我的理解是这项研究中代码仓库的质量标准就是非常高的。

所以如果一个记者，甚至坦率地说，如果是一个在该仓库上没有大量经验的优秀软件工程师，但肯定是一个不是软件工程师的人，能够在这些仓库上第一次就提交一个干净的 PR，我会非常惊讶。

**(43:45 - 45:00)**

事实上，我认为这里发生的很大一部分情况是，AI 实际上确实在正确的方向上取得了进展，在相当一部分时间里是好的，但由于各种原因，有时是正确性的原因，但有时是关于它们如何尝试解决问题，以及这是否是解决问题的典型方式，或者项目的各个部分如何相互对话等考虑。这些类型的考虑，AI 没有适当地考虑到。

所以人们不仅需要花费昂贵的时间来验证，还要清理所有这些东西。我的感觉是，没有所有这些经验的人基本上不会知道如何执行那个步骤。因此无法向这些仓库提交干净的 PR。

**(45:00 - 46:15)**

相对于这些人来说，我在软件开发方面很糟糕，我一直在内部提交 PR，我认为它们质量更差，但随着时间的推移它们正在变好。我确实相信，人们在无法编程的时候正在编程。他们在完全无法做到的情况下，以较低的质量标准提交 PR。但是提交这些专家级别的 PR，我确实感到有点怀疑。

**主持人：** 这实际上也是我想表达的一部分，在这些大型高质量项目中，新手的 PR 经常被拒绝，原因仅仅是 PR 对开发者人体工程学的影响，对吧？所以事实上它让我未来维护变得更困难，因为对于开源项目来说，几乎所有的激励都偏向于让我更容易维护项目。

**(46:15 - 47:30)**

所以每次有 PR 进来时，如果它没有让我更容易维护项目，我就倾向于拒绝它。如果它确实让维护项目变得更容易，那么太好了，我很喜欢。这与你在典型商业环境中的情况不同，在商业环境中最重要的实际上是完成某些事情。因为有人必须花大量时间维护它几乎就是工作保障，但对于开源来说恰恰相反，实际上导致人们离开项目的是维护困难。所以对于接受 Pull Request 有不同的偏见。

你能提醒我维护 Haskell 编译器的那位英国绅士的名字吗？

Simon... 不，我记不起名字了。

**(47:30 - 48:00)**

这里有一个可能相关的故事。研究中的一群仓库都有这些特征，其中一个是 Haskell 编译器。在 Haskell 编译器上，有一定概率，我不知道是 50% 还是 30%，但如果你提交一个 PR，Haskell 编译器的创建者 Simon 会在评论中与你争论很多很多小时，比你在 Pull Request 上工作的时间还要长，直到 PR 完全符合他的规范。

结合这个显著的事实，我认为研究中 PR 的中位数，他们在代码审查后花费的工作时间是零分钟。也就是说，中位数的 PR 第一次就是完美的，因为这些开发者的专业激励就是这样的。

### (48:00 - 56:00) Part 7

**(48:00 - 49:15)**

对于这些困难的任务，我的想法是，如果它在非常具有挑战性的长期任务上成功率是 90% 而不是 99%，那么我们还有其他可以退守的方案，我准备好退守到这些方案。但至少朴素的解释——它之所以不构成存在威胁是因为它没有能力——我认为至少开始被推翻了。

所以这里有另一种我们可以采取的可能性。如果我们不是用时间范围，而是用"被密切监控时的时间范围"，然后是时间。那么也许"不被密切监控时的时间范围"是这样的，但"被密切监控时的时间范围"是这样的。

**(49:15 - 50:30)**

也就是说，我希望主要的 AI 公司有监控设置在运行，比如 AI 查看 AI 执行工作的记录，看是否有任何可疑的事情在发生。虽然欺骗这些监控器也许不是不可能的，但要欺骗这些监控器是有挑战性的。所以也许你可以在没有任何监控的情况下执行 40 小时的危险能力相关任务，但如果你被非常密切地监控，只能执行 2 小时长的任务。

主持人：被监控是指如果有另一个模型在评估输出，这就是你说的那种情况吗？也许会上报给人类，在没有安全控制的情况下？

**(50:30 - 51:45)**

是的，大致如此。现在我们又获得了更多的倍增空间，我们可以继续进行能力外推。这是我在创造更长任务之外考虑的事情之一。

主持人：我想一些模型公司确实有在有安全控制和没有安全控制情况下的能力评估，因为我确信他们的研究人员和安全团队之间存在争论。

是的，我觉得我看到过一些关于这方面的内容，但不多。我认为这可能是一个在量化上特别重要的考虑因素，我预计它会将有效时间范围减少一到两个数量级。我同意在某些重要意义上，并没有真正的本质区别。

**(51:45 - 53:00)**

主持人：当然，然后我也会担心发布这些信息会鼓励人们减少对安全的关注，或者试图反对安全措施，因为它们如何影响能力。

是的，我认为在各种安全工作中都有很多雷区，不仅仅是这个领域。

好的，下一个问题。我们在开始时讨论过这个趋势，它会永远持续下去吗？这是宇宙的事实还是在某种程度上取决于输入？你对智能爆炸或类似事情有什么想法？试图思考这条线实际上会走向何方是一个相当活跃的工作领域。

**(53:00 - 54:15)**

这条线或特定点与我关心的事情不完全对应的方式也很重要。一个明显的方式是，这些模型是根据算法评分来判断的。我认为我们在 METR 任务上使用的算法评分比仅仅使用基准测试和单元测试在覆盖相关关注点方面更加稳健，但它仍然具有很多相同的特征。

还有一些考虑因素，比如能否在未来基于这项工作构建，而不仅仅是解决眼前的问题，这些都没有被评分捕获。如果你确实捕获了这一点，你可能会得到类似从 50% 成功率到 80% 成功率的结果。如果不需要考虑是否能基于工作进行构建，你可以做一小时长的任务，但如果需要考虑这一点，可能只能做 30 分钟的任务。

**(54:15 - 55:30)**

将这些数字再次带到我更关心的事情上，然后预测未来，如果出现算力放缓，如果我们将进入 AI 构建 AI 的某种制度，导致曲线变陡峭，这些考虑因素是我正在思考的另一件事。

然后是从新角度进行的能力测量。这里有一个我认为不是被接受的 METR 历史，可能也不是非常准确的历史，当然不是最准确的历史，但这是一种可能的叙述。

在早期，METR 提前获得了 GPT-4 的访问权限，当时我不在那里，我对此没有内部了解。当时到处都是问答数据集，比如 MMLU 数据集，GPT-4 相对于之前的东西似乎如此聪明。它能做什么？所以你尝试了一些任务，答案是它能做一些事情，不能做其他事情。

**(55:30 - 56:00)**

人们说："哦，这很酷，你尝试了这个有趣的新事物，让模型去做事而不是回答问题。"然后随着时间推移，不同的模型出现了——这个模型一月发布，那个模型二月发布。它们能做不同种类的事情吗？如果我们在相同的任务上测试它们，然后我们会想到某种最明显的总结统计，来反映它们是否能做事情——时间范围，把它随时间绘制出来，看看会发生什么。你会想，"哦，这很有趣。"

### (56:00 - 1:04:00) Part 8

**(56:00 - 57:15)**

然后还有另一个例子。有一个叫做 AI Village 的组织，你们应该去看看。他们让很多不同的模型或智能体生活在这个村庄里，偶尔与人类交谈，试图完成一些模糊的目标，基本上是使用计算机来做事。他们尝试做一些事情，比如在公园组织活动，或者进行一些人体实验，或者经营商品店，你知道的，那些规格不那么明确的事情。

基本上他们一直发现模型都会失败，表现很糟糕。不相信这个证据有很多理由。

**(57:15 - 58:30)**

以下是一些原因。第一，它使用的是计算机操作，我认为计算机操作远不如基于命令行的计算机操作。目前基于命令行的能力比基于图形界面的要好得多，或者说文本类的东西通常更好。也许你更关心基于文本的东西，因为这与你关心的各种事情更相关，而且很多基于图形界面的东西都可以转换为文本形式。

村庄里有各种不同的模型游荡。我想，为什么有这么多模型？为什么是一个村庄而不是某种大型的亚洲式编排设置？我不太理解那里发生了什么。总之，有很多理由不相信它。

**(58:30 - 59:45)**

但另一方面，这确实是模型在现实世界中做事情。这不是基准测试风格的任务。它们试图完成某个目标，但甚至无法完成目标中非常基础的子集。我觉得这极其有趣。我想知道你是否能摆脱一些最明显的缺陷——你知道，让这变成纯文本，给它们一些相关的文本工具，在启发方面做大量工作以使这些模型更有表现力，摆脱村庄中性能较差的模型，等等。然后试着让它们完成这些模糊的目标。

你知道，只是观察它们在哪里搞砸了——比如它们在第一步做得很好，但然后变得语无伦次，或者与其他模型进入奇怪的心理状态，或者无法以适当的方式与外部服务交互，或者无法弄清楚它们的资源使用。我会很有兴趣定性地了解发生了什么。

**(59:45 - 1:01:00)**

再次记住，我们感兴趣的是——至少目前我最感兴趣的是——AI 自动化研发的能力，或者说为什么目前不是这样，为什么在不久的将来可能不是这样。类似这样的东西似乎可能会奇怪地指出为什么不是这样。不确定那里究竟有什么，但是的。

我的观察是它们实际上是神经多样性个体，对吧？我们的世界不是为此而建造的。我们拥有的一切都是为人类定义的。它们的形状和大小适合人类。就像军队一样——背包有多大？这是基于他们认为一个人能合理携带多少，对吧？我们期望某人处理多少税务，这基于我们认为人类能做什么。

**(1:01:00 - 1:02:15)**

哇。如果你想想神经多样性个体，他们在世界期望与他们不一致的地方会遇到挑战，与神经多样性个体相比，这些智能体真的非常不同，对吧？所有那些与我们世界不一致的粗糙边缘，这就是为什么它们需要人类助手才能在我们的世界中完成任何真正的事情——对它们来说太难了。

目前是这样。

是的，我想是的。有朝一日可能会改变，但现在它们就是无望的，对吧？

它们必须变得非常非常好。或者我们的世界必须改变。这两件事中的一件。

**(1:02:15 - 1:03:30)**

我强烈认同这种感觉。但是，如果你要我真正指出为什么会是这种情况——当它们在这些极其困难的科学问题上击败所有 GPQA 专家，并且能做各种事情时——到底为什么它们无法在世界中完成事情？

你见过神经多样性个体不擅长某事但在生活中完全无用的吗？

是的。是的。他们都非常擅长读书。

世界上有很多这样的人。

这并不令人惊讶。

虽然我对 AI Village 的唯一感觉是，就像，今天是我的汽车没有从地球上起飞并以逃逸速度飞向月球的第200天。

那是因为你还没有造火箭。

**(1:03:30 - 1:04:00)**

我想一年前有很多关于计算机操作能力在今天令人印象深刻的讨论。

有很多关于它的讨论，但我几乎没有和任何将其用于实际用途的人交谈过。

完全是，完全是。但如果我们将其移到纯文本，这似乎是合理的——你仍然会有火箭方面的担忧吗？

不，我会...这取决于任务是什么。

确实。人类可以通过命令行完成的那种事情。

### (1:04:00 - 1:12:00) Part 9

**(1:04:00 - 1:05:15)**

确实，几乎所有这些基准测试基本上都是基于文本的。

**主持人：** 是的，确实如此。那些不是基于文本的测试——需要视觉能力的测试——明显缺乏。我不太确定如何理解这个图表。我认为从中可以看出，在不同任务分布中，斜率或倍增时间可能没有太大的差异。我认为这方面只有微弱的证据。

但是，在我们目前所处的基础层面，可能存在很大的差异，特别是在图像类能力与其他能力之间，更不用说物理能力了。

**(1:05:15 - 1:06:30)**

是的，完全正确。我是说，你甚至可以按感官来分类，对吧？比如触觉——如今所有模型在触觉方面都是零分。没有什么具备触觉能力，所以它无法告诉你任何关于触觉的事情。

**研究员：** 在制作这个图表时，我们试图让模型在一些保留的测试集上表现得尽可能好，我们确实给了它们一些触觉相关的内容。我不确定它们的表现是零分。

当然，我们确实有一些例子。比如空间判断之类的。我们显然在其他机器人技术中见过配置、查找、控制等功能。只是我甚至不知道是否有人列出了我们未来期望的所有能力——如果我们真的想要AGI，完整的能力清单是什么？

**(1:06:30 - 1:07:45)**

这是一个永远不会结束的辩论话题。我想Basel Halperin和Arjun Romani可能会在几个月内发表一篇关于这个的论文。

**主持人：** 确实需要思考我们现在处于什么位置，以及所有能力是否都遵循相同的规律——我们目前测量的所有能力是否都遵循相同的对数规律？

这似乎是一个合理的零假设，对你我都是如此。我认为并不确定。谁知道呢？

还有一件事我想补充。这里有另一个我在思考的问题，虽然不完全是研究层面的，但有点相关。

**(1:07:45 - 1:09:00)**

有些像我这样的人对"纯软件奇点"持怀疑态度。也就是说，你可以在不自动化芯片设计，可能也不自动化芯片生产的情况下，自动化AI研究的想法。你很快就会遇到计算瓶颈，因为对于固定的硬件，你只能运行有限数量的实验，这些实验足够有效率以推动快速向上发展。

但即使对于像我这样持怀疑态度的人，你可能会认为芯片生产实际上将会被自动化。机器人正在到来，它们可以做人类能做的事情，然后你真的可能拥有一个完全自给自足的机器人加AI经济。所以你可能会看到计算速度放缓的缓慢趋势，但一旦整个系统形成紧密循环，就会出现某种向上的反弹。

**(1:09:00 - 1:10:15)**

我最近听到的一个有趣辩论，想要更多思考的是——在公共讨论中有一种感觉：为什么机器人能力比LLM能力滞后这么多？这是否与训练数据有关，还是与硬件限制有关？

我很好奇，如果不是硬件限制的话，具体是什么硬件限制？如果我们把超级智能放入今天存在的硬件部件中，它能建造芯片生产设施吗？我不知道，因为我在这方面完全是外行，但我不清楚答案是什么。我觉得这是相当可能的。我不确定你需要非常灵活的精细运动控制才能做到这一点。我觉得也许精细运动控制是存在的，前提是有超级智能来控制它。

**(1:10:15 - 1:11:30)**

公平地说，芯片生产的关键环节已经完成了。但我也在考虑建造机器人的问题。

**主持人：** 我有一个朋友，他职业生涯的大部分时间都在做软件开发，但在COVID期间开始从事制造业，制造纸张等东西来帮助人们，他发现制造业世界有多么困难，迭代过程有多么缓慢。

他说这真的像——他知道情况会更糟，但他没想到会是下一个级别，像数量级的更糟。我认为从我们这些不从事制造业的人的角度来看，似乎能有多糟呢？但我从所有真正在这个领域工作的人那里得到的反馈是，这完全不同。

我也听说过这样的话。我只和一些在晶圆厂工作的人聊过一点，但当我和他们交谈时，我对所需的人类专业知识水平感到惊讶。

**(1:11:30 - 1:12:00)**

为了在晶圆厂工作，很多这些工作实际上是薪酬相当高的工程工作，为了成功完成。而且改进的速度实际上相比软件来说是极其缓慢的。

我认为这也是因为建造一个晶圆厂要花费十亿美元。迭代的成本是巨大的时间和金钱，这是残酷的。

所以我认为这就是为什么很难一路做到底的原因——也许再给他们几个世纪，他们就能完成。

**主持人：** 这真的是你的观点吗？几个世纪？

我确实像你一样对这些任务的难易程度持怀疑态度。我们认为它们很容易，但根据我的经验...我记得当自动驾驶出现时，人们在推广它，我实际上在那个领域工作过一段时间。我知道我们可以非常接近目标，但要完全达到可接受的标准是极其困难的。我们低估了完成最后一点点工作需要多少努力。前90%，我知道我们在十年前就基本上可以用计算机做到，但要让每个人都满意的最后一点...

我自己也有这种感受——我没有在预期的时候考取驾照，因为我期待自动驾驶汽车的到来。我完全理解，但时间还没有那么长，而且它们正在扩展到整个湾区。它们会实现的，我不认为需要...

机器人经济、建造芯片生产设施会需要几个世纪吗？

我不知道。自动驾驶的关键在于经济激励在推动它更快发展，机器人建造机器人的情况可能也是如此。我们现在的情况是，Ripple大概是我们在机器人建造机器人方面走得最远的。

但是，这是否充分关注了图表？GPT-2是2019年的。这太近了，我觉得也许我们正处在某种GPT-2时刻。

**主持人：** 这是一个公平的观点。我可能是错的，只是我的猜测是这会比我们想象的花费更长时间。

### (1:12:00 - End) Part 10

**(1:12:00 - 1:13:15)**
至少要能够实现真正的大规模生产。

在你所说的那种能造成全球影响的规模上。对的，我认为他们已经能很好地完成一次性制造，机器人非常擅长小规模的一次性制造，但在大规模生产上完全不切实际。

**(1:13:15 - 1:14:30)**
有一个我认为相当引人注目的事实是——机器人模型所投入的计算力增长率与其他领域大致相同，但在绝对水平上有两个数量级的差距。我很好奇如果这个差距能缩小，我们会看到什么。至少看起来更强大的机器人在某种意义上很有可能很快就能实现，如果这种情况发生的话。我不是说要达到完全的水平，当然也不是说要达到大规模生产，只是似乎存在某种数据瓶颈。

**(1:14:30 - 1:15:45)**
是的，从直觉上来说很有趣。

另外，你不只需要扩展数据规模。你还可以扩展参数，用同样的数据量，用灵活的方式使用计算力来缩小某些差距。

很有趣。

**(1:15:45 - 1:17:00)**
请给我一个关于AI如何进入制造业的概述。

它显示了很多领域现在在不久的将来可能会得到相当大的帮助，其中很多是计算方面的。有很多计算方面极其昂贵。比如设计用于激光制造晶体管的掩模基本上就是你使用的孔。

**(1:17:00 - 1:18:15)**
计算如何构建它并确保它符合你编写的规格基本上是极其昂贵的计算工作。AI在这方面有很大的机会。另外理论上还有可能——显然芯片制造极其精密但也很脆弱，AI有机会检测基本上出现偏差并可能导致失效的参数，比如在晶圆成像中，理论上可以大幅提高良品率。

**(1:18:15 - 1:19:30)**
良品率是芯片制造中的一个大问题。你的CPU有不同速度的原因是，实际上它们只有一条生产线生产所有这些CPU，有些制造得更好，有些制造得更差。这就是为什么更高频率的型号更贵，而较低频率的——比如你的NVIDIA家用GPU，你的RTX 5040、5050、5060、5090实际上都是同一块芯片，只是质量不同，容差本质上不同。

**(1:19:30 - 1:20:00)**
但问题是——停止录音吧。他们很快就要把我们赶出去了，但可以自由地继续讨论。

好的，很酷。

你也可以在这里继续聊，但我要先——

---

*生成时间: 2026-01-20 00:22:54*
*由 YouTube Monitor & Translator (Claude CLI) 生成*