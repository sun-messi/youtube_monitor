# Build a Prompt Learning Loop - SallyAnn DeLucia & Fuad Ali, Arize

## 📹 视频信息

- **频道**: AI Engineer
- **发布日期**: 2026-01-06
- **时长**: 51:57
- **原始链接**: [https://www.youtube.com/watch?v=SbcQYbrvAfI](https://www.youtube.com/watch?v=SbcQYbrvAfI)

---

I'll analyze this AI Engineer conference workshop video about building a prompt learning loop by Arize AI.

> 本文内容整理自 Arize AI 产品总监萨莉安·德卢西亚（SallyAnn DeLucia）和产品经理福阿德·阿里（Fuad Ali）在 AI Engineer 频道的技术工作坊。

## TL;DR（一句话核心洞察）

Arize AI 展示了一种基于人类反馈和 LLM 解释的提示词学习系统，通过不断迭代优化系统提示词，在 SWE-bench 编码任务上实现了 15% 的性能提升，且无需微调或架构改变，成本仅为原来的三分之二。

## 📑 章节导航表

| 时间戳 | 章节标题 | 一句话概括 |
|--------|----------|-----------|
| 00:00-02:19 | 开场介绍与议程 | 讲师介绍背景，设定工作坊目标 |
| 02:19-05:22 | Agent 失败原因分析 | 探讨当今 Agent 可靠性差的核心问题 |
| 05:22-08:57 | 提示词学习理论基础 | 对比强化学习、元提示和提示词学习的区别 |
| 08:57-13:34 | 案例研究：编码 Agent | 展示 15% 性能提升的具体实现 |
| 13:34-16:09 | 提示词学习 vs DSPy | 基准测试显示提示词学习优于 DSPy |
| 16:09-23:43 | 实践准备与 QA | 回答观众问题，准备动手环节 |
| 23:43-32:13 | 环境设置与数据加载 | 克隆仓库，配置 OpenAI API |
| 32:13-43:18 | 评估器与生成函数 | 设置 LLM-as-judge 评估系统 |
| 43:18-49:58 | 优化循环实现 | 实现核心的提示词优化算法 |
| 49:58-51:57 | 结果提取与总结 | 展示企业版解决方案 |

## 📊 核心论点

### 1. Agent 失败的三大核心原因

- **核心内容**：当前 Agent 失败主要不是因为模型能力弱，而是因为环境和指令设计薄弱。具体表现为：缺乏从环境中学习的能力（自适应性差）、规划能力不足或过于静态、上下文工程欠缺（缺少工具、工具选择指导不明确）。这些问题本质上反映了系统设计而非模型能力的缺陷。
- **关键概念**：自适应学习、动态规划、上下文工程、工具选择指导、环境反馈
- **实际意义**：企业在构建 Agent 时应将重点从追求更强大的模型转向改进系统设计，特别是提示词优化、工具集完善和动态规划能力，这能以更低成本实现更大改进。

### 2. 提示词学习的独特优势

- **核心内容**：提示词学习结合了强化学习的迭代改进思想和元提示的 LLM 驱动优化，但关键创新在于利用富文本反馈。系统不仅使用正确/错误的标签，还收集人类解释（为什么错了、违反了哪条规则）和 LLM-as-judge 的推理过程。这些文本域的丰富信息直接用于改进系统提示词，而非仅优化数值指标。
- **关键概念**：富文本反馈、人类解释、LLM-as-judge、系统提示词优化、文本域操作
- **实际意义**：企业可以利用现有的人工标注和自动评估系统，通过收集详细的失败原因说明来持续改进 AI 系统，无需昂贵的模型微调或架构重构。

### 3. 15% 性能提升的案例验证

- **核心内容**：通过对开源编码 Agent（如 Aider）的系统提示词添加具体规则（错误处理方式、设计对齐要求、测试要求等），在 SWE-bench 基准测试上实现了 15% 的性能提升。使用 GPT-4.1 达到了接近 GPT-4.5 的性能，但成本仅为三分之二。整个优化过程无需微调、工具改变或架构调整。
- **关键概念**：系统提示词规则、SWE-bench、成本效益、无需微调、规则泛化
- **实际意义**：证明了提示词优化是提升 Agent 性能的最低成本、最高效益方法，企业应优先考虑提示词工程而非立即升级到更昂贵的模型。

### 4. 过拟合即专业化

- **核心内容**：传统机器学习中的"过拟合"在提示词学习中应被重新理解为"专业化"。就像新入职的工程师需要熟悉特定代码库一样，Agent 也应该针对特定任务和环境进行优化。通过训练-测试分割确保规则的泛化性，同时保持对特定领域的深度理解。
- **关键概念**：专业化 vs 过拟合、领域专长、持续学习、规则泛化、代码库熟悉度
- **实际意义**：企业应该为不同的任务和部门构建专门化的 Agent，而非追求一个万能的通用 Agent，这样能获得更好的实际效果。

### 5. 评估器质量决定优化上限

- **核心内容**：提示词学习系统的效果完全依赖于评估器（evaluator）的质量。需要同时优化两个循环：Agent 性能优化循环和评估器质量优化循环。评估器本身也需要通过收集低置信度案例、人工审核等方式不断改进。高质量的评估包括不仅给出对错判断，还要提供详细的失败原因。
- **关键概念**：双循环优化、评估器可靠性、置信度评分、评估器的评估、详细反馈
- **实际意义**：企业在实施 AI 系统时，必须同等重视评估系统的建设，将其视为核心基础设施而非辅助工具，并持续投入资源改进。

### 6. 人机协作的新模式

- **核心内容**：技术用户（AI 工程师）负责代码、自动化和性能优化，而领域专家（产品经理、业务专家）负责定义成功标准、标注数据和提供反馈。提示词学习架起了这两个群体之间的桥梁，让非技术人员也能通过提供高质量反馈来改进 AI 系统。
- **关键概念**：角色分工、领域专家参与、反馈驱动改进、民主化 AI 优化、跨职能协作
- **实际意义**：企业应建立包含技术和业务团队的 AI 优化流程，充分利用领域专家的知识，而不是将 AI 开发完全交给技术团队。

### 7. 实时优化 vs 批量优化

- **核心内容**：提示词优化不是一次性的任务，而是持续的过程。系统应该持续收集失败案例，定期运行优化循环，生成新的提示词版本。这类似于软件的持续集成/持续部署（CI/CD），但针对的是 AI 系统的提示词。
- **关键概念**：持续优化、失败案例收集、版本管理、A/B 测试、渐进式改进
- **实际意义**：企业需要建立 AI 系统的 DevOps 流程，包括监控、反馈收集、优化和部署的完整闭环，而非将 AI 部署视为一次性项目。

### 8. 提示词学习超越 DSPy

- **核心内容**：基准测试显示，提示词学习在更少的优化循环中达到了比 DSPy（包括最新的 GABA 优化器）更好的效果。关键差异在于提示词学习充分利用了文本反馈的丰富信息，而 DSPy 主要优化数值指标。GABA 的进化算法虽然引入了反思机制，但仍未充分利用失败的具体原因。
- **关键概念**：DSPy、GABA、进化优化、文本反馈优势、优化效率
- **实际意义**：选择 AI 优化框架时，应优先考虑那些能够充分利用人类反馈和解释性信息的方法，而非仅关注自动化程度。

### 9. 多 Agent 系统的独立优化

- **核心内容**：在多 Agent 系统中，每个 Agent 可以独立进行提示词优化，因为它们往往有不同的专业化需求。独立优化后通过集成测试验证整体系统性能。这种方法避免了复杂的联合优化，同时保证了每个 Agent 在其专门领域的优秀表现。
- **关键概念**：模块化优化、专业化 Agent、独立测试、集成验证、组合复杂度
- **实际意义**：构建复杂 AI 系统时，应采用模块化方法，先优化各个组件，再通过系统级测试确保整体性能，这比尝试端到端优化更实际。

### 10. 企业级解决方案的必要性

- **核心内容**：虽然开源工具可以实现基本的提示词学习，但企业级应用需要更完善的基础设施，包括：提示词版本管理、实验跟踪、人工标注界面、自动化优化任务、与现有 MLOps 工具集成等。Arize 提供的企业版将这些功能打包，减少了自建系统的复杂性。
- **关键概念**：版本管理、实验跟踪、标注工具、自动化流程、企业集成
- **实际意义**：企业在评估是否自建 AI 优化系统时，应充分考虑长期维护成本和功能完整性，对于核心业务应用，采用成熟的企业级平台可能更具成本效益。

## 🏢 提及的公司/产品

| 公司名 | 讨论语境 | 重要性 |
|--------|----------|--------|
| Arize AI | 工作坊主办方，提供提示词学习平台和企业解决方案 | ⭐⭐⭐ |
| OpenAI (GPT-4) | 演示中使用的主要语言模型，性能基准参考 | ⭐⭐⭐ |
| Anthropic (Claude) | 提到的竞争模型，编码 Agent 示例 | ⭐⭐ |
| Aider | 开源编码 Agent，案例研究的优化对象 | ⭐⭐ |
| Cursor/Claude Code | 成功的编码 Agent 示例，有良好的规划能力 | ⭐⭐ |
| Booking.com | Arize 客户案例，展示主观评估的处理方法 | ⭐ |
| DSPy | 竞争性的提示词优化框架，用于基准对比 | ⭐ |

## 💬 经典金句

> "It's not because the models are weak. It's a lot of times the environment and the instructions are weak."
> — SallyAnn DeLucia

> "Overfitting is expertise. We're not training in the traditional sense, we're building expertise."
> — SallyAnn DeLucia

> "The explanations and human instructions... That text is really really valuable."
> — SallyAnn DeLucia

> "15% improvement with no fine-tuning, no tool changes, no architecture changes... just adding rules."
> — SallyAnn DeLucia

## 👤 主要人物

### SallyAnn DeLucia（萨莉安·德卢西亚）

**身份**：Arize AI 产品总监
**背景**：技术背景出身，从数据科学转向产品管理，但仍保持编程实践。负责构建 Arize 平台内的 AI Agent "Alex"
**核心观点**：强调提示词优化是提升 Agent 性能的最有效方法，主张利用人类反馈和详细解释来改进系统，而非仅依赖数值指标。认为"过拟合"在 AI 系统中应被理解为有益的"专业化"

### Fuad Ali（福阿德·阿里）

**身份**：Arize AI 产品经理
**背景**：曾长期担任后端分布式系统工程师，深谙可观测性基础设施的重要性
**核心观点**：支持通过代码实践来理解和改进 AI 系统，强调评估系统质量对整体优化效果的决定性作用

## 📺 视频类型判断

**教程示范**：技术教学、产品演示

---

## 📝 完整翻译

### (0:00 - 2:19) 开场介绍与议程
> 讲师介绍背景，设定工作坊目标

大家好，我们现在开始。非常感谢大家今天的参与。我是 Sally，RISE 的主管。我将带领大家学习群体提示学习 (crowd prompt learning)。在今天的研讨会中，我们实际上会构建一个驱动优化循环。我有技术背景，最初从数据科学开始，后来转向产品。我现在仍然喜欢接触代码。我最喜欢的项目之一是在我们的平台中构建我们自己的智能体 Alex。所以我非常熟悉所有的痛点，以及优化提示的重要性。我会先花一点时间讲幻灯片，设定背景，确保在座的每个人都了解我们要做什么，然后我们就跟着我一起进入代码环节。

非常感谢，Sally。很高兴见到大家。很兴奋能与大家一起学习提示学习。不知道大家昨天是否有机会看到 Harness 的演讲，希望那个演讲能为大家提供一些关于提示和提示学习多么强大的良好背景。我的名字是...我也是 Arise 的产品经理。正如 Sally 说的，我们喜欢保持在代码中。我们会做一些幻灯片，然后我们会走过代码，我们会四处走动帮助大家调试等等。我的背景也是技术性的。我长期从事后端分布式系统工程师工作。所以对于可观察性基础设施的重要性并不陌生。我觉得在 AWS 的环境下讨论这个很合适。很兴奋与大家深入探讨前置加载。

### (2:19 - 5:22) Agent 失败原因分析
> 探讨当今 Agent 可靠性差的核心问题

很棒。好的，我们开始吧。给大家一个我将要涵盖内容的议程。我们将讨论为什么智能体今天会失败，什么是晚间提示学习，我想通过一个案例研究来展示为什么这真的有效，我们将讨论学习 vs GA。我想每个人...在会议期间有几个人向我提到了 GEA？我们有一些针对它的基准测试，然后我们将进入我们的研讨会。

但首先我想问一个问题。这里有多少人正在构建智能体？

好的，这是我预期的。有多少人真的觉得他们构建的智能体是可靠的？

是的，这也是我想到的。所以让我们谈谈为什么智能体今天会失败。为什么它们会失败？我们在很多用户那里看到了一些问题，甚至在我们内部构建 Alex 时也看到了智能体为什么会崩溃的原因。我认为很多时候并不是因为模型很弱，很多时候是环境和指令很弱。没有从学习环境中获得指令，没有规划或非常静态的规划。我感觉现在很多智能体都没有规划。我们确实有一些规划的好例子，比如 Claude Code、Cursor。这些都是非常好的例子，但我没有看到它在我遇到的每个智能体中都有应用。缺少工具是一个大问题。有时你就是没有需要的工具集。

然后缺少关于应该选择哪些工具的工具指导，以及上下文工程仍然是人们面临的一个大困难。如果我要提炼出来，我认为是这三个核心问题。适应性和自学习。没有从环境中学习的系统指令，涉及确定性与非确定性平衡。有规划或没有规划与做非常静态的规划。你想要在那里有一些灵活性。然后上下文工程我认为是一个在过去六到八个月中刚刚出现的术语，但这是我们发现真的非常重要的东西，你知道缺失的工具、工具指导，就是没有上下文或确认你的数据，没有给 LM 足够的上下文。这些是核心问题。

### (5:22 - 8:57) 提示词学习理论基础
> 对比强化学习、元提示和提示词学习的区别

但我认为还有一个相当重要的事情，那就是谁负责什么的责任分配。有这些技术用户，你的 AI 工程师、数据科学家、开发人员，他们真正负责代码自动化管道，实际管理性能和成本。但是我们有领域专家、主题专家、AI 产品经理。这些是真正知道用户体验会是什么样的人。他们可能非常熟悉我们实际构建的 AI 应用程序的原则。他们在跟踪我们的评估，真正试图确保产品成功。所以责任之间有这种分割，但每个人都在贡献，但在技术能力方面有差异。

所以通过提示学习，这将是所有这些事情的组合。每个人都真的需要参与进来，我们可以更多地讨论这一点。那么什么是提示学习呢？我首先要介绍一些我们在提出提示学习时借鉴的方法。这是 Arise 一直在非常专注于进行研究的东西。我们借鉴的第一个东西是强化学习。这里有多少人熟悉强化学习是如何工作的？很好。

如果我要给一个非常简单的类比，我们有一个强化模型。假装它像一个我们试图提升的学生大脑。他们将采取一个行动，这可能是参加测试或考试，会有一个分数。老师会来实际评分考试，这会产生一种标量奖励，假设学生大脑中有一个算法，可以接收这些分数并更新他们大脑中的权重和学习行为，然后我们重新处理。

### (8:57 - 13:34) 案例研究：编码 Agent
> 展示 15% 性能提升的具体实现

所以在这种强化学习中，我们基于一些标量来更新权重。但直接更新权重实际上真的很困难，特别是在 LLM 世界中。所以强化学习在我们做提示这样的事情时不会工作得很好。

然后有元提示 (metaprompting)，这与我们在提示学习中所做的非常接近，但仍然不太正确。在元提示中，我们要求 LM 改进提示。再次使用学生例子。我们有一个智能体，就是我们的学生。它将产生某种输出，比如用户提问并得到输出。那是我们这个例子中的测试。然后我们要评分。评估基本上就是你可以想到的。它将输出一个分数，从那里我们有像元提示的东西。现在老师有点像元提示。它将获取我们评分器的结果并基于此更新提示。但这仍然不是我们想要做的。

这就是我们引入提示学习这个想法的地方。提示学习将进行考试并产生输出。我们将在那里进行 LLM 评估。但还有一个非常重要的部分，就是英语反馈。哪些答案是错误的？为什么答案是错误的？学生实际需要在哪里学习？真正指出这些问题。然后我们仍然在使用元提示。我们仍然在要求 LLM 改进提示。只是我们给那个 LLM 的信息是完全不同的。所以我们将用所有这种反馈来更新提示。来自我们的评估，来自主题专家进去标注并使用它来提升我们的提示，提供更好的指令，有时是示例。

这有点像传统的提示优化，我们有数据和提示。我们说优化这个提示并最大化我们的预测脉冲。但这对于 Allen 来说不太有效，我们缺少很多上下文。我们真正发现的是失败原因的人类指令。想象你有你的应用数据、跟踪、数据集，无论是什么。你的主题专家进去，他们不仅在注释正确或不正确，他们在说这就是为什么这是错误的。它没有遵守这个关键指令。它没有遵守上下文。它遗漏了什么，无论是什么。然后你还有来自 Ellen 作为判断的自我解释，这是相同的原则，不是只有标签，它提供标签背后的推理。

然后我们将它指向要更改的确切指令。我们正在更改系统提示以帮助它改进，这样我们就得到预测标签，但我们也得到那些评估和解释。所以我们不仅仅是在优化我们的输出。我认为一个真正关键的学习是解释和人类指令或通过你自己作为判断。那个文本真的非常有价值。我认为这是我们在很多其他广泛优化方法中看到的没有被利用的东西。他们要么在为分数优化，要么只关注输出。但你可以这样想。就像这些元素在文本域中运作。所以我们有所有这些丰富的文本告诉我们它需要做什么来改进。我们为什么不用它来实际改进我们的...

这就是提示学习的基础，但每个人总是来问我，听起来很棒，但它真的有效吗？

### (13:34 - 16:09) 提示词学习 vs DSPy
> 基准测试显示提示词学习优于 DSPy

它确实有效，我们有一些我们这样做的例子。所以我们做了一个小案例研究。我想编程智能体，每个人现在基本上都在使用它们。有相当多的非常成功的例子，我认为 Claude Code 是一个很好的例子，Cursor，但也有 Clien，这更像是一个开源版本。所以我们决定看看并比较看看我们是否能做任何事情来改进。

这些是我们开始的基准。你可以看到不同模型之间的差异。显然使用 Claude 3.5 Sonnet 是最先进的，但我们也有这个机会，CL 使用的是 Claude 3.5，在 30% 对 40% 的情况下工作得相当好。然后有关于...这就是我们开始的地方，我们尝试优化系统提示。

### (15:00 - 30:00) Part 2

第二点是，你的评估（emails）的外观和可靠性确实很重要。我认为这是我们在 Arise 非常坚信的一点——你绝对应该优化你的智能体提示词，但我认为很多人忘记了一个事实，那就是你也应该优化你的邮件提示词，因为如果你使用邮件作为信号，如果你对它们没有信心，你就无法真正依赖它们。所以在这方面投资同样重要，确保你将应用于智能体提示词的原则同样应用于邮件提示词，这样你就有了一个真正可靠的信号，你可以信任并将其输入到提示词优化中。

在这两个图表中，粉色线是提示词学习（prompt learning）。我们也对它进行了基准测试，与 me pro 他们较旧的优化技术相比，我之前提到的那种围绕评分和评估进行优化的功能。

### (16:09 - 23:43) 实践准备与 QA
> 回答观众问题，准备动手环节

所以这在某种程度上...我在这张幻灯片上强调了，通过评估工程我们能够做到这一点。所以我们确实必须确保提示词学习的评估部分质量非常高，因为这只有在评估本身正常工作时才有效。

所以，是的，邮件起到了关键作用。在这里花些时间优化提示词。同样，这一切都是为了确保你有适当的指令。同样的规则适用。

我想带大家走一遍。我知道内容很多。我认为有上下文背景真的很重要。但在我们开始任何工作坊之前，对于我到目前为止讨论的内容，有什么问题我可以回答的吗？

主持人：我有一个问题评论。我认为编程是在结构和评估方面最好的例子。我有点好奇的一件事是，你们是否有其他例子，关于与系统交互的一般提示词，这些交互不那么容易量化。我只是对你们在这方面的任何经验感到好奇。

Sil：是的。那是针对一般评估的吗？

主持人：我认为问题是如何设置评估的样子很清楚，我只是想知道对于其他类型的任务你们会如何做。所以问题是关于如何设置评估的任何指导吗？编程似乎是一个非常直接的例子。你想确保代码是正确的，对吧？但对于其他一些智能体任务来说，这有点困难。

Sil：我通常给人们的建议是，我们确实有一套开箱即用的工具。你总是可以从QA正确性或专注于任务这样的东西开始。但我总是建议让所有利益相关者都参与进来。让那些主题专家、安全专家、领导层真正定义成功是什么样的，然后开始将其转换为不同的评估。

我认为一个例子是 Sterling 和 Alex。我有一些任务级别的评估。比如我真的关心它是否找到了应该找到的正确数据。它是否应该使用语义搜索或结构化搜索创建过滤器，比如做出正确的工具调用？然后我关心它是否按正确的顺序调用了东西？计划是否正确？所以思考每个步骤是什么，然后甚至安全方面会说，我们关心人们多久尝试越狱 Alex 一次。所以，就是采用每个成功标准，将其转换为评估。我们确实有不同的工具可以帮助你，但这通常是我给人们的框架——从成功开始，然后担心之后转换为邮件。

主持人：是的。补充一下，更多像主观用例的例子，比如 Booking.com 是我们的客户之一，所以当他们做什么是房产的好发布时，什么是好照片？定义这个真的很难，对吧？对你来说，你可能认为某个东西对酒店来说是非常有吸引力的发布，对吧？但对其他人来说，它可能看起来完全不同。有时，就像 Sil 暗示的那样，简单地将其分为好、坏就足够了，然后从那里迭代。所以比如，这是好照片还是坏照片？让我们决定，然后从那里进入具体背景，比如，这个光线昏暗，房间布局不同等等。

主持人：是的。这实际上建立在我要问的问题上，他们最终得到的二进制结果不一定给你一个前进的梯度，你然后有效地使用这些问题，比如数字照明不是为了得到更连续的空间吗？

完全正确，然后从那里当你得到更多信号时，你可以进一步完善你的评估器，然后使用这些状态，你实际上可以在你的提示中加入很多这些，对吧。

主持人：我有两个问题，我不确定是否应该问这两个问题，或者你的工作坊会回答。一个是关于规则和规则部分或操作程序。我好奇你是如何持续地用英语完善它们，并可能减少任何矛盾规则的摩擦。这是第一个问题。然后另一个是我想看关于评估的幻灯片，如果你能多说一点关于你如何处理这个问题，因为我在做这项工作时的问题是是否要有一个产品的模拟器然后模拟器在评估，还是做我想做的端到端评估。

Sil：是的，当然。关于第一个问题，关于指令如何随时间迭代，这绝对是我认为的事情。很多时候我们采取最佳猜测，我们手动编写它们，对吧？我认为我们试图通过适当的优化做的是利用数据动态改变它们。这在移除冗余指令等方面很出色。但目标是我们想要摆脱静态指令。我们非常确信这不会真正扩展。它不会导致可持续的性能。

所以提示词学习的确切想法是你可以随时间运行的东西。我们甚至在长期运行的任务中看到这种情况，最终你正在建立不正确事物的例子，可能让人类注释它们，然后任务总是在运行，产生优化的提示词，你可以在生产中拉取，它是一个随时间重复的循环。

### (23:43 - 32:13) 环境设置与数据加载
> 克隆仓库，配置 OpenAI API

主持人：抱歉，只是打断一下。所以，你是说当你长期做这件事并且有例子时，你只是将结果输入回你的规则部分？

Sil：有点像。当我们到达实际的优化循环时，我们将要构建的，你会看到它就像你正在输入将构建新指令集的数据，然后你会推送到生产中使用。

主持人：好的。

Sil：我认为你的第二个问题是关于评估以及如何开始、如何编写它们以及如何优化这些。是这样吗？

主持人：是的。

Sil：是的。所以，这是一个非常相似的方法。我认为你正在审查的数据有点不同。让我尝试快速显示一些东西来展示这个。

这就是我们看到的方式，你有两个共同进化的循环。我一直在谈论左边的蓝色循环，关于我们正在改进智能体，我们正在收集失败案例，设置它来进行微调或提示词学习，但你基本上想对你的评估做同样的事情，我们正在收集失败的数据集，但不是考虑失败是你的智能体的输出，我们实际上在谈论评估输出。

让某人去评估评估器或使用像对数概率作为置信度分数或陪审团作为法官来确定哪些地方不确信。我们在做同样的事情。所以找出你的评估低置信度的地方，然后你收集那个，注释，可能让某人去说好的，这是评估出错的地方。所以这是优化你的评估提示词的相同过程。只是我认为人们认为他们可以从货架上抓取一些东西或写一次，然后就可以忘记它。但这个循环，我说过几次，但左边的循环只能和你的评估一样好地工作。

主持人：抱歉，我认为我的问题实际上更静态和基础。就像你谈论这个橙色圆圈是在为评估构建系统或模拟器，还是只是谈论系统提示词、用户提示词、评估？

Sil：是的，我认为现在我们谈论的更多是不同的提示词。你绝对可以做模拟，但我认为那是一个完全不同的工作坊。

主持人：谢谢。在我们进入桥牌俱乐部之前还有其他问题吗？

好的。所以这里会有一个二维码，用于我们的提示词学习仓库。我会给大家几分钟时间来获取它。在你的笔记本电脑上获取它。我知道添加这个二维码和隔空投送有点笨拙，不确定有什么更好的方法。我也可以在这里展示给你，如果你想找到它。它将在我们的 Rise AI 仓库这里，在提示词学习下面，你只需要克隆它。我们将在本地运行它。

主持人：当你构建新的智能体或任何可以评估的工作时，你的流程是什么？你们是先尝试原型，然后看哪里不好，然后做评估吗？

Sil：是的，我认为对此有不同的观点。我们的观点是评估永远不应该阻碍你。你需要开始，你需要构建一些非常粗糙的东西。我们不认为你应该浪费时间做评估。我认为在这些情况下从货架上拉一些东西有时是有帮助的，因为梳理你的数据很困难。这是我们在 Alex 上经历的，当你开始时，只是手动运行测试审查，这有点痛苦。所以我认为有评估是有帮助的，但不应该是阻碍。从货架上拉一些东西，也许从那开始，然后当你迭代时，你了解你的问题在哪里，然后你开始完善你的评估，同时完善你的智能体。

主持人：最后一个问题。

主持人：所以优化系统或子智能体或命令是有意义的，你如何考虑这个多智能体？

Sil：是的。所以问题是你只是做一个单一提示词还是你如何在多智能体中考虑这个？我认为我们现在认为这是可以独立优化你的提示词的独立任务，然后运行测试来进入将它们全部一起运行的智能体模拟。但现在，我们的方法有点孤立，但我绝对看到一个未来，我们将满足子智能体和现在发生的所有其他事情的标准。

不，我认为这相当准确。而且即使在单智能体用例与多智能体用例中，最终每个智能体可能都是专门的。它们可能有自己需要学习的提示词。所以我认为孤立地做这件事对整个多智能体系统仍然有好处，可以随时间在交接等场景中传递，使某些东西真正专门化。所以我想我们谈论的过拟合也是如此，这也是我们一直得到的问题，但作为工程师，你真的想要在你的代码库上过拟合。你不想过于泛化以至于你在代码库中拾取特定工作时不再擅长。

### (30:00 - 45:00) Part 3

还有规则数量。基本上就是用于评估的特定规则数量。这只是决定使用哪些提示词。当我们运行这些循环时，我们会输出很多不同的提示词。所以这只是说我们应该使用多少个来进行评估。然后这里的关键一个，优化循环次数。这设置了每个实验要运行多少次优化迭代。每个循环基本上生成那些输出，评估它们并完善提示词。

所以这些只是控制实验范围和数据分割。我们刚刚经历了整个提示词学习循环以及我们想要使用多少数据。所以你可以按原样运行这些，或者如果你想调整它们，请随意。然后下一步很简单。如果你还没有设置的话，我们只是要获取那个 OpenAI 密钥。所以，get passage 会弹出来。我在这里快速展示一下。它会在那里弹出。在我们开始查看数据之前，你可以在那里粘贴你的 API 密钥。

如果有人遇到任何问题，你就把这个给出去。好的。我想这个特别的...我们完成这个...

主持人：我做得不错，但如果你有免费的想给我...

嘉宾：我希望有...好的，让我们谈谈数据。我们为你提供了查询数据。你可以在这里看到，我们基于上面设置的配置做了 80/20 分割。我只是要拉取这个训练集...

主持人：是的，我运行了，因为是负 50...

嘉宾：哦，是的。你是对的。那是我的错误。是的，确实是 50。

### (32:13 - 43:18) 评估器与生成函数
> 设置 LLM-as-judge 评估系统

让我们看看这个数据集是什么样子的。只是为了让大家能够理解。从这里开始，一些基本的输入和输出。我们在这里打印出的行中没有任何反馈，但你可以想象你可以在这里有不同的正确性标签、解释、任何真实的验证数据都可以是你想要的任何内容。有些人使用多重评估反馈，有时是组合，但你真的想要有输入和输出，我们会这样使用。

主持人：我的训练集输出应该和你的一样吗？

嘉宾：不一定。取决于...我不知道 head 是否排序。这完全取决于...也许是一样的，但我们可以看看，比如如果我这样做，这对你来说应该是一样的，也许只是为了确保...

主持人：是的...你是这个意思。好的。是的。

快速问题。输入有可能是聊天历史记录而不仅仅是...

嘉宾：很好的问题。我认为这取决于你想要做什么。如果你只是做一个简单的系统输入，你希望它是一对一的。你不想给它大量与你正在优化的提示词无关的对话数据。我们通常只使用单一输入，但我认为有一些应用程序你可以使用对话级别的输入。

主持人：是的。因为失败通常发生在中间的某个地方，对吧。所以如果你只放入原始任务，那么你在中间遇到失败的概率...

嘉宾：完全对。在这种情况下，我们通常看到的是不同行，让每个来回对话都作为独立的行，因为你可能会评估每一个，老实说，可能会在每一个上获得人类反馈。所以我们通常以这种方式分离它们。

主持人：但这是一个很好的观点。如果你总是专注于第一轮，那里可能有很多冗余。你肯定需要在对话的某些部分...

嘉宾：我们如何区分指令，我们也有一些上下文。所以...

主持人：不应该触及上下文。它应该只操作系统指令或提示上下文，上下文应该是静态的，不应该基于答案改变我的上下文。

嘉宾：是的。你说的是在查看输入时可能有一个工具卷上下文，你传递进去。你绝对可以在你的数据集中包含这些，这样应用程序就能理解还有什么其他的...不是应用程序，而是提示词学习 LM 可以理解所有可用的数据。所以如果你想的话，你可以将其作为额外的列传入。大多数人从输入和反馈开始。但你绝对可以添加你认为相关的其他数据，当我们在做实验测试的重新运行时，你肯定总是希望有回答所需的数据...

主持人：即使是很简单的一些调用或一些上下文，它正在拉取一些 API 调用，无论什么提示词工程，都应该基于输出...得到输出，无论什么上下文前端加上我所做的工具调用，所有的上下文工程，然后最后完成...

嘉宾：完全对，所以在这一点上，我们正在测试一个提示词，而不是端到端的，但你肯定想要有所有流入你正在优化的提示词的内容。所以如果你的系统提示词接收用户输入，比如来自外部 API 的一些数据，你肯定想要提供所有这些数据，这有意义吗？

因为你说的是轨迹，工具调用以及代理要做什么取决于工具调用是什么，这是你想要优化的。

嘉宾：是的，完全正确。我们想要...因为我们试图重播和优化其中的一个步骤。我们肯定不想完全孤立地做这件事。所以如果有数据流入那个提示词，那就是使用的上下文，产生输出，对吧？所以我们想确保我们包含了这些。我们不想排除任何东西。但如果是在不同步骤出现的数据，你可能不想那样做。这就像思考什么与我们试图在这里优化的步骤相关。

好的。还有其他问题吗？好的。酷。所以我们要设置我们的初始系统提示词。你可以看到这是一些非常非常基本的东西。我认为我们绝对可以做得比这好得多，但我只是想说明一些我们要测试和优化的东西。所以我们只是说你是 JSON 网页创建的专家。你的任务是输入。然后所有这些我们看到的输入都将是我们实际生成输出和试图优化的内容。

现在我已经涉及了这一点。评估器对于使所有这些工作极其重要，对吧？所以我们要初始化两个使用模型作为判断者来评估生成输出质量的评估器。所以我们使用模型作为判断者。如果你有任何其他基于代码的评估，无论你需要做什么来评估，你绝对可以交换那些。

我们要做评估输出。这将是一个综合评估器，根据输入查询和评估规则评估 JSON 网页的正确性。它将提供正确或不正确的输出标签。所以相当简单的二进制。同样，你可以使用多级别。然后它也会有详细的解释。然后我们有一个规则检查器。这是一个更专业的评估器，执行细粒度的逐规则分析。它检查每个规则是否符合。

然后这两个都将生成反馈，进入我们的优化循环，以迭代改进系统提示词。解释角色违规指南。我们会看到这个提示词学习优化器并创建更有效的提示词。

我在这里有一些导入。让我们看看实际的评估输出有什么。我们确实有一些规则在这里...它们会在仓库中。所以我们要作为文件打开它。我们有这个 LLM 提供者，我们这里使用 OpenAI。然后我们要做我们的分类评估器。所以，我们只是称它为评估输出。我们有一个我们从底部这里读取的评估模板。然后我们只有正确和不正确的选择。现在我们将标签映射到分数。有时能够添加或评分是有帮助的。有时数字比只看一堆标签更容易。

如果你有多类用例，这是可选的，你想要映射这些。你可以相应地设置分数。但这些只是我们的选择，就像我们希望我们的模型作为判断者遵守的准则。然后我们在这里做的就是获取我们的结果。我让它做一些打印，所以你可以看看。所以这与你在笔记本中看到的会略有不同。

所以我只是在这里暂停一下。如果你想从你看到的可能是你的版本中进行代码更改，现在是一个好时机。

评估器的设置对所有关键的东西都有意义吗？它将是准则。它将是输出。当然还有我们的模板。

主持人：是的，你会想要在这里获取你自己的 OpenAI 密钥来设置...

嘉宾：如果你想使用不同的提供者，我们可以帮助你交换这个，如果这对任何人有帮助的话。

好的，我要开始带你了解输出生成。所以这只是你可以想象的作为你自己的代理逻辑或你正在测试的部分。这只是一个实际生成 JSON 输出的函数。我们在这里使用一个，JSON 响应格式，零温度以获得一致的输出。

### (43:18 - 49:58) 优化循环实现
> 实现核心的提示词优化算法

它接受数据集，系统提示词为所有行生成输出，返回用于评估的结果。它在每次迭代期间被调用以产生输出。所以这就像我们正在编写的实验函数。当我们传入数据时，它产生新的提示词。我们需要一种方法来测试它，评估，理解我们如何推动进展。所以这就是全部。所以这是一个非常直接的函数，称为生成输出。我们有那个输出模型。同样，我们使用 OpenAI。如果有人想要帮助切换东西，很高兴帮助。

我们使用响应格式是因为我们在这里处理 JSON。所以我们知道你刚刚提示的。我是说一些较新的模型在这方面还不错，但使用响应格式真的很有帮助。然后我们也将温度设置为零。这里就是我们传入所有数据的地方。所以数据集，因为我们又想要在所有测试数据上运行这个，系统提示词将是输入。所以当我们进入优化循环时，我们将用数据集传入新的提示词，然后评估。

### (45:00 - End) Part 4

我们在产品环境中可能会跳过这个评估步骤，但我想让我们从零开始，这样能真正感受到这个过程。然后它开始循环。我们生成输出，将其设置为训练输出。当我打印训练时，你看到了输出结果，我在那里跳过了一些内容。它还会设置正确性、解释和任何规则违规情况。然后我们实际使用提示词学习优化器。这个优化器附带在SDK中，即你可以在Arise中使用的提示词学习SDK。我们发送提示词优化、最佳选择和该API。

在底层，正如我们在幻灯片中讨论的，它接受反馈，接受原始提示词并尝试优化以获得更好的结果，然后生成提示词。我们还可以添加评估器。同样，我们希望获得那三个反馈列：正确性、解释，以及是否有规则违规。从那里我们启动优化器，使用训练集输出、这些反馈列进行优化，以及你想要添加的任何上下文大小限制。

下一步，优化器将接受我们的数据产生提示词，我们想要评估它，这样我们就能了解我们的表现如何。这段代码在做什么呢？它试图获得包含所有细节的新提示词，获得我们的结果，然后我们对测试集也这样做，获得分数和指标值，然后进行检查。我们重复这个过程，直到超过阈值或达到最大循环次数，然后返回结果。这就是这里要发生的事情。

有什么问题吗？这里还有一些结果保存函数和辅助函数。我们显然想要保存所有这些结果，不希望它们只是临时的，以后无法再次访问。所以我们保存所有结果。你也可以保存所有单个实验，这样你就有了所有数据。到最后我们能够提取这些数据并确定最佳提示词。但这些只是非常基本的辅助函数。我不会花太多时间，归根结底就是将它们保存为CSV文件。

现在我们执行它。这个单元格运行提示词优化实验，保存结果。我们以JSON格式、CSV格式获得结果。它包括迭代次数、规则数量、测试和训练准确率分数，所有我们实际需要评估这个东西是否成功的数据。

然后我们开始获得结果。这确实需要很长时间来运行。我们运行它，我认为这将是讨论的好时机。在你运行它的时候，你会开始看到不同的循环输出。这可能需要20到30分钟来运行，但我很乐意回答任何问题并帮助遇到问题的人。

学员：有一件事，你能回到我们需要更改的代码部分吗？

讲师：更改...让我提醒一下，对于这一行，当你进行安装时，你确实希望使用2.2版本。因为我认为有一些软件包问题。所以如果你在评估时遇到错误，请确保使用这个版本，如果不行，请告诉我，我们试着修复它。这就是为什么...

### (49:58 - 51:57) 结果提取与总结
> 展示企业版解决方案

学员：使用通用评估吗？

讲师：是的。如果你去看，你可以看到评估问题。我们已经把那部分从这里拿出来了，但我们绝对可以介绍一下。如果你看这里，在这一行，我们在prompts下面读取，如果你好奇的话可以找到评估。这就是为什么每个人都讨厌docker的原因。这就是为什么我们使用...

学员：绝对是的。

讲师：notebook。我还建议如果你还没有的话，用nestio修补你的代码。它有助于运行得更快。而且为了研讨会的目的，我将我们的循环改为一次。这花了我六分钟运行。所以也建议这样做而不是五次。显然当你实际优化提示词时不会建议这样做，但现在这会帮助你完成研讨会。


---

*生成时间: 2026-01-07 14:05:02*
*由 YouTube Monitor & Translator (Claude CLI) 生成*