# No Priors Ep. 135 | With Humans& Founder Eric Zelikman

本文内容整理自 **No Priors: AI, Machine Learning, Tech, & Startups** 频道的视频。

原始链接：https://www.youtube.com/watch?v=Oh0oQnKn9dw

## 📝 视频简介

The AI industry is obsessed with making models smarter. But what if they’re building the wrong kind of intelligence? In launching his new venture, humans&, Eric Zelikman sees an opportunity to shift the focus from pure IQ to building models with EQ. Sarah Guo is joined by Eric Zelikman, formerly of Stanford and xAI, who shares his journey from AI researcher to founder. Eric talks about the challenges of building human-centric AI, integrating long-term memory in models, and the importance of creating AI systems that work collaboratively with humans to unlock their full potential. Plus, Eric shares his views on abundance and what he’s looking for in talent for humans&.
Sign up for new podcasts every week. Email feedback to show@no-priors.com

Follow us on Twitter: @NoPriorsPod | @Saranormous | @EladGil | @ericzelikman
Chapters:

---

# 视频摘要：Eric Zelikman 论人工智能的未来：以人为本的智能模型

> 本文内容整理自 humans& 创始人埃里克·泽利克曼（Eric Zelikman）在 No Priors 播客的精彩访谈，分享了他对人工智能发展的独特见解。

## TL;DR

AI不应仅追求智力（IQ），而要关注情商（EQ）和人机协作，通过深入理解人类目标来赋能个人。

## 📑 章节导航表

| 时间戳 | 章节标题 | 一句话概括 |
|--------|----------|-----------|
| 00:00-00:29 | Eric Zelikman 简介 | 介绍Eric的研究背景和对AI的独特视角 |
| 00:29-01:29 | AI 动机与初衷 | 探讨利用AI解放人类潜能的初衷 |
| 01:29-02:25 | AI 与自动化挑战 | 分析自动化过程中理解人类目标的复杂性 |
| 02:25-06:14 | 研究贡献 | 介绍Q-STaR等研究工作及其在AI推理中的创新 |
| 06:14-08:14 | AI 模型现状 | 讨论当前AI模型的能力和局限性 |
| 08:14-15:23 | AI 模型智能评估 | 深入分析AI模型的智能程度及其在不同任务上的表现 |
| 15:23-22:08 | 以人为本的AI | 阐述建立以人为中心的AI系统的重要性 |
| 22:08-35:33 | humans& 新公司 | 解释创立新公司的愿景和使命 |
| 35:33-36:58 | 招聘目标 | 分享公司寻找的人才类型和特征 |

## 📊 核心论点

#### AI 智能的局限性与人机协作愿景

- **核心内容**：当前AI模型主要专注于提高智力（IQ）指标，但忽视了理解人类情感、目标和长期意图的重要性。Eric认为，真正有价值的AI应该是能够深入理解用户需求，并协助人类实现目标，而不是简单地替代人类。
- **关键概念**：人机协作、情感智能（EQ）、长期目标理解、多轮交互
- **实际意义**：突破当前以任务为中心的AI训练范式，转向更加以人为本、理解人类复杂性的智能系统

#### 记忆与上下文理解的关键性

- **核心内容**：目前的AI模型将每次对话视为独立事件，缺乏长期记忆和上下文理解能力。Eric强调，一个真正有价值的AI应该能够记住用户的历史、理解复杂的个人背景，并在此基础上提供更加个性化和有针对性的交互。
- **关键概念**：长期记忆、上下文理解、个性化交互、多轮对话
- **实际意义**：提升AI系统的实用性，使其成为真正的个人助手，而非简单的信息检索工具

#### 重新定义AI的发展目标

- **核心内容**：Eric批评当前AI发展过度追求全自动化和单一任务优化，主张AI应该赋能人类，帮助人们实现原本难以触及的目标。他认为，通过深入理解个人愿望和价值观，AI可以成为人类潜能的放大器。
- **关键概念**：赋能（Empowerment）、人类潜能、价值对齐、协作智能
- **实际意义**：重塑AI技术的社会价值定位，从单纯的效率工具转变为人类潜能的催化剂

## 🏢 提及的公司/产品

| 公司名 | 讨论语境 | 重要性 |
|--------|----------|--------|
| humans& | Eric Zelikman的新创公司，致力于构建以人为本的AI系统 | ⭐⭐⭐ |
| xAI | Eric之前工作的公司，专注于AI研究 | ⭐⭐ |
| Google | 讨论AI benchmarks和资源分配 | ⭐ |

## 💬 经典金句

> "AI不应该是去自动完成任务，而是要理解并赋能人类实现他们真正想做的事情。"
> — Eric Zelikman

> "我们需要的是能够理解人们目标、协助人们的模型，而不是试图取代人类的AI系统。"
> — Eric Zelikman

## 👤 主要人物

#### Eric Zelikman（埃里克·泽利克曼）

**身份**：humans& 创始人；前Stanford研究员；AI研究者
**背景**：专注于机器学习、AI推理和人机交互领域。曾在xAI工作，参与多项开创性AI研究，包括Q-STaR等重要项目。
**核心观点**：AI发展应该超越单纯的智力指标，转向深入理解人类目标、情感和长期意图的系统。强调通过协作而非替代的方式赋能人类。

## 📺 视频类型判断

- **访谈对话**：多人讨论、问答形式、播客

---

## 📝 完整翻译

### 📑 章节导航表（翻译参考）

（摘要中未提供章节导航表）

### (0:29 - 1:29) Eric’s Early Interest in AI

Eric：回溯到很久以前，我一直被这个问题所驱动：世界上有这么多人才，拥有各种独特的才能和热情。但我一直有些失望的是，由于各种现实情况和限制，这些人才往往无法被充分利用。

对我来说，这意味着人类并没有充分发挥自身潜能。我真正感兴趣的是如何构建这样的技术，让人们能够专注于他们真正热爱的事情。最初，我认为自动化是最自然的方式——通过自动化人们不想做的部分，从而腾出时间让他们去做想做的事。

但我逐渐意识到，这actually是非常复杂的。要真正赋能人们追求所想，你必须深入理解人们真正想做什么。构建能够理解人们目标和期望的系统，实际上是非常困难的。

### (1:29 - 2:25) Challenges in AI and Automation

Sarah：你最初选择研究问题时就有这种以人为中心的视角吗？

Eric：最开始，我选择研究时更多地是关注能力的提升。回到2021年，当我看待AI或语言模型时，我认为它们并不是很智能，能力很有限。当时有一些早期工作，比如使用思维链（chain of thought）让模型能更聪明地回答问题，但那只是一个小小的改进。那时的提示工程（prompting）能带来的收益也非常有限。

所以那时我在思考如何真正让这些模型能够稍微像样地解决更复杂的问题。

### (2:25 - 6:14) Research Contributions

主持人：你能给我们一个大致的直觉吗？我们的听众从研究人员到商务人士都有。如果有一个模型能够通过思考来解决这些稍微困难一些的问题，那么如果你实际教它"你为这个问题找到的解决方案让你得到了正确的答案，干得好"，或者如果模型没有找到正确答案，基本上就不奖励它。

Eric：最初版本的 SAR 实际上没有基准。我们将其与强化学习中的一种流行算法 reinforce（一个非常简单的策略梯度方法）进行比较。当时这是一个非常简单的算法：你迭代地生成解决方案，如果这些解决方案能让你得到正确答案，你就从中学习；如果不能，就不学习。然后你就这样继续，让模型解决越来越困难的问题，并从中学习。

主持人：在研究过程中，你是否在某个时候对它的效果感到惊讶，或者你对这种方法具有可扩展性是否有一些直觉？

Eric：我记得有一个实验，那是很久以前的事了。我们研究了 n 位数的加法或乘法。当时，这被认为是语言模型难以处理的任务。这曾被视为证明这些模型为什么如此愚蠢的典型例子。有趣的是，随着训练迭代次数的增加，模型能处理的数字位数不断增加。这对我来说是一个很大的惊喜，因为似乎没有明显的性能瓶颈。

我们还观察到模型没有学习的数据，所以我们提出了另一个变体：对于模型无法正确解决的问题，我们让它思考为什么应该得到正确答案，然后像它已经得到正确答案那样进行训练。这是一种扩展模型学习边界的方法。如果只在正面样本上训练，模型就会陷入一个没有更多可解决数据的局部最优。我们的想法是展示它无法解决的问题，并尝试从中学习。后来的研究表明，大量采样也能起到类似的作用。

主持人：SAR 已经成为推理范式中广泛使用的一部分。你能介绍一下你最后发表的工作 Qstar 吗？

Eric：Qstar 是我在斯坦福最后做的项目，非常有趣。我们展示了一些很酷的东西。主要目标是证明可以通过使用预训练风格的数据将其扩展到预训练技能。现在已经有很多关于强化学习预训练的工作出现。不是问答，而是使用任意文本块，尝试预测接下来会出现什么，这是标准的语言建模目标。

我们展示了原始 Qstar 论文中一些被忽视的关键改进，对 SAR 算法很有价值。例如，证明算法在线运行很重要，对于更困难的问题学习得更多，对于较容易的问题学习得相对较少。当时我可能没有完全意识到这些细节是对原始方法的重大改进。

### (6:14 - 8:14) Q-STaR and Scaling Up AI

Eric：就像我们在 Qstar 工作中展示的那样，我们不是进行问答，而是使用任意文本块，尝试预测接下来会出现什么，这是标准的语言建模目标。那么，我们是否可以让模型更普遍地学会推理？

我认为原始 Qstar 论文中被忽视的一个比较酷的东西是，我们展示了对 SAR 论文很有价值的关键改进。例如，证明这个算法在线运行非常重要。证明对于较难的问题，你学习得更多，而对于较容易的问题，学习得相对较少。当时我可能没有完全意识到这些细节是对原始方法的重大改进。

主持人：你后来在 XAI 工作了几年，在 Grock 项目中处理了不同的范式。在 Grock 2 中是预训练数据，Grock 3 是整体推理配方，Grock 4 涉及工具使用和智能基础设施。如果要评估当前模型的智能水平，你会如何看待？

Eric：就 IQ 层面来说，如果问题能够很好地阐述，比如一些高级的物理或数学问题，我认为它们相当聪明。但这种智能是不均衡的。

比如，一些模型能解决的人文最后一试（HLE）问题对实际的博士研究者来说都不是trivial。这些问题中有一大类是需要识破陷阱的技巧性问题。如果你熟悉这类问题，就会意识到它们往往诱导你做出某些假设，但如果更仔细地思考，那个假设其实并不成立。

但更重要的是，这些模型在情感层面并不聪明。它们不理解人们真正关心什么，也不知道如何帮助人们实现他们的目标。

对于非研究人员，我的建议是，尽可能多给模型提供上下文，这会显著改善模型的表现。目前的模型在处理那些封闭形式的、易于检查答案的问题时表现最好。如果你能想象出一种简单的方式来验证答案，这会让模型更容易回答。

关于为什么在代码等可验证领域使用模型仍然困难，部分原因是需要在响应速度和给予模型更多思考时间之间找到平衡。模型的性能很大程度上取决于问题是否与其训练分布相似。如果问题与模型之前见过的问题很接近，它就会做得很好；如果问题非常出格，效果就会大打折扣。

在模型的 IQ 扩展方面，我认为仍有很多未被充分探索的维度。关键是在扩展模型能力的同时，要有意识地保持人类参与。设计新算法时，要主动思考如何让人类保持在环路中，而不是试图将人类排除在外。

我认为，与其简单地用模型替代现有任务，不如赋能人类。如果我们构建能真正理解人们目标并支持他们实现目标的模型，我们就有可能扩大蛋糕，而不仅仅是替代某些工作。

从长远来看，我坚信我们更可能通过协作来解决根本性的人类问题。构建善于与大群体协作、理解不同人的目标、抱负和价值观、了解人们的弱点，并协调这些大型群体以提高每个人效率的模型，这才是关键。

与那种独自运行 20 小时，最后回来声称找到了生命、宇宙和一切答案的 AI 愿景相比，我认为后者不太可能实现。当然，最终我们拭目以待。

### (8:14 - 15:23) Current State of AI Models

Eric Zelikman：在目前的模型中，从数字算术的角度来看，它们显然可以进行运算。从智商层面来说，如果你能很好地定义问题，比如一些高级的物理或数学问题，我认为它们相当聪明。

主持人：给我一个人类对比的参考。什么算是"相当聪明"？

Eric Zelikman：我认为很难直接比较，因为智能是不均匀的。比如，这些模型能解决的一些高难度考试（HLE）问题，对于实际的博士研究者来说确实是非常不平凡的。我并不是说这些是未解决的问题，但它们确实相当复杂。

我研究这些高难度考试问题时，发现了一个有趣的类别。这些问题往往是陷阱题，需要你质疑原有的假设。如果你了解这类问题，会发现看似理所当然的假设其实并不成立。所以我认为，这些模型确实很聪明，但也容易被这些狡猾的问题绊倒。

更重要的是，它们缺乏情感智能。它们不擅长理解人们真正关心什么，也不知道如何帮助人们实现他们的目标。对于不是研究者的人来说，我建议在使用这些模型时，提供尽可能多的上下文信息。模型对额外信息非常敏感，给出的答案会因此而改变。

目前的模型特别擅长处理可以用封闭形式轻松回答的问题，比如有简单数值答案或从一组选项中选择的问题。如果你能想象出一种方法来验证答案，这对模型来说会更容易。

在可验证的领域（如编程）中，模型在复杂任务上仍然存在挑战。这部分原因在于问题与模型训练数据的分布差异。如果问题与模型之前见过的问题相似，它就会表现得很出色；如果问题非常不同，效果就会大打折扣。

从扩展智商的角度来看，我认为还有很多未被充分探索的维度。关键是在扩展模型能力的同时，要有意识地保持人类参与。设计新算法时，要考虑如何将人保持在循环中，而不是试图将人完全排除。

许多实验室的本能是尽可能地将人从循环中移除，因为引入人类会使过程变得复杂。但我认为，如果我们设计能真正理解人们目标并支持他们实现目标的模型，我们就有可能扩大蛋糕，而不仅仅是替代某些工作。

从长远来看，我坚信我们更可能通过协作来解决根本性的人类问题。构建善于与大群体协作、理解不同人的目标、抱负和价值观、了解人们的弱点，并协调这些大型群体以提高每个人效率的模型，这才是关键。

与那种独自运行20小时，最后回来声称找到了生命、宇宙和一切答案的AI愿景相比，我认为后者不太可能实现。当然，最终我们拭目以待。

### (15:23 - 22:08) Human-Centric AI and Future Directions

Eric Zelikman：关于模型扩展的新维度，很自然地会意识到有些方式会将人纳入其中，而有些方式则更倾向于将人排除在外。在设计新算法时，要非常谨慎地思考如何提高模型的智能（IQ），同时有意识地保持人的参与，这是一个主动的选择。

许多实验室的本能是尽可能地将人从循环中移除，因为从扩展的角度来看，引入人类会使过程变得复杂。比如，招募人们来处理尚未分布的复杂推理任务，对于一个组织来说并不像简单的迭代那么容易执行。那么从能力的角度来看，这有什么重要性呢？

从某种程度上说，随着模型自动化范围的扩大，我们看到了一些有趣的趋势。最近的一些结果，比如IMO（国际数学奥林匹克）的成果，展示了模型可以在没有人类干预的情况下进行长达数小时的推理。这已经成为许多实验室衡量成功的一个指标。例如，有一个叫METR的基准测试，大家都喜欢分享模型从可以自主完成两小时任务到2.5小时任务的进展。当然，这些数字的具体含义值得商榷，但这确实已成为衡量进步的指标。

然而，随着我们越来越多地将人从交互中移除，结果是人们对所构建的事物的影响力越来越小。想象一个模型独自工作8小时，最后回来呈现一些成果的场景，人们可能会感到对自己正在构建的东西缺乏真正的代理权。我认为人们已经开始感到对所构建的事物缺乏理解。比如，现在已经有20,000行生成的代码看起来不错，开发者提交的PR可能达到10万行，这种趋势似乎还会持续。

那么，将人类纳入输出或推理过程是否重要？是因为有人在环路中可以提高上限、提高效率、在模型偏离轨道时进行纠错，还是出于哲学层面人们希望保持参与，或者是这些原因的组合？

我认为这是多方面的。当我们自动化现有任务时，最自然的做法是查看世界GDP，找出最容易被模型替代的部分。比如看到编程是一个数十亿美元的市场，就想要完全自动化。但我认为，如果我们赋能人类，构建真正理解人们意图并支持他们实现目标的模型，我们就有可能扩大蛋糕，而不仅仅是替代现有市场。

如果这些模型的目的仅仅是替代某个工作领域的人，我们可能会失去真正的创新。相反，如果我们有能真正理解人们目标并赋能他们的模型，我们将进入一个截然不同的境地，能够将这些能力推向分布之外的领域。

当我说我希望开发能赋能而非替代人类的模型时，人们往往会敷衍地附和。有人会说不如去攻克癌症这样的重大问题，这确实是非常重要的目标。构建能解决人类最困难和最根本问题的模型极其重要。但我个人坚信，通过协作，通过构建善于与大群体合作、理解不同人的目标、抱负、价值观和弱点，并协调这些大群体以提高每个人效率的模型，我们更有可能解决这些根本性的人类问题。

我认为那种独自运行20小时、最后声称找到生命、宇宙和一切答案的AI愿景不太可能实现。当然，最终还是要拭目以待。

### (35:33 - 36:58) Recruitment Goals for humans&

Eric Zelikman：我正在寻找能够构建产品的顶尖研究人员。我在寻找能够构建产品的优秀研究者。我在寻找能够构建产品的出色产品经理。我在寻找那些深入思考用户、在研究方面思考过内存的人。在基础设施方面，我在寻找那些深入思考分布式系统、超快推理，并有过大规模项目扩展经验的人。在产品方面，我希望找到那些在交互模式上极具创造力，真正在乎打造精美、品味出众产品的人。

主持人： 太棒了。非常感谢，Eric。

Eric Zelikman： 非常感谢。

主持人： 恭喜你创办了新公司。

Eric Zelikman： 非常感谢。[音乐]

主持人： 在推特上关注 No Prior Pod。如果想看我们的脸，请订阅我们的 YouTube 频道。在 Apple Podcasts、Spotify 或任何你常听播客的平台上追踪我们的节目。这样你就能每周获得新的节目。并在 no-briers.com 网站上订阅邮件或获取每集的文字稿。