# Stanford CME295 Transformers & LLMs | Autumn 2025 | Lecture 1 - Transformer

## 📹 视频信息

- **频道**: Stanford Online
- **发布日期**: 2025-10-17
- **时长**: 1:41:56
- **原始链接**: [https://www.youtube.com/watch?v=Ub3GoFaUcds](https://www.youtube.com/watch?v=Ub3GoFaUcds)

---

I'll analyze this Stanford lecture on Transformers and LLMs and provide a structured summary.

> 本文内容整理自斯坦福大学 CME 295 课程《Transformers & LLMs》的第一讲，由双胞胎兄弟 Afin 和 Shervin 共同授课，两位讲师均有 MIT/Stanford 学术背景和 Uber/Google/Netflix 的工业界 LLM 开发经验。

---

## TL;DR（一句话核心洞察）

> 本讲从 NLP 基础概念出发，系统讲解了从传统 RNN 到革命性 Transformer 架构的演进历程，深度剖析了自注意力机制如何解决长距离依赖问题，并通过完整的编码器-解码器架构实例展示了现代大语言模型的技术基石。

---

## 📑 章节导航表

| 时间戳 | 章节标题 | 一句话概括 |
|--------|----------|-----------|
| 00:00-10:42 | 课程介绍与背景 | 双胞胎讲师介绍课程目标、先修要求和评分方式 |
| 10:42-22:35 | NLP任务分类与评估 | 系统梳理分类、多分类、生成三大NLP任务类型及其评估指标 |
| 22:35-30:21 | 文本预处理：分词技术 | 从词级、子词到字符级分词方法的优缺点对比分析 |
| 30:21-46:02 | 词嵌入：从独热编码到Word2Vec | 讲解如何将文本转换为模型可理解的数值表示 |
| 46:02-59:29 | 循环神经网络（RNN）架构 | 介绍RNN如何处理序列数据及其长距离依赖问题 |
| 59:29-1:07:08 | 注意力机制的诞生 | 解释注意力机制如何解决RNN的梯度消失问题 |
| 1:07:08-1:27:49 | Transformer架构详解 | 深入讲解编码器-解码器架构和自注意力机制 |
| 1:27:49-1:41:56 | 完整实例演示 | 通过机器翻译任务演示Transformer的完整工作流程 |

---

## 📊 核心论点

#### NLP任务三大分类：从简单分类到复杂生成

- **核心内容**：NLP任务可分为三大类：分类（输入文本→标签，如情感分析）、多分类（输入文本→多个标签，如命名实体识别）、生成（文本→文本，如机器翻译）。生成任务是目前最热门的研究方向，也是ChatGPT等大模型的核心应用场景。评估方法从传统的准确率、F1分数，到BLEU、ROUGE等序列匹配指标，再到现代的无参考评估方法。
- **关键概念**：情感分析、命名实体识别、机器翻译、BLEU评分、ROUGE评分、困惑度
- **实际意义**：为后续理解Transformer在各类NLP任务中的应用奠定基础，明确了当前大模型主要解决的问题类型和评估标准的演进方向。

#### 分词技术权衡：效率与表达能力的博弈

- **核心内容**：分词是NLP的基础步骤，存在词级、子词、字符级三种主要方法。词级分词简单但面临OOV（词汇表外）问题和词形变化挑战；子词分词（如BPE）平衡了词根利用和序列长度；字符级分词虽然彻底解决OOV问题，但序列过长导致计算复杂度剧增。现代大模型普遍采用子词分词策略。
- **关键概念**：OOV问题、BPE算法、词汇表大小、序列长度、计算复杂度
- **实际意义**：分词策略直接影响模型的训练效率和性能，是决定大模型规模化部署成本的关键因素之一。

#### 词嵌入革命：从静态表示到上下文感知

- **核心内容**：独热编码虽简单但所有词向量正交，无法表达语义相似性。Word2Vec通过预测任务学习词嵌入，首次实现了"king-queen = man-woman"这样的语义运算。然而Word2Vec为每个词分配固定表示，无法处理一词多义问题（如"bank"的不同含义）。这为后续上下文感知表示方法奠定了基础。
- **关键概念**：独热编码、余弦相似度、Word2Vec、CBOW、Skip-gram、代理任务
- **实际意义**：确立了现代NLP中"词语意义由上下文决定"的核心理念，为Transformer的自注意力机制提供了理论基础。

#### RNN架构局限：序列处理的先驱与困境

- **核心内容**：RNN通过隐状态机制首次实现了对序列顺序的建模，能够处理变长输入序列。然而RNN面临两大致命问题：梯度消失/爆炸导致长距离依赖学习困难，以及串行计算特性使得训练效率低下。LSTM通过门控机制部分缓解了长距离依赖问题，但仍无法根本解决并行化问题。
- **关键概念**：隐状态、梯度消失、长距离依赖、LSTM、串行计算、反向传播
- **实际意义**：RNN的局限性直接推动了注意力机制的发明，是理解Transformer革命性意义的重要背景。

#### 注意力机制突破：直接连接的魅力

- **核心内容**：注意力机制的核心思想是在预测时直接关注输入序列中的相关部分，而非依赖串行传递的隐状态。通过Query-Key-Value三元组机制，模型可以动态计算输入不同部分的重要性权重，从而实现直接的长距离依赖建模。这种"直接连接"思想彻底改变了序列建模范式。
- **关键概念**：Query-Key-Value、权重计算、动态注意力、直接连接、长距离依赖
- **实际意义**：注意力机制是Transformer成功的核心，也是现代大模型能够处理超长文本的技术基础。

#### Transformer架构革新：编码器-解码器的完美结合

- **核心内容**：Transformer通过编码器-解码器架构实现了完全并行化的序列处理。编码器使用自注意力机制将输入序列中的每个token表示为其他所有token的加权和，解码器则通过掩码自注意力和交叉注意力实现条件生成。多头注意力机制允许模型学习不同类型的语义关系，位置编码解决了注意力机制天然缺乏位置信息的问题。
- **关键概念**：编码器-解码器、自注意力、交叉注意力、多头机制、位置编码、并行化
- **实际意义**：Transformer架构成为了GPT、BERT等所有主流大模型的基础，其可并行化特性使得大规模预训练成为可能。

#### 自注意力数学本质：矩阵运算的优雅

- **核心内容**：自注意力的数学表达式 Attention(Q,K,V) = softmax(QK^T/√d_k)V 看似简单，实则蕴含深刻的计算智慧。Q、K、V矩阵通过可学习的投影矩阵从输入嵌入中生成，softmax确保注意力权重归一化，√d_k缩放防止梯度消失。整个计算过程高度适配GPU的矩阵运算能力，这种硬件友好性是Transformer能够规模化的重要原因。
- **关键概念**：Softmax归一化、投影矩阵、梯度缩放、矩阵并行计算、硬件适配
- **实际意义**：自注意力机制的数学设计不仅解决了语言建模问题，更为大规模并行训练提供了理论基础，是AI硬件革命的重要推动力。

#### 多头注意力机制：表征学习的多样性

- **核心内容**：多头注意力通过并行运行多个注意力头，每个头学习不同的投影矩阵（WQ、WK、WV），从而捕获输入序列的不同语义关系。类似于CNN中的多个卷积核，多头机制允许模型同时关注语法关系、语义关系、共指关系等多种语言现象。最终通过连接和投影操作将多头结果融合为统一表示。
- **关键概念**：并行学习、投影多样性、语义关系捕获、表征融合、注意力头专门化
- **实际意义**：多头机制显著提升了Transformer的表达能力，使单个模型能够处理语言的多层次复杂性，为大模型的多任务能力奠定基础。

#### 标签平滑技术：应对生成任务的不确定性

- **核心内容**：在自然语言生成任务中，给定上下文往往存在多个合理的续写选择（如"今天天气真好"可以续写"适合出门"、"心情愉悦"等）。标签平滑通过将硬目标（1,0,0）软化为（1-ε, ε/(V-1), ε/(V-1)），明确告知模型预测存在不确定性，避免过度自信的预测，在实践中显著提升BLEU等评估指标。
- **关键概念**：生成不确定性、软目标、过度自信、标签软化、评估指标提升
- **实际意义**：标签平滑反映了语言生成的本质特性，对现代大模型的训练稳定性和生成质量具有重要影响。

#### 位置编码设计：序列信息的巧妙注入

- **核心内容**：Transformer的自注意力机制天然缺乏位置信息，因为它将所有token视为集合而非序列。位置编码通过正弦和余弦函数为不同位置生成独特的编码模式，这些编码与词嵌入相加而非拼接，保持了模型的维度不变性。这种设计使模型既能利用位置信息，又保持了计算效率。
- **关键概念**：位置不变性问题、正弦余弦编码、维度保持、加法融合、计算效率
- **实际意义**：位置编码的设计平衡了表征能力和计算效率，为处理超长文本序列奠定了技术基础。

---

## 🏢 提及的公司/产品

| 公司名 | 讨论语境 | 重要性 |
|--------|----------|--------|
| MIT / Stanford | 讲师学术背景，课程设置机构 | ⭐⭐ |
| Uber | 讲师工业界经验，早期LLM应用 | ⭐ |
| Google | 讲师工业界经验，AI技术巨头 | ⭐⭐ |
| Netflix | 讲师当前工作单位，LLM应用前沿 | ⭐⭐ |
| OpenAI (ChatGPT) | LLM革命的标志性产品，2022年突破 | ⭐⭐⭐ |
| Google (Gemini) | ChatGPT的主要竞争对手 | ⭐⭐ |

---

## 💬 经典金句（3-5 句）

> "注意力机制就是要在你想预测的内容和过去的信息之间建立直接连接。"
> — Afin

> "Transformer的作者们想要摆脱这种序列化的文本处理方式，让模型能够直接连接到文本的所有部分。"
> — Afin

> "GPUs喜欢矩阵运算，而这正是自注意力机制的优势。"
> — Afin

> "梯度下降就是这么神奇，模型会自然地学会不同的表征方式。"
> — Shervin

---

## 👤 主要人物

#### Afin（讲师）

**身份**：Stanford CME 295课程主讲教师，Netflix机器学习工程师
**背景**：法国Centrale Supélec工程师学位，MIT硕士，曾就职于Uber和Google，专注于NLP和大语言模型开发。与双胞胎兄弟Shervin共同开设本课程已有多年。
**核心观点**：强调从基础概念系统性理解Transformer架构，注重理论与实践的结合，主张通过代理任务理解表征学习的本质。

#### Shervin（讲师）

**身份**：Stanford CME 295课程协同教师，Netflix机器学习工程师
**背景**：法国Centrale Supélec工程师学位，Stanford ICME硕士，与兄弟Afin有相似的职业发展路径（Uber→Google→Netflix），在大语言模型领域有丰富的工业界经验。
**核心观点**：擅长通过具体实例解释抽象概念，注重数学公式背后的直观理解，强调实际工程中的权衡考量。

---

## 📺 视频类型判断

**教程示范**：学术课程讲授，系统性技术教学，包含理论讲解和实例演示

---

## 📝 完整翻译

### (0:00 - 10:42) 课程介绍与背景
> 双胞胎讲师介绍课程目标、先修要求和评分方式

大家好，欢迎来到 CME 295 课程：Transformers 和大语言模型。我的名字是 Afin，我将和 Shervin 一起教授这门课，Shervin 现在在后面。在开始之前，我先介绍一下我们自己。

我们是双胞胎兄弟，有着相似的背景。我们都曾在法国的一所名为 Salbar 的学校就读，然后各自走向不同的道路。我去了 MIT，Shervin 去了斯坦福大学攻读 ICME 硕士学位。之后我们的行业背景也非常相似。我先去了 Uber，然后 Shervin 也来到了 Uber，接着 Shervin 离开去了谷歌，我也去了谷歌，最近我加入了 Netflix，Shervin 也加入了 Netflix，我们一直在研究大语言模型。我们都有技术背景，主要专注于 LLM。

为什么我们要开设这门课？自 2020 年以来，Shervin 和我一直专注于 NLP 领域，我们每年都会以研讨会的形式开设这门课。2021、2022、2023、2024 年都有。ChatGPT 在 2022 年问世后，突然间人们对 LLM 产生了浓厚兴趣。实际上是在去年春天，我们开始将这门课作为斯坦福的正式课程 CME 295，这是第二次开课。

那么你们可以从这门课中期待什么？首先，AI 现在基本上无处不在，我们的目标有两个方面。第一是学习让这一切运作的底层机制，我们将学习 Transformer，这是让这一切成为可能的基础架构。第二是了解这些 LLM 是如何训练的，以及它们被应用在哪些领域。

如果你们还在犹豫这门课是否适合你，我想说这门课非常适合对这个领域有兴趣的人，无论是因为你想把它作为职业目标，想成为研究科学家或机器学习科学家，还是想开发依赖 LLM 的个人项目，了解什么有效什么无效的注意事项，或者即使你在其他领域，只是想了解整个 AI、生成式 AI、LLM 是如何运作的，以及如何将其应用到你的领域。

在先修要求方面，我认为最基本的是你应该有一些机器学习基础，比如知道模型是如何训练的，什么是神经网络，以及一些线性代数基础，比如矩阵如何相乘。但即使你在这些领域的能力还在发展中也没关系，我们会在这里帮助你。这些是理想的先修要求。

关于课程安排。这门课每周五下午 3:30 到 5:20 在这里举行。

这门课是两个学分，你可以选择按字母等级或通过/不通过来计分。

正如你从现场设置可以看到的，我们正在录制这门课。如果你因为某种原因无法参加这个时间段，我们会确保在每周五晚上或周六提供录像。

关于成绩，本季度我们安排了两次考试。一次是期中考试，将在第五次课时举行，也就是 10 月 24 日。第二次是期末考试，将在 12 月 8 日那周举行，具体日期待定。

每次课后我们都会在网站上发布幻灯片和录像。如果你感兴趣的话，我们网站上也有教学大纲，你可以了解我们将要讨论的主题。

课程教材是这本《Transformer LLM 超级学习指南》，我们这里有一本，如果你想看看的话。这门课中的很多概念实际上都在这本书里，所以它是一个很有帮助的学习工具。

我们还制作了整门课程的精简版本，叫做《VIP 备忘单》，可以在 GitHub 上获取。我们还将它翻译成了多种语言。顺便说一下，如果你的语言不在其中，请告诉我们，我们很乐意一起制作。

关于通知公告，我们会在 Canvas 上发布信息。如果你有任何问题，当然可以联系我们，Canvas 上也有一个叫 ED 的标签，我相信你们很熟悉。只需点击它，发布你的问题，Shervin 和我会回复。要联系我们，你可以使用这个邮件列表，或者直接联系我们，因为我们就两个人。

关于课程安排，有什么问题吗？我忘记提到的一件事是，鉴于我们在录制这门课，如果你提问，观众可能不太清楚你的问题是什么。所以我会努力重复你的问题，这听起来可能很奇怪，但我会尽量不忘记。

到目前为止，关于课程安排有任何问题吗？

学生： [关于考试是否有编程部分的问题]

Afin： 问题是考试中是否有编程部分。答案是没有。考试将纯粹关注我们在课堂上学到的概念，实际上不是为了难倒你们。如果你跟上课程，看幻灯片，理解我们讨论的概念就应该没问题。

学生： [关于候补名单的问题]

Afin： 问题是如果你在候补名单上该怎么办？根据经验，很多人会最终确定他们的课程安排，有些人会退课。如果你仍在候补名单上，来和我们谈谈，但我很有信心应该没问题，因为现在候补名单只有大约六个人。

学生： [关于幻灯片在哪里的问题]

Afin： 幻灯片会在网站上，我们也会确保在 Canvas 上发布链接。

学生： [关于考试权重的问题]

Afin： 关于考试权重的问题。没有作业，50% 是期中考试，50% 是期末考试。如果这个时间段与其他事情冲突，记住我们在录制，所以如果你不能参加某次课程也没关系。

学生： [关于期末考试是否只涵盖后半部分内容的问题]

Afin： 问题是期末考试是否只涵盖课程的后半部分。我们还没有写考试，但我认为这是我们正在考虑的。期末考试可能会涵盖后半部分的主题。

简而言之，50% 期中考试，50% 期末考试，这是一门有趣的课程。

好，现在我要慢慢开始正式上课。另一件我想提到的事是，每当我们谈论某些内容时，你会看到幻灯片底部有资料来源。这主要是为了引用我们所引用的内容，同时也为了让你在感兴趣的情况下能更深入地研究这些材料。当然，我们每周只有两个小时，只有九到十周的时间，远远不够涵盖所有内容。

第二个免责声明是，你会发现这个领域充满了缩写。我刚开始时完全被它们吓到了。但希望在课程结束时，你们能建立起这些缩写的心理映射，知道它们对应什么。如果你们在课程结束时有了这种心理映射，那我们就知道我们做得很好。

现在让我们开始，我想从非常高的层次开始，因为我假设我们从零开始，我们将谈论一般的 NLP。NLP 将是我们的第一个缩写。NLP 代表自然语言处理 (natural language processing)，它是一个围绕操作文本、用文本进行计算的领域。

在非常高的层次上，我们基本上可以将 NLP 任务分为三个类别。第一个类别是我们称之为分类的。

我们有输入文本作为输入，然后我们想要预测某些东西。一个例子是你有一个电影评论，你想要预测情感是积极的、消极的还是中性的。这是一个例子。你也可以进行意图检测，知道例如这个人想要做什么。假设你说"我想为明天设置一个闹钟"，这里的意图是设置闹钟。

还有检测语言。例如，如果你用法语写作，你想检测该文本是法语。还有主题建模。

### (10:42 - 22:35) NLP任务分类与评估
> 系统梳理分类、多分类、生成三大NLP任务类型及其评估指标

第二个类别是我们称之为多分类的。

我们仍然有文本作为输入，但这次我们预测不止一样东西。这个类别中也有很多任务。一个非常流行的任务叫做命名实体识别 (named entity recognition)，简称 NER。

这个任务的作用是，给定输入文本，我们想要基本上标记一些特定的词，比如识别某些东西是位置还是时间等等。

然后你还有一些其他任务，更偏语言学方面。我认为现在它们不太流行了，但十年前人们会大量研究它们。比如词性标注，就是弄清楚哪个词是名词、动词等，或者一些解析相关的任务，如依存解析或成分句法分析。

最后一个类别是现在非常流行的生成类别。

你有文本作为输入，也有文本作为输出，这里长度可以是可变的，意味着你事先不知道输出文本的长度会是多少。这里你有几个任务。例如你有机器翻译，将英语翻译成德语。

问答系统。通常你知道你使用的 ChatGPT、Gemini 这些助手，你问一个问题，得到一个回答。

然后你还有其他任务，比如摘要，你想要总结一篇文章，或者生成某些内容。可以生成代码，生成诗歌，可以是很多东西。

现在我们要逐一浏览这些任务来说明人们通常如何处理它们。我们先从第一个类别开始，也就是分类类别。这里我们将用情感提取任务来说明。假设我们有一个句子："这个泰迪熊太可爱了。"我们希望我们的模型预测这是积极情感。

通常你会使用情感提取数据集。我提到了电影评论，比如 IMDb 影评，但你也有产品评论，如亚马逊评论，或者推文，现在叫 X，所以是 X 帖子。

你评估这种输出的方式通常是使用传统的分类指标。你有准确率，也就是你正确预测的观察结果的百分比。

但你还有两个关键指标，我要提醒一下，我不确定是否每个人都知道它们。一个是精确率，即在你做出的所有积极预测中，哪些是正确的。

第二个是召回率。

### (15:00 - 30:00) Part 2

在所有真实标签中，你正确预测为正例的有多少？还有一个叫做 F1 分数的指标，它基本上是精确率和召回率的调和平均值，给你一个综合数字。

你可能会想，为什么需要所有这些指标？简单来说，有时候你的任务和数据集中类别非常不平衡。比如你的数据集中可能有 99% 是正标签，只有 1% 是负标签。在这种情况下，如果你使用准确率这样的指标就会很误导，因为如果你有一个模型预测所有东西都是多数类，那么你会有一个很棒的分类器，但实际上并非如此。这就是为什么精确率和召回率真的发挥了作用。

这是第一类。现在让我们转到第二类 NLP 任务。这一类是多分类范畴。你有一个输入文本，然后预测多个事物，我们用命名实体识别任务来说明这一点，正如我提到的，它是关于识别给定词语的类别。

在这里，比如我们想要识别 teddy bear 作为一个实体。我想对于这个，你会使用分类指标，但不是在句子层面，而是在词元层面或实体类型层面。我的意思是，假设你有一个类别，比如说位置，你想知道你在该类别中预测词语的表现如何。所以你通常会根据这个来聚合这些指标。

好的。让我们转到最后一类，正如我提到的，这是最受欢迎的一类。这一类是文本输入文本输出。我用机器翻译任务来说明这一点，它是关于将文本从源语言翻译到目标语言。这里你有英语到法语的例子。"可爱的泰迪熊正在阅读。" 

对于这个，我想获取数据集更困难，因为这里你需要有成对的文本。所以你有一个非常受欢迎的数据集叫做 WMT，代表机器翻译研讨会。

它包含了不同语言的一堆配对序列。比如你有来自欧洲议会数据集的英语-法语、英语-德语对。评估模型的性能实际上要复杂得多，因为正如你能想象的，你可以有很多不同的方式来翻译某个东西。我相信我们房间里的许多人都是双语、三语使用者。所以，这就是使它如此困难的原因。

在过去，人们使用了几种基于规则的指标来做这件事。你可能听说过的一个是 BLEU。BLEU 代表双语评估研究，它是衡量你的翻译相对于参考文本表现如何的指标。

ROUGE 也是同样的情况，它实际上是一套指标，但以不同的方式捕捉这一点。你会看到机器学习社区很有趣，因为 blue 我不确定你是否知道法语中意思是蓝色，但 rouge 意思是红色。我想他们试图在其中增加一些乐趣。但这些指标的问题是你总是需要一个参考文本。所以你基本上需要标签。

在实践中，获得标签是非常昂贵的。获得标签需要大量的时间和金钱，我们稍后在课程中会看到，随着我们在大语言模型空间取得的进展，或者说社区在大语言模型空间取得的进展，我们实际上可以抛弃这些基于参考的指标，转向更无参考的指标，我们稍后会看到这一点。

最后一个我要说人们有时使用的指标叫做困惑度。困惑度只关注模型输出的概率。它基本上量化了模型对其输出的惊讶程度。所以 BLEU 和 ROUGE 是越高越好。困惑度是越低越好。

我想 LLM 自 2022 年以来一直是一个热门话题，但实际上这个领域的历史要追溯到那一年之前很久。在 80 年代，我们稍后会看到，有一类模型实际上在 80 年代就被考虑过了，90 年代我们有了 LSTM，我们稍后也会看到。

但那时的问题是我们没有互联网，我们没有大量的计算资源，我想这是阻止这些模型被训练的限制因素之一，然后更近期我们有了几个进展，所以 Word2Vec 真的是在计算有意义的嵌入设置方面的开创性工作之一，我们稍后会看到。然后当然我们有了 Transformer，它是 2017 年发表的一篇论文的一部分，它基本上是你今天看到的模型的基础。

然后这些模型通过计算以及用于训练它们的数据进行了扩展。这就是 LLM 被命名的方式。我想这些更像是 2020 年代的事情。

### (22:35 - 30:21) 文本预处理：分词技术
> 从词级、子词到字符级分词方法的优缺点对比分析

好的。关于高层次的内容有什么问题吗？大家都好吗？

好的。我想我想问自己的第一个问题是，我们想要做的是有一个处理文本的模型。但模型理解数字。它们不真正理解文本。所以我们需要以某种方式对那个文本做一些事情来使它更可量化，模型能够理解的东西。

如果你看一个句子，比如"一只可爱的泰迪熊正在阅读"，你首先需要问自己如何切割这个句子来传递给模型。

这部分叫做分词，它包含的基本上是根据文本的一些任意单位来切割文本。有几种方法来做这件事。我想第一种方法是完全任意地做。所以这里比如你会有"a"作为一个文本单位，"cute"会是另一个文本单位，"bear"会是另一个，等等。顺便说一下，文本单位叫做 token，这就是为什么这个方法被称为分词。

另一种方法是简单地按词分割。但我想我们总是有利弊。我想我们想要实现的目标之一是让我们能够以有意义的方式表示这些 token。

在词级别这样做的一个缺点是你最终会有看起来相似但实际上被认为是不同 token 的词。我想这里的限制是你需要为这些相似但不同的 token 计算嵌入，并以某种方式使它们的嵌入相似。我给你一个例子。假设我有词"bear"，然后你有另一个词复数形式"bears"。

这两个词非常相似，只是一个是单数，另一个是复数。如果我们采用词级分词，那么我们最终会得到两个不同的实体，它们基本上被认为是不同的。"run"和"runs"也是一样，动词的变化。

出于这个原因，人们深入研究了一类叫做子词分词器的分词器，它是关于利用词的词根来找到我们可以在这些词中找到的共同词根。比如，对于"bear"和"bears"，你会有"bear"部分被共享。

我想优点是你可以利用词的词根。但这里的缺点是你的序列会更长。我们稍后会看到为什么这是一个缺点。我想我可以给你一个预览。这些模型的复杂性也是序列长度的函数。

你处理的 token 越多，你的模型运行所需的时间就越多，因为它需要基本上处理所有这些 token。这是一个缺点。优点是它利用词根。缺点是它只是使你的序列更长。

你有最后一类分词方法，就是在字符级别，就像取所有字符一样。这里我想当我们写东西时，有时会有拼写错误，用子词分词方式，你可能无法识别拼写错误的词，这是字符级分词器可以考虑的。但这里的问题是你有一个更长的序列长度，这会使你的模型处理这个序列需要更多时间。这是一个缺点。另一个缺点是当你想表示每个 token 时，很难知道字母的表示真正意味着什么。像字母 U 的表示意味着什么？非常困难。

### (30:00 - 45:00) Part 3

听起来不错吗？我想这确实是处理文本的基础。但是，总体上说得通吗？

好的。现在，我们所做的是获取了输入文本。我们所做的是将其切割成基本上是 token 的部分。

为了让我们的模型理解这些 token，我们需要为每个 token 找到一个表示。所以这里我们要来看看这个。这被称为词表示，或者更准确地说，应该是 token 表示。我们想要找到一种表示每个 token 的方法。

### (30:21 - 46:02) 词嵌入：从独热编码到Word2Vec
> 讲解如何将文本转换为模型可理解的数值表示

最简单和朴素的方法就是为每个词或每个 token 分配一个独热向量。比如假设我们有一个包含三个 token 的词汇表：book、soft 和 teddy bears。我们会有，比如说 soft 是一个 1 0 0 向量，teddy bear 是比如说一个 0 1 0 向量，book 是比如说一个 0 0 1 向量。

这被称为独热编码，我们通常会看到这种方法。这是表示我们 token 的一种方式，但基本上人们想要做的是比较这些 token，以便看出哪些与其他哪些更相似。

人们使用的一个常见相似性度量叫做余弦相似性。不确定你们是否听说过。你可以把它想象成在 n 维空间中看这些向量形成的角度。如果它们指向相同的方向，那么它们可能是相似的；如果它们是正交的，那么它们可能是独立的；如果它们完全相反，那么它们可能是相对的。这基本上就是我们想要进入的思维模型。

问题是，如果你用独热方式表示你的 token，你最终会得到所有向量彼此正交的结果。这就是问题所在。

理想情况下，我们希望意思相同或相似的 token 基本上具有高相似性，而不相似的 token，比如关于不同事物的，要更加疏远。

这里我只是为了说明目的，teddy bears 是 soft 的。所以你希望 teddy bear 和 soft 具有高相似性，而比如说 teddy bear 和 book，它们是相对独立的，你希望它们更接近零。

这就是你想要的。这就是独热编码的情况，这就是你想要的。

抱歉。哦，我明白了。这个问题是为什么你关心范数？嗯，所以我想余弦相似性实际上是由范数归一化的。所以它是点积。哦，你的意思是为什么我这里只写点积而不是...

哦，我明白了。你的问题是为什么我们不关心范数？嗯，好的。我想观众知道这个问题。我想这些度量它们都是尝试捕获这些相似性的方法。所以我想为什么你不关心范数？

我想这就是人们如何尝试量化这一点的。我想你需要看看你的向量是如何训练的，以及范数是否会指示某些东西。

我想我能给你的最好答案是，我想这是一个度量。这不是完美的度量。人们可能也会使用乘积作为度量，但是我没有很好的答案给你。

好的。但只要你捕获，我想这些向量是如何指向的。我想通常你关心的是它们之间的角度。但是，通常你不会真正考虑范数。

好的。有什么问题吗？还有其他问题吗？

这是一个很好的问题。问题是关于词汇表的大小以及这如何影响关于词、子词的选择，以及这在不同语言中是如何变化的。这是一个很好的问题。

我想说这首先真的取决于你试图完成的任务。如果你的任务只涉及一种语言，你就只使用那种语言。由于我们这里提到的原因，你通常会选择子词分词器。所以我想子词是一个很好的权衡，能够通过词根识别词汇，同时也减少遇到 OOV（词汇外）风险。

就大小而言，我知道人们尝试了不同的东西。我认为通常对于英语，你会目标定在数万个词汇量的数量级，但现在的模型是多语言的，它们也涉及代码，所以你会看到词汇量现在有时达到数十万的数量级。

对于中文，你有使用字符的差异，所以对于拉丁文，这是我们都习惯的字母表，但当然对于其他语言，你有类似的东西，但是用目标语言字符。所以我想说，一种语言的数量级是数万，如果是多语言的话是数十万，这些是你要瞄准的数量级。

很好的问题。问题是如何获得那些嵌入？这实际上就是下一张幻灯片。我们将谈论这个。

好的。现在我们知道独热编码不是表示 token 的好方法，我们想要做的是从数据中学习这些嵌入。

我提到了 2010 年代出现的一篇论文。我想是 2013 年，叫做 Word2vec。它如此受欢迎的原因是因为他们展示了一种非常直观和可解释的方式来看这些嵌入。因为他们说的是，比如国王之于女王就像这个之于那个，巴黎之于法国就像柏林之于德国。所以基本上有一种方法来理解嵌入。现在问题是他们是如何做到的？

他们有两种计算这些嵌入的方法。一种方法叫做连续词袋。另一种叫做跳字模型。但它们都依赖于相同的想法，就是让我们利用我们拥有的文本，然后尝试基于上下文预测文本的某一部分。

例如，连续词袋。目标是你考虑给定目标词周围的词，你的目标是预测那个目标词。

跳字模型有点相反。你从一个目标词开始，你想预测它周围的词。我想这个任务通常被称为代理任务。因为归根结底，在这个练习中，我们关心的不一定是预测下一个词，至少现在还不是。我们的目标是学习这些词的有意义的表示。

这里的想法是，如果你有一个模型以某种方式知道如何预测下一个词，那么意味着你的模型对语言如何工作有一些理解，这基本上就是你想要的。你基本上想要一个反映语言的嵌入，比如国王和女王，或者巴黎和法国，比如这是首都，你想要在表示中嵌入这些关联。

让我们通过一个非常简单的例子来看看这是什么样子。在我们的例子中，假设我们的代理任务是关于预测下一个词。

这里我们采用的是一个非常普通的神经网络模型，它基本上接收一个大小为 V 的向量，有一些乘法和偏置项来得到隐藏状态，然后另一组乘法来得到我们的最终向量。

所以这里基本上是一个非常简单的神经网络。输入大小是 V。隐藏层大小是 D，通常比词汇表小得多。词汇表通常是数万或数十万。所以 D 通常是几百，比如 768 就是一个维度的例子。

所以它要小得多。我们试图做的是通过这个代理任务学习词表示。我们要做的是尝试考虑一个词作为输入并预测下一个词。

### (45:00 - 1:00:00) Part 4

我们要做的就是预测下一个 token。这里是 teddy bear。

所以你现在看到你的模型在这个例子中预测下一个词是近似均匀分布的，但你想要最大化 teddy bear 的概率。所以你对所有词重复这个过程。最终，你得到了一个学会如何预测下一个词的模型，这基本上就是代理任务。你要做的是提取模型学到的表示，也就是这些绿色的单元。

现在发生的情况是，每当你有一个词时，你就将其表示为 one-hot 编码表示，然后将其与这些权重相乘，然后得到绿色表示，这就是你的词表示。这说得通吗？

### (46:02 - 59:29) 循环神经网络（RNN）架构
> 介绍RNN如何处理序列数据及其长距离依赖问题

是的，好问题。问题是 V 对应什么以及为什么只有六个。所以是的，在这个例子中，我们只有六个可能的词，这基本上就是词汇表大小，这只是一个非常简单的玩具例子，因为在实践中会有更多。我想这是语言的挑战之一。技术上你可以有许多词的变体，这就是为什么如果你采用词级别的方法将文本分割成 token，你最终可能得到非常大的词汇表，因为你需要考虑给定词的所有变体。

我想指出的另一件事是，假设你有一个大小为六的词汇表，这是你在训练时看到的六个词。但如果在推理时你遇到一个在训练时没有见过的词会怎么样？答案是人们通常会为所谓的未知 token 或词汇表外 token 预留一个位置，基本上可以把它想成一个桶，用来装我们无法识别的所有东西。

所以假设在推理时你有一个无法识别的 token，它们都会采用那个表示，也就是未知 token 表示。

顺便说一下，这是词级别 tokenizer 有些困难处理的事情，因为你有更大的机会遇到词汇表外的 token。词级别子词级别会有更低的机会，然后字符级别，我想你就没有这个问题了。这回答了你的问题吗？

好的，很好的问题。第一个问题是你怎么知道什么时候完成了？

代理任务的问题是，当你训练模型时，我想你的真正目标不是真正学习...我是说在这种情况下学会如何预测下一个词，你的目标是获得有意义的表示，但你可以做的是某种程度上跟踪你所追求的代理任务的损失函数，但同时也要考虑到这不一定是你的最终目标。

所以我想一个非常合理的方法就是等到你的模型收敛。在这里你要做的是跟踪损失作为...有这个术语叫 epoch，就是你的模型看到训练集多少次，所以你比较这些不同的曲线，当这收敛时，这通常是一个很好的时间来停止训练过程，只是看看是否有意义，当然这取决于你的下游任务，但这是一个方法。

你的第二个问题，抱歉你能重复一下第二个问题吗？

哦，很好的问题。问题是你怎么知道生成什么时候停止？我想不然它会永远不停。是的，完全正确。所以你有一些特殊 token。通常你有序列结束 token。所以通常当你生成了序列结束 token 时，就是它停止的时候。

好的。第二个问题是什么决定了隐藏层的大小？我会说这是一个权衡，因为你希望嵌入足够丰富，能够为你的下游任务提供信息。例如，如果你想获得句子的嵌入，如果你想做一个非常非常专门的任务，有很多不同的结果，也许你想要一个真正能捕捉到这一点的向量。所以也许你想要一个更大的向量。但如果你有一个非常简单的任务，也许一个较小的向量可能有意义。

我想你的隐藏维度的大小也会影响你之后运行的任何东西的复杂性，因为当然如果你有更长的向量，你会有更多的计算。所以你的推理可能会更昂贵等等。所以我想有很多因素。

总结一下，一个是你的任务有多复杂。第二个是你对延迟成本等这些东西有多敏感。所以这真的是一个权衡，但在外面你通常会看到几百或几千的嵌入。当然，这些模型一直在增长，所以数字可能会改变，但这是你正在寻找的数量级。

对，这确实是经验性的。是的，我想你也可以依赖别人发现的东西，然后从那里开始。但是 768 和...这些数字是人们通常采用的。

好问题。问题是你如何区分拼写相同但在不同上下文中的词？你比我想得更远。这基本上是基础知识，我们将要处理能够解决这些问题的方法，即在句子中将词语语境化。所以我们很快就会看到这一点。

我没有按时间进行，所以我会尝试继续前进。好的，现在我们做的是看我们如何学习 token 的表示，但我想你可能也想得到句子或文本片段的表示。

用我们之前看到的方法来做这件事的一个非常简单的方法是取词表示的平均值，但问题是你失去了很多意义，你失去了顺序，我想这里你指出得很好，你学到的表示是特定于 token 的，不管它们在哪里。

这就是为什么我们有一类模型旨在捕捉文本出现的序列性质。所以我们要谈论 RNN，代表循环神经网络。

RNN 所做的不是一次处理一个词，而是它们保持一个到目前为止的句子的隐藏表示，并一次考虑一个 token。

如我之前提到的，这项技术实际上很久以前就被引入了，也是在 80 年代。这个模型做的是考虑词或 token 出现的顺序。

在这个例子中，你从句子的最开始开始处理。你有一些虚拟的隐藏状态，通常记作 a 或 h，称为隐藏状态激活，或者有时称为上下文向量。你有某种模块，考虑到目前为止的隐藏状态和时间步 t 的词。这里是时间步一。

这里它做的是接收到目前为止句子的意义，并考虑现在发生的词，它产生一个输出向量，这里可以用来尝试预测下一个词。例如，这里我们有这个隐藏状态和词的表示，然后在这个蓝色框中你有一些矩阵乘法，你有一个输出向量，你尝试训练来预测下一个词。

然后你通过保持跟踪这些隐藏状态来继续这样做，所以你重复这个过程，我想你解释这些隐藏状态的方式是它是到目前为止处理的序列的表示。

RNN 的好处是现在词序很重要，你也能够以更自然的方式编码句子。

让我们粗略地看看它是如何工作的。我们有同样的最喜欢的例子。So cute teddy bear is reading. 所以你会有 token A。你找到 one-hot 编码向量。你把它传递给你的网络。你计算隐藏状态。你尝试预测 cute。

但然后你跟踪隐藏状态，然后你将其输入到另一个模块中，然后你也考虑下一个词。所以你不仅考虑词本身，还考虑到目前为止句子的隐藏状态，你再次尝试预测下一个词，一次又一次。

这就是 RNN。

RNN 被用于许多任务，就像直接映射到我们之前看到的类别一样。

对于分类目的，你基本上可以使用句子中最后一个词的隐藏状态。例如，如果你想预测评论的情绪，你基本上会取这里的最后一个向量，并尝试将其投影到你想要预测的预测或标签空间中。例如，如果你想要正面或负面，我们基本上将那个向量投影到那个空间中。你可以在这里进行多分类。所以你基本上会有感兴趣的 token 的表示，你会投影它，或者对于生成，你基本上会处理整个源文本，然后在你处理结束时有上下文向量（也就是激活向量或隐藏状态），然后它将被用来解码输出预测。

这就是你如何为每个这些任务使用 RNN。你现在没有真正听说过 RNN 的原因是因为它们有一些优点但有很多缺点。其中一个缺点是句子的意义基本上完全封装在这个隐藏状态中。

所以你有这个长距离依赖的问题，这基本上影响了你"记住"模型在过去看到的东西的能力，这就是为什么你有另一类试图建立在 RNN 基础上的模型。这个叫做 LSTM，长短期记忆。

LSTM 试图解决 RNN 的一些限制，特别是长距离依赖问题。它们引入了更复杂的门控机制，能够选择性地保留或遗忘信息，这使得模型能够更好地处理较长的序列并保持重要信息。

然而，即使是 LSTM 也有其局限性，这最终导致了 Transformer 架构的发展，它能够并行处理序列并更有效地建模长距离依赖关系。这就是为什么在现代自然语言处理中，我们看到 Transformer 成为主导架构的原因。

### (1:00:00 - 1:15:00) Part 5

### (59:29 - 1:07:08) 注意力机制的诞生
> 解释注意力机制如何解决RNN的梯度消失问题

LSTM 被称为长短期记忆网络。这种扩展架构的目标是在我们之前讨论的隐藏状态之上，找到一种方法来跟踪那些"重要需要记住"的信息。所以这里你有 a_t，这是你的激活值，基本上是到目前为止编码的序列，然后你还有另一个需要跟踪的量，叫做细胞状态，在这里用 C 表示。

这种架构旨在改进那部分功能，但我想它也不是完美的。这就是基于 RNN 方法的主要问题，即它们有忘记过去信息的问题。你会在文献中看到这种现象被称为梯度消失，之所以这样命名是有原因的。我知道我们时间不多了，但我要解释这部分内容。

为了预测最后的单词，你基本上依赖于之前的每个隐藏状态，这到目前为止都没问题。所以当你想要更新模型的权重以使这里的预测与实际预测匹配时，当你进行反向传播时，你需要考虑到这里的损失值不仅仅是这个计算的问题，也是以顺序方式发生的这个计算或那个计算的问题。

所以你有这种通过时间反向传播的现象。但问题是在实践中当你写下这个公式时，虽然它是一个非常难看的公式，但当你写下它时，它最终会是一堆量的乘积，如果它大于1，那么它就会爆炸。如果它小于1，它就会消失，因为如果你把很多小于1的东西相乘，它就会趋于零。所以我想如果你有一个试图更新的东西趋于零，你基本上就无法进行更新了。

这就是一个高层次的直觉。这不是这门课的重点，这就是为什么我不会详细讨论这些难看的公式。但我希望你能理解，对于记住过去的东西，由于这种顺序特性，它做得不是很好。这说得通吗？

好的。我希望下一个东西会更有意义一些。但在此之前，我先回顾一下我们看到的内容。

我们的目标是表示文本。所以我们首先从表示单词或标记开始，这就是我们试图用 Word2Vec 做的事情。我们看到这是一种利用代理测试来学习这种表示的好方法，但我们有很多限制，你提到的其中之一是它不了解上下文，而且单词顺序也不重要。

### (1:07:08 - 1:27:49) Transformer架构详解
> 深入讲解编码器-解码器架构和自注意力机制

所以你有另一类能够考虑单词的方法，但当序列变得很长时，它们在跟踪事物方面遇到了一些困难，你就会遇到梯度消失或长距离依赖的问题。每当你看到这个术语时，它基本上就是指这个问题。还有一件我没有提到的事情，但计算非常慢。

所以当你想要训练这些模型时，在训练时为了预测这个单词，你基本上需要计算之前所有的隐藏状态。所以当你的序列变得很长时，它就会花费很长时间。由于所有这些原因，由于模型在记住过去事物方面有困难的事实，人们尝试在某个东西和过去的事物之间建立更直接的连接。这就是注意力机制背后的想法。

注意力机制所做的是试图在我们试图预测的东西和过去的某些东西之间建立直接链接。在这个例子中，假设我试图将英语句子翻译成法语句子。这里我想输入句子是给定的，我在计算隐藏状态，我一次处理一个单词。这是我的传统RNN。

所以"a cute teddy bear is reading"，这里我有一个隐藏状态，然后我在解码它。

你可以想象，当想要生成翻译的下一个单词时，如果我知道我试图预测什么单词就太好了。换句话说，如果我能偷看输入文本的某个区域就太好了。所以注意力机制背后的想法是在你试图预测的东西和之前的东西之间建立直接链接。

这就是注意力机制背后的想法。它在2014年被引入，这再次试图解决这些长距离依赖问题。这个概念实际上将成为这门课的关键，因为我们将看到注意力机制是让大多数东西工作的关键。这实际上是 Transformer 论文所依赖的主要原理。

Transformer 是我们在这门课中将看到的核心架构，它在2017年在这篇名为"Attention Is All You Need"的论文中被引入。甚至从标题你就可以看出，作者们想要仅仅依赖那个部分。作者们试图做的是摆脱这种顺序处理文本的方式，而是让模型与文本的所有部分同时建立直接连接。这被称为自注意力机制。他们在翻译任务上尝试了这个方法，发现它给出了很好的结果。

### (1:15:00 - 1:30:00) Part 6

这意味着你要计算每个token的表示，作为其他token的函数。你通过使用称为注意力层的层来做到这一点。所以多头注意力层，但多头只是以不同的方式进行这种计算，让模型学习不同的表示或不同的投影。

但这里的想法是你将输入你的输入文本，输入文本中的所有token都将相互关注。所以例如，"一只可爱的泰迪熊在阅读"。你将计算这个文本中所有token的表示，基本上作为其他token的函数。你将通过编码器来做到这一点。所以这里使用多头注意力，然后你有一个前馈层，这只是让模型学习另一种投影。在编码过程结束时你将获得的是输入句子中token的丰富表示。

到目前为止都很好。但现在你的目标是实际翻译输入句子。所以你要做的是用句子开始token来开始你的翻译。它是你的第一个token。你要做的是使用来自输入句子的所有表示来弄清楚接下来要预测什么。

我刚才说的就是交叉注意力层，这是第二个。基本上你看到有两个箭头来自编码器，一个箭头来自解码器。有人能告诉我来自解码器的箭头代表什么吗？它是查询、键还是？我猜有三分之一的概率。谁想试试？

学生：是键吗？

好的。查询。好的。所以思考的方式是你想问自己输入中哪些词很重要，对吧？所以基本上你想知道，给定你的查询，输入中哪些元素很重要。所以这里这个箭头确实是查询，因为这是你想要弄清楚的东西，而键和值实际上来自编码器，基本上来自输入序列。

然后你有另一个注意力层，就是这个。那个试图弄清楚你正在解码的输出句子的哪些其他token对预测下一个token有用。

所以假设你开始解码并说，用法语预测下一个词，你想基本上弄清楚到目前为止翻译的哪些token对预测下一个词有用。这就是这个注意力层的作用，它被称为掩码，因为它只看到目前为止翻译的token。

它不看没有被翻译的token，因为当然它们没有被翻译。所以在你试图预测的token的右边没有办法。

很好。所以在一个非常高的层面上，你有这个注意力层，它存在于编码器中，存在于解码器中，但它有几个用例。所以这里的注意力层旨在从输入句子计算嵌入，作为它们自身的函数。然后来自解码器的那些。所以第一个，掩码自注意力层旨在将某些东西表达为到目前为止已解码的一切的函数。第二个，交叉注意力层试图将事物表达为在输入中看到的内容的函数。

所以这里，鉴于你与不同的token有直接链接，你没有这种顺序感，对吧？因为在RNN中你基本上是一次表达一个事物，所以你对词序有一些感觉，但这里你没有，因为它就像一个直接链接。这就是为什么你有位置编码，它们是为了告知词在序列中的位置。我们今天不会深入研究这个，但我只是想指出这一点。

所以在一个非常高的层面上，我们将在一个详细的例子中看到这一点。为了将句子从源语言翻译到目标语言，我们首先要对文本进行标记化。所以你知道，分成任意单元。我们将为这些token学习嵌入。这就是输入嵌入的作用。然后我们必须添加一些关于位置的编码。我们今天不会谈论它，但值得注意。然后我们通过编码器。

所以编码器试图弄清楚如何将事物表达为来自输入的其他事物的函数。所以它在多头注意力层中做到这一点，然后它通过一个前馈神经网络，这只是一种投影向量的方式，让学习更有自由度。

然后一旦你有了来自输入的这些表示，你就要开始你的翻译。所以你从BOS token开始。你要做的是弄清楚下一个词是什么。所以你会看到，好的，到目前为止翻译的哪些词对翻译有用。这就是掩码多头注意力层所做的。然后你有另一个注意力层，它是关于将事物表达为输入中内容的函数，这就是那里的交叉注意力层。然后你有一个前馈神经网络，再次给出更多的自由度。最终，你有一个向量，然后通过softmax，这只是一种让你猜测下一个词是什么的方式。

所以你会有一个词汇表大小的向量，你将使用这些值来确定你的下一个词是什么。

简单，对吧？对此有什么问题吗？

学生：什么是"头"的含义？

那是个很好的问题。问题是，头是什么意思？我想我讲得太快了。我有点忽略了那部分。但当你进行注意力自注意力计算时，你基本上让查询与键交互，然后取相应的值。但没有什么阻止你多次这样做。

所以头这个术语是给你用来获得查询键和值的投影矩阵的。当你有几个头时，你正在做的是允许你的模型学习不同的投影。

所以这基本上是你的模型学习向量之间不同关联的额外自由度。这是个很好的问题。所以通常它会用小写h表示头数，这就是它对应的。

这回答了你的问题吗？

很好。

很好。我们有很多要讨论的，但我实际上为此有一张幻灯片。所以，这就是你提到的多头。所以，我们基本上并行运行自注意力计算几次，再次使用模型学习的不同投影矩阵。

所以如果你有计算机视觉背景，这类似于在你的卷积中有多个滤波器。这是相同的想法，但这里有所不同。

学生：投影是不同的吗？

好问题。问题是投影是否不同？我们通常不约束事物。我们只是让模型学习，但在实践中它倾向于学习看同一事物的不同方式。所以是的，通常没有约束。当然你有论文深入研究，如果你改变这个会怎样，但通常你没有任何约束。

好的。我将提到Transformer作者使用的另一个技巧。它叫做标签平滑。

这里有谁听说过标签平滑？

好的。所以这里的一个新事物是在NLP中，当你想要预测接下来会发生什么时，通常有不止一种方法。比如当你说"多么美好的一天"、"多么好的讲座"、"多么好的书"、"多么好的"，总是有多种选择，总是有不止一种填补空白的方式。所以标签平滑是一种试图直观地解决这个问题的技术。

它做的不是说100%预测这个词就是这个，没有其他词，它做的是说好的，预测这个词，但有可能不是这个词。在实践中它做的是取独热编码，而不是说你需要预测的是1 0 0，它说实际上是1减去epsilon，然后是epsilon除以v减去1。

所以在实践中，这是一种倾向于让你的模型更不确定的方法，它对这个预测会不那么确定，因为你总是告诉它好的，试图预测这个，但实际上可能不是正确的值，但在实践中作者看到它倾向于改善像BLEU这样的指标，这是翻译任务的一种代理指标。

学生：这种方法对NLP来说很通用吗？

是的，我认为这种方法对NLP来说相当通用。所以是的，这是一个很好的了解。有了这个，我认为还剩大约20分钟。所以是的，Shervin将带你们通过一个端到端的例子。

关于explore和exploit有关系吗？这是个有趣的问题。我猜最终你要做的是将你的预测与标签进行比较。所以我猜这里的问题是你想要与1 0 0比较还是想要与不是1 0 0的东西比较。所以我猜softmax不允许你做到那一点。

完全正确。是的。所以我不确定这是否超级清楚，但这实际上是标签。所以我们试图预测的不是1 0 0，但我们以一种让模型预测某些东西不那么确定的方式改变标签。

谢谢Ashin。是的，所以我们基本上看到了Transformer是如何工作的，现在我们将通过一个具体的例子把它们拼接在一起。

好的，让我们再次用我们最喜欢的例子，"一只可爱的泰迪熊在阅读"，然后我们将一起经历每个步骤。所以首先我们从标记化开始。

如我们所说，我们可以使用任何任意的分解将其分解为token。然后正如有人提到的，你知道你需要有某种方式来指示序列的开始和结束。所以通常这是用BOS和EOS token来完成的。所以你添加它们。

### (1:30:00 - End) Part 7

### (1:27:49 - 1:41:56) 完整实例演示
> 通过机器翻译任务演示Transformer的完整工作流程

正如我们所说，我们可以使用任何任意的分解将其分解为token。然后正如有人提到的，你需要有某种方式来指示序列的开始和结束。所以通常这是用BOS和EOS token来完成的。所以你添加它们。

好的。现在让我们专注于每个token表示的组成。

所以你有其学习到的嵌入，然后如前所述，为了了解单词或者我应该说token作为序列一部分的位置，你有一些以位置嵌入形式添加的信息。这里原论文使用了一些正弦和余弦的约定，它以加法的方式添加到表示中。所以这就像是逐元素的加法。

好的，很棒。所以现在你有了一个位置感知的token嵌入，你对每个token都重复这个过程。

好的，所以现在你可以看到所有这些嵌入以矩阵的格式，大小为D model，这是你嵌入的大小，然后另一个维度是序列的长度，通常为n。

到目前为止都很有意义。对输入有任何问题吗？

好的，很棒。所以现在我们将把这个表示发送到编码器。

好的，正如Ashin所说，你有这个自注意力的概念，执行自注意力的方式是，你接受这个输入并将其投影到三个空间。所以你将其投影到空间WQ，得到查询。你将相同的嵌入投影到空间WK，得到键。对值也做同样的事情。你得到你的值。

WQ、WK和WV由模型学习。它们基本上就像投影矩阵。

到目前为止都很好。

好的。所以现在考虑到所有这些，你可以应用Ashin提到的公式，即自注意力公式：softmax(QK^T/√dk) * V，这从所有这些中给你另一个矩阵。

现在让我们暂停一下，看看这个计算在实践中是如何完成的，以及每一步的含义。

所以让我们看看Q。当你计算Q时，基本上你将嵌入投影到那个空间。你得到什么？你得到一个矩阵，其中每一行代表一个给定的查询。

当你说K转置时，基本上是同一种矩阵但转置了，其中每列代表每个token的键表示。

现在让我们通过矩阵乘法将它们混合在一起。所以当你将它们相乘时，你看到每一行代表查询在每个键上的投影。

这样当你进行矩阵乘法并对所有这些取softmax时，你得到查询在键上投影的概率分布，对每个查询都是如此。就像每一行都会有这个。

我不知道是否有人问过关于为什么要按√dk缩放的问题。它也可以是dq，因为矩阵乘法，这里的点积强制dq等于dk的事实，基本上你看到的是，随着键和查询维度的增长，这些点积也会倾向于增长。所以你想要标准化这个点积，这就是为什么你要除以键维度的平方根。

好的，很棒。然后现在你有了所有这些的softmax，然后你乘以矩阵V，这就是我看到的解释，即查询投影到键的空间，然后乘以相应的值。所以值是我们投影的相应键的表示。所以你最终得到每个查询的值的加权和。

好的，很棒。

到目前为止有意义吗？

好的，太棒了。有人问，多头是什么？所以你是对的。所以它不只是单一的一次完成。实际上它被做了h次，你得到的是所有这些都并行完成，最后你得到每个这样的矩阵，你按列连接它们。

在这个结束时，你有另一个叫做WO的投影矩阵，它将所有这些投影回嵌入的原始维度。

所以这是网络基本上有一种维度不变的方式来让你从原始维度回到原始维度。

有任何问题吗？

是的。

所以问题是关于头。每次都能得到相同的结果吗？我的意思是，如果你连接相同的东西，这会有帮助吗？我理解问题正确吗？

那么，是什么让它不同？这就是梯度下降的魔力。


---

*生成时间: 2026-01-03 05:57:15*
*由 YouTube Monitor & Translator (Claude CLI) 生成*