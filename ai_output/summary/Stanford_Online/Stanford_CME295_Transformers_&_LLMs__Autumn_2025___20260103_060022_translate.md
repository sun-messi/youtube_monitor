# Stanford CME295 Transformers & LLMs | Autumn 2025 | Lecture 1 - Transformer

## 📹 视频信息

- **频道**: Stanford Online
- **发布日期**: 2025-10-17
- **时长**: 1:41:56
- **原始链接**: [https://www.youtube.com/watch?v=Ub3GoFaUcds](https://www.youtube.com/watch?v=Ub3GoFaUcds)

---

> 本文内容整理自斯坦福大学 Ashin 和 Shervin 兄弟在 Stanford Online 频道的《Transformers & LLMs》课程第一讲。

---

## TL;DR

斯坦福 CME295 课程深度解析 Transformer 架构：从传统 NLP 任务分类（分类/多分类/生成）到词表示学习（Word2Vec），再到 RNN/LSTM 的序列建模局限，最终揭示注意力机制如何解决长程依赖问题，详细解构 Transformer 的编码器-解码器架构及自注意力核心原理。

---

## 📑 章节导航表

| 时间戳 | 章节标题 | 一句话概括 |
|--------|----------|-----------|
| 00:00-10:42 | 课程介绍和背景 | 双胞胎讲师介绍课程设置、先修要求、评分标准及教学目标 |
| 10:42-23:06 | NLP 任务概览 | 介绍三大类 NLP 任务：分类、多分类、生成，及其评估指标 |
| 23:06-30:21 | 文本标记化 | 词级、子词级、字符级标记化方法的利弊分析 |
| 30:21-53:19 | 词向量表示 | 从独热编码到 Word2Vec，通过代理任务学习语义嵌入 |
| 53:19-1:07:08 | 循环神经网络 | RNN/LSTM 处理序列数据的原理及梯度消失问题 |
| 1:07:08-1:14:15 | 注意力机制引入 | 注意力解决长程依赖，Transformer 架构设计理念 |
| 1:14:15-1:29:34 | Transformer 架构 | 编码器-解码器结构、多头自注意力、位置编码详解 |
| 1:29:34-1:41:45 | 端到端实例 | 完整演示机器翻译的标记化、编码、解码全流程 |

---

## 📊 核心论点

#### NLP 任务的三大分类体系

- **核心内容**：NLP 任务可系统性分为三类：分类（文本→标签）、多分类（文本→多标签）、生成（文本→文本）。分类任务如情感分析使用准确率、精确率、召回率、F1分数评估；多分类如命名实体识别在token或实体类型级别聚合指标；生成任务如机器翻译使用BLEU、ROUGE等基于参考的指标或困惑度等概率指标。每类任务对应不同的数据集结构和评估范式。
- **关键概念**：情感分析、命名实体识别、机器翻译、BLEU评分、ROUGE指标、困惑度
- **实际意义**：为NLP应用提供清晰的任务分类框架；指导模型选择和评估策略；奠定后续Transformer多任务学习基础。

#### 文本标记化的层次选择困境

- **核心内容**：标记化面临词汇表大小、序列长度、语义保持的三元权衡。词级标记化简单但存在OOV问题和形态变化处理困难（如bear vs bears）；子词级标记化（如BPE）利用词根结构减少OOV但增加序列长度；字符级标记化处理拼写错误强但序列过长且单字符语义模糊。现代模型普遍采用子词标记化平衡各种权衡。
- **关键概念**：OOV（词汇表外）、BPE（字节对编码）、子词标记化、序列长度复杂度
- **实际意义**：影响模型训练效率和推理速度；决定多语言模型设计策略；指导实际应用中的预处理选择。

#### Word2Vec 通过代理任务学习语义表示

- **核心内容**：Word2Vec突破独热编码的正交性限制，通过CBOW（上下文预测中心词）和Skip-gram（中心词预测上下文）代理任务学习密集语义向量。关键洞察是：能够预测下一个词的模型必须理解语言结构，因此学习的表示具有语义相似性（如king-queen关系）。使用余弦相似度衡量向量间语义距离，维度通常为数百维。
- **关键概念**：代理任务、CBOW、Skip-gram、余弦相似度、密集表示、语义向量空间
- **实际意义**：开创现代NLP嵌入范式；为后续预训练模型奠定理论基础；实现语义相似性的数值化计算。

#### RNN/LSTM 的序列建模与梯度消失挑战

- **核心内容**：RNN通过隐状态维护序列记忆，解决词序问题，但存在梯度消失/爆炸问题。反向传播需要通过时间展开，梯度计算涉及连乘，当梯度<1时连乘趋零（梯度消失），>1时连乘发散（梯度爆炸）。LSTM引入门控机制和细胞状态缓解长程依赖问题，但仍未根本解决。计算串行化导致训练效率低下。
- **关键概念**：隐状态、梯度消失、BPTT（通过时间的反向传播）、门控机制、长程依赖
- **实际意义**：揭示序列模型的根本局限性；推动注意力机制的发展；为并行计算优化提供动机。

#### 注意力机制的直接连接创新

- **核心内容**：注意力机制通过建立查询（Query）、键（Key）、值（Value）的直接连接，突破RNN的串行限制。核心思想是让模型在预测时直接"关注"输入序列的相关部分，而非依赖压缩的隐状态。2014年首次用于解决机器翻译的对齐问题，为Transformer的"Attention Is All You Need"理念奠定基础。
- **关键概念**：Query-Key-Value机制、直接连接、并行计算、序列对齐
- **实际意义**：解决长程依赖问题；支持并行计算提升训练效率；成为现代Transformer的核心组件。

#### Transformer 的编码器-解码器架构设计

- **核心内容**：Transformer采用纯注意力的编码器-解码器架构。编码器通过多头自注意力计算输入序列的上下文化表示，每个token关注所有其他token。解码器包含三种注意力：掩码自注意力（只看已生成token）、交叉注意力（关注编码器输出）、和前馈网络。多头机制允许学习不同的投影空间，类似CNN的多滤波器。
- **关键概念**：编码器-解码器、多头自注意力、掩码注意力、交叉注意力、并行处理
- **实际意义**：彻底摆脱RNN依赖；实现高效并行训练；为大规模预训练模型提供可扩展架构。

#### 自注意力的矩阵化计算优势

- **核心内容**：自注意力公式 Attention(Q,K,V) = softmax(QK^T/√d_k)V 实现了向量化矩阵运算。Q、K、V通过学习的投影矩阵W_Q、W_K、W_V获得。缩放因子√d_k防止维度增长导致softmax饱和。整个计算过程高度并行化，充分利用GPU矩阵运算优势，相比RNN的串行计算实现显著加速。
- **关键概念**：向量化计算、softmax缩放、投影矩阵、GPU并行化、矩阵乘法
- **实际意义**：硬件友好的算法设计；为大规模模型训练提供计算基础；推动AI硬件优化发展。

#### 位置编码解决序列顺序建模

- **核心内容**：Transformer的并行注意力机制天然缺乏位置信息，需要显式位置编码。原始论文使用sin/cos函数的固定位置编码，通过不同频率的正弦余弦函数为每个位置生成唯一向量。位置编码与词嵌入相加（而非拼接），保持维度不变。这种设计允许模型处理训练时未见过的序列长度。
- **关键概念**：位置编码、sin/cos函数、固定编码、维度不变性、长度泛化
- **实际意义**：保持Transformer的位置感知能力；支持变长序列处理；为后续位置编码改进提供基线。

#### 标签平滑技术应对预测不确定性

- **核心内容**：NLP生成任务存在多个合理答案（如"what a great day/book/lecture"），硬性one-hot标签过于绝对。标签平滑将目标分布从[1,0,0...]调整为[1-ε, ε/(V-1), ε/(V-1)...]，为非目标词分配小概率。这种正则化技术让模型在保持主要预测的同时承认其他可能性，在实践中提升BLEU等翻译指标。
- **关键概念**：标签平滑、正则化、概率分布、不确定性建模、BLEU指标
- **实际意义**：提升生成质量；减少过度自信预测；为现代语言模型的概率校准提供技术基础。

#### 多头注意力的表示学习多样性

- **核心内容**：多头注意力机制并行运行h个注意力头，每个头使用不同的投影矩阵W_Q^i、W_K^i、W_V^i。各头输出拼接后通过输出投影W_O回到原始维度。类似CNN的多滤波器设计，不同头可学习不同类型的关系（句法、语义、共指等）。梯度下降的优化动力自然驱动各头学习差异化表示，无需显式约束。
- **关键概念**：多头并行、投影矩阵、表示多样性、梯度驱动分化、维度恢复
- **实际意义**：增强模型表达能力；自动发现多种语言关系；为模型可解释性研究提供结构化入口。

---

## 🔬 提及的技术/方法/论文

| 技术/论文 | 讨论语境 | 重要性 |
|----------|----------|--------|
| Attention Is All You Need (2017) | Transformer架构的原始论文，提出纯注意力机制 | ⭐⭐⭐ |
| Word2Vec (2013) | 词嵌入学习的开创性工作，引入代理任务概念 | ⭐⭐⭐ |
| RNN/LSTM (1980s-1990s) | 序列建模的经典方法，存在梯度消失问题 | ⭐⭐⭐ |
| BLEU评分 | 机器翻译质量评估的标准指标 | ⭐⭐ |
| 注意力机制 (2014) | 解决长程依赖问题的关键突破 | ⭐⭐⭐ |
| 子词标记化 (BPE) | 现代NLP的标准预处理技术 | ⭐⭐ |
| 位置编码 | Transformer中保持位置信息的技术 | ⭐⭐ |
| 标签平滑 | 正则化技术，提升生成质量 | ⭐ |

---

## 💬 经典金句

> "Attention is all you need"
> — Transformer论文标题

> "The field is full of abbreviations. So I myself was completely scared of them when I started."
> — Afin

> "If you have that mental mapping towards the end of the class then we'll know we did a good job."
> — Afin

> "GPUs love matrices."
> — Afin

---

## 👤 主要人物

#### Afin（主讲教师）

**身份**：Stanford CME 295课程讲师；Netflix机器学习科学家
**背景**：法国École Supérieure毕业，MIT硕士，曾在Uber、Google工作，专精NLP和大语言模型领域。与twin兄弟Shervin共同开展LLM教学和研究。
**核心观点**：强调理解Transformer底层机制的重要性；认为掌握术语映射是学习LLM的关键；主张从基础概念循序渐进构建完整知识体系。

#### Shervin（协同讲师）

**身份**：Stanford CME 295课程协同讲师；Netflix机器学习科学家
**背景**：法国École Supérieure毕业，Stanford ICME硕士，与Afin有相似的Uber、Google、Netflix职业轨迹，专注LLM实际应用。
**核心观点**：负责课程的实例演示部分；强调端到端理解Transformer工作流程；注重理论与实践的结合。

---

## 📺 视频类型判断

**教程示范**：学术讲座形式，系统性介绍Transformer架构原理和实现细节

---

## 📝 完整翻译

### (0:00 - 10:42) 课程介绍和背景
> 双胞胎讲师介绍课程设置、先修要求、评分标准及教学目标

大家好，欢迎来到 CME 295 课程：Transformers 和大语言模型。我是 Afin，我将和后面的 Shervin 一起教授这门课程。在开始之前，让我先介绍一下我们自己。

我们是双胞胎兄弟，有着相似的背景。我们都在法国一所叫 Salbar 的学校上学，然后各自走上不同的道路。我去了 MIT，Shervin 去了 Stanford 攻读 ICME 硕士项目。

之后我们的行业背景也非常相似。我先去了 Uber，然后 Shervin 也来到 Uber，接着 Shervin 离开去了 Google，我也去了 Google，最近我加入了 Netflix，Shervin 也加入了 Netflix，我们一直在研究大语言模型。所以我们都有技术背景，主要专注于 LLMs。

那么为什么要开这门课呢？自 2020 年以来，Shervin 和我一直专注于 NLP (自然语言处理) 领域，我们以研讨会的形式每年开设这门课程。

在 2021、2022、2023、2024 年，ChatGPT 在 2022 年问世，突然间人们对 LLMs 产生了极大兴趣。实际上是在去年春天，我们开始将这门课作为 Stanford 课程提供，现在叫做 CME 295，这是第二次开课。

那么你能从这门课中期待什么呢？首先，LLMs 现在基本上无处不在，我们的目标有两个方面。第一个是了解使这一切工作的底层机制，我们将学习 Transformer，这是使这一切成为可能的基础架构。

第二个是了解这些 LLMs 是如何训练的以及它们被应用在哪些领域。

如果你仍在考虑这门课是否适合你，我想说这门课非常适合对这个领域有兴趣的人，无论是因为你想将其作为职业目标，比如想成为研究科学家或 ML 科学家，或者你想开发依赖 LLMs 的个人项目，了解其局限性、什么有效什么无效，或者你在其他领域工作，只是想了解整个 AI、生成式 AI、LLMs 是如何工作的，以及如何将其应用到你的领域。

在先决条件方面，我认为至少你应该有一些 ML 基础，基本上知道模型是如何训练的，什么是神经网络，以及一些线性代数基础，比如矩阵是如何相乘的。但即使你在这些领域的能力还在发展中，也没关系，我们会在这里帮助你。这是理想的先决条件集合。

关于课程安排，这门课将在每周五下午 3:30 到 5:20 在这里举行。

这门课是两个学分，你可以选择字母评分或通过/不通过。

正如你从设置中看到的，我们正在录制这门课。如果你因为某种原因无法参加这个时间段，我们会确保在每周五晚上或周六提供录像。

在成绩方面，这个季度我们将有两次考试。一次是期中考试，将在我们的第五次课程中进行，也就是 10 月 24 日。第二次考试是期末考试，将在 12 月 8 日那周举行，具体日期待定。

每次讲座后，我们会在网站上发布幻灯片和录像。如果你有兴趣，我们在那里还有教学大纲，这样你就能了解我们将要讨论的主题。

课程教科书是这本《Transformer LLMs 学习指南》，如果你想看看的话，这里有一本。这本书包含了我们课程中的很多概念，所以这是跟进课程的有用方式。

我们还制作了这整门课程的简化版本，叫做 VIP 速查表，在 GitHub 上可以找到。

我们现在已经将它翻译成多种语言。顺便说一下，如果你的语言不在其中，请告诉我们，我们很乐意一起合作。

关于公告，我们会在 Canvas 上发布信息。如果你有任何问题，当然可以联系我们。Canvas 上还有一个叫 ED 的标签页，我相信你们都很熟悉。只需点击那里，发布你的问题，Shervin 和我会回复。要联系我们，你可以使用这个邮件列表，或者直接联系我们俩。

关于课程安排，到目前为止有什么问题吗？我忘了提到的一点是，由于我们在录制这门课，如果你提问，观看者可能不清楚你的问题是什么。所以我会努力重复你的问题。这可能听起来很奇怪，但我会尽量不忘记。

到目前为止关于课程安排有任何问题吗？

学生提问关于考试是否有编程部分。答案是没有。考试将纯粹关注我们在课堂上看到的概念，实际上不是为了难倒你。如果你跟上课程，看幻灯片和我们讨论的概念，应该就没问题。

### (10:42 - 23:06) NLP 任务概览
> 介绍三大类 NLP 任务：分类、多分类、生成，及其评估指标

关于候补名单的问题，根据经验，很多人会最终确定他们的课程安排。有些人会退课，有些不会。如果你仍在候补名单上，来和我们谈谈，但我很有信心会没问题的，因为现在候补名单大约只有六个人。

幻灯片会在网站上，我们也会确保在 Canvas 上发布链接。

关于考试权重的问题。没有作业，50% 是期中考试，50% 是期末考试。如果这个时间段与其他事情冲突，记住我们在录制，所以如果你无法参加某些课程也没关系。

关于期末考试是否只关于下半学期内容的问题。我们还没有写考试，但这是我们正在考虑的。期末考试可能会关于下半学期的主题。

总之，50% 期中考试，50% 期末考试，这是一门有趣的课程。

现在我要慢慢开始正式上课。我想提到的另一件事是，每当我们讨论某个内容时，你会看到幻灯片底部有一个来源。这主要是为了引用我们所引用的内容，同时也让你在感兴趣的情况下更深入地研究这些材料。

因为我们每周只有大约两小时，只有九到十周时间，远不足以涵盖所有内容。

第二个免责声明是，你会看到这个领域充满了缩写。当我开始时，我自己完全被它们吓到了。但希望在课程结束时，你会对这些缩写的含义有一个心理映射。如果你在课程结束时有了这种心理映射，那么我们就知道我们做得很好。

现在让我们开始吧。我们将从非常高的层面开始，因为我假设我们从零开始，我们将讨论一般的 NLP。NLP 将是我们的第一个缩写。NLP 代表自然语言处理，这是一个围绕操作文本、用文本进行计算的领域。

### (15:00 - 30:00) Part 2

发布内容评估通常使用传统的分类指标。你有准确率，也就是你正确预测的观察值的百分比。

但你还有两个关键指标，我想提醒一下，因为我不确定是否每个人都了解它们。第一个是精确率（precision），即在你做出的所有正向预测中，有多少是正确的。

第二个是召回率（recall）。在所有真实标签中，你正确预测为正向的有多少？还有一个叫做 F1 分数的指标，它基本上计算精确率和召回率的调和平均数，给你一个单一的数字。

那么你可能会想，为什么需要所有这些指标？简短的答案是，有时你的任务和数据集中类别非常不平衡。比如你的数据集中可能有 99% 是正向标签，只有 1% 是负向标签。

在这种情况下，如果你使用准确率这样的指标会很误导，因为如果你有一个模型预测所有内容都是多数类别，那么你会有一个看起来很好的分类器，但实际上并非如此。这就是为什么精确率和召回率真正发挥作用的原因。

这是第一类任务。现在让我们转到第二类 NLP 任务。

这一类是多分类任务。你有一个输入文本，需要预测多个东西，我们用 NER 任务来说明，正如我提到的，它是关于识别给定单词的类别。

在这里，比如我们想要识别 teddy bear 作为一个实体。我想对于这个任务你会使用分类指标，但不是在句子层面，而是在词元（token）层面或实体类型层面。

我的意思是，假设你有一个类别，比如说地点（location），你想知道你在预测该类别中的单词方面表现如何。通常你会根据这个函数来聚合这些指标。

好的。让我们来看最后一类，正如我提到的，这是最受欢迎的一类。这一类是文本输入文本输出。我用机器翻译任务来说明，它是将文本从源语言翻译到目标语言。这里你有英语到法语的例子。所以"可爱的泰迪熊正在阅读"。

对于这种任务，获取数据集更困难，因为这里你需要有成对的文本。你有一个非常流行的数据集叫做 WMT，代表机器翻译研讨会。

这个数据集包含大量不同语言的配对序列。比如你有英语-法语、英语-德语，来自欧洲议会数据集等。

评估这些模型的性能实际上要复杂得多，因为你可以想象，翻译某些东西有很多不同的方式。我相信我们房间里的许多人都是双语或三语使用者。这就是让它如此困难的原因。

过去，人们使用了几种基于规则的指标来做这件事。你可能听过的一个是 BLEU。BLEU 代表双语评估研究，它是衡量你的翻译相对于参考文本表现如何的指标。

ROUGE 也是同样的情况，它实际上是一套指标，但以不同的方式捕获这一点。你会看到机器学习社区很有趣，因为 BLEU，我不确定你是否知道法语，意思是蓝色，但 ROUGE 意思是红色。所以我想他们试图在其中增加一些乐趣。

但这些指标的问题是你总是需要一个参考文本。所以你基本上需要标签，而在实践中获得标签是非常昂贵的。需要大量时间和金钱来获得标签。

我们将在课程后面看到，随着我们在大语言模型（LM）领域取得的进展，或者说社区在 LM 领域取得的进展，我们实际上可以放弃这些基于参考的指标，转向更无参考的指标，我们稍后会看到。

最后一个我要说的人们有时使用的指标叫做困惑度（perplexity）。

困惑度只关注模型输出的概率。它基本上量化了模型对其输出的惊讶程度。

BLEU 和 ROUGE 是越高越好。困惑度是越低越好。

我想 LLM 自 2022 年以来一直是热门话题，但实际上这个领域的历史要早得多。在 80 年代，我们马上会看到，有一类模型实际上在 80 年代就被考虑过了。90 年代我们有 LSTM，我们也会马上看到。

但那时的问题是我们没有互联网，没有大量的计算资源，我想这是阻止这些模型，也就是今天的模型被训练的限制因素之一。

最近我们有了几个进展，Word2Vec 真的是在计算有意义的嵌入设置方面的开创性工作之一，我们马上会看到。然后当然我们有了 Transformer，这是 2017 年发表的一篇论文的一部分，基本上是你今天看到的模型的基础。

### (23:06 - 30:21) 文本标记化
> 词级、子词级、字符级标记化方法的利弊分析

然后这些模型通过计算和训练数据的扩展而得到了扩展。这就是 LLM 被称为 LLM 的原因。我想这些更像是 2020 年代的事情。

但是，我们会看到这些。

在这个高层面上有什么问题吗？大家都还好吗？

好的。我想我想问我们自己的第一个问题是，我们想要的是有一个处理文本的模型。

但模型它们理解数字。它们不太理解文本。所以我们需要以某种方式对文本做一些处理，使其更可量化，使模型能够理解的东西。

如果你看一个句子，比如"a cute teddy bear is reading"，你首先需要问自己如何切分这个句子以传递给模型。

这部分叫做分词（tokenization），它基本上涉及根据一些任意的文本单位来切分文本。

有几种方法可以做到这一点。我想第一种方法是完全任意地做。

所以这里比如你会有"a"作为一个文本单位，"cute"是另一个文本单位，"bear"是另一个，依此类推。顺便说一句，文本单位叫做词元（token），这就是为什么这个方法叫做分词的原因。

另一种方法是按单词分隔。但我想我们总是有利弊。我想我们想要实现的目标之一是能够以有意义的方式表示这些 token。

在单词级别执行此操作的一个缺点是，你最终会有看起来相似但实际上被认为是不同 token 的单词。这里的限制是你需要为这些相似但不同的 token 计算嵌入，并以某种方式使它们的嵌入相似。

我给你一个例子。假设我有单词"bear"，然后你有另一个单词复数形式"bears"。

这两个词非常相似，只是一个是单数，另一个是复数。如果我们使用单词级分词，那么我们最终会有两个不同的实体，基本上被认为是不同的。"run"和"runs"也是一样，你知道动词的变化。

因此，人们深入研究了一类叫做子词分词器（subword tokenizers）的分词器，它围绕利用单词的词根来找到我们可以在这些单词中找到的常见词根。

例如，对于"bear"和"bears"，你会有"bear"这个部分是共享的。

所以我想优点是你可以利用单词的词根。但缺点是你的序列会更长。我们稍后会看到为什么这是一个缺点。我想我可以给你一个预览。这些模型的复杂度也是序列长度的函数。

所以你拥有的 token 越多，你的模型运行所需的时间就越多，因为它需要基本上处理所有这些 token。

这是一个缺点。所以优点是它利用单词的词根。缺点是它只是让你的序列更长。

好的，你有最后一类分词方式，就是在字符级别进行，就像取所有字符一样。我想当我们写消息时，有时会有拼写错误，使用子词分词方式可能无法识别拼写错误的单词，这是字符级分词器可以考虑的事情。

但这里的问题是你的序列长度要长得多，这会使你的模型需要更多时间来处理这个序列。这是一个缺点。

另一个缺点是，当你想表示每个这些 token 时，很难知道字母的表示真正意味着什么。比如字母 U 的表示意味着什么？

非常困难。

好的。我有一个快速回顾。单词级别是一种非常简单的将文本划分为任意单位的方式。但问题是，正如我们提到的，我们没有利用单词的词根。我没有提到的是，每当你切分某些东西时，在推理时当你想做预测时，你有一个先决条件，就是你需要在训练时看到的 token 必须在你的训练集中。

问题是，假设在推理时你将文本切分为单词，假设你在训练时没有看到某个单词，你需要将其标记为未知，这叫做 OOV（词汇表外）。

幸运的是，子词级分词器缓解了这个问题。你有较低的 OOV 风险，但仍然可能有。正如我们提到的，在优点方面，你利用了单词的词根。

字符级别对拼写错误和大小写错误具有鲁棒性，但问题是它使计算变得更慢，你的序列会非常长，这也会使你的推理时间更高。

### (30:00 - 45:00) Part 3

听起来不错吧？我觉得这确实是处理文本的基础。总的来说，这样理解对吗？

好的。那么现在，我们做的是获取输入文本，将其切分为基本单位，也就是 token。

为了让我们的模型理解这些 token，我们需要为每个 token 找到一种表示方法。所以这里我们要看一下词表示，或者更准确地说，应该叫 token 表示。我们想找到一种方法来表示每个 token。

### (30:21 - 53:19) 词向量表示
> 从独热编码到 Word2Vec，通过代理任务学习语义嵌入

最简单朴素的方法是为每个词或每个 token 分配一个独热向量。比如，假设我们有一个包含三个 token 的词汇表：book、soft 和 teddy bears。我们会让 soft 是一个 (1, 0, 0) 向量，teddy bear 是一个 (0, 1, 0) 向量，book 是一个 (0, 0, 1) 向量。

这叫做独热编码（one hot encoding），我们通常会看到这种方法。

这是表示 token 的一种方式，但人们想要做的是比较这些 token，看看哪些彼此更相似。

人们使用的常见相似性度量叫做余弦相似度，不知道你们是否听说过。你可以把它理解为看这些向量在 n 维空间中形成什么角度。如果它们指向同一个方向，那么它们可能是相似的；如果它们正交，那么它们可能是独立的；如果它们完全相对，那么它们可能是对立的。这基本上就是我们想要的思维模型。

问题是，如果你用独热方式表示 token，你最终会得到所有向量彼此正交。

这就是问题所在。

理想情况下，我们希望意思相同或相似的 token 基本上有高相似度，而不相似的 token（关于不同事物的）更多地是... 或者较低的相似度。

这里为了说明目的，teddy bears 是 soft 的。所以你希望 teddy bear 和 soft 有高相似度，而 teddy bear 和 book 这种相对独立的，你希望它们接近零。

这就是你想要的。这是你用独热编码得到的，这是你想要的。

抱歉。哦，我明白了。问题是为什么你关心范数？余弦相似度实际上是按范数标准化的。所以它是点积...

哦，你的意思是为什么我这里只放了点积而不是...

我明白了。你的问题是为什么我们不关心范数？我想观众知道这个问题。这些度量方法都是试图捕捉相似性的方式。为什么你不关心范数？

我想这是人们试图量化这种相似性的方法。你需要看看你的向量是如何训练的，以及范数是否能表明什么。

我能给你的最好答案是，这是一种度量方法，不是完美的度量。人们也可能使用点积作为度量，但我没有很好的答案给你。

只要你捕捉到这些向量的指向方式，通常你关心的是它们之间的角度。但通常你不会真正考虑范数。

有问题吗？还有其他问题吗？

这是个很好的问题。问题是关于词汇表大小，以及这如何影响词级、子词级的选择，以及在不同语言中这如何变化。这是个很好的问题。

我会说这真的首先取决于你试图完成的任务。如果你的任务只涉及一种语言，你通常会选择子词 tokenizer，就是因为我们这里提到的原因。子词是一个很好的折中方案，既能通过词根识别词汇，又能减少 OOV 风险。

在大小方面，我知道人们尝试了不同的方法。我认为通常对于英语，你会瞄准数万的词汇表大小，但现在的模型是多语言的，也涉及代码，所以你会看到词汇表大小有时是数十万的数量级。

关于中文，你使用的字符有差异。对于拉丁文，我们都熟悉的字母表，但对于其他语言，你有类似但用目标语言字符的东西。我会说一种语言是数万的数量级，多语言的话是数十万，这些是你想要瞄准的数量级。

很好的问题。问题是如何得到这些嵌入？这实际上是下一张幻灯片，我们要谈论这个。

好的。现在我们知道独热编码不是表示 token 的好方法，我们想要从数据中学习这些嵌入。

我提到有一篇 2010 年代的论文，我想是 2013 年，叫做 Word2Vec。

它之所以如此流行，是因为他们展示了一种非常直观和可解释的方式来看待这些嵌入。他们说类似"国王之于女王，就像巴黎之于法国，柏林之于德国"这样的关系。基本上有一种方法来理解嵌入。那么问题是他们是如何做到的？

他们有两种计算这些嵌入的方法。一种叫做连续词袋模型（continuous bag of words），另一种叫做 skip-gram。但它们都依赖于同一个想法：

利用我们拥有的文本，然后尝试基于上下文预测文本中的某些部分。

例如，连续词袋模型的目标是考虑给定目标词周围的词，你的目标是预测那个目标词。

Skip-gram 有点相反。你从一个目标词出发，想要预测它周围的词。这个任务通常叫做代理任务（proxy task）。因为在这个练习中，我们关心的最终目标不一定是预测下一个词，至少现在还不是。我们的目标是学习这些词的有意义表示。

这里的想法是，如果你有一个模型知道如何预测下一个词，那意味着你的模型对语言如何工作有一定理解，这基本上就是你想要的。你基本上想要一个嵌入，它反映语言的特点，比如你希望国王和女王的关联，或者巴黎和法国（这是首都）的关联嵌入到表示中。

让我们通过一个非常简单的例子来看看这是什么样的。

在我们的例子中，假设我们的代理任务是预测下一个词。

这里我们使用一个非常标准的神经网络模型，它基本上接收一个大小为 V 的向量，通过乘法和偏置项得到隐藏状态，然后通过另一组乘法得到最终向量。

这基本上是一个非常简单的神经网络。输入大小是 V，隐藏层大小是 D，通常比词汇表小得多。词汇表通常是数万或数十万，而 D 通常是数百，比如 768 就是一个维度的例子。

它要小得多。我们试图通过这个代理任务学习词表示。

我们要做的是考虑一个词作为输入，预测下一个词。

让我们从序列的第一个词开始。顺便说一下，我交替使用 token 和 word。

假设我们有词"a"，我们想预测下一个词，也就是词"cute"。

我们做的是取词"a"，取其独热编码表示，并通过网络传递它。如果你熟悉神经网络，这里你有矩阵和向量之间的乘法。你有一个大小为 D 的隐藏状态表示向量。这里假设是 (2, 1.9)，所以 D = 2。

然后你再传递一次，通过 softmax 后得到一组概率，表示下一个词是什么。在这个例子中，我们有大小为 6 的词汇表。第一个词预测概率为 0.2，第二个词为 0.4，其他词在这个例子中都是 0.1。

假设我们想最大化对词汇表第二个词的预测，也就是 0.4。我们基本上将预测与 (0, 1, 0, 0, 0, 0) 比较，这是词汇表第二个词的表示，然后进行反向传播，更新权重。不确定是否每个人都熟悉这部分。但想法是，一旦你得到预测，你计算损失，通常是交叉熵，这将决定你距离真实答案有多远，基于这个差异，你将更新权重以使你的预测更接近真实情况。

这就是你要做的，然后重复这个过程。假设你取词"cute"，正如我们说的，它是词汇表中的第二个词。所以独热编码表示是 (0, 1, 0, 0, 0, 0)。你通过网络，有一个隐藏状态向量 (0.8, 4)，然后再做一遍。你想预测的是下一个 token，这里是"teddy bear"。

### (45:00 - 1:00:00) Part 4

你想要做的是预测下一个 token。这里是 teddy bear。

所以你看到现在你的模型在这个例子中预测下一个词基本上是均匀分布的，但你想要以某种方式最大化 teddy bear 的概率。所以你一遍又一遍地对所有词这样做。最终，你得到一个学会如何预测下一个词的模型，这基本上就是代理任务。你要做的是利用模型学到的表示，也就是这些绿色单元。

现在发生的情况是，每次你有一个词，你就将其表示为独热编码表示，然后将其与这些权重相乘，然后你得到绿色表示，这就是你的词表示。这样理解吗？

好问题。是的，好问题。问题是关于 V 对应什么以及为什么只有六个。是的，在这个例子中，我们只有六个可能的词，这基本上就是词汇表大小，只是一个非常简化的玩具例子，因为在实践中有更多的词。我想这是语言的挑战之一。从技术上讲，你可以有很多词的变体，这就是为什么如果你采用词级别的方式将文本分割成 token，你可能会得到一个非常大的词汇表，因为你需要考虑给定词的所有变体。

我想指出的另一件事是，假设你有大小为六的词汇表，这是你在训练时看到的六个词。但是如果在推理时你遇到一个在训练时没有见过的词会发生什么？答案是人们通常做的是为他们称为未知 token 或词汇表外 token 预留一个位置，基本上可以将其视为一个桶，用于存放我们无法识别的所有内容。

所以假设在推理时你有一个无法识别的 token，它们都会采用那个表示，也就是未知 token 表示。

顺便说一下，我想词级别的 tokenizer 在这方面有些困难，因为你会有更大的机会遇到词汇表外的 token。词级别的子词级别会有更低的机会，然后字符级别，我想你就没有这个问题了。这回答了你的问题吗？

好的，好问题。第一个问题是你如何知道什么时候完成了？

关于代理任务的问题是，当你训练模型时，我想你的真正目标并不是真的学习——我是说在这种情况下学习如何预测下一个词——你的目标是获得有意义的表示，但你可以做的是以某种方式跟踪你正在追求的代理任务的损失函数，但同时也要考虑到这不一定是你的最终目标。

所以我想一个非常合理的方法就是等到你的模型收敛。这里你要做的是跟踪损失作为 epoch 的函数——epoch 是指你的模型看到训练集的次数——所以你比较这些不同的曲线，当它收敛时，这通常是停止训练过程的好时机，看看这是否有意义，当然这取决于你的下游任务，但这是一种方法。

你的第二个问题，抱歉，你能重复一下第二个问题吗？

好问题。问题是你如何知道生成何时停止？我想不然它永远不会停止。所以，是的，确实如此。你有一些特殊的 token。通常你有序列结束 token。所以通常当生成序列结束 token 时，就是它停止的时候。

第二个问题是什么决定了隐藏层的大小？我会说这是一个权衡，因为你希望嵌入足够丰富，能够为你的下游任务提供信息。例如，如果你想获得句子的嵌入，如果你想做一个非常非常专业的任务，有很多不同的结果，也许你想要一个真正能捕捉到这一点的向量。所以也许你想要一个更大的向量。但如果你有一个非常简单的任务，也许一个较小的向量就有意义。

我想你的隐藏维度的大小也会影响你之后运行的任何东西的复杂性，因为如果你有更长的向量，你会有更多的计算。所以你的推理可能会更昂贵等等。所以我想有很多因素。总结一下，一个是你的桌面任务有多复杂，第二个是你对延迟成本等所有这些东西有多敏感。这真的是一个权衡，但通常你会看到数百或数千的嵌入。

当然，这些模型一直在增长，所以数字可能会改变，但这是你正在寻找的数量级。这确实是经验性的。我想你也可以依赖于其他人发现的东西。768 这样的数字是人们通常采用的。

好问题。问题是你如何区分拼写相同但在不同上下文中的词？你比我走得更远了。这基本上是基础知识，我们将要处理能够解决在句子中将词语上下文化这些问题的方法。我们稍后会看到这一点。

我时间不够，所以我会尝试继续前进。现在我们看到了如何学习 token 的表示，但我想你可能也想获得句子或文本片段的表示。

用我们之前看到的方法做到这一点的一个非常天真的方法是取词表示的平均值之类的东西，但问题是你失去了很多意义，你失去了顺序，我想这里你很好地指出了你学到的表示是特定于 token 的，无论它们在哪里。

这就是为什么我们有一类旨在捕捉文本出现的连续性质的模型。我们要谈论的是 RNN，代表循环神经网络。

RNN 所做的不是一次处理一个词，它们做的是保持到目前为止句子的隐藏表示，并一次考虑一个 token。

如我之前提到的，这项技术实际上是在相当长时间前引入的，也是在 80 年代。这个模型做的是考虑词或 token 出现的顺序。

### (53:19 - 1:07:08) 循环神经网络
> RNN/LSTM 处理序列数据的原理及梯度消失问题

在这个例子中，你从句子的最开始开始处理。你有一些虚拟的隐藏状态，通常记为 a 或 h，称为隐藏状态激活，有时甚至称为上下文向量。你有某种模块，它考虑到目前为止的隐藏状态和时间步 t 的词。这里是时间步一。

这里它做的是接受到目前为止句子的意思，并考虑现在正在发生的词，它产生一个输出向量，这里可以用来尝试预测下一个词。例如，这里我们有这个隐藏状态和这个词的表示，然后你在这个蓝色框中进行一些矩阵乘法，你有一个输出向量，你试图训练来预测下一个词。

然后你通过保持跟踪这些隐藏状态继续这样做，所以你重复这个过程，我想你解释这些隐藏状态的方式是它是到目前为止处理的序列的表示。

RNN 的好处是现在词序很重要，你也能够以更自然的方式编码句子。

让我们大致看看它是如何工作的。我们有同样的最喜欢的例子。可爱的泰迪熊在阅读。你会有 token A。你找到独热编码向量。你通过网络传递它。你计算隐藏状态。你试图预测 cute。

但然后你跟踪隐藏状态，然后你将其输入到另一个模块中，然后你也考虑下一个词。所以你不仅考虑词本身，还考虑到目前为止句子的隐藏状态，你再次尝试预测下一个词，一次又一次。

这就是 RNN。

RNN 被用于一系列任务，就像直接映射到我们之前看到的类别一样，用于分类目的。你基本上可以使用句子中最后一个词的隐藏状态。例如，如果你想预测评论的情感，你基本上会取这里的最后一个向量，并尝试将其投影到你想要预测的预测或标签空间中。例如，如果你想要正面或负面，我们基本上将该向量投影到该空间中。你可以在这里进行多分类。所以你基本上会有感兴趣 token 的表示，你会投影它，或者对于生成，你基本上会处理整个源文本，然后在处理结束时有某种上下文向量，也就是激活向量，也就是隐藏状态，然后用于解码输出预测。

这就是你如何为这些任务中的每一个使用 RNN。

你这些天没有真正听说过 RNN 的原因是因为它们有一些优点但有很多缺点。其中一个缺点是句子的意思基本上完全封装在这个隐藏状态中。

所以你有这个长距离依赖的问题，这基本上影响了你引用-取消引用记住模型过去看到的内容的能力，这就是为什么你有另一类试图建立在 RNN 基础上的模型。这一类叫做 LSTM，长短期记忆。

LSTM 架构被设计来解决传统 RNN 的梯度消失问题，它通过引入门机制来控制信息流。具体来说，LSTM 有三个门：遗忘门、输入门和输出门，这些门共同工作来决定什么信息应该被保留、更新或输出。

遗忘门决定从细胞状态中丢弃什么信息，输入门决定什么新信息将被存储在细胞状态中，而输出门决定基于细胞状态输出什么部分。这种门机制允许网络学习长期依赖关系，这是传统 RNN 难以处理的。

虽然 LSTM 在很大程度上解决了长距离依赖问题，但它们仍然面临计算效率和并行化的挑战，这最终导致了 Transformer 架构的兴起，它通过注意力机制彻底改变了序列建模的方式。

### (1:00:00 - 1:15:00) Part 5

这种架构旨在改进 RNN 的记忆问题，但也不是完美的解决方案。

RNN 方法的主要问题是它们会忘记过去的信息。在文献中，这种现象被称为梯度消失，之所以这样命名是有原因的。虽然我们时间有限，但我想解释一下这个概念。

为了预测最后几个词，你基本上依赖于之前的每一个隐藏状态。这本身没有问题。

当你想要更新模型的权重以使预测结果与实际结果匹配时，在进行反向传播时，你需要考虑到这里的损失值不仅仅是这次计算的结果，还涉及之前以序列方式发生的所有计算。这就产生了通过时间进行反向传播的现象。

但问题在于，当你把这个过程写成数学形式时，尽管公式很复杂，最终会变成一系列量的乘积。如果这些量大于1，就会发生梯度爆炸；如果小于1，就会发生梯度消失。因为当你把很多小于1的数相乘时，结果会趋向于零。如果你要更新的量变成零，你就无法进行有效的更新。

这就是高层次的直觉理解。由于这不是本课程的重点，我不会深入这些复杂公式的细节。但希望你能理解，对于记住过去信息这件事，RNN 由于其序列特性并不能很好地胜任。

这样理解了吗？

好的，希望接下来的内容会更清楚一些。在此之前，我先回顾一下我们所学的内容。我们的目标是表示文本。首先，我们从表示单词或 token 开始，这就是我们用 Word2Vec 尝试做的事情。我们看到这是利用代理任务学习表示的好方法，但也有一些限制。你们提到的其中一个限制是它不了解上下文，而且词序也不重要。

因此，有另一类方法能够考虑词汇的顺序，但当序列变得很长时，它们在跟踪信息方面遇到困难，这就是梯度消失或长程依赖问题。每当你看到这个术语，基本上就是在指这个问题。

另外我没有提到的一点是，计算速度非常慢。当你想在训练时训练这些模型，为了预测某个词，你基本上需要计算之前所有的隐藏状态。所以当序列变得很长时，计算就会花费很长时间。

由于所有这些原因，由于模型在记住过去信息方面有困难，人们尝试在当前预测和过去信息之间建立更直接的连接。这就是注意力机制背后的思想。

注意力机制要做的是在我们试图预测的内容和过去的信息之间建立直接链接。

在这个例子中，假设我要将一个英语句子翻译成法语。这里输入句子已经给出，我正在计算隐藏状态，逐词处理。这是我传统的 RNN。

### (1:07:08 - 1:14:15) 注意力机制引入
> 注意力解决长程依赖，Transformer 架构设计理念

"A cute teddy bear is reading"（一只可爱的泰迪熊在阅读）。这里我有一个隐藏状态，然后进行解码。

你可以想象，当想要生成翻译的下一个词时，如果我知道我要预测哪个词就太好了。换句话说，如果我能瞥一眼输入文本的某个特定区域就太好了。

注意力机制背后的思想就是在你要预测的内容和之前的内容之间建立直接链接。

这就是注意力机制的理念。它在2014年被引入，目的是解决这些长程依赖问题。

这个概念对于这门课程实际上非常关键，因为我们会看到注意力机制是让大部分功能运作的核心。这实际上是 Transformer 论文所依赖的主要原理。

Transformer 是我们在这门课程中会看到的核心架构，它在2017年的一篇名为"Attention Is All You Need"的论文中被引入。仅从标题你就能看出，作者们想要完全依赖注意力机制。

作者们试图摆脱这种序列处理文本的方式，而是让模型与文本的所有部分同时建立直接连接。这就叫做自注意力机制。他们在翻译任务上尝试了这种方法，发现效果非常好。

回到我们仍在使用的例子："A cute teddy bear is reading"。我们说为了计算 token "teddy bear" 的表示，我们要同时查看序列中所有其他的 token，并通过直接链接进行处理。

回到你之前的问题，这里我们会有一个 "teddy bear" 的表示，它对其所在的上下文是独特的。所以回到你关于 "river bank"（河岸）和 "robbing a bank"（抢银行）的问题，这里的 "bank" 会有不同的表示。

这就是基本思想。这个概念大致理解了吗？

这就是所谓的自注意力机制。

我的时间怎么样？晚了。晚了。好的，很好。所以这就是基本思想。现在我要介绍另一组概念，更多是术语方面的，但这会非常重要。

当你想要用某样东西来表达其他东西时，我们使用查询（query）、键（key）和值（value）这些词，记作 Q、K、V。在这个例子中，我们的目标是找出查询 "teddy bear" 与其他哪些 token 更相似。

这里的问题是，你有一个查询，你想看看哪些其他 token 最相似。所以你要查看所有其他 token，它们基本上由键和值组成。你将查询与键进行比较，来量化你的查询与给定键的相似程度，然后取对应的值。

让我们在这个例子中看看。假设你想用其他所有内容来表达 "teddy bear"。你要做的是取查询 "teddy bear"，将该查询与所有其他键进行比较，看哪个元素最相似，然后对更相似的元素赋予更大的权重，取它们对应的值。

这就是这些概念如何工作的高层次思想。当然，我们会确切地看到它们是如何工作的，但这就是总体思路。

### (1:15:00 - 1:30:00) Part 6

### (1:14:15 - 1:29:34) Transformer 架构
> 编码器-解码器结构、多头自注意力、位置编码详解

意思是你想要计算每个 token 相对于其他 token 的表示。你通过一个叫做注意力层的层来做到这个。它是多头注意力层，但多头只是以不同的方式进行这种计算，让模型能够学习不同的表示或不同的投影。

这里的想法是你要输入你的输入文本，输入文本中的所有 token 都会相互关注。比如，"一只可爱的泰迪熊在读书"，你将基本上将这个文本中所有 token 的表示计算为其他 token 的函数。你将通过编码器来做这件事。

通过多头注意力，然后你有一个前馈层，这只是让模型学习另一种投影。在你的编码过程结束时，你将获得的是输入句子中 token 的丰富表示。

到目前为止一切都好。但现在你的目标实际上是翻译输入句子。所以你要做的是用句子开头 token 开始你的翻译，这是你的第一个 token。你要做的是使用输入句子中的所有表示来弄清楚接下来要预测什么。

这就是我刚才说的交叉注意力层，它是第二个层。你看我不确定你是否看到箭头，但有两个箭头来自编码器，一个箭头来自解码器。有人能告诉我来自解码器的箭头代表什么吗？是查询、键还是值？

是键？好的。查询？好的。思考的方式是你试图问自己输入中哪些词很重要，对吧？基本上你想知道，给定你的查询，输入中哪些元素是重要的。

所以这里这个箭头确实是查询，因为这是你想要弄清楚的东西，而键和值实际上来自编码器，它们基本上来自输入序列。

然后你有另一个注意力层，就是这个。那个层试图弄清楚你正在解码的输出句子的哪些其他 token 对预测下一个 token 有用。

假设你已经开始解码并说出了一些词，为了预测下一个词，你基本上想要弄清楚迄今为止翻译的哪些 token 对预测下一个词有用。

这就是这个注意力层的作用，它被称为掩码的，因为它只查看迄今为止翻译的 token。它不查看未翻译的 token，因为当然它们还没有被翻译。所以在你试图预测的 token 的右侧没有办法做到这一点。

很好。在非常高的层次上，你有这个注意力层，它存在于编码器中，也存在于解码器中，但它有几个用例。所以这里的注意力层旨在从输入句子计算嵌入，作为它们自身的函数。

然后来自解码器的那些。所以第一个，掩码自注意力层，旨在将某些东西表达为迄今为止已解码的一切的函数。第二个，交叉注意力层，试图将事物表达为在输入中看到的东西的函数。

因为你与不同的 token 有直接连接，你没有这种顺序感，对吧？因为在 RNN 中，你基本上是一次一个地表达事物，所以你对词序有一些感觉，但在这里你没有，因为它就像直接连接一样。

这就是为什么你有位置编码，它们是为了告知单词在序列中的位置。我们今天不会深入讨论这个，但我只是想指出这一点。

在非常高的层次上，我们将在详细的例子中看到这一点。为了将句子从源语言翻译到目标语言，我们首先要对文本进行标记化。你知道，将其分成任意单位。我们将为这些 token 学习嵌入。这就是输入嵌入的作用。

然后我们必须添加一些关于位置的编码。我们今天不会讨论它，但知道这点很好。然后我们通过编码器。编码器试图弄清楚如何将事物表达为输入中其他事物的函数。它在多头注意力层中这样做，然后它通过一个前馈神经网络，这只是一种投影向量的方式，让模型有更多的自由度来学习事物。

一旦你有了来自输入的这些表示，你就开始翻译。

你从 BOS token 开始。你试图做的是弄清楚下一个词是什么。你会看，好的，迄今为止翻译的哪些词对翻译有用。这就是掩码多头注意力层的作用。然后你有另一个注意力层，它是关于将事物表达为输入中的东西的函数，这就是那里的交叉注意力层。

然后你有一个前馈神经网络，再次给出更多的自由度。最终，你有一个向量，然后通过 softmax，这只是让你猜测下一个词是什么的方法。

所以你会有一个词汇量大小的向量，你将使用这些值来确定你的下一个词是什么。

很简单，对吧？有什么问题吗？

好的，这是一个很好的问题。问题是，头是什么意思？

我想我讲得太快了。我有点忽略了那部分。但是当你做注意力自注意力计算时，你基本上让查询与键交互，然后取相应的值。但没有什么能阻止你多次这样做。

所以术语"头"是指你用来获得查询、键和值的投影矩阵。当你有多个头时，你所做的是让你的模型学习不同的投影。所以这基本上是你的模型学习向量之间不同关联的额外自由度。所以这是个很好的问题。通常它会用小写 h 表示头的数量，这就是对应的内容。

这回答了你的问题吗？

很好。

好的，我们有很多要讨论的，但我确实为此准备了一张幻灯片。所以，这就是你提到的多头。我们基本上是并行运行自注意力计算多次，同样使用模型学习的不同投影矩阵。

如果你有计算机视觉背景，这类似于在卷积中有多个滤波器。这是同样的想法，但在这里有所不同。

很好的问题。问题是投影是否不同？我们通常不约束事物。我们只是让模型学习，但在实践中它倾向于学习看同一件事的不同方式。所以是的，通常没有约束。当然你有论文深入研究如果你改变这个会怎么样，但通常你没有任何约束。

### (1:30:00 - End) Part 7

### (1:29:34 - 1:41:45) 端到端实例
> 完整演示机器翻译的标记化、编码、解码全流程

如前所述，我们可以使用任意分解方式将其分解为 Token。然后正如有人提到的，你需要有某种方式来指示序列的开始和结束。这通常通过 BOS 和 EOS Token 来实现。

现在让我们关注每个 Token 表示的组成。你有学习到的嵌入，然后如前所述，为了了解单词（应该说是 Token）作为序列一部分的位置，你需要添加位置信息，以位置嵌入的形式。原始论文使用正弦和余弦的约定，将其加性地添加到表示中。这就像元素级的加法。

很好。现在你有了 Token 的位置感知嵌入，对每个 Token 重复这个过程。你可以看到所有这些嵌入以矩阵的格式存在，大小为 D_model（嵌入的大小），另一个维度是序列的长度，通常为 n。

到目前为止一切都说得通。对输入有任何问题吗？

很好。现在我们将把这个表示发送到编码器。如 Ashin 所说，你有自注意力的概念，执行自注意力的方式是取这个输入并将其投影到三个空间。将其投影到空间 W_Q，得到查询。将相同的嵌入投影到空间 W_K，得到键。对值也做同样的操作，得到你的值。W_Q、W_K 和 W_V 是由模型学习的，它们基本上是投影矩阵。

现在考虑到所有这些，你可以应用 Ashin 提到的自注意力公式，即 softmax(QK^T/√d_k) × V，这会从所有这些中给出另一个矩阵。

现在让我们暂停一下，看看这个计算在实践中是如何完成的，以及每一步意味着什么。

让我们看 Q。当你计算 Q 时，基本上是将嵌入投影到那个空间。你得到什么？你得到一个矩阵，其中每一行代表一个给定的查询。

当你说 K 转置时，它基本上是相同类型的矩阵但转置了，其中每一列代表每个 Token 的键表示。

现在让我们通过矩阵乘法将它们混合在一起。当你将每个相乘时，你会看到每一行代表查询在每个键上的投影，这样当你进行矩阵乘法并对所有这些取 softmax 时，你会得到每个查询的查询在键上投影的概率分布。每一行都会有这个。

我不知道是否有人问了关于为什么要按 √d_k 缩放的问题。它也可以是 d_q，因为矩阵乘法（这里的点积）强制 d_q 等于 d_k 的事实，基本上你看到的是这些点积随着键和查询的维度增长也会趋于增长。所以你想要标准化这个点积，这就是为什么要除以键维度的平方根。

很好。然后现在你有了所有这些的 softmax，然后你与矩阵 V 相乘，这就是我看到的解释为查询投影到键的空间，然后乘以相应的值。所以值是我们投影到的相应键的表示。所以你最终得到每个查询的值的加权和。

这到目前为止有意义吗？

太好了。有人问，多头是什么？你说得对。不只是做一次。实际上是做 h 次，你得到的是所有这些都是并行完成的，最后你得到每个这样的矩阵，并按列将它们连接起来。在这个末尾，你有另一个投影矩阵，称为 W_O，它将所有这些投影回嵌入的原始维度。


---

*生成时间: 2026-01-03 06:00:14*
*由 YouTube Monitor & Translator (Claude CLI) 生成*